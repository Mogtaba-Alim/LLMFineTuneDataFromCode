{
  "repo": "research_papers",
  "file": "Drug_sensitivity_prediction_from_cell_line-based_pharmacogenomics_data:_guidelines_for_developing_machine_learning_models.pdf",
  "language": "research_paper",
  "content": "1Briefings in Bioinformatics 22(6),  2021,  114 https, //doi.org/10.1093/bib/bbab294 Review Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines fordeveloping machine learning models Hossein Sharifi-Noghabi , Soheil Jahangiri-Tazehkand,  Petr Smirnov,  Casey Hon,  Anthony Mammoliti,  Sisira Kadambat Nair, Arvind Singh Mer,  Martin Ester and Benjamin Haibe-Kains Corresponding authors,  Martin Ester, 9971 Applied Science Building,  Simon Fraser University,  8888 University Drive, Burnaby BC Canada V5A1S6., Tel+1 778-782-4277,  E-mail,  ester@sfu.ca,  Benjamin Haibe-Kains,  Princess Margaret Cancer Centre, University Health Network,  610 University Ave,  Toronto,  ON M5G 2C1,  Canada., Tel +1 416 581 8626,  E-mail, bhaibeka@uhnresearch.ca Abstract The goal of precision oncology is to tailor treatment for patients individually using the genomic profile of their tumors., Pharmacogenomics datasets such as cancer cell lines are among the most valuable resources for drug sensitivity prediction, a crucial task of precision oncology., Machine learning methods have been employed to predict drug sensitivity based on themultiple omics data available for large panels of cancer cell lines., However there are no comprehensive guidelines on how to properly train and validate such machine learning models for drug sensitivity prediction., In this paper we introduce a set of guidelines for different aspects of training gene expression-based predictors using cell line datasets., These guidelinesprovide extensive analysis of the generalization of drug sensitivity predictors and challenge many current practices in the community including the choice of training dataset and measure of drug sensitivity., The application of these guidelines in future studies will enable the development of more robust preclinical biomarkers., Key words pharmacogenomics,  drug response prediction, machine learning Hossein Sharifi-Noghabi is a PhD candidate in computer science at Simon Fraser University working on transfer learning and pharmacogenomics., He obtained BEng in Information Technology and MSc in Artificial Intelligence. Soheil Jahangiri-Tazehkand is a postdoctoral researcher at the Princess Margaret Cancer Centre. He obtained his PhD in bioinformatics from the Shahid Beheshti University, Tehran, Iran. Petr Smirnov is a PhD candidate in Medical Biophysics at the University of Toronto. Smirnov received HBSc from the University of Toronto with a specialist in Mathematics and Physics from the University of Toronto.Casey Hon is an undergraduate student in Bioinformatics and Computational Biology at the University of Toronto., Anthony Mammoliti is a MSc candidate in medical biophysics at the University of Toronto working on biomedical platform development and pharmacogenomics., He obtained BSc in Biology and PgDip in Bioinformatics. Sisira Kadambat Nair is a research analyst at University Health Network working on pharmacogenomics bioconductor package development and data curation., She is a postgraduate in Biotechnology.Arvind Singh Mer is a postdoctoral researcher at the Princess Margaret Cancer Centre., Dr Mer has completed PhD in bioinformatics from the Max Delbruck Center for Molecular Medicine Berlin,  Germany., Martin Ester is a professor at the School of Computing Science of Simon Fraser University Canada and senior research scientist at the Vancouver Prostate Center., Ester received PhD in Computer Science from ETH Zurich, Switzerland. Benjamin Haibe-Kains is a senior scientist at the Princess Margaret Cancer Centre and associate professor at the departments of Medical Biophysics and Computer Science of the University of Toronto, Canada., He is also a consultant to Code Ocean. Haibe-Kains received PhD in Computer Science from the Universite Libre de Bruxelles, Belgium. Submitted: 12 April 2021; Received (in revised form): 29 June 2021  The Author(s) 2021. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 2 Sharifi-Noghabi et al. Introduction Cancer is a complex genetic disease. Because of the hetero- geneous nature of tumors, the treatment of cancer is very challenging. Precision oncology aims to tailor the therapies according to the genomic profile of the tumor. Pharmacoge-nomics a crucial component of precision oncology, promisesto utilize the genomic landscape of each individual patient to find the most effective treatment options [ 13]., However it still has limited clinical utility [ 4], and the availability of clinical pharmacogenomics datasets is limited by a lack of public access and small size, both in terms of patient cohorts and investigated therapies for the few publicly available datasets., As a resultresources such as cancer cell lines [ 511],  patient-derived xenografts (PDX) [ 12, 13] or organoids [ 14] are being employed in pharmacogenomics to decipher drug sensitivity prediction.Although these preclinical resources do not fully recapitulate the inter- and intra-tumor heterogeneity of cancer, they act as proxies for patient tumors and provide larger dataset, usuallyscreened with hundreds or thousands of drugs separately or in combination along with multi-omics characterization [ 15]., Because of the complexity of generating pharmacogenomics datasets discrepancies can even exist across cell line datasets[11, 1622]., However recent efforts such as the PharmacoDB project (pharmacodb.ca) [ 15], the ORCESTRA platform (orces- tra.ca) [ 23] and CellMinerCDB [ 24] aimed at standardizing, and integrating different preclinical pharmacogenomics datasets to improve downstream machine learning modeling., The data-rich nature of preclinical pharmacogenomics datasets has paved theway for the development of machine learning approaches to predict drug sensitivity in vitro and in vivo [2527]., These compu- tational approaches range from simple linear regression models[28 29] Lasso [ 30] and Elastic Net [ 31]t oR a n d o mF o r e s t[ 32],  kernel-based models [ 3336], highly non-linear models based on Deep Neural Networks [ 3744],  and most recently, reinforcement learning [ 45],  few-shot learning [ 46] and multitask learning [ 47]., These methods often take gene expression as input and predict the area above/under the doseresponse curve (AAC/AUC) or half-maximal inhibitory concentration (IC50), the concentrationof the drug that reduces the viability by 50%., Although machine learning for pharmacogenomics is a promising direction [ 25] existing guidelines are based on a single pharmacogenomics dataset [ 48] or based on bench- marking different methods without considering technical differences between molecular profiles or drug screeningassays across different datasets [ 26 ]., We believe that there is a need for comprehensive guidelines based on multiple uniformly processed datasets on how to properly train andevaluate drug sensitivity predictors., In this study we conducta systematic and comprehensive analysis based on RNA-seq data as the input (gene expression-based models) and different measures of drug sensitivity such as AAC and IC50 as theoutput., We employ univariable modeling (using prospective biomarkers) and multivariable modeling (using state-of-the- art machine learning methods) to investigate generalization indrug sensitivity prediction., We consider two common machine learning paradigms: within-domain analysis and cross-domain analysis. In within-domain analysis models are trained andtested on the same dataset via cross-validation which means train and test data are from the same distribution., In cross- domain analysis models are trained and tested on different cellline datasets to investigate generalization capability., We alsoexamine the effect of an analysis choice first proposed by [ 5] to separate the data for cell lines originating from hematopoieticcancers and solid tumors on the ability to learn predictors of drug sensitivity., As a result of this study we provide guidelines,  which we refer to as PGx guidelines ( Figure 1 ), on the following questions,  1., Which dataset(s) and measure(s) of drug sensitivity are best for training predictors? 2. How much does the performance of pharmacogenomics methods change when moving from within-domain anal- ysis to cross-domain analysis?, 3. What is the impact of non-solid tumors on the performance of drug sensitivity predictors? We focused on these questions based on what we consider the most urgent challenges that the field is currently facing., (i) Obtaining integrated and standardized data for cross-domain analysis. (ii) Employing datasets/measures that offer more con-sistency for training predictors. (iii) Compatibility between dif-ferent datasets comparing the performance using multiple met- rics and multiple methods., There are existing studies that cover comparison of different methods [ 2633], omics data types [ 33],  different unintegrated datasets [ 26], different adjusted and unadjusted measures of drug sensitivity [ 49], or different representations of input omics data [ 33]., But we noticed a gap with respect to generalization capability between these studies and formulated our questions to bridge this gap by employed integrated and standardized dataand showing a path that starts with simple (univariable based on one gene), then becomes more complex (within-domain multi- variable analysis) and eventually becomes cross-domain multi-variable analysis., We argue that it is necessary to evaluate the generalization of cell line-based predictors first on cell line datasets before employing them on PDX or patient data, and therefore we focuson cell line datasets in this study., We believe that the PGx guidelines will lead to the development of more accurate and more generalizable machine learning models for drug sensitivityprediction from pharmacogenomics data and will contribute toward the goal of extending the benefits of precision oncology to a wider range of patients., Methods Drug sensitivity metrics The datasets analyzed in this study combine molecular profilingof cancer cell lines with high throughput screening for drug sen-sitivity., For each drug-cell pair investigated in a dataset cell via-bility at several increasing doses of the drug was measured and compared to an untreated control, to obtain % viability values., To learn predictors of drug response it is desirable to obtain a singlenumber summarizing a particular cell lines sensitivity to a drug treatment (which can then be used as a label in fitting predictive models from the molecular features)., We study two differentsummary measures the AAC and the half-maximal inhibitory concentration (IC50)., Both of these measures are derived by first fitting a Hill Curve model to the doseresponse data. Toensure consistency in the inference method we fit 3 parameter Hill Curve to all the datasets, using the logLogisticRegression function in the PharmacoGx R package,  as described previously[17, 50]., The AAC is then the AAC integrated from the lowest to highest measured concentration, normalized to the concen- tration range., The IC50 is the concentration at which the curve crosses 50% viability. Some curves estimated in the data nevercross this 50% threshold and therefore the IC50 does not exist Drug sensitivity prediction from cell line-based pharmacogenomics data 3 Figure 1., Schematic overview of the PGx guidelines. ( A) The raw pharmacogenomics datasets are obtained from the ORCESTRA platform. ( B) The molecular (RNA-seq) and pharmacological profiles (area above doseresponse curveAAC) are obtained for each dataset via the PharmacoGx package., Finally ( C) univariable modeling based on prospective biomarkers from the literature is performed via the PharmacoGx package, and multivariable modeling using protein coding genes and fe ature selection is performed via different packages., for many experiments where the AAC can be calculated. In this paper both these values were calculated using methodsimplemented in the PharmacoGx package [ 50]., Datasets We employed the following pan-cancer datasets ( Table 1 ) The Cancer Therapeutics Response Portal (CTRPv2) [ 5, 6] The Genentech Cell Line Screening Initiative (gCSI) [ 10, 11] The Genomics of Drug Sensitivity in Cancer (GDSCv1 and GDSCv2) [ 7, 8] We obtained these datasets in the format of PharmacoSet (PSet) that is an R-based data structure that aids in reproducibleresearch for drug sensitivity prediction., PSets are obtained via the ORCESTRA platform (orcestra.ca) [ 23]. The molecular profiles (RNA-seq) were preprocessed via Kallisto 0.46.1 [ 51]u s i n gG E N - CODE v33 transcriptome as the reference and the pharmacolog- ical profiles (AAC and IC50) were preprocessed and recomputedvia PharmacoGx package [ 50]., In this paper we focused on 11 drugs in common between these datasets including,  Borte-zomib, Entinostat,  Sirolimus,  Docetaxel,  Gemcitabine,  Crizotinib, Lapatinib,  Vorinostat,  Erlotinib, Paclitaxel and Pictilisib., These datasets have missing values for different samples and given a specific drug the number of available cell lines for train-ing/test can change ( Table S1 ),  moreover, they also have different number of doses, replicates and the negative control used for normalization ( Table S2 )., These 11 drugs are important enough to be studied in three different large-scale pharmacogenomics datasets, and also they cover a wide range of drugs includ- ing chemotherapy agents,  targeted therapeutics, FDA approveddrugs and experimental drugs ( Table S1 )., It is important to note that the data we employed throughout this paper may be slightly different from the data accompanying the published studiesbecause we obtained the data from the ORCESTRA platform, which hosts the integrated and standardized versions of these datasets, and because the datasets may have been updated by the study groups since their original publications., 4 Sharifi-Noghabi et al. Table 1. Characteristics of the studied datasets CTRPv2 GDSCv2 GDSCv1 gCSI # drugs 544 190 343 16 # cell lines 821 328 427 334# tissue types 25 27 28 22 # genes (# protein coding) 60 662 (19 957) 60 662 (19 957) 60 662 (19 957) 60 662 (19 957) Gene expression assay RNA-seq RNA-seq RNA-seq RNA-seq Sensitivity assay CellTiter Glo CellTiter Glo Syto60 CellTiter GloUsage Training Test Training Test State-of-the-art in preclinical pharmacogenomics We categorized the state-of-the-art predictors of drug sensitiv- ity based on their input, output and the pharmacogenomics datasets that they used for training and test ( Figure 2 )., Gene expression was the most common input data type to predict drug sensitivity as it was determined to be the most effective data type in multiple studies [ 8, 26, 31, 33]., However some studies based on multi-omics data also demonstrated that adding otheromics data types can improve the prediction performance [ 26, 40]., For drug sensitivity, IC50 was the most common measure used. The cross-domain training approach was more commoncompared to the within-domain approach. Moreover, the major- ity of these methods were trained on GDSCv1 gene expression data. We also observed that incorporating drug structure such asthe SMILES representation of the drug molecule,  is an emerging trend in the field., Because the goal of this study is investigat- ing generalization in gene expression cell line-based predic-tors, we did not provide detailed descriptions of drug struc- ture,  interaction,  adverse reaction, the type of clinical or PDX datasets that existing methods have employed and illustrated allof them under broad categories of drugs, patients and PDX, respectively., Univariable and multivariable analysis To study the impact of model complexity on the performanceand generalization of drug sensitivity predictors, we investigate a wide range of modeling approaches ranging from univariable modeling based on prospective biomarkers to highly complexand multivariable approaches such as Deep Neural Networks., The univariable analysis consists of retrieving estimates for the association between previously studied prospectivebiomarkers and AAC or IC50 as measures of drug sensitivity.In this study, we focused on the prospective biomarkers of 11 drugs in common between the studied datasets as molecular features., A total of 35 unique prospective biomarkers wereretrieved from literature for eight drugs (out of 11) and used in the analysis ( Table S3 )., The majority of these prospective biomarkers were based on gene expression but some of themwere also based on mutation, copy number aberration and gene fusion., Because the pharmacological datasets store genes as Ensembl gene ID the biomarkers were mapped to thevariant identifier using the Uniprot Retrieve/ID mapping tool (Table S3 ) We explored four preprocessing approaches for IC50 includ- ing, using the raw IC50 values,  log transformation of the values, truncating the values based on the concentration ranges of each study and a combination of both., IC50 values can span several orders of magnitude, are bounded below by 0 and areoften skewed. Log transformation tends to reduce the influenceof outliers and brings the distribution of IC50 values closer to normal., Truncating based on predefined concentration rangesalso reduces outliers and reduces the influence of IC50 val-ues that are extrapolated past the measured concentrations., These extrapolated values tend to be very sensitive to slight errors in estimation of the Hill Curve arising from noise in themeasurements., AAC values were left unchanged. Then we used the PharmacoGx drugSensitivitySig function to compute estimates of the association between prospectivebiomarkers and drug sensitivity., For each measured gene this association is independently modeled using a linear regres- sion model Y i=0+Gi+/summationtext t>1tTit+/epsilon1i.Yidenotes the measured drug sensitivity for sample i, Gidenotes the mea- sured gene expression for sample i, Titis an indicator variable for sample ibelonging to tissue of origin t, /epsilon1iis a random error term which is assumed to be normally distributed, andthes are the estimated regression coefficients [ 50]., The first (alphabetically) tissue was taken as the reference and excluded from the summation. As such  0can be interpreted as the effect of this reference tissue on Y, whereas each tis the difference in effect of a tissue tfrom this reference tissue., Y and Gare scaled to have mean 0 and standard deviation of 1 prior to fitting the model so that s returned are standardized coefficients estimating the strength of the gene-drug associa- tion., The standardization facilitates comparison across genesand drugs which may have very different scales and ranges of measured values., Note that this differs from a partial correla- tion in that scaling is done before adjusting for the covariates(tissues)., The multivariable analysis consists of making predictions of the drug sensitivity measures (AAC or IC50) given the level of expression of input gene features., Unlike univariable analysisthat considers each biomarker at a time multivariable analysis considers all of the input genes together., The goal of multi- variable modeling is to learn a mapping function Y=f (X) parametrized by one or more parameters that maps the input gene expression matrix XNMto the drug sensitivity values YN1, where Nis the number of samples,  and Mis the number of input features., For all models considered in this paper we employed the mean squared error as the loss function to optimize as fol- lows, LMSE=/bardblYf(X)/bardbl2 2+(),  where (.), denotes regularization. The regularization used was ()=/bardbl/bardbl2 2for Ridge Regression ()=[(1)/bardbl/bardbl2 2+/bardbl/bardbl1]for Elastic Net, ()=/bardbl/bardbl2 2for the Deep Neural Networks, and no regularization was applied for the Random Forest models ( andare hyperparameters controlling the strength of the regularization)., In addition to regularizing the norm of the parameters the Deep Neural Networks were fit to the data with dropout and early stopping., More details ontraining and hyper-parameters of the final models correspond- ing to each method are provided in the supplementary material (Table S5 )., From the mapping function point of view ( f (X)) Ridge Drug sensitivity prediction from cell line-based pharmacogenomics data 5 Figure 2., Published studies for drug sensitivity prediction. Gene expression is the most common molecular profile and IC50 is the most common pharmacological profile, but AAC/AUC has become more common in recent studies., GDSCv1 (originally named CGP) is the most common training dataset and the use of drug inf ormation for training has been more frequent in recent years., The cross-domain training approach denoted by c was more common compared to the within-domain a pproach denoted by w. When a method employs both of them, we denote it by cw., Regression and Elastic Net are based on linear transformations of the input and Random Forest and Deep Neural Networks are based on non-linear transformations of the input., RandomForest learns the mapping function via an ensemble of decisiontrees and Deep Neural Networks learns this function via layer- wise transformations with non-linear activation functions., Within-domain and cross-domain analysis To study the impact of data discrepancy on generalizationof drug sensitivity predictors, we investigate two commonapproaches of within-domain and cross-domain., In within- domain analysis the goal is to train and test models on the same dataset via cross-validation., The hypothesis is that if amodel trained to predict sensitivity for a given drug cannot makeaccurate predictions for the same dataset (on the test splits), it is very unlikely that it generalizes to other datasets for the same drug., In cross-domain analysis, the goal is to train and testmodels on different datasets. The hypothesis is that models that demonstrate high performance in the within-domain should have better performance in cross-domain and models thatperform poorly in within-domain should also perform poorly in 6 Sharifi-Noghabi et al., cross-domain analysis. Intuitively if there is enough predictive information in the training data for the given drug, the model should have a higher chance of generalizing to other datasets for the same drug (if the other datasets also have adequatepredictive information)., Experimental design We designed our experiments to justify the choice of trainingdataset (the input) and the measure of drug sensitivity (theoutput) as well as studying generalization of different models in within-domain and cross-domain analysis., PGx guideline experimental questions IC50 is the most common measure of the drug sensitivity for machine learning ( Figure 2 ), however,  it suffers from known limitations., By definition the IC50 does not exist for anyexperiment where the maximum inhibition of growth is notat least 50%., Furthermore IC50 estimation is unstable when there is not at least 1 point measured on each plateau of the curve [ 52], and the common technique to overcome this limitation, by setting IC50s outside the measured range to the maximal tested concentration, effectively creates a right- censored measurement and loses all differences in sensitivitybetween such experiments., Our hypothesis is that models trained to predict AAC should generalize better than those trained to predict IC50., To answer the first PGx Guideline question on the best mea- sure of drug sensitivity we investigated a wide range of modeling approaches ranging from simple univariable models based onprospective biomarkers of each drug to more complex multi-variable models based on Ridge Regression, Elastic Net,  Random Forest and Deep Neural Networks., We also compared CTRPv2 and GDSCv1 to determine which dataset is a better trainingdataset to build drug sensitivity predictors., We picked GDSCv1 as the competitor because it is the most common training dataset (Figure 2 ). GDSCv1 utilizes a different drug screening assay com- pared to the other datasets and for the majority of the drugs,  it has a smaller sample size [ 23]., Our hypothesis is that models trained on CTRPv2 are more generalizable because it utilizes thesame assay as other datasets and also has a relatively larger sample size., To answer the second question on generalization perfor- mance we utilized the state-of-the-art cell line datasets (seeDatasets section) in within-domain and cross-domain analy- sis., For within-domain analysis we used 10-fold nested cross- validation on CTRPv2, the largest dataset in our collection9 folds for train and validation and the 10th fold for testing., For cross-domain analysis we trained models on the CTRPv2 and tested them on the other cell line datasets (GDSCv2 andgCSI)., To answer the last question we investigated the associ- ation between tissue type and model predictions when themodel was trained with all available tissue types (solid and non-solid tissues) and when it was trained only on solid tissue types., Evaluation We employed different metrics in our analyses and experiments of the PGx guidelines including the Peason correlation, Spear- man correlation,  root mean squared error (RMSE), Jaccard indexand standardized regression coefficients., In all of the analyses the Baseline performance indicates the correlation of cell lines in common between train and test dataset of that particular analysis., To summarize the figures we also reported the aver- agestandard deviation of the Pearson correlation over the 11 drugs in common (only in the main text)., Assessing stability of univariable feature rankings To compare the rankings of univariable associations of gene expression (60 662 genes) with drug response, we investigatedthe intersections between the top-K strongest associations (absolute value of standardized coefficient) for a range of K-values across GDSCv2, CTRPv2 and gCSI., We chose thesedatasets because they all shared the same drug responseassay (CellTiter-Glo). We focus on the top-K rankings as weaker associations are more likely to be spurious due to the noise of the experiments, and therefore should not be expected toreproduce across datasets., For each drug the Jaccard index between the three top-K lists was computed at each K. We then investigated two ways of measuring the stability of thetop-K list across all three datasets., We first evaluated the minimum K ( K min) for which the intersection was non-empty which can be interpreted as measuring how many associationsdiscovered in a single dataset would need to be tested across the other two datasets before a single hit is replicated., We also computed/integraltext log(Kmax) log(Kmin)log(Jobs(k)/Jexpected (k))d(log( k)) where Jobs(k)w a s the Jaccard observed for the top-k intersection, and Jexpected (k)is the expected intersection if the rankings of the three lists were unrelated., The integral was estimated numerically on a grid of K values. For this integral Kminwas chosen as the first value where Jobs(k) was non-zero (consistent with above), removing values from the integrand that would otherwise be infinite (and negative)., When comparing values for this integral this can beseen as giving an unfair advantage to list-triplets,  which have a high K min, and therefore it should be evaluated in tandem with our first metric., Implementation details To ensure the reproducibility of this study we provide a detailed description of preprocessing,  training and evaluation., For all of the multivariable experiments gene expression input data were normalized via z-score transformation using the parameters ofthe training dataset., Furthermore to correct for the impact of tissue type, the one-hot encoded representation of it was added as an input feature to the normalized expression data afterremoving non-solid tissue types (except when the goal was to study the impact of non-solid samples) and those tissue types that were not available in the training data (CTRPv2)., We implemented the univariable analysis in R via the Phar- macoGx package (version 2.0.5) [ 50]. The multivariable analyses were implemented in Python using the scikit-learn package (ver-sion 0.23.2)., All of the hyper-parameter tunings were performedvia grid search in nested 10-fold cross-validation. We repeated the within-domain experiments 10 times and fixed the random seed for the cross-domain experiments and performed it once., We implemented the deep neural networks in the Pytorch framework (version 1.4 cpu only) and used 10-fold cross- validation and 100 trials of random search to select the besthyper-parameter settings for each drug., In all of the analyses we employed previously reported values of the hyper-parameters as our initial sets for each method andtuned to select the best setting for each method., More details on Drug sensitivity prediction from cell line-based pharmacogenomics data 7 the considered values and the selected ones are provided in the supplementary material ( Table S5 )., Research reproducibility All the data code and results employed and obtained in this study are publicly available for research reproducibility., Code and supplementary tables/data are available at https://github.com/bhklab/PGx_Guidelines . Data and models are available at https://zenodo.org/reco rd/4642024#.YGCkbK9KiUl . Code Ocean capsule: https://codeocean.com/capsule/7358839/ tree/v1 . Results Models trained to predict AAC outperforms those trained to predict IC50 T wo common summary metrics have been used in the litera- ture for summarizing doseresponse experiments, the IC50 andthe AAC., The IC50 is a measurement of potency whereas the AAC can be interpreted as measuring an average of potency and maximal efficacy, or as a measure of the mean viabilityacross the concentrations tested., Although the IC50 is easily interpretable and is an absolute metric (unlike the AAC which depends on the concentration range tested), the IC50 has sometechnical drawbacks which may make it difficult to use in train- ing machine learning models., AAC/AUC is a normalized value between 0 and 1 but IC50 (the concentration) is not necessarilybounded and can be very small (close to zero) when samples are highly sensitive to a given drug or very large when they are highly resistant to a given drug., These issues make prepro-cessing of IC50 critical. Therefore we investigated both methodsto preprocess IC50, as one of the key measures of the drug sensitivity in previous studies and then exploited univariable and multivariable analysis to compare these two metrics., Univariable analysis using prospective biomarkers is not conclusive for preprocessing IC50 We employed univariable analysis of the prospective biomarkers on different preprocessing approaches for IC50 including, (i)estimating the associations using the raw IC50, (ii) estimating the associations using the truncated IC50, (iii) estimating the associ- ation using log transformed IC50 and (iv) estimating the associa-tion using log truncated IC50 values., We presented the standard- ized regression coefficients obtained from the univariable anal- ysis for eight drugs that we could obtain prospective biomarkersand highlight one biomarker for each drug ( Figure 3A , Table S6)., Across three datasets (CTRPv2 GDSCv2 and gCSI), we did not observe a clear winner for different ways of preprocessingIC50., This can be due to the fact that some of these biomarkers were based on gene expression data and some others based on mutation ( Table S3 ), and this suggests further investigation., Univariable analysis using prospective biomarkers is not conclusive for AAC We performed the same process of estimating associations for AAC and compared it to different ways of preprocessing IC50.Although for Lapatinib and Erlotinib AAC captures the associa- tions between biomarkers and drug sensitivity more accurately compared to different approaches to preprocessing IC50, thispattern is not visible for other drugs ( Figure 3A , Table S6 )., These results are not conclusive to compare AAC and IC50 (differentways to preprocess it) via the univariable analysis which also suggests further investigation., Univariable cross-domain stability analysis suggests AAC and log-truncated IC50 produce most stable associations with drug response For each gene with quantified expression (60 662 genes) in the CTRPv2, gCSI and GDSCv2 datasets, we computed the strength of association with drug response for the 11 drugs in common across these datasets., We then ranked the associations bymagnitude and computed the Jaccard index for the 3-way intersection of the top K ranked univariable features for a range of Ks between 10 and 10 000 (with steps of 0.1 on a log10scale)., We examined two metrics the first K at which the top-K intersection is non-empty ( Figure S1A ), and the integral of the observed Jaccard adjusted to the Jaccard expected by chance, on a loglog scale ( Figure S1B )., By both metrics AAC produced the most stable or was tied for the most stable rankings of gene expression markers for the majority of the drugs (9/11by both first non-empty K and integrated enrichment overnull)., Log-truncated IC50 similarly outperformed (or was ranked most stable or tied for most stable) the other transformations of IC50 (8/11 drugs by first non-empty K and 7/11 drugs byintegrated enrichment over null)., This suggests that AAC and log-truncated IC50 are better measures for multivariable analyses. Multivariable within-domain analysis confirms that models trained to predict AAC outperforms those of log-truncated IC50 We compared Ridge Regression, Elastic Net and Random Forest when trained on protein coding genes to predict AAC and log- truncated IC50, log IC50,  truncated IC50 and raw IC50 in a within-domain analysis using CTRPv2., The within-domain analysis using Ridge Regression and Elastic Net reconfirmed the stability analysis results thatlog-truncated IC50 outperforms the other approaches to preprocessing IC50 in terms of the studied metrics ( Table S7 )., Interestingly models for Docetaxel, Sirolimus and Paclitaxelfailed because of training to predict very large raw or log IC50values but models for these drugs were successfully trained when using truncated IC50., We observed that AAC achieved higher within-domain performance ( Figure 3B Ridge Regression achieved 0.24 0.17 in AAC versus 0.23 0.14 in IC50, Elastic Net achieved 0.4 0.17 in AAC versus 0.31 0.12 in IC50, Random Forest achieved 0.410.1 in AAC versus 0.33 0.07 in IC50)., These results reconfirm the stability results that AAC is a better metric for drug sensitivity prediction compared to log-truncated IC50.We observed a similar pattern in the Spearman results ( Figure S2) and RMSE ( Table S8 )., In terms of Pearson and Spearman 7 drugs (out of 11) benefited from training to predict AACinstead of log-truncated IC50 in at least two different methods(out of three)., These experimental results also align with the within-domain results in the previous study [ 48]. For simplicity, we refer to log-truncated IC50 as IC50 for the rest of thepaper. Cross-domain analysis decreases generalization perfor- mance. To study the generalization capabilities of drug sensitivity predictors we analyzed them in a cross-domain setting where the models are trained and tested on different cell line datasets.To perform this analysis, first,  we determined the most suitable training dataset., 8 Sharifi-Noghabi et al. Figure 3. (A) Comparison of AAC (red) to different approaches of preprocessing IC50 via univariable analysis tested on selected prospective biomarkers of the s tudied drugs in terms of the standardized coefficients., A single prospective biomarker per drug is shown (generally the marker with the strongest associati on), full results are available in supplementary data., ( B) Mean Pearson correlation (over 10 runs) for different multivariable methods in within-domain analysis trained to predict AAC or log-truncated log-truncated IC50., Multivariable within-domain analysis results indicated that AAC outperforms IC50 on average. Multivariable analysis reveals that models trained on CTRPv2 outperform those of GDSCv1 in generalization As mentioned before, GDSCv1 is the most common training dataset for machine learning in pharmacogenomics., However this dataset utilized the Syto60 assay in contrast to other majorpharmacogenomics datasets that utilized the CellTiter Glo assay.We believe the difference in the drug screening assay influences the generalization capability of models because the Syto60 assay generates noisier drug response estimates [ 11]., To validate this we trained two Ridge Regression models to predict AAC usingprotein coding genes, one trained on CTRPv2 and the other trained on GDSCv1 and then tested both of them on gCSI., We Drug sensitivity prediction from cell line-based pharmacogenomics data 9 Figure 4. Comparison of CTRPv2 and GDSCv1 as training datasets for Ridge Regression models in terms of Pearson correlation in cross-domain analysis to predict AAC on gCSI., For the majority of the drugs models trained on CTRPv2 (yellow) achieved better performance compared to those trained on GDSCv1 (green) even though GDSCv1 has higher baseline correlation (correlation of AAC values between cell lines in common between GDSCv1/CTRPv2 and gCSICTRPv2 baseline in bl ue and GDSCv1 baseline in red)., removed GDSCv2 from this analysis because of the overlap of molecular profiles with GDSCv1. We selected CTRPv2 because itis larger compared to gCSI which makes it naturally a more viable choice for training., We observed that the model trained on CTRPv2 demonstrated better performance in terms of the Pearson correlation com- pared to the model, which was trained on GDSCv1 ( Figure 4 )., To be more specific on average (over 11 drugs), the modeltrained on CTRPv2 achieved the Pearson correlation of 0.4 0.21 (0.390.18 for IC50 Table S9 ), whereas the model trained on GDSCv1 achieved 0.26 0.16 (0.16 0.17 for IC50 Table S9 )., This suggests that agreement between the drug screening assay aswell as sample size play significant roles in cross-domain gen- eralization., We observed a similar pattern in the Spearman correlation ( Figure S3 ) and RMSE ( Table S9 ). It is important to note that unlike the within-domain analysis this analysis is based on one run using the best model (from cross-validation) and not on multiple runs., Multivariable analysis reveals that the performance of models decreases when moving from within-domain to cross-domainanalysis To study the generalization of drug sensitivity predictors, we trained different models on CTRPv2 dataset and tested them of GDSCv2 and gCSI ( Figure 5A )., The cross-domain performance for the majority of the studied drugs is decreased significantly com- pared to the within-domain performance ( Figure 5BD )., Elastic Net performance decreased from 0.4 0.17 (within-domain AAC) to 0.34 021 in GDSCv2 and 0.34 0.21 in gCSI (both in AAC, Figure 5C )., Similarly Random Forest decreased from 0.41 0.1 (within-domain AAC) to 0.33 0.2 in GDSCv2 and 0.35 0.21 in g C S I( b o t hi nA A C , Figure 5D )., Ridge Regression demonstrated a different trend and increased from 0.24 0.17 (within-domainAAC) to 0.33 0.17 in GDSCv2 and 0.4 0.21 in gCSI (both in AAC, Figure 5A )., This was due to some outlier predictions Pear- son correlation is sensitive to outliers and when we looked at the Spearman correlation results, the performance of Ridge Regression also decreased in cross-domain analysis ( Figure S4 compared to Figure S2)., These results suggest that even when the train and test data of a model utilized the same drug screening assay andwere preprocessed similarly, it does not necessarily guarantee generalization., Moreover the within-domain and cross-domain analysis together suggest that making models more compleximproves the performance compared to the univariable analysis.For example, ERBB2 had an estimated association of 0.41 in GDSCv2 and 0.44 in gCSI,  however, Elastic Net achieved 0.61 in GDSCv2 and Ridge Regression achieved 0.6 in gCSI which demon-strates the power of multivariable analysis., Finally the cross- domain analysis using multivariable methods also reconfirmed that AAC is a better metric compared to IC50 ( Table S10 )b e c a u s e datasets are more consistent on AAC (baseline correlations of 0.450.18 in GDSCv2 and 0.43 0.21 in gCSI for AAC in contrast to 0.38 0.27 and 0.42 0.13 in IC50, respectively) and meth- ods are more accurate (for example,  in gCSI, Ridge Regression achieved 0.4 0.21 in AAC versus 0.36 0.18 in IC50, Elastic Net achieved 0.34 0.21 in AAC versus 0.33 0.18 in IC50, DNN achieved 0.35 0.2 in AAC versus 0.32 0.21 in IC50, Random Forest achieved 0.35 0.2 in AAC versus 0.37 0.16 in IC50)., We observed a similar pattern in the Spearman correlation ( Figure S3AD ). We also observed similar patterns in both Pearson and Spearman results when comparing the best performing within- domain model to the best performing cross-domain model for each drug ( Figures 5E and S4E)., Although employing gCSI offers more robust comparison across multiple datasets it also limits the number of drugs that we can study because this dataset is only screened with 16 10 Sharifi-Noghabi et al., Figure 5. Comparison of multivariable methods in terms of Pearson correlation in cross-domain analysis trained on CTRPv2 to predict AAC, tested on GDSCv2 and gCSI ( A)., Comparison of the within-domain performance of Ridge Regression ( B) elastic net ( C) and random forest ( D) to their cross-domain performance in terms of Pearson correlation., Comparison of the baseline correlation the best-obtained performance in within-domain, and the best-obtained performance in cross-domain in terms of Pearson correlation ( E)., Drug sensitivity prediction from cell line-based pharmacogenomics data 11 drugs. To study the cross-domain performance on more drugs we limited our focus to 70 drugs in common between CTRPv2 and GDSCv2., We trained three models using Ridge Regression Elastic Net and Random Forest for each drug using CTRPv2 topredict AAC and IC50 separately and tested the performance in terms of Pearson, Spearman and RMSE on GDSCv2., We removed those drugs that have less than 100 samples for training or 50samples for tests or had a failed model for AAC or IC50 to ensure a fair comparison., We observed that the results are fairly competitive between models trained to predict AAC and those of IC50 when we only focus on one dataset in terms of Pearson and Spearman correlations., However RMSE shows that AAC outperforms IC50which can be due to larger magnitude of IC50 values as opposedto AAC (Table S11)., Non-solid tissue types influence the performance of models The majority of pharmacogenomics datasets are pan-cancer with solid and non-solid tissue types., We studied the molecularand pharmacological profiles of non-solid tissues (hematopoi- etic and lymphoid tissue types) in CTRPv2, GDSCv2 and gCSI., We observed that the sensitivity outcome (AAC) in non-solidsamples is significantly different compared to solid samples and they tend to be more sensitive than solid samples ( Figure S5AC ) which aligns with the previous studies [ 5, 53, 54]., Similarly the non-solid samples also clustered differently compared to solid samples ( Figure S5DF )., These results raise the question of whether including both liquid and solid lines in the training setis beneficial for learning models to predict drug sensitivity., To answer this we trained two Ridge Regression models to predict AAC using protein coding genes as follows, one trained on all samples (solid and non-solid together) in CTRPv2, and theother one trained only on solid samples (non-solid samples were removed) in CTRPv2., We measured the associations between the predictions and the binary status of tissue type (solid versusnon-solid) in GDSCv2 and gCSI using the area under precision- recall curve (AUPR)., The predictions of the model that was trained on all samples demonstrated a very high AUPR comparedto the model that was only trained on solid samples., This sug- gests that by including non-solid samples models predict the tissue type rather than the drug sensitivity itself ( Figure 6 )., To confirm this we trained another Ridge Regression model afterremoving a random subset of solid samples with the same size as the non-solid samples to make sure that the observed result was not because of sample size (we repeated the random selection10 times and reported the average value)., We also reported the Baseline AUPR that indicates the ground truth association between actual AAC and the binary status of tissue type., Weobserved that models that were trained on all samples (including solid and non-solid tissues) and the one with a random subset removed had the highest AUPR in both GDSCv2 and gCSI for themajority of the drugs compared to the model that was trained only on solid samples ( Figure 6 )., This confirms previous results that the difference in molecular profiles and drug sensitivity ofnon-solid samples have a negative impact on the drug sensitivityprediction task, and it is crucial to remove all non-solid tissue types before any machine learning modeling., We also studied the impact of different tissue types on the performance by comparing three scenarios, (i) training a Ridge Regression model on solid and non-solid tissues combined and testing it on solid tissues only, non-solid tissues only and alltissues combined., (ii) training a Ridge Regression model on solid tissues only and testing it on solid tissues only non-solid tissues only and all tissues combined., Finally (iii) training aRidge Regression model on non-solid tissues only and testing it on solid tissues only, non-solid tissues only and all tissues combined., For each analysis we used CTRPv2 as the training dataset to predict AAC and tested the model on GDSCv2 andgCSI and reported the results in terms of Pearson, Spearman and RMSE., For each scenario the dataset with the largest sample size was downsampled to have the same size as the smaller one10 times to control for this factor., We observed that on average (over 10 runs) models trained on non-solid tissues had the best performance when tested on non-solid tissue types and simi-larly, models trained on solid tissues had the best performance when tested on solid tissues., This reconfirms the importance of removing non-solid tissue types from the training data for solidtissues (Table S12)., Discussion In this study we investigated the fundamental challenges of developing machine learning models to predict drug sensitivity from cell line pharmacogenomics data., We named our study PGxguidelines because we believe that the answers to these ques- tions provide actionable guidelines for developing predictors of drug sensitivity., The guidelines show that the performance of machine learn- ing models decreases when moving from within-domain multi- variable modeling to cross-domain multivariable modeling., Thisis particularly important because it shows that models face generalization difficulties when trained and tested on cell line datasets with comparable molecular and pharmacological pro-files., Consequently such models are highly unlikely to gener-alize to clinical samples when they fail to generalize to (more similar) preclinical samples., The PGx guidelines also demonstrate that the AAC is a more suitable measure of drug sensitivity as opposed to the IC50 in terms of Pearson and Spearman correlations, and CTRPv2 is a more suitable training dataset as opposed to GDSCv1 dueto the larger sample size available with RNA sequencing and the difference in the drug screening assay., This is particularly important because employing IC50 and GDSCv1 is currently thetrend in machine learning for drug sensitivity prediction., We also reported RMSE results but we note that unlike Pearson and Spearman, RMSE does not allow comparison across differentdrugs or measures of drug sensitivity, and proper normalizationis required before comparison using this metric., Finally The PGx guidelines demonstrate the necessity of removing non-solid tissue types from the datasets before anymodeling, which is often not considered in training models., This is especially true for post hoc interpretation of feature impor- tance. Our results suggest that models trained on a mixture ofthese two tissue types primarily learn to predict non-solid tumor status, bringing into question whether importance scores will be relevant to the task of drug sensitivity prediction., Our goal was not to provide a comparative studytrain mod- els to achieve the highest possible performancein terms of method, we selected some of the most basic available methodsto focus on the importance of data for drug sensitivity prediction.The reported results can likely be improved by investing more time on hyper-parameter tuning or adopting more complex training schemes or objective functions (particularly for DeepNeural Networks)., However our experiments shed light on some of the current issues with machine learning for drug sensitivity prediction., Although Ridge Regression and Random Forest showed slightly better performance compared to Elastic Net, overall,  these methods showed a competitive performance., We focused 12 Sharifi-Noghabi et al. Figure 6. The association between predictions of a Ridge Regression model trained on CTRPv2 to predict AAC and tissue binary type status of GDSCv2 ( A) and gCSI ( B) in terms of AUPR., Training on cell lines with solid (Red) tissue types had lowest AUPR compared to training on all samples (solid and non-solidpurple) and training on a randomly selected subset with the same size as solid samples (average AUPR over 10 different subsetsgreen)., The results confirmed that removing non-solid samples decreases the association of predictions with tissue type., on Ridge Regression for the majority of the analyses of PGx guidelines because it is less sensitive to the setting of hyper-parameters than other methods, in particular Deep Neural Networks, which have the highest number of hyper-parameters and are more sensitive to the choice of their values., Therefore we included Deep Neural Networks for cross-domain analysisbut did not consider them for other experiments., We also did not perform within-domain analysis for Deep Neural Networks because of the limited sample size of the nested cross-validationfor the high number of parameters of each network and the early stopping regularization that makes the comparison difficult for within-domain analysis., We also utilized feature selection toreduce the input dimensionality (number of genes) and tried focusing only on the L1000 landmark genes [ 55], or focusing on top genes selected by the Minimum RedundancyMaximumRelevance method [ 56]., However, we did not observe any significant difference ( Figure S6 and Table S13 ). Some of the major limitations of this study are as follows we assumed a similar concentration range across the studieddatasets, this can be an important factor in generalization but the problem is that by focusing on the samples with the same range, we will not have enough samples to train modelsespecially given the high dimensionality of the data., We believe this is a very important factor that should be considered when more samples are available [ 49, 57]., Similarly we did not consider multi-omics data because comparable omics data types (mutation, proteomics,  copy number aberration,  etc.), are not available in the studied pharmacogenomics datasets toinvestigate the impact of multi-omics data on cross-domain generalization [ 33, 40]., For PGx guidelines we only focused on monotherapy models and did not investigate multi-outputor multitask learning, or drug combination which can bepromising future direction, similar to incorporating the chemical structure representation of the drugs as input., Also we did not consider the pathway transformation of the genes as inputfeatures and employed genes themselves., Such transformations can improve the prediction performance [ 33]. We studied gene expression-based predictors and our approach can bereplicated for other omics data types when more data are available, and for other gene/feature representations such as pathway representation, which is covered in other studies[33]., Investigating the source of the performance drop occurring when moving to cross-domain analysis is outside the scope ofthe current study., However there have been extensive studies into inconsistencies between drug screening experiments ont h es a m ec e l ll i n e s , a n dt h er e a s o n sw h yt h e ya r i s e[ 11, 16,  21, 58]., These studies have shown that some inconsistency can be explained by differences in experimental protocols, includ-ing,  choices of drug concentration range and number of testedpoints, cell seeding densities,  timepoints for measuring viability,  cell viability assays used, number of technical and biological replicates, growth media and different choices for positive andnegative controls (we summarize a subset of these variables for the studies used in Supplementary Table S2 )[11, 17, 58]., Genetic drift in cell lines and different cell line doubling times betweenlabs has also been shown to affect drug sensitivity measures s u c ha st h eI C 5 0a n dA A C[ 5861]., Finally technical sources of variation,  even with identical (or as close as possible) protocols, both in executing the experiments and subsequent analysis have been shown to lead to considerable variability between labs [ 21]., Importantly, Niepel et al. [21] found that inconsistencies between labs often arise when experimental differences interact withbiologically meaningful variation, meaning that particular cell lines or drugs may be strongly affected by differing experimental decisions, whereas others are not., It is also important to remem-ber that IC50 and AAC are complex phenotypes that can only be measured indirectly through accessing a doseresponse curve and fitting a model to these data., Although in our study we haveremoved variation arising from choices of different curve esti- mation methods, all the sources of variability discussed above affect each measured point on these curves and the error inthe measurement., This means that the model used to calculate IC50 and AAC will unavoidably have different bias and variance characteristics between studies., Overall measuring and analyz-ing drug response data in cell lines is technically complex andgiven that there is no consensus experimental and analytical protocol e, our findings reinforce the importance of checking performance across cell line domains to truly understand therobustness and generalizability of machine learning models in this field., In summary the key takeaways of PGx guidelines are, Models tend to be more accurate when trained to predict AAC rather than trained to predict IC50., However we note that our training datasets for AAC prediction were larger than those for IC50 prediction, which may have impactedthe accuracy of the resulting models., Drug sensitivity prediction from cell line-based pharmacogenomics data 13 If IC50 is used for the modeling, truncating the IC50 val- ues after logarithmic transformation yields more predictive models., Models trained on CTRPv2 to predict AAC tend to be more accurate than those trained on GDSCv1 which is partly due to the smaller size of the GDSCv1 dataset and the use of a different cell viability assay (which considerably reduce theconsistency across datasets) In pan-cancer datasets, our results indicate that it is advis- able to stratify the analysis by tissue types, in particularsolid versus non-solid cancer cell lines., It is important to note that we did not perform a comprehensive comparison of all existing methods and some modeling strategies maybe able to leverage the difference between solid and non-solid cancer cell lines to develop more generalizable models., To evaluate the predictive performance only looking at one metric might not be sufficient and it is more reliable to studymultiple metrics., We suggest a modeling path that starts with simple analysis using one gene (biomarker) then performs multivariablemodeling within one dataset, and eventually performs mul- tivariable modeling across multiple datasets., We note that testing on one cell line dataset only does not even give anadequate measure of model performance on another cell line dataset., It is important to note that our guidelines do not cover best practices to choose specific methods or types of input data., We refer interested readers to previously published literature that has extensively explored these topics [ 26, 33, 48, 49, 62]., Acknowledgments We would like to thank Hossein Asghari Colin C. Collins (Vancouver Prostate Centre), and Ian Smith (Princess Mar-garet Cancer Centre) for their kind support., Funding This work was supported by Natural Sciences and Engi-neering Research Council via a Discovery grant to M.E and #RGPIN-2021-02680 to B.HK and Canadian Institutes of Health Research via #363288 to B.HK., References 1. Garraway LA, Verweij J, Ballman KV. Precision oncology: an overview. J Clin Oncol 2013; 31: 18035. 2. T womey JD, Brahme NN, Zhang B. Drug-biomarker co- development in oncology 20 years and counting. Drug Resist Updat 2017; 30: 4862. 3. Pal SK, Miller MJ, Agarwal N, et al. Clinical cancer advances 2019 annual report on progress against Cancer from theAmerican Society of Clinical Oncology., J Clin Oncol 2019; 37: 83449. 4. Marquart J Chen EY, Prasad V. Estimation of the percentage of US patients with Cancer who benefit from genome-driven oncology., JAMA Oncol 2018; 4: 10938. 5. Basu A, Bodycombe NE, Cheah JH, et al. An interactive resource to identify cancer genetic and lineage dependen- cies targeted by small molecules., Cell2013; 154: 115161. 6. Seashore-Ludlow B, Rees MG, Cheah JH, et al. Harness- ing connectivity in a large-scale small-molecule sensitivity dataset. Cancer Discov 2015; 5: 121023.7. Garnett MJ, Edelman EJ, Heidorn SJ, et al. Systematic iden- tification of genomic markers of drug sensitivity in cancer cells. Nature 2012; 483: 5705. 8. Iorio F, Knijnenburg TA, Vis DJ, et al. A landscape of pharma- cogenomic interactions in Cancer. Cell2016; 166: 74054. 9. Barretina J, Caponigro G, Stransky N, et al. The cancer cell line encyclopedia enables predictive modelling of anticancerdrug sensitivity. Nature 2012; 483: 6037. 10. Klijn C, Durinck S, Stawiski EW, et al. A comprehensive tran- scriptional portrait of human cancer cell lines. Nat Biotechnol 2015; 33: 30612. 11. Haverty PM, Lin E, Tan J, et al. Reproducible pharmacoge- nomic profiling of cancer cell line panels. Nature 2016; 533: 3337. 12. Gao H, Korn JM, Ferretti S, et al. High-throughput screening using patient-derived tumor xenografts to predict clinical trial drug response., Nat Med 2015; 21: 131825. 13. Mer AS, Ba-Alawi W, Smirnov P, et al. Integrative pharma- cogenomics analysis of patient-derived xenografts. Cancer Res2019; 79: 453950. 14. Shi R, Radulovich N, Ng C, et al. Organoid cultures as pre- clinical models of non-small cell lung Cancer. Clin Cancer Res 2020; 26: 116274. 15. Smirnov P, Kofia V, Maru A, et al. PharmacoDB: an integra- tive database for mining in vitro anticancer drug screening studies. Nucleic Acids Res 2018; 46: D9941002. 16. Haibe-Kains B, El-Hachem N, Birkbak NJ, et al. Inconsis- tency in large pharmacogenomic studies. Nature 2013; 504: 38993. 17. Safikhani Z, Smirnov P, Freeman M, et al. Revisiting incon- sistency in large pharmacogenomic studies. F1000Res 2333; 2016 :5 . 18. Geeleher P, Gamazon ER, Seoighe C, et al. Consistency in large pharmacogenomic studies. Nature 2016; 540: E12. 19. Cancer Cell Line Encyclopedia Consortium, Genomics of Drug Sensitivity in Cancer Consortium. Pharmacogenomicagreement between two cancer cell line data sets. Nature 2015; 528: 847. 20. Mpindi JP, Yadav B, Ostling P, et al. Consistency in drug response profiling. Nature 2016; 540: E56. 21. Niepel M, Hafner M, Mills CE, et al. A multi-center study on the reproducibility of drug-response assays in mammalian cell lines. Cell Syst 2019; 9: 3548.e5. 22. Bouhaddou M, DiStefano MS, Riesel EA, et al. Drug response consistency in CCLE and CGP. Nature 2016; 540: E910. 23. Mammoliti A, Smirnov P, Nakano M, et al. ORCESTRA: a plat- form for orchestrating and sharing high-throughput phar- macogenomic analyses. Cold Spring Harbor Laboratory 2020; 2020.09.18.303842. 24. Luna A, Elloumi F, Varma S, et al. CellMiner Cross-Database (CellMinerCDB) version 1.2 exploration of patient-derivedcancer cell line pharmacogenomics., Nucleic Acids Res 2021; 49: D108393. 25. Adam G, Rampa sek L, Safikhani Z, et al. Machine learning approaches to drug response prediction: challenges andrecent progress. NPJ Precis Oncol 2020; 4: 19. 26. Chen J Zhang L. A survey and systematic assessment of computational methods for drug response prediction., Brief Bioinform 2020; 22: 232246. 27. GuvencPaltun B Mamitsuka H, Kaski S. Improving drug response prediction by integrating multiple data sources, matrix factorization,  kernel and network-based approaches., Brief Bioinform 2019; 22: 346359. 14 Sharifi-Noghabi et al. 28. Geeleher P, Cox NJ, Huang RS. Clinical drug response can be predicted using baseline gene expression levels and in vitro drug sensitivity in cell lines., Genome Biol 2014; 15: R47. 29. Geeleher P, Zhang Z, Wang F, et al. Discovering novel phar- macogenomic biomarkers by imputing drug response in cancer patients from large genomics studies., Genome Res 2017; 27: 174351. 3 0 . H u a n gE W ,B h o p eA ,L i mJ , et al. Tissue-guided LASSO for pre- diction of clinical drug response using preclinical samples. PLoS Comput Biol 2020; 16: e1007607. 31. Ding Z, Zu S, Gu J. Evaluating the molecule-based prediction of clinical drug responses in cancer. Bioinformatics 2016; 32: 28915. 32. Riddick G, Song H, Ahn S, et al. Predicting in vitro drug sensitivity using random forests. Bioinformatics 2011; 27: 2204. 33. Costello JC, NCI DREAM Community, Heiser LM, et al. A community effort to assess and improve drug sensitivity prediction algorithms. Nat Biotechnol 2014; 32: 120212. 34. He X, Folkman L, Borgwardt K. Kernelized rank learning for personalized drug recommendation. Bioinformatics 2018; 34: 280816. 35. Mourragui S, Loog M, van de Wiel MA, et al. PRECISE a domain adaptation approach to transfer predictors of drug response from pre-clinical models to tumors., Bioinformatics 2019; 35: i5109. 36. Mourragui S, Loog M, Vis DJ, et al. Predicting clinical drug response from model systems by non-linear subspace-based transfer learning.. bioRxiv 2020. https, //www.biorxiv.org/co ntent/early/2020/11/16/2020.06.29.177139 ., 37. Ding MQ, Chen L, Cooper GF, et al. Precision oncology beyond targeted therapy combining omics data with machine learning matches the majority of cancer cells to effectivetherapeutics., Mol Cancer Res 2018; 16: 26978. 38. Rampa sek L, Hidru D, Smirnov P, et al. Dr.VAE: improving drug response prediction via modeling of drug perturbationeffects. Bioinformatics 2019; 35: 374351. 39. Sakellaropoulos T, Vougas K, Narang S, et al. A deep learning framework for predicting response to therapy in cancer. Cell Rep2019; 29: 33673373.e4. 40. Sharifi-Noghabi H, Zolotareva O, Collins CC, et al. MOLI: multi-omics late integration with deep neural networks for drug response prediction. Bioinformatics 2019; 35: i5019. 41. Sharifi-Noghabi H, Peng S, Zolotareva O, et al. AITL adversar- ial inductive transfer learning with input and output space adaptation for pharmacogenomics., Bioinformatics 2020; 36: i3808. 42. Snow O, Sharifi-Noghabi H, Lu J, et al. BDKANN - biologi- cal domain knowledge-based artificial neural network fordrug response prediction. Cold Spring Harbor Laboratory 2020; 840553 . 43. Kuenzi BM, Park J, Fong SH, et al. Predicting drug response and synergy using a deep learning model of human cancercells. Cancer Cell 2020; 38: 672684.e6. 44. Zhu Y, Brettin T, Evrard YA, et al. Ensemble transfer learning for the prediction of anti-cancer drug response. Sci Rep 2020; 10: 18040.45. Born J, Manica M, Oskooei A, et al. Paccmann rl: designing anticancer drugs from transcriptomic data via reinforce- ment learning. International Conference on Research in Compu- tational Molecular Biology 2020; 2313. 46. Ma J, Fong SH, Luo Y, et al. Few-shot learning creates pre- dictive models of drug response that translate from high- throughput screens to individual patients., Nature Cancer 2021; 2: 233244. 47. Jiang Y, Rensi S, Wang S, et al. DrugOrchestra Jointly pre- dicting drug response,  targets, and side effects via deepmulti-task learning., Cold Spring Harbor Laboratory 2020; 2020 (11):17.385757. 48. Jang INS, Neto EC, Guinney J, et al. Systematic assess- ment of analytical methods for drug sensitivity predic-tion from cancer cell line data., Biocomputing 2013; 2014 : 6374. 49. Xia F, Allen J, Balaprakash P, et al. A cross-study analysis of drug response prediction in cancer cell lines. arXiv [q- bio.QM] 2021. 50. Smirnov P, Safikhani Z, El-Hachem N, et al. PharmacoGx: an R package for analysis of large pharmacogenomic datasets. Bioinformatics 2016; 32: 12446. 51. Bray NL, Pimentel H, Melsted P, et al. Erratum: Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol 2016; 34: 888. 52. Sebaugh JL. Guidelines for accurate EC50/IC50 estimation. Pharm Stat 2011; 10: 12834. 53. Yao F, Tonekaboni SAM, Safikhani Z, et al. Tissue specificity of in vitro drug sensitivity. J Am Med Inform Assoc 2017; 25: 158166. 54. Gerdes H, Casado P, Dokal A, et al. Drug ranking using machine learning systematically predicts the efficacy of anti-cancer drugs. Nat Commun 2021; 12: 1850. 55. Subramanian A, Narayan R, Corsello SM, et al. A next genera- tion connectivity map: L1000 platform and the first 1,000,000 profiles. Cell2017; 171: 14371452.e17. 56. Ding C, Peng H. Minimum redundancy feature selection from microarray gene expression data. J Bioinform Comput Biol 2005; 3: 185205. 57. Pozdeyev N, Yoo M, Mackie R, et al. Integrating heteroge- neous drug sensitivity data from cancer pharmacogenomic studies. Oncotarget 2016; 7: 5161925. 58. Hafner M, Niepel M, Chung M, et al. Growth rate inhibition metrics correct for confounders in measuring sensitivity to cancer drugs. Nat Methods 2016; 13: 5217. 59. Hafner M, Niepel M, Sorger PK. Alternative drug sensitivity metrics improve preclinical cancer pharmacogenomics. Nat Biotechnol 2017; 35: 5002. 60. Ben-David U, Siranosian B, Ha G, et al. Genetic and transcrip- tional evolution alters cancer cell line drug response. Nature 2018; 560: 32530. 61. Quevedo R, Smirnov P, Tkachuk D, et al. Assessment of genetic drift in large pharmacogenomic studies. Cell Syst 2020; 11: 393401.e2. 62. Ali M Aittokallio T. Machine learning and feature selection for drug response prediction in precision oncology applica-tions., Biophys Rev 2019; 11: 319.",
  "qa_pairs": [
    {
      "question": "What is the main objective of the research in this paper?",
      "answer": "The main objective of the research in this paper is to provide comprehensive guidelines for developing machine learning models aimed at predicting drug sensitivity from cell line-based pharmacogenomics data. The authors focus on addressing the challenges associated with training and validating these models, particularly emphasizing the need for standardized datasets and methodologies. They aim to improve the robustness and generalizability of drug sensitivity predictors, ultimately contributing to the advancement of precision oncology by enabling more accurate predictions of treatment responses based on the genomic profiles of tumors."
    },
    {
      "question": "Can you summarize the abstract of the paper?",
      "answer": "The abstract of the paper discusses the importance of precision oncology, which aims to customize cancer treatment based on the genomic profiles of tumors. It highlights the value of pharmacogenomics datasets, particularly cancer cell lines, for predicting drug sensitivity, a key aspect of precision oncology. The authors note that while machine learning techniques have been applied to predict drug sensitivity using various omics data, there is a lack of comprehensive guidelines for training and validating these models. The paper introduces a set of guidelines focused on training gene expression-based predictors using cell line datasets, addressing issues related to the generalization of drug sensitivity predictors and challenging current practices in the field. The authors emphasize that following these guidelines in future studies could lead to the development of more reliable preclinical biomarkers."
    },
    {
      "question": "What are the softwares and computational tools that were used in this paper?",
      "answer": "The research paper mentions several software and computational tools used in the study, including:\n\n1. **PharmacoGx R package**: This package was used for analyzing pharmacogenomics data, specifically for fitting a Hill Curve model to the dose-response data and computing drug sensitivity metrics such as the area above the dose-response curve (AAC) and half-maximal inhibitory concentration (IC50).\n\n2. **Kallisto**: Version 0.46.1 of this software was used for preprocessing RNA-seq data, utilizing the GENCODE v33 transcriptome as the reference.\n\n3. **scikit-learn**: This Python library was employed for multivariable analyses, including various machine learning methods such as Ridge Regression, Elastic Net, and Random Forest.\n\n4. **PyTorch**: The deep learning framework (version 1.4, CPU only) was used for implementing deep neural networks in the analysis.\n\n5. **R**: The univariable analysis was implemented in R using the PharmacoGx package.\n\nThe paper emphasizes the use of these tools to develop guidelines for training and validating machine learning models for drug sensitivity prediction based on pharmacogenomics data."
    },
    {
      "question": "Describe the methodology used in the paper.",
      "answer": "The methodology used in the paper \"Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines for developing machine learning models\" involves a systematic and comprehensive analysis of drug sensitivity prediction using machine learning techniques applied to pharmacogenomics datasets derived from cancer cell lines. Here are the key components of the methodology:\n\n1. **Data Sources**: The study utilizes several pan-cancer datasets, including the Cancer Therapeutics Response Portal (CTRPv2), the Genentech Cell Line Screening Initiative (gCSI), and the Genomics of Drug Sensitivity in Cancer (GDSCv1 and GDSCv2). These datasets combine molecular profiling (RNA-seq data) with high-throughput drug sensitivity screening.\n\n2. **Drug Sensitivity Metrics**: Two primary metrics for drug sensitivity are analyzed: the area above the dose-response curve (AAC) and the half-maximal inhibitory concentration (IC50). The AAC is calculated as the integral of the dose-response curve, while the IC50 is the concentration at which the viability of cells is reduced by 50%. The study employs a three-parameter Hill Curve model to fit the dose-response data.\n\n3. **Modeling Approaches**: The methodology includes both univariable and multivariable modeling approaches:\n   - **Univariable Modeling**: This approach focuses on the association between individual prospective biomarkers (identified from literature) and drug sensitivity measures (AAC or IC50). A total of 35 unique prospective biomarkers were analyzed for eight drugs.\n   - **Multivariable Modeling**: This involves using multiple gene expression features to predict drug sensitivity. Various machine learning methods are employed, including Ridge Regression, Elastic Net, Random Forest, and Deep Neural Networks. The mean squared error is used as the loss function for optimization.\n\n4. **Analysis Paradigms**: The study distinguishes between within-domain analysis (training and testing on the same dataset) and cross-domain analysis (training on one dataset and testing on another). This distinction helps evaluate the generalization capabilities of the models.\n\n5. **Experimental Design**: The experiments are designed to address specific questions regarding the choice of datasets and measures of drug sensitivity, as well as the impact of non-solid tumors on model performance. The authors conduct nested cross-validation for within-domain analysis and evaluate the performance of models across different datasets for cross-domain analysis.\n\n6. **Evaluation Metrics**: Various metrics are employed to assess model performance, including Pearson correlation, Spearman correlation, root mean squared error (RMSE), and Jaccard index. The baseline performance is also reported, indicating the correlation of cell lines common between training and testing datasets.\n\n7. **Feature Stability Analysis**: The study investigates the stability of univariable feature rankings across different datasets by computing the Jaccard index for the top K strongest associations.\n\n8. **Implementation Details**: The analysis is implemented using R and Python, with specific packages such as PharmacoGx for univariable analysis and scikit-learn for multivariable analysis. Hyper-parameter tuning is performed using grid search in nested cross-validation.\n\n9. **Research Reproducibility**: The authors emphasize the importance of reproducibility in their research, providing access to data, code, and supplementary materials for further validation and exploration.\n\nOverall, the methodology is designed to provide comprehensive guidelines for developing robust machine learning models for drug sensitivity prediction, addressing critical challenges in the field of pharmacogenomics and precision oncology."
    },
    {
      "question": "What are the key findings of the paper?",
      "answer": "The key findings of the paper \"Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines for developing machine learning models\" by Sharifi-Noghabi et al. can be summarized as follows:\n\n1. **Guidelines for Model Development**: The authors propose a set of comprehensive guidelines (referred to as PGx guidelines) for training gene expression-based predictors using pharmacogenomics datasets. These guidelines address critical aspects of model training and validation, emphasizing the importance of dataset choice and drug sensitivity measures.\n\n2. **Comparison of Drug Sensitivity Metrics**: The study finds that models trained to predict the area above the dose-response curve (AAC) generally outperform those trained to predict half-maximal inhibitory concentration (IC50). This suggests that AAC may be a more reliable metric for drug sensitivity prediction.\n\n3. **Dataset Selection**: The research indicates that the Cancer Therapeutics Response Portal (CTRPv2) is a more suitable training dataset compared to the Genomics of Drug Sensitivity in Cancer (GDSCv1) due to its larger sample size and more consistent drug screening assay.\n\n4. **Generalization Challenges**: The authors highlight that the performance of machine learning models tends to decrease when moving from within-domain (training and testing on the same dataset) to cross-domain (training on one dataset and testing on another) analysis. This emphasizes the need for models to demonstrate generalization capabilities across different datasets.\n\n5. **Impact of Tissue Types**: The study reveals significant differences in drug sensitivity outcomes between solid and non-solid tissue types. It suggests that including non-solid samples in training datasets can negatively impact the predictive performance of models for solid tumors, advocating for the removal of non-solid tissue types from training data.\n\n6. **Model Complexity and Performance**: The findings indicate that more complex multivariable models generally yield better performance compared to simpler univariable models. However, the authors caution that the choice of input data and preprocessing methods can significantly influence model outcomes.\n\n7. **Recommendations for Future Research**: The paper calls for further investigation into the integration of multi-omics data and the development of more sophisticated modeling approaches, including multitask learning and drug combination studies, to enhance drug sensitivity prediction in precision oncology.\n\nOverall, the paper contributes valuable insights and actionable guidelines for researchers in the field of pharmacogenomics and machine learning, aiming to improve the robustness and applicability of drug sensitivity prediction models."
    },
    {
      "question": "How was the data analyzed in the study?",
      "answer": "The data in the study was analyzed using a combination of univariable and multivariable modeling approaches. Specifically, the authors employed the following methods:\n\n1. **Univariable Modeling**: This approach involved analyzing the association between individual prospective biomarkers (derived from literature) and drug sensitivity measures (such as the area above the dose-response curve (AAC) and half-maximal inhibitory concentration (IC50)). The analysis was conducted using linear regression models, where the gene expression data served as the independent variable and the drug sensitivity measure as the dependent variable.\n\n2. **Multivariable Modeling**: The study also utilized more complex multivariable models, including Ridge Regression, Elastic Net, Random Forest, and Deep Neural Networks. These models aimed to predict drug sensitivity based on multiple gene expression features simultaneously. The mean squared error was used as the loss function for optimization, and various regularization techniques were applied to prevent overfitting.\n\n3. **Within-Domain and Cross-Domain Analysis**: The authors conducted both within-domain analysis (training and testing on the same dataset) and cross-domain analysis (training on one dataset and testing on another) to evaluate the generalization capabilities of the models. They employed nested 10-fold cross-validation for within-domain analysis and tested the models on different cell line datasets for cross-domain analysis.\n\n4. **Evaluation Metrics**: The performance of the models was assessed using various metrics, including Pearson correlation, Spearman correlation, root mean squared error (RMSE), and Jaccard index. These metrics helped to evaluate the predictive accuracy and stability of the models across different datasets and drug sensitivity measures.\n\n5. **Data Preprocessing**: The study involved preprocessing of the pharmacogenomics datasets, including normalization of gene expression data and handling of missing values. The authors also compared different preprocessing approaches for IC50 values to determine their impact on model performance.\n\nOverall, the analysis aimed to provide comprehensive guidelines for developing robust machine learning models for drug sensitivity prediction based on pharmacogenomics data."
    },
    {
      "question": "Was the data in the study pre-processed in anyway? If so how?",
      "answer": "Yes, the data in the study was pre-processed in several ways. Here are the key pre-processing steps mentioned in the paper:\n\n1. **RNA-seq Data Preprocessing**: The molecular profiles (RNA-seq data) were preprocessed using Kallisto (version 0.46.1) with the GENCODE v33 transcriptome as the reference. This step is crucial for obtaining accurate gene expression levels from the raw sequencing data.\n\n2. **Drug Sensitivity Metrics Calculation**: The pharmacological profiles, specifically the area above the dose-response curve (AAC) and half-maximal inhibitory concentration (IC50), were preprocessed and recomputed using the PharmacoGx package. The AAC is calculated by fitting a three-parameter Hill Curve model to the dose-response data, ensuring consistency in the inference method across datasets.\n\n3. **IC50 Value Preprocessing**: The study explored four different preprocessing approaches for IC50 values:\n   - Using raw IC50 values.\n   - Log transformation of the IC50 values to reduce the influence of outliers and bring the distribution closer to normal.\n   - Truncating IC50 values based on the concentration ranges of each study to mitigate the impact of extrapolated values that may be sensitive to measurement noise.\n   - A combination of log transformation and truncation.\n\n4. **Normalization**: For multivariable analyses, gene expression input data were normalized via z-score transformation using the parameters of the training dataset. This normalization helps in standardizing the input features for better model performance.\n\n5. **Tissue Type Encoding**: To account for the impact of tissue type on drug sensitivity predictions, a one-hot encoded representation of tissue types was added as an input feature after removing non-solid tissue types, except when the analysis aimed to study the impact of non-solid samples.\n\nThese preprocessing steps were essential to ensure the robustness and reliability of the machine learning models developed for predicting drug sensitivity based on pharmacogenomics data."
    },
    {
      "question": "What conclusions were drawn in the paper?",
      "answer": "The paper concludes with several key findings and guidelines regarding the development of machine learning models for drug sensitivity prediction from pharmacogenomics data. The main conclusions drawn are:\n\n1. **AAC vs. IC50**: Models trained to predict the area above the dose-response curve (AAC) generally outperform those trained to predict the half-maximal inhibitory concentration (IC50). This suggests that AAC is a more suitable measure for drug sensitivity prediction.\n\n2. **Dataset Selection**: The Cancer Therapeutics Response Portal (CTRPv2) is identified as a more suitable training dataset compared to the Genomics of Drug Sensitivity in Cancer (GDSCv1) due to its larger sample size and the consistency of the drug screening assay used.\n\n3. **Generalization Challenges**: The performance of machine learning models tends to decrease when moving from within-domain (training and testing on the same dataset) to cross-domain (training on one dataset and testing on another) analysis. This indicates that models may struggle to generalize to clinical samples if they do not generalize well to other preclinical datasets.\n\n4. **Impact of Tissue Types**: The presence of non-solid tissue types in training datasets negatively impacts the performance of models predicting drug sensitivity for solid tumors. The guidelines recommend removing non-solid tissue types from the datasets before modeling.\n\n5. **Guidelines for Model Development**: The paper provides actionable guidelines (referred to as PGx guidelines) for developing predictors of drug sensitivity, emphasizing the importance of dataset selection, the choice of drug sensitivity measures, and the need for stratification by tissue type.\n\n6. **Evaluation Metrics**: It is suggested that evaluating predictive performance should involve multiple metrics rather than relying on a single metric, as this provides a more comprehensive assessment of model performance.\n\nOverall, the study highlights the necessity of careful consideration of data sources, preprocessing methods, and model evaluation strategies to improve the robustness and generalizability of drug sensitivity prediction models in precision oncology."
    },
    {
      "question": "Can you provide a summary of the literature review from the paper?",
      "answer": "The literature review in the paper \"Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines for developing machine learning models\" by Sharifi-Noghabi et al. provides a comprehensive overview of the current state of research in pharmacogenomics and machine learning for drug sensitivity prediction. \n\nKey points from the literature review include:\n\n1. **Precision Oncology and Pharmacogenomics**: The review emphasizes the goal of precision oncology, which is to tailor treatments based on the genomic profiles of tumors. Pharmacogenomics datasets, particularly those derived from cancer cell lines, are highlighted as critical resources for predicting drug sensitivity.\n\n2. **Machine Learning Approaches**: Various machine learning methods have been employed to predict drug sensitivity using multi-omics data from cancer cell lines. The review categorizes these methods, which range from simple linear models to complex deep learning architectures, and discusses their applications in predicting metrics such as the area above the dose-response curve (AAC) and half-maximal inhibitory concentration (IC50).\n\n3. **Challenges in Current Practices**: The authors identify a lack of comprehensive guidelines for training and validating machine learning models in this field. They note that existing guidelines often rely on single datasets or do not adequately account for the technical differences between various molecular profiles and drug screening assays.\n\n4. **Data Standardization Efforts**: The review mentions recent initiatives aimed at standardizing and integrating pharmacogenomics datasets, such as PharmacoDB and ORCESTRA, which are intended to enhance the quality and consistency of data used in machine learning modeling.\n\n5. **Generalization Issues**: The authors discuss the importance of evaluating the generalization capabilities of drug sensitivity predictors, particularly when transitioning from within-domain (same dataset) to cross-domain (different datasets) analyses. They highlight that models trained on one dataset may not perform well on another due to discrepancies in data collection and processing.\n\n6. **Need for Comprehensive Guidelines**: The review concludes with a call for comprehensive guidelines that address the urgent challenges in the field, including the selection of appropriate datasets and measures of drug sensitivity, and the necessity of evaluating the generalization of predictors across different datasets.\n\nOverall, the literature review sets the stage for the authors' proposed guidelines, which aim to improve the robustness and accuracy of machine learning models for drug sensitivity prediction in precision oncology."
    },
    {
      "question": "What future research directions do the authors suggest in the paper?",
      "answer": "The authors suggest several future research directions in the paper, including:\n\n1. **Integration of Multi-Omics Data**: The authors highlight the potential for incorporating multi-omics data types (such as mutation, proteomics, and copy number aberration) into drug sensitivity prediction models, which could enhance the accuracy and robustness of predictions.\n\n2. **Exploration of Pathway Transformations**: They recommend investigating the use of pathway transformations of genes as input features, which may improve prediction performance compared to using gene expression data alone.\n\n3. **Investigation of Drug Combination Effects**: The authors suggest that future studies could explore drug combinations and multitask learning approaches, which may provide insights into more effective treatment strategies.\n\n4. **Addressing Generalization Challenges**: They emphasize the need for further research into the sources of performance drops when transitioning from within-domain to cross-domain analyses, particularly focusing on the inconsistencies observed in drug screening experiments across different laboratories.\n\n5. **Development of Comprehensive Guidelines**: The authors call for the establishment of comprehensive guidelines that address best practices for training models, including considerations for dataset selection, preprocessing methods, and evaluation metrics.\n\n6. **Focus on Clinical Relevance**: Future research should aim to bridge the gap between preclinical models and clinical applications, ensuring that findings from cell line studies can be effectively translated to patient care.\n\nThese directions aim to enhance the predictive capabilities of machine learning models in pharmacogenomics and improve the overall utility of precision oncology."
    },
    {
      "question": "What statistical techniques were used in the paper?",
      "answer": "The paper employs several statistical techniques for drug sensitivity prediction from cell line-based pharmacogenomics data. The key statistical methods mentioned include:\n\n1. **Univariable Modeling**: This involves using linear regression models to estimate the association between individual prospective biomarkers and drug sensitivity metrics (AAC or IC50). The model can be represented as:\n   \\[\n   Y_i = \\beta_0 + G_i \\beta + \\sum_{t>1} \\gamma_t T_{it} + \\epsilon_i\n   \\]\n   where \\(Y_i\\) is the drug sensitivity for sample \\(i\\), \\(G_i\\) is the gene expression for sample \\(i\\), and \\(T_{it}\\) is an indicator variable for the tissue of origin.\n\n2. **Multivariable Modeling**: This includes more complex approaches such as Ridge Regression, Elastic Net, Random Forest, and Deep Neural Networks. These models consider multiple input features simultaneously to predict drug sensitivity.\n\n3. **Cross-Validation**: The study uses nested 10-fold cross-validation for model evaluation, particularly in the within-domain analysis where models are trained and tested on the same dataset.\n\n4. **Statistical Metrics for Evaluation**: The paper evaluates model performance using various metrics, including:\n   - Pearson correlation\n   - Spearman correlation\n   - Root Mean Squared Error (RMSE)\n   - Jaccard index\n   - Standardized regression coefficients\n\n5. **Hill Curve Fitting**: The paper mentions fitting a 3-parameter Hill Curve model to doseresponse data to derive drug sensitivity metrics (AAC and IC50).\n\n6. **Regularization Techniques**: In multivariable modeling, regularization methods are applied to prevent overfitting, such as L2 regularization for Ridge Regression and a combination of L1 and L2 for Elastic Net.\n\nThese techniques collectively aim to improve the robustness and generalizability of drug sensitivity predictors in pharmacogenomics."
    },
    {
      "question": "Can you describe the experimental setup in the paper?",
      "answer": "The experimental setup described in the paper involves a systematic and comprehensive analysis of drug sensitivity prediction using pharmacogenomics data from cancer cell lines. Here are the key components of the experimental setup:\n\n1. **Datasets**: The study utilized several pan-cancer datasets, including:\n   - The Cancer Therapeutics Response Portal (CTRPv2)\n   - The Genentech Cell Line Screening Initiative (gCSI)\n   - The Genomics of Drug Sensitivity in Cancer (GDSCv1 and GDSCv2)\n\n   These datasets were obtained in the format of PharmacoSet (PSet), which is an R-based data structure that facilitates reproducible research for drug sensitivity prediction. The datasets included molecular profiling (RNA-seq) and pharmacological profiles (area above the dose-response curve, AAC, and half-maximal inhibitory concentration, IC50).\n\n2. **Drug Sensitivity Metrics**: The study focused on two measures of drug sensitivity:\n   - **AAC**: This is a normalized value representing the area under the dose-response curve.\n   - **IC50**: This is the concentration of the drug that reduces cell viability by 50%. The study noted that IC50 has limitations, such as instability when the maximum inhibition is not at least 50%.\n\n3. **Modeling Approaches**: The authors employed both univariable and multivariable modeling approaches:\n   - **Univariable Modeling**: This involved retrieving estimates for the association between prospective biomarkers (identified from literature) and drug sensitivity measures (AAC or IC50).\n   - **Multivariable Modeling**: This utilized machine learning methods such as Ridge Regression, Elastic Net, Random Forest, and Deep Neural Networks to predict drug sensitivity based on gene expression data.\n\n4. **Analysis Paradigms**: The study distinguished between two common analysis paradigms:\n   - **Within-Domain Analysis**: Models were trained and tested on the same dataset using cross-validation.\n   - **Cross-Domain Analysis**: Models were trained on one dataset and tested on different datasets to evaluate generalization capabilities.\n\n5. **Experimental Design**: The experiments were designed to address specific questions regarding the choice of training datasets and measures of drug sensitivity. The authors conducted 10-fold nested cross-validation for within-domain analysis and trained models on CTRPv2 while testing on GDSCv2 and gCSI for cross-domain analysis.\n\n6. **Evaluation Metrics**: Various metrics were employed to evaluate model performance, including Pearson correlation, Spearman correlation, root mean squared error (RMSE), and Jaccard index.\n\n7. **Preprocessing**: The molecular profiles were preprocessed using Kallisto for RNA-seq data, and drug sensitivity measures were computed using the PharmacoGx package. Different preprocessing approaches for IC50 values were also explored.\n\n8. **Feature Selection**: The study included feature selection to reduce the input dimensionality, focusing on protein-coding genes and prospective biomarkers.\n\nOverall, the experimental setup was comprehensive, involving multiple datasets, various modeling techniques, and a focus on evaluating the generalization of drug sensitivity predictors across different cancer cell line datasets."
    },
    {
      "question": "What are the implications of the research findings?",
      "answer": "The research findings presented in the paper have several important implications for the field of precision oncology and pharmacogenomics:\n\n1. **Guidelines for Model Development**: The introduction of the PGx guidelines provides a structured approach for developing machine learning models aimed at predicting drug sensitivity from pharmacogenomics data. These guidelines emphasize the importance of selecting appropriate datasets and drug sensitivity measures, which can lead to more robust and generalizable models.\n\n2. **Improved Drug Sensitivity Prediction**: The findings suggest that models trained to predict the area above the dose-response curve (AAC) outperform those trained to predict the half-maximal inhibitory concentration (IC50). This indicates that AAC may be a more reliable metric for drug sensitivity prediction, which could enhance the accuracy of treatment recommendations in clinical settings.\n\n3. **Dataset Selection**: The research highlights that the choice of training dataset significantly impacts model performance. Specifically, models trained on the Cancer Therapeutics Response Portal (CTRPv2) dataset demonstrated better generalization capabilities compared to those trained on the Genomics of Drug Sensitivity in Cancer (GDSCv1) dataset. This underscores the necessity of using larger and more consistent datasets for training predictive models.\n\n4. **Impact of Tissue Type**: The study reveals that non-solid tumor samples (e.g., hematopoietic cancers) exhibit different drug sensitivity profiles compared to solid tumors. This finding suggests that models should be stratified by tissue type to improve predictive accuracy and that non-solid samples may need to be excluded from training datasets focused on solid tumors.\n\n5. **Generalization Challenges**: The research emphasizes the challenges of generalization when moving from within-domain (same dataset) to cross-domain (different datasets) analyses. The observed drop in performance when models are applied to different datasets indicates that careful validation is necessary before translating findings from preclinical models to clinical applications.\n\n6. **Recommendations for Future Research**: The authors advocate for further investigation into the discrepancies observed across different datasets and the need for standardized experimental protocols. They also suggest that future studies should explore multi-omics approaches and consider the integration of additional data types to enhance predictive modeling.\n\n7. **Clinical Utility**: By establishing clearer guidelines and demonstrating the importance of specific metrics and datasets, the research aims to facilitate the development of more effective preclinical biomarkers. This could ultimately lead to improved patient outcomes in precision oncology by enabling more tailored treatment strategies based on individual tumor profiles.\n\nIn summary, the implications of the research findings are significant for advancing the field of drug sensitivity prediction and precision oncology, providing a pathway for more accurate and clinically relevant models."
    },
    {
      "question": "What are the limitations and delimitations mentioned in the paper?",
      "answer": "The research paper outlines several limitations and delimitations regarding the study of drug sensitivity prediction from cell line-based pharmacogenomics data. Here are the key points:\n\n### Limitations:\n1. **Assumption of Similar Concentration Ranges**: The study assumed that the concentration ranges across the datasets were similar, which could significantly impact generalization. However, focusing on samples with the same range could lead to insufficient samples for model training due to high dimensionality.\n\n2. **Exclusion of Multi-Omics Data**: The study did not consider multi-omics data (e.g., mutation, proteomics, copy number aberration) due to the lack of comparable omics data types in the pharmacogenomics datasets analyzed. This omission limits the understanding of the impact of multi-omics data on cross-domain generalization.\n\n3. **Focus on Monotherapy Models**: The guidelines primarily focused on monotherapy models and did not explore multi-output or multitask learning, nor did they investigate drug combinations, which could be a promising direction for future research.\n\n4. **Lack of Pathway Transformations**: The study did not consider transformations of genes into pathway representations as input features, which could potentially improve prediction performance.\n\n5. **Generalization Challenges**: The study highlighted that models trained on cell line datasets may not generalize well to clinical samples, especially when they fail to generalize to similar preclinical samples.\n\n6. **Technical Complexity**: Measuring and analyzing drug response data in cell lines is technically complex, and the lack of a consensus on experimental and analytical protocols contributes to variability in results.\n\n### Delimitations:\n1. **Dataset Selection**: The study focused on specific pharmacogenomics datasets (e.g., CTRPv2, GDSCv2, GDSCv1, gCSI) and the drugs included in these datasets, which may limit the generalizability of the findings to other datasets or drugs not included in the analysis.\n\n2. **Gene Expression-Based Predictors**: The research concentrated on gene expression-based predictors, which may not encompass the full range of potential predictive features available in pharmacogenomics.\n\n3. **Single Assay Focus**: The study primarily utilized the CellTiter Glo assay for drug screening, which may not represent the variability seen in other assays.\n\n4. **Performance Metrics**: The study emphasized specific performance metrics (e.g., Pearson and Spearman correlations) for evaluating model performance, which may not capture all aspects of model efficacy.\n\nThese limitations and delimitations provide context for the findings and suggest areas for future research to enhance the robustness and applicability of drug sensitivity prediction models in pharmacogenomics."
    },
    {
      "question": "What recommendations do the authors make in the paper?",
      "answer": "The authors of the paper provide several key recommendations, summarized as follows:\n\n1. **Preference for AAC over IC50**: The authors recommend that models trained to predict the area above the dose-response curve (AAC) tend to be more accurate than those trained to predict the half-maximal inhibitory concentration (IC50). They note that while IC50 is a commonly used metric, it has limitations that can affect model performance.\n\n2. **Truncation of IC50 Values**: If IC50 is used for modeling, the authors suggest that truncating the IC50 values after logarithmic transformation yields more predictive models compared to using raw IC50 values.\n\n3. **Dataset Selection**: The authors recommend using the Cancer Therapeutics Response Portal (CTRPv2) as a training dataset over the Genomics of Drug Sensitivity in Cancer (GDSCv1) dataset. This preference is due to CTRPv2's larger sample size and the consistency of the drug viability assay used.\n\n4. **Stratification by Tissue Types**: In pan-cancer datasets, it is advisable to stratify the analysis by tissue types, particularly distinguishing between solid and non-solid cancer cell lines. This stratification is crucial as non-solid samples may influence model predictions negatively.\n\n5. **Multiple Metrics for Evaluation**: The authors emphasize the importance of evaluating predictive performance using multiple metrics rather than relying on a single metric. This approach provides a more comprehensive assessment of model performance.\n\n6. **Modeling Pathway**: They suggest a modeling path that begins with simple analysis using one gene (biomarker), progresses to multivariable modeling within a single dataset, and eventually extends to multivariable modeling across multiple datasets.\n\n7. **Caution in Generalization**: The authors highlight that testing models on only one cell line dataset does not provide an adequate measure of model performance on another dataset. They stress the need for careful evaluation of generalization capabilities across different datasets.\n\nThese recommendations aim to enhance the robustness and generalizability of machine learning models for drug sensitivity prediction in pharmacogenomics."
    },
    {
      "question": "Who funded the research in the paper?",
      "answer": "The research in the paper was funded by the Natural Sciences and Engineering Research Council via a Discovery grant to Martin Ester and #RGPIN-2021-02680 to Benjamin Haibe-Kains, as well as by the Canadian Institutes of Health Research via #363288 to Benjamin Haibe-Kains."
    },
    {
      "question": "Is there any conflict of interest disclosed in the paper?",
      "answer": "The provided content does not explicitly mention any conflicts of interest. However, it does include a section titled \"Acknowledgments\" and \"Funding,\" which typically might contain disclosures related to conflicts of interest. In this case, the authors acknowledge support from various funding sources, but there is no direct statement regarding conflicts of interest. \n\nTo determine if there are any conflicts of interest, it would be necessary to look for a specific section that addresses this issue, often found towards the end of academic papers. Since the content provided does not include such a section, we cannot conclude that any conflicts of interest are disclosed in the paper."
    },
    {
      "question": "What ethical considerations are discussed in the paper?",
      "answer": "The paper discusses several ethical considerations related to drug sensitivity prediction from cell line-based pharmacogenomics data. Here are the key points:\n\n1. **Data Privacy and Consent**: The use of pharmacogenomics data, especially when derived from human samples, raises concerns about patient privacy and the need for informed consent. Researchers must ensure that data is collected and used in compliance with ethical standards and regulations regarding patient confidentiality.\n\n2. **Bias and Fairness**: The paper highlights the importance of addressing potential biases in machine learning models. If the training datasets are not representative of the broader population, the resulting models may not generalize well, leading to inequitable treatment recommendations. This is particularly critical in precision oncology, where treatment decisions can significantly impact patient outcomes.\n\n3. **Interpretability of Models**: Ethical considerations also extend to the interpretability of machine learning models used in drug sensitivity prediction. Clinicians need to understand how predictions are made to trust and effectively use these models in clinical settings. Lack of transparency can lead to ethical dilemmas regarding the reliance on automated systems for patient care.\n\n4. **Impact of Non-Solid Tumors**: The paper discusses the necessity of stratifying analyses by tissue types, particularly between solid and non-solid tumors. This consideration is crucial as it can affect the accuracy of predictions and, consequently, the treatment decisions made based on these predictions. Ethical implications arise if models trained on mixed datasets fail to provide accurate predictions for specific patient groups.\n\n5. **Clinical Utility and Patient Outcomes**: The authors emphasize the need for guidelines that ensure the clinical utility of drug sensitivity predictions. Ethical considerations include the potential consequences of incorrect predictions on patient treatment and outcomes, which can lead to harm if not properly addressed.\n\n6. **Reproducibility and Research Integrity**: The paper stresses the importance of reproducibility in research findings. Ethical research practices require that studies be conducted transparently and that results can be independently verified. This is essential for maintaining trust in scientific research and its applications in clinical settings.\n\nOverall, the paper underscores the importance of ethical considerations in the development and application of machine learning models in pharmacogenomics, particularly in ensuring fairness, transparency, and the protection of patient rights."
    },
    {
      "question": "Which studies are most frequently cited in the paper?",
      "answer": "The most frequently cited studies in the paper are as follows:\n\n1. **Basu et al. (2013)** - An interactive resource to identify cancer genetic and lineage dependencies targeted by small molecules.\n2. **Barretina et al. (2012)** - The cancer cell line encyclopedia enables predictive modelling of anticancer drug sensitivity.\n3. **Iorio et al. (2016)** - A landscape of pharmacogenomic interactions in cancer.\n4. **Garnett et al. (2012)** - Systematic identification of genomic markers of drug sensitivity in cancer cells.\n5. **Haverty et al. (2016)** - Reproducible pharmacogenomic profiling of cancer cell line panels.\n6. **Niepel et al. (2019)** - A multi-center study on the reproducibility of drug-response assays in mammalian cell lines.\n7. **Smirnov et al. (2016)** - PharmacoGx: an R package for analysis of large pharmacogenomic datasets.\n\nThese references are highlighted throughout the paper, indicating their significance in the context of drug sensitivity prediction and pharmacogenomics."
    },
    {
      "question": "Can you explain the technical terms used in the paper?",
      "answer": "Certainly! Here are explanations of some of the technical terms used in the paper:\n\n1. **Pharmacogenomics**: This is the study of how genes affect a person's response to drugs. It combines pharmacology (the science of drugs) and genomics (the study of genes and their functions) to develop effective, safe medications and doses tailored to a person's genetic makeup.\n\n2. **Drug Sensitivity Prediction**: This refers to the process of predicting how sensitive a particular cancer cell line or patient tumor will be to a specific drug. This is crucial for personalized medicine, where treatments are tailored to individual patients based on their unique tumor characteristics.\n\n3. **Machine Learning**: A subset of artificial intelligence that involves the use of algorithms and statistical models to enable computers to perform tasks without explicit instructions. In this context, machine learning is used to analyze pharmacogenomics data to predict drug responses.\n\n4. **Omics Data**: This term refers to the collective technologies used to explore the roles, relationships, and actions of the various types of molecules that make up the cells of an organism. Examples include genomics (study of genomes), transcriptomics (study of RNA transcripts), proteomics (study of proteins), and metabolomics (study of metabolites).\n\n5. **Gene Expression**: This is the process by which information from a gene is used to synthesize a functional gene product, usually proteins. The level of gene expression can influence how a cell responds to drugs.\n\n6. **Area Above/Under the Dose-Response Curve (AAC/AUC)**: These are metrics used to summarize the effectiveness of a drug at various concentrations. The area under the curve represents the total drug effect over a range of doses, while the area above the curve can indicate the maximum efficacy of the drug.\n\n7. **Half-Maximal Inhibitory Concentration (IC50)**: This is a measure of the effectiveness of a substance in inhibiting a specific biological or biochemical function. It is the concentration of a drug that is required for 50% inhibition of a given biological process or biological component.\n\n8. **Cross-Domain Analysis**: This involves training a model on one dataset (domain) and testing it on another. It helps assess the generalization capability of the model across different datasets.\n\n9. **Within-Domain Analysis**: This refers to training and testing a model on the same dataset. It is often used to evaluate how well a model can predict outcomes within the same context.\n\n10. **Univariable and Multivariable Modeling**: Univariable modeling examines the relationship between a single predictor (e.g., one gene) and an outcome (e.g., drug sensitivity), while multivariable modeling considers multiple predictors simultaneously to understand their combined effect on the outcome.\n\n11. **Ridge Regression and Elastic Net**: These are types of regression analysis used to predict outcomes while addressing multicollinearity (when predictor variables are highly correlated). Ridge regression adds a penalty to the loss function to reduce the complexity of the model, while Elastic Net combines penalties from both Ridge and Lasso regression.\n\n12. **Random Forest**: A machine learning method that uses an ensemble of decision trees to improve predictive accuracy and control overfitting.\n\n13. **Deep Neural Networks**: A type of machine learning model that mimics the way human brains operate, consisting of layers of interconnected nodes (neurons) that can learn complex patterns in data.\n\n14. **PharmacoDB**: An integrated database for mining in vitro anticancer drug screening studies, which provides access to pharmacogenomics data.\n\n15. **Jaccard Index**: A statistic used for gauging the similarity and diversity of sample sets. It measures the size of the intersection divided by the size of the union of two sample sets.\n\nThese terms are foundational to understanding the methodologies and analyses presented in the paper regarding drug sensitivity prediction in cancer treatment."
    },
    {
      "question": "What data sources were used in the paper, and are they accessible for further research?",
      "answer": "The research paper utilized several data sources for drug sensitivity prediction based on cell line-based pharmacogenomics data. The specific datasets mentioned in the paper include:\n\n1. **The Cancer Therapeutics Response Portal (CTRPv2)**\n2. **The Genentech Cell Line Screening Initiative (gCSI)**\n3. **The Genomics of Drug Sensitivity in Cancer (GDSCv1 and GDSCv2)**\n\nThese datasets were obtained in the format of PharmacoSet (PSet), which is an R-based data structure designed to facilitate reproducible research for drug sensitivity prediction. The data were processed using the ORCESTRA platform, which integrates and standardizes various pharmacogenomics datasets.\n\nRegarding accessibility for further research, the paper states that all the data, code, and results employed and obtained in this study are publicly available for research reproducibility. Specifically, the code and supplementary tables/data can be accessed at the following links:\n\n- GitHub repository: [https://github.com/bhklab/PGx_Guidelines](https://github.com/bhklab/PGx_Guidelines)\n- Zenodo record: [https://zenodo.org/record/4642024#.YGCkbK9KiUl](https://zenodo.org/record/4642024#.YGCkbK9KiUl)\n- Code Ocean capsule: [https://codeocean.com/capsule/7358839/tree/v1](https://codeocean.com/capsule/7358839/tree/v1)\n\nThis indicates that the datasets and methodologies used in the study are accessible for further research, allowing other researchers to replicate or build upon the findings."
    },
    {
      "question": "Can you summarize the research paper?",
      "answer": "The research paper titled \"Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines for developing machine learning models\" provides a comprehensive review of the methodologies and challenges associated with predicting drug sensitivity using pharmacogenomics data from cancer cell lines. The authors, led by Hossein Sharifi-Noghabi and others, emphasize the importance of precision oncology, which aims to tailor cancer treatments based on the genomic profiles of tumors.\n\nThe paper identifies a significant gap in the existing literature regarding guidelines for training and validating machine learning models for drug sensitivity prediction. To address this, the authors propose a set of guidelines, referred to as PGx guidelines, which focus on key aspects such as the choice of datasets, measures of drug sensitivity, and the generalization capabilities of predictive models.\n\nKey findings and recommendations from the study include:\n\n1. **Data Utilization**: The authors advocate for the use of integrated and standardized pharmacogenomics datasets, such as those from the ORCESTRA platform, to improve model training and validation.\n\n2. **Drug Sensitivity Metrics**: The paper discusses two common metrics for drug sensitivity\u2014Area Above Curve (AAC) and half-maximal inhibitory concentration (IC50). The authors argue that models trained to predict AAC generally outperform those trained on IC50, particularly due to the inherent limitations of IC50 as a metric.\n\n3. **Model Generalization**: The study highlights the challenges of generalization when moving from within-domain (training and testing on the same dataset) to cross-domain (training on one dataset and testing on another) analyses. The authors provide evidence that models trained on larger datasets, such as CTRPv2, tend to generalize better than those trained on smaller datasets like GDSCv1.\n\n4. **Impact of Tissue Types**: The research underscores the necessity of stratifying analyses by tissue types, particularly distinguishing between solid and non-solid tumors, as this can significantly influence model performance.\n\n5. **Methodological Recommendations**: The authors suggest a modeling approach that begins with simple univariable analyses and progresses to more complex multivariable analyses, emphasizing the importance of evaluating models across multiple metrics to ensure robustness.\n\nIn conclusion, the PGx guidelines aim to enhance the development of more accurate and generalizable machine learning models for drug sensitivity prediction, ultimately contributing to the advancement of precision oncology and improving treatment outcomes for cancer patients. The paper also calls for further research to explore the integration of multi-omics data and the impact of various modeling strategies on predictive performance."
    },
    {
      "question": "What is the significance of this research in its field?",
      "answer": "The significance of this research lies in its contribution to the field of precision oncology, particularly in the development of robust machine learning models for predicting drug sensitivity based on pharmacogenomics data. The study addresses a critical gap in the existing literature by providing comprehensive guidelines\u2014referred to as PGx guidelines\u2014for training and validating drug sensitivity predictors using cell line datasets. \n\nKey points of significance include:\n\n1. **Guidelines for Model Development**: The research introduces systematic guidelines that help researchers choose appropriate datasets and drug sensitivity measures, which are essential for training effective machine learning models. This is particularly important as there has been a lack of standardized practices in the field.\n\n2. **Focus on Generalization**: The study emphasizes the importance of evaluating the generalization capabilities of drug sensitivity predictors across different datasets. This is crucial because models that do not generalize well to new data may not be reliable in clinical settings.\n\n3. **Comparison of Drug Sensitivity Metrics**: The research highlights that models trained to predict the area above the dose-response curve (AAC) outperform those trained on half-maximal inhibitory concentration (IC50), suggesting that AAC is a more suitable measure for drug sensitivity prediction. This insight can influence future research and clinical applications.\n\n4. **Impact of Tissue Types**: The findings indicate that non-solid tissue types can negatively impact the performance of drug sensitivity models. The research advocates for the removal of non-solid samples from training datasets to improve model accuracy, which is a significant consideration for future studies.\n\n5. **Contribution to Precision Oncology**: By enhancing the predictive power of drug sensitivity models, this research supports the broader goal of precision oncology, which aims to tailor cancer treatments based on individual genomic profiles. Improved predictive models can lead to better treatment outcomes for patients.\n\nOverall, this research provides actionable insights and methodologies that can enhance the reliability and applicability of machine learning in pharmacogenomics, ultimately contributing to more effective cancer treatment strategies."
    },
    {
      "question": "How does this paper contribute to the existing body of knowledge?",
      "answer": "The paper titled \"Drug sensitivity prediction from cell line-based pharmacogenomics data, guidelines for developing machine learning models\" contributes to the existing body of knowledge in several significant ways:\n\n1. **Establishment of Comprehensive Guidelines**: The authors introduce a set of guidelines, referred to as PGx guidelines, for training and validating machine learning models specifically for drug sensitivity prediction using pharmacogenomics data. This addresses a notable gap in the literature, as prior guidelines were often based on single datasets or did not consider the complexities of different molecular profiles and drug screening assays.\n\n2. **Focus on Generalization**: The paper emphasizes the importance of generalization in drug sensitivity predictions. It systematically analyzes the performance of models in both within-domain and cross-domain settings, providing insights into how well models trained on one dataset can predict outcomes on another. This is crucial for ensuring that findings from cell line studies can be reliably translated to clinical settings.\n\n3. **Comparison of Drug Sensitivity Metrics**: The study critically evaluates two common metrics for drug sensitivity\u2014Area Above Curve (AAC) and half-maximal inhibitory concentration (IC50)\u2014and demonstrates that models trained to predict AAC generally outperform those trained on IC50. This finding has implications for future research and clinical applications, suggesting a shift in focus towards using AAC as a more reliable measure.\n\n4. **Dataset Selection and Impact**: The authors provide evidence that the choice of training dataset significantly affects model performance. They argue that CTRPv2 is a more suitable training dataset compared to GDSCv1 due to its larger sample size and consistency in drug screening assays. This insight is valuable for researchers in selecting appropriate datasets for their studies.\n\n5. **Addressing Tissue Type Variability**: The paper highlights the impact of including both solid and non-solid tissue types in training datasets, showing that models trained on mixed tissue types may learn to predict tissue type rather than drug sensitivity. This finding underscores the necessity of stratifying analyses by tissue type to improve model accuracy.\n\n6. **Actionable Recommendations**: The PGx guidelines provide actionable recommendations for researchers developing drug sensitivity predictors, including the importance of using standardized datasets, the need for careful preprocessing of drug sensitivity measures, and the necessity of removing non-solid tissue types from training datasets.\n\n7. **Contribution to Precision Oncology**: By enhancing the robustness and generalizability of drug sensitivity prediction models, the paper contributes to the broader goal of precision oncology, which aims to tailor cancer treatments based on individual genomic profiles. The guidelines proposed can lead to the development of more accurate preclinical biomarkers, ultimately benefiting patient care.\n\nIn summary, this paper not only fills critical gaps in the methodology of drug sensitivity prediction but also provides a framework that can guide future research in pharmacogenomics and precision oncology."
    },
    {
      "question": "Are there any novel techniques or approaches introduced in this paper?",
      "answer": "Yes, the paper introduces novel techniques and approaches, specifically a set of comprehensive guidelines referred to as the PGx guidelines. These guidelines address various aspects of training gene expression-based predictors using pharmacogenomics data from cancer cell lines. The authors provide extensive analysis on the generalization of drug sensitivity predictors and challenge existing practices in the field, including the selection of training datasets and measures of drug sensitivity.\n\nKey novel aspects of the guidelines include:\n\n1. **Framework for Training and Validation**: The paper outlines a systematic approach for training and validating machine learning models for drug sensitivity prediction, emphasizing the importance of using multiple uniformly processed datasets.\n\n2. **Comparison of Drug Sensitivity Metrics**: The authors argue that predicting the area above the dose-response curve (AAC) is generally more effective than using half-maximal inhibitory concentration (IC50) for training models, providing evidence to support this claim.\n\n3. **Within-Domain vs. Cross-Domain Analysis**: The paper distinguishes between within-domain analysis (training and testing on the same dataset) and cross-domain analysis (training on one dataset and testing on another), highlighting the implications for model generalization.\n\n4. **Impact of Non-Solid Tumors**: The guidelines also address the influence of non-solid tumors on the performance of drug sensitivity predictors, recommending that models should be trained on solid tumor data to improve accuracy.\n\n5. **Recommendations for Dataset Selection**: The authors suggest that the Cancer Therapeutics Response Portal (CTRPv2) is a more suitable training dataset compared to others like GDSCv1 due to its larger sample size and consistency in drug screening assays.\n\nOverall, the PGx guidelines aim to enhance the robustness and generalizability of machine learning models in pharmacogenomics, contributing to the advancement of precision oncology."
    },
    {
      "question": "What are the potential real-world applications of this research?",
      "answer": "The research paper discusses the development of guidelines for training machine learning models to predict drug sensitivity from pharmacogenomics data derived from cancer cell lines. The potential real-world applications of this research include:\n\n1. **Precision Oncology**: The guidelines aim to enhance the accuracy and generalizability of drug sensitivity predictions, which can lead to more personalized treatment plans for cancer patients based on the genomic profiles of their tumors.\n\n2. **Drug Development**: By providing a systematic approach to predict how different cancer cell lines respond to various drugs, the research can assist pharmaceutical companies in identifying promising drug candidates and optimizing clinical trial designs.\n\n3. **Biomarker Discovery**: The guidelines facilitate the identification of robust preclinical biomarkers that can predict drug response, potentially leading to the development of companion diagnostics that guide treatment decisions in clinical settings.\n\n4. **Clinical Decision Support Systems**: Implementing these machine learning models in clinical decision support tools could help oncologists make informed choices about the most effective therapies for individual patients, thereby improving treatment outcomes.\n\n5. **Integration of Multi-Omics Data**: The research highlights the importance of integrating various omics data types, which can lead to a more comprehensive understanding of cancer biology and drug interactions, ultimately aiding in the development of combination therapies.\n\n6. **Standardization of Pharmacogenomics Data**: The emphasis on standardized datasets and methodologies can improve the reproducibility of research findings, which is crucial for regulatory approval processes and clinical applications.\n\n7. **Training and Validation of Predictive Models**: The guidelines can serve as a framework for future studies in pharmacogenomics, ensuring that machine learning models are trained and validated appropriately, which is essential for their successful application in real-world scenarios.\n\nOverall, the research has the potential to significantly impact cancer treatment strategies, drug development processes, and the broader field of precision medicine."
    },
    {
      "question": "How does the paper address potential biases in the research?",
      "answer": "The paper addresses potential biases in the research by emphasizing the importance of dataset selection, the choice of drug sensitivity measures, and the need for standardized and integrated data for training machine learning models. Specifically, it highlights several key points:\n\n1. **Dataset Selection**: The authors argue that the choice of training dataset significantly impacts the generalization capability of drug sensitivity predictors. They compare the Cancer Therapeutics Response Portal (CTRPv2) and the Genomics of Drug Sensitivity in Cancer (GDSCv1) datasets, suggesting that CTRPv2 is more suitable due to its larger sample size and consistency in drug screening assays. This comparison helps mitigate biases that may arise from using datasets with different characteristics.\n\n2. **Drug Sensitivity Measures**: The paper discusses the limitations of commonly used drug sensitivity metrics, particularly IC50, which can be unstable and may not exist for all experiments. The authors advocate for the use of the area above the dose-response curve (AAC) as a more reliable measure, arguing that models trained to predict AAC tend to be more accurate than those trained on IC50. This shift in focus helps reduce bias associated with the choice of measurement.\n\n3. **Cross-Domain Analysis**: The authors conduct both within-domain and cross-domain analyses to assess the generalization of their models. They find that models trained on one dataset often perform poorly when tested on another, indicating that biases can arise from differences in experimental conditions and data processing across studies. By systematically evaluating model performance across multiple datasets, the authors aim to identify and address these biases.\n\n4. **Stratification by Tissue Type**: The paper highlights the importance of stratifying analyses by tissue types (solid vs. non-solid tumors) to avoid biases in model training and evaluation. The authors demonstrate that including non-solid samples can negatively impact the performance of models trained on solid tissue data, suggesting that careful consideration of tissue type is crucial for accurate predictions.\n\n5. **Technical Variability**: The authors acknowledge that technical differences in experimental protocols, such as drug concentration ranges and assay methods, can introduce variability and bias in drug response measurements. They emphasize the need for standardized protocols to minimize these biases and improve the reproducibility of results.\n\nOverall, the paper provides comprehensive guidelines (PGx guidelines) aimed at developing more robust and generalizable machine learning models for drug sensitivity prediction, while actively addressing potential biases in the research process."
    },
    {
      "question": "What validation methods were used to ensure the reliability of the results?",
      "answer": "The research paper employs several validation methods to ensure the reliability of the results in drug sensitivity prediction from cell line-based pharmacogenomics data. Here are the key validation methods mentioned:\n\n1. **Within-Domain Analysis**: This method involves training and testing models on the same dataset using cross-validation. Specifically, a 10-fold nested cross-validation approach is utilized, where 9 folds are used for training and validation, and the 10th fold is reserved for testing. This method helps assess the model's performance on the same distribution of data it was trained on.\n\n2. **Cross-Domain Analysis**: In this approach, models are trained on one dataset and tested on different cell line datasets. This method evaluates the generalization capability of the models, providing insights into how well the models can predict drug sensitivity across different datasets.\n\n3. **Performance Metrics**: Various metrics are employed to evaluate model performance, including:\n   - Pearson correlation\n   - Spearman correlation\n   - Root mean squared error (RMSE)\n   - Jaccard index\n   - Standardized regression coefficients\n\n4. **Stability Analysis**: The stability of univariable feature rankings is assessed by comparing the rankings of gene expression associations with drug response across multiple datasets. The Jaccard index is computed to measure the intersection of top-ranked features across datasets, providing insights into the consistency of the associations.\n\n5. **Experimental Design**: The experimental design is structured to justify the choice of training datasets and measures of drug sensitivity. The authors investigate the impact of different datasets (e.g., CTRPv2 vs. GDSCv1) on model performance and generalization.\n\n6. **Hyper-Parameter Tuning**: The models undergo hyper-parameter tuning through grid search in nested cross-validation, ensuring that the best model configurations are selected for training.\n\n7. **Data Normalization**: Gene expression input data is normalized via z-score transformation, and one-hot encoding is used to account for tissue types, which helps in reducing bias in the model training.\n\n8. **Reproducibility Measures**: The authors emphasize the importance of reproducibility by providing access to data, code, and results, allowing other researchers to validate and replicate the findings.\n\nThese validation methods collectively contribute to the robustness and reliability of the drug sensitivity prediction models developed in the study."
    },
    {
      "question": "Are there any contradictions between this paper's findings and previous research?",
      "answer": "Based on the content of the research paper, there are several points where the findings may contradict or challenge previous research:\n\n1. **Preference for AAC over IC50**: The paper argues that models trained to predict the Area Above the Curve (AAC) outperform those trained to predict the half-maximal inhibitory concentration (IC50). This finding challenges the common trend in previous studies that have predominantly used IC50 as a measure of drug sensitivity. The authors suggest that IC50 has limitations, such as instability in estimation and being unbounded, which may not provide as reliable predictions as AAC.\n\n2. **Training Dataset Selection**: The research indicates that models trained on the Cancer Therapeutics Response Portal (CTRPv2) dataset demonstrate better generalization performance compared to those trained on the Genomics of Drug Sensitivity in Cancer (GDSCv1) dataset. This contradicts the notion that GDSCv1, being a widely used dataset, is the best choice for training models. The authors attribute the better performance of CTRPv2 to its larger sample size and the consistency of the drug screening assay used.\n\n3. **Impact of Non-Solid Tumors**: The paper emphasizes the necessity of removing non-solid tumor samples from training datasets to improve model performance. This finding may contradict previous studies that did not account for the differences in drug sensitivity between solid and non-solid tumors, potentially leading to misleading conclusions about drug efficacy across different cancer types.\n\n4. **Generalization Performance**: The authors highlight that the performance of drug sensitivity predictors decreases significantly when moving from within-domain to cross-domain analysis. This finding suggests that many existing models may not generalize well to other datasets, which could contradict earlier studies that reported successful cross-domain predictions without acknowledging the potential for significant performance drops.\n\n5. **Guidelines for Model Development**: The introduction of comprehensive guidelines for training and validating machine learning models for drug sensitivity prediction challenges the existing practices in the field, which may lack such structured approaches. The authors argue that many current practices are based on single datasets or do not consider the technical differences across datasets, which could lead to inconsistent results.\n\nIn summary, the findings of this paper present several contradictions to previous research, particularly regarding the choice of drug sensitivity metrics, the selection of training datasets, the treatment of non-solid tumors, and the generalization capabilities of predictive models."
    }
  ]
}