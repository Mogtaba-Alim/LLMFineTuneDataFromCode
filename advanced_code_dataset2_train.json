[
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utils-testing.R",
    "language": "R",
    "content": "#' Tests of table 1 is a subset of table2, in which case there will be no rows\n#' is the set difference.\n#'\n#' @param table1,table2 A `data.table` or a table-like object coercible to one \n#' via `as.data.table`.\n#'\n#' @return `logical(1)` TRUE if `table1` is a subset of `table2`, otherwise \n#' `FALSE`\n#'\n#' @importFrom data.table fsetdiff as.data.table\n#'\n#' @noRd\n#' @keywords internal\n.table_is_subset <- function(table1, table2) {\n    if (!is(table1, \"data.table\")) table1 <- as.data.table(table1)\n    if (!is(table2, \"data.table\")) table2 <- as.data.table(table2)\n    nrow(fsetdiff(\n        table1,\n        table2,\n    )) == 0\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.table_is_subset` function in this code snippet?",
        "answer": "The `.table_is_subset` function checks if `table1` is a subset of `table2`. It returns `TRUE` if `table1` is a subset of `table2`, and `FALSE` otherwise. It does this by performing a set difference operation using `fsetdiff` and checking if the result has zero rows."
      },
      {
        "question": "How does the function handle input tables that are not of class 'data.table'?",
        "answer": "The function uses the `is()` function to check if the input tables are of class 'data.table'. If they are not, it converts them to 'data.table' objects using the `as.data.table()` function. This ensures that the function can work with various table-like objects that can be coerced to 'data.table'."
      },
      {
        "question": "What is the significance of the `@noRd` and `@keywords internal` tags in the function documentation?",
        "answer": "The `@noRd` tag indicates that this function should not be included in the package's R documentation. The `@keywords internal` tag marks the function as internal, meaning it's not intended for direct use by package users. These tags suggest that `.table_is_subset` is a helper function meant for internal use within the package rather than a public-facing function."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' Tests if table1 is a subset of table2\n#'\n#' @param table1,table2 A `data.table` or a table-like object\n#'\n#' @return `logical(1)` TRUE if `table1` is a subset of `table2`, otherwise `FALSE`\n#'\n#' @importFrom data.table fsetdiff as.data.table\n#'\n#' @noRd\n#' @keywords internal\n.table_is_subset <- function(table1, table2) {\n    # Convert inputs to data.table if necessary\n    if (!is(table1, \"data.table\")) table1 <- as.data.table(table1)\n    if (!is(table2, \"data.table\")) table2 <- as.data.table(table2)\n    \n    # Complete the function to check if table1 is a subset of table2\n    \n}",
        "complete": "#' Tests if table1 is a subset of table2\n#'\n#' @param table1,table2 A `data.table` or a table-like object\n#'\n#' @return `logical(1)` TRUE if `table1` is a subset of `table2`, otherwise `FALSE`\n#'\n#' @importFrom data.table fsetdiff as.data.table\n#'\n#' @noRd\n#' @keywords internal\n.table_is_subset <- function(table1, table2) {\n    # Convert inputs to data.table if necessary\n    if (!is(table1, \"data.table\")) table1 <- as.data.table(table1)\n    if (!is(table2, \"data.table\")) table2 <- as.data.table(table2)\n    \n    # Check if table1 is a subset of table2\n    nrow(fsetdiff(table1, table2)) == 0\n}"
      },
      {
        "partial": "#' Tests if table1 is a subset of table2\n#'\n#' @param table1,table2 A `data.table` or a table-like object\n#'\n#' @return `logical(1)` TRUE if `table1` is a subset of `table2`, otherwise `FALSE`\n#'\n#' @importFrom data.table fsetdiff as.data.table\n#'\n#' @noRd\n#' @keywords internal\n.table_is_subset <- function(table1, table2) {\n    # Complete the function to check if table1 is a subset of table2\n    # Ensure both inputs are converted to data.table if necessary\n    # Use fsetdiff to compare the tables\n    \n}",
        "complete": "#' Tests if table1 is a subset of table2\n#'\n#' @param table1,table2 A `data.table` or a table-like object\n#'\n#' @return `logical(1)` TRUE if `table1` is a subset of `table2`, otherwise `FALSE`\n#'\n#' @importFrom data.table fsetdiff as.data.table\n#'\n#' @noRd\n#' @keywords internal\n.table_is_subset <- function(table1, table2) {\n    table1 <- if (!is(table1, \"data.table\")) as.data.table(table1) else table1\n    table2 <- if (!is(table2, \"data.table\")) as.data.table(table2) else table2\n    nrow(fsetdiff(table1, table2)) == 0\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat/test-LongTable-accessors.R",
    "language": "R",
    "content": "library(testthat)\nlibrary(CoreGx)\nlibrary(data.table)\n\ndata(nci_TRE_small)\ntre <- nci_TRE_small\n\n## tre = treatmentResponseExperiment\n## ntre = New treatmentResponseExperiment\n\n# see https://github.com/bhklab/CoreGx/wiki/CoreGx-Design-Documentation for\n# explanation\ntest_that(\"`rowData,LongTable-method` orders data correctly\", {\n    ## TODO::\n})\n\n# == @rowData slot\n\ntestthat::test_that(\"`rowData<-` rowData must be updated with data.table or data.frame\", {\n    ntre <- copy(tre)\n    testthat::expect_error({ rowData(ntre) <- NULL }, ## rowData slot\n        regexp = \".*Please pass a data.frame or data.table to update.the rowData slot.*\"\n    )\n})\n\n\ntestthat::test_that(\"`rowData<-` prevents intentionally breaking referential integrity\", {\n    ntre <- copy(tre)\n    rowData_bad <- rowData(ntre)\n    rowData_bad <- rbind(rowData_bad, rowData_bad[.N, ])\n    testthat::expect_warning({ rowData(ntre) <- rowData_bad },\n        regexp = \".*The ID columns are duplicated for rows [0-9]+! These rows will be dropped before assignment.\"\n    )\n})\n\ntestthat::test_that(\"`colData<-` prevents intentionally breaking referential integrity\", {\n    ntre <- copy(tre)\n    colData_bad <- colData(ntre)\n    colData_bad <- rbind(colData_bad, colData_bad[.N, ])\n    testthat::expect_warning({ colData(ntre) <- colData_bad },\n        regexp =  \".*The ID columns are duplicated for rows [0-9]+! These rows will be dropped before assignment.\"\n    )\n})\n\n# This warning doesn't trigger if we remove another ID column.\n# Instead, an error like in the NCI-ALMANAC script will occur. (Too many duplicate rows)\n\n## FIXME:: We should probably just throw an error for these cases! This test\n##   doesn't work for the full NCI_TRE object due to cartesian join\n# testthat::test_that(\"`rowData<-` ensures necessary row ID columns present in the replacement rowData\", {\n#     ntre <- copy(tre)\n#     rowData_missingID <- rowData(ntre)\n#     rowData_missingID[, (rowIDs(ntre)[4]) := NULL] # remove one ID column\n#     testthat::expect_warning({ rowData(ntre) <- rowData_missingID },\n#         regexp = \".*The function will attempt to join with existing rowIDs, but this may fail!.*\"\n#     )\n# })\n\n# == @colData slot\n\ntestthat::test_that(\"`colData<-` colData must be updated with data.table or data.frame\", {\n    ntre <- copy(tre)\n    testthat::expect_error({ colData(ntre) <- NULL }, ## colData slot\n        regexp = \".*Please pass a data\\\\.frame or data\\\\.table.*\"\n    )\n})\n\n# == @assay slot\n\ntestthat::test_that(\"`assay` invalid assay name and index\", {\n    testthat::expect_error({ assay(tre, c(1, 2)) },\n        regexp = \".*Please specifying a single string assay name or integer.*\"\n    )\n    testthat::expect_error({ assay(tre, paste(assayNames(tre), collapse = '')) },\n        regexp = \".*There is no assay.*\"\n    )\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` prevents invalid assay slot assignment\", {\n    ntre <- copy(tre)\n    testthat::expect_error({\n        assay(ntre, i = \"sensitivity\", withDimnames = FALSE) <- c(1, 2, 3)\n    },\n    regexp = \".*Only a\\ndata.frame or data.table can be assiged to the assay slot!.*\"\n    )\n})\n\ntestthat::test_that(\"`assay,LongTable-method` and `assays,LongTable-method` return equivalent data\", {\n    assay_list <- lapply(seq_along(assayNames(tre)), FUN=assay,\n        x=tre, withDimnames=TRUE, summarize=FALSE)\n    assays_ <- assays(tre)\n    for (i in seq_along(assay_list)) {\n        testthat::expect_true(all.equal(assay_list[[i]], assays_[[i]]))\n    }\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` assignment does not corrupt data relationships\", {\n    ntre <- copy(tre)\n    for (nm in assayNames(tre)) {\n        ntre[[nm]] <- ntre[[nm]]\n        testthat::expect_true(all.equal(ntre[[nm]], tre[[nm]]))\n        testthat::expect_true(all.equal(assays(ntre, raw=TRUE)[[nm]], assays(tre, raw=TRUE)[[nm]]))\n    }\n    testthat::expect_true(all.equal(getIntern(ntre)$assayIndex, getIntern(tre)$assayIndex))\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` allows non-id column updates\", {\n    ntre <- copy(tre)\n    assay_ <- ntre[[\"sensitivity\"]]\n    assay_[, viability := rnorm(.N)]\n    ntre[[\"sensitivity\"]] <- assay_\n    testthat::expect_true(all.equal(ntre[[\"sensitivity\"]], assay_))\n    testthat::expect_false(isTRUE(all.equal(ntre[[\"sensitivity\"]], tre[[\"sensitivity\"]])))\n})\n\ntestthat::test_that(\"`assay<-LongTable-method` prevents id column updates\", {\n    ntre <- copy(tre)\n    assay_ <- ntre[[\"sensitivity\"]]\n#    assay_[, treatment1dose := rnorm(.N)]\n#    testthat::expect_error({ ntre[[\"sensitivity\"]] <- assay_ },\n#        regexp=\".*Identifier columns cannot be modified via assay assignment!.*\"\n#    )\n    testthat::expect_true(all.equal(ntre$sensitivity, tre$sensitivity))\n})\n\ntestthat::test_that(\"`assay<-LongTable-method` allows simple summary assignments\", {\n    ntre <- copy(tre)\n    sens <- ntre$sensitivity\n    sens_sum <- sens[,\n        .(\n            mean_treatment1dose=mean(treatment1dose, na.rm=TRUE),\n            mean_treatment2dose=mean(treatment2dose, na.rm=TRUE),\n            mean_viability=mean(viability, na.rm=TRUE)\n        ),\n        by=.(treatment1id, treatment2id, sampleid)\n    ]\n    testthat::expect_silent(ntre$sens_sum <- sens_sum)\n    # ensure that the returned assay matches the assigned assay when\n    #   summarize=TRUE (the default)\n    sens_sum_accessed <- ntre$sens_sum[, colnames(sens_sum), with=FALSE]\n    setkeyv(sens_sum, key(sens_sum_accessed))\n    testthat::expect_true(all.equal(\n        sens_sum,\n        sens_sum_accessed,\n    ))\n    # test that summarzie=FALSE attaches all original data\n    testthat::expect_true(all.equal(\n        rowIDs(tre, data=TRUE),\n        unique(assay(ntre, \"sens_sum\", summarize=FALSE)[, rowIDs(ntre), with=FALSE]),\n        check.attributes=FALSE\n    ))\n    testthat::expect_true(all.equal(\n        colIDs(tre, data=TRUE),\n        unique(assay(ntre, \"sens_sum\", summarize=FALSE)[order(sampleid), colIDs(ntre), with=FALSE]),\n        check.attributes=FALSE\n    ))\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` summary assignment doesn't break referential integrity\", {\n    ntre <- copy(tre)\n    sens <- ntre$sensitivity\n    sens_sum <- sens[,\n        .(\n            mean_treatment1dose=mean(treatment1dose, na.rm=TRUE),\n            mean_treatment2dose=mean(treatment2dose, na.rm=TRUE),\n            mean_viability=mean(viability, na.rm=TRUE)\n        ),\n        by=.(treatment1id, treatment2id, sampleid)\n    ]\n    testthat::expect_silent(ntre$sens_sum <- sens_sum)\n    testthat::expect_true(all.equal(rowData(tre), rowData(ntre)))\n    testthat::expect_true(all.equal(colData(tre), colData(ntre)))\n    non_summary_assays <- setdiff(assayNames(ntre), \"sens_sum\")\n    for (aname in non_summary_assays) {\n        testthat::expect_true(all.equal(\n            tre[[aname]],\n            ntre[[aname]]\n        ))\n    }\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` prevents modified row ID in new assay from breaking referential integrity\", {\n    ntre <- copy(tre)\n    sens <- ntre$sensitivity\n    sens_sum <- sens[,\n        .(\n            mean_treatment1dose=mean(treatment1dose, na.rm=TRUE),\n            mean_treatment2dose=mean(treatment2dose, na.rm=TRUE),\n            mean_viability=mean(viability, na.rm=TRUE)\n        ),\n        by=.(treatment1id, treatment2id, sampleid)\n    ]\n    set(sens_sum,\n        i     = which(sens_sum[[\"treatment1id\"]] == sens_sum[1, treatment1id]),\n        j     = \"treatment1id\",           # rowID to modify\n        value = sens_sum[1, sampleid]) # Replace a treatment id with a sample id\n    testthat::expect_error({ ntre$sens_sum <- sens_sum },\n        regexp = paste(\n            \".*One or more rowIDs\\\\(x\\\\) columns have been modified.\",\n            \"Identifier columns cannot be modified via assay assignment!.*\"\n            )\n    )\n})\n\ntestthat::test_that(\"`assay<-,LongTable-method` prevents modified column ID in new assay from breaking referential integrity\", {\n    ntre <- copy(tre)\n    sens <- ntre$sensitivity\n    sens_sum <- sens[,\n        .(\n            mean_treatment1dose=mean(treatment1dose, na.rm=TRUE),\n            mean_treatment2dose=mean(treatment2dose, na.rm=TRUE),\n            mean_viability=mean(viability, na.rm=TRUE)\n        ),\n        by=.(treatment1id, treatment2id, sampleid)\n    ]\n    set(sens_sum,\n        i = which(sens_sum[[\"sampleid\"]] == sens_sum[1, sampleid]),\n        j = \"sampleid\",             # column ID to modify\n        value = sens_sum[1, treatment2id]) # Replace a sample ID with a treatment ID\n    testthat::expect_error({ ntre$sens_sum <- sens_sum },\n        regexp = paste(\n            \".*One or more colIDs\\\\(x\\\\) column have been modified.\",\n            \"Identifier columns cannot be modified via assay assignment!.*\"\n            )\n    )\n})\n\n# == @metadata slot\n\ntestthat::test_that(\"`metadata<-` invalid metadata slot assignment\", {\n    ntre <- copy(tre)\n    testthat::expect_error({ metadata(ntre) <- NULL },\n        regexp = \".*The `metadata` slot must be a list!.*\"\n    )\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `rowData<-` method test in this code, and what does it check for?",
        "answer": "The `rowData<-` method test checks for referential integrity when updating the rowData slot of a TreatmentResponseExperiment object. It ensures that duplicate rows in the rowData are detected and warns the user. Specifically, it creates a new rowData with a duplicated last row and expects a warning about duplicate ID columns when trying to assign this to the object."
      },
      {
        "question": "How does the code test the `assay<-` method for preventing invalid assignments?",
        "answer": "The code tests the `assay<-` method by attempting to assign an invalid value (a vector of numbers) to an assay slot. It expects an error with a message indicating that only a data.frame or data.table can be assigned to the assay slot. This ensures that the method properly validates the type of data being assigned to maintain the integrity of the TreatmentResponseExperiment object."
      },
      {
        "question": "What is the purpose of the test checking if `assay` and `assays` methods return equivalent data?",
        "answer": "This test ensures consistency between the `assay` and `assays` methods of the TreatmentResponseExperiment object. It creates a list of assays using the `assay` method for each assay name, and then compares this list with the result of the `assays` method. The test verifies that both methods return the same data, which is crucial for maintaining consistent behavior across different ways of accessing assay data in the object."
      }
    ],
    "completion_tasks": [
      {
        "partial": "testthat::test_that(\"`assay,LongTable-method` and `assays,LongTable-method` return equivalent data\", {\n    assay_list <- lapply(seq_along(assayNames(tre)), FUN=assay,\n        x=tre, withDimnames=TRUE, summarize=FALSE)\n    assays_ <- assays(tre)\n    for (i in seq_along(assay_list)) {\n        testthat::expect_true(all.equal(assay_list[[i]], assays_[[i]]))\n    }\n})",
        "complete": "testthat::test_that(\"`assay,LongTable-method` and `assays,LongTable-method` return equivalent data\", {\n    assay_list <- lapply(seq_along(assayNames(tre)), FUN=assay,\n        x=tre, withDimnames=TRUE, summarize=FALSE)\n    assays_ <- assays(tre)\n    for (i in seq_along(assay_list)) {\n        testthat::expect_true(all.equal(assay_list[[i]], assays_[[i]]))\n    }\n})"
      },
      {
        "partial": "testthat::test_that(\"`assay<-,LongTable-method` allows non-id column updates\", {\n    ntre <- copy(tre)\n    assay_ <- ntre[[\"sensitivity\"]]\n    assay_[, viability := rnorm(.N)]\n    ntre[[\"sensitivity\"]] <- assay_\n    testthat::expect_true(all.equal(ntre[[\"sensitivity\"]], assay_))\n    testthat::expect_false(isTRUE(all.equal(ntre[[\"sensitivity\"]], tre[[\"sensitivity\"]])))\n})",
        "complete": "testthat::test_that(\"`assay<-,LongTable-method` allows non-id column updates\", {\n    ntre <- copy(tre)\n    assay_ <- ntre[[\"sensitivity\"]]\n    assay_[, viability := rnorm(.N)]\n    ntre[[\"sensitivity\"]] <- assay_\n    testthat::expect_true(all.equal(ntre[[\"sensitivity\"]], assay_))\n    testthat::expect_false(isTRUE(all.equal(ntre[[\"sensitivity\"]], tre[[\"sensitivity\"]])))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/mergeAssays-method.R",
    "language": "R",
    "content": "#' @include LongTable-class.R\n#'\n#' @importFrom data.table key merge.data.table\n#' @import checkmate\nNULL\n\n#' Merge assays with an `S4` object.\n#'\n#' @param object `S4` An S4 object a list-like slot containing assays for the\n#'   object.\n#' @param ... Allow new arguments to be defined for this generic.\n#'\n#' @return A modified version of `object`.\n#'\n#' @examples\n#' \"This is a generic method!\"\n#'\n#' @exportMethod mergeAssays\nsetGeneric(\"mergeAssays\", function(object, ...) standardGeneric(\"mergeAssays\"))\n\n\n#' Endomorphically merge assays within a `LongTable` or inheriting class\n#'\n#' @param object A `LongTable` or inheriting class.\n#' @param x `character(1)` A valid assay name in `object`.\n#' @param y `character(1)` A valid assay name in `object`.\n#' @param target `character(1)` Name of the assay to assign the result to.\n#' Can be a new or existing assay. Defaults to `x`.\n#' @param ... Fallthrough arguments to merge.data.table to specify the join\n#'   type. Use this to specify which columns to merge on. If excluded, defaults\n#'   to by=assayKeys(objecty, y).\n#' @param metadata `logical` A logical vector indicating whether to attach\n#' metadata to either assay before the merge occurs. If only one value is\n#' passed that value is used for both assays. Defaults to `FALSE`.\n#'\n#' @return A copy of `object` with assays `x` and `y` merged and assigned to\n#' `target`.\n#'\n#' @seealso [`merge.data.table`]\n#'\n#' @author\n#' Christopher Eeles\n#'\n#' @export\nsetMethod(\"mergeAssays\", signature(\"LongTable\"),\n        function(object, x, y, target=x, ..., metadata=FALSE) {\n    checkmate::qassert(target, \"S1\")\n    z <- .merge_longtable_assays(object, x=x, y=y, ...,\n        metadata=metadata)\n    object[[target]] <- z\n    object\n})\n\n#' @noRd\n.merge_longtable_assays <- function(object, x, y, ..., metadata=FALSE) {\n    # -- input validation\n    checkmate::qassert(x, \"S1\")\n    checkmate::qassert(y, \"S1\")\n    checkmate::assertChoice(x, assayNames(object))\n    checkmate::assertChoice(x, assayNames(object))\n    checkmate::qassert(metadata, c(\"B1\", \"B2\"))\n    if (length(metadata) == 1) metadata <- c(metadata, metadata)\n\n    # -- extract assays to merge\n    x_ <- assay(object, x, summarize=TRUE, metadata=metadata[1])\n    y_ <- if (x == y) x_ else\n        assay(object, y, summarize=TRUE, metadata=metadata[2])\n\n    # -- handle by argument\n    by <- NA\n    by_args <- c(\"by\", \"by.x\", \"by.y\")\n    if (!(any(by_args %in% ...names())))  {\n        by <- assayKeys(object, y)\n    }\n\n    if (!is.character(by))\n        merge.data.table(x=x_, y=y_, ...)\n    else\n        merge.data.table(x=x_, y=y_, by=by, ...)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mergeAssays` generic function and how is it implemented for the `LongTable` class?",
        "answer": "The `mergeAssays` generic function is designed to merge assays within an S4 object. For the `LongTable` class, it's implemented as a method that merges two specified assays (`x` and `y`) and assigns the result to a target assay (defaulting to `x`). It uses the `.merge_longtable_assays` helper function to perform the actual merge operation and returns a modified copy of the input object with the merged assay."
      },
      {
        "question": "How does the `.merge_longtable_assays` function handle the 'by' argument for merging data tables?",
        "answer": "The `.merge_longtable_assays` function checks if any of the 'by', 'by.x', or 'by.y' arguments are provided in the ... (ellipsis) arguments. If none are provided, it defaults to using `assayKeys(object, y)` as the 'by' argument. If a 'by' argument is provided or defaulted, it's passed to `merge.data.table` along with other arguments. This allows flexibility in specifying merge conditions while providing a sensible default."
      },
      {
        "question": "What is the purpose of the `metadata` parameter in the `mergeAssays` method, and how is it used?",
        "answer": "The `metadata` parameter is a logical vector that determines whether to attach metadata to the assays before merging. If a single logical value is provided, it's used for both assays. The function uses this parameter when calling `assay(object, x, summarize=TRUE, metadata=metadata[1])` and `assay(object, y, summarize=TRUE, metadata=metadata[2])`. This allows users to optionally include metadata in the merge operation, which can be useful for preserving additional information during the merge process."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"mergeAssays\", signature(\"LongTable\"),\n        function(object, x, y, target=x, ..., metadata=FALSE) {\n    checkmate::qassert(target, \"S1\")\n    z <- .merge_longtable_assays(object, x=x, y=y, ...,\n        metadata=metadata)\n    object[[target]] <- z\n    object\n})",
        "complete": "setMethod(\"mergeAssays\", signature(\"LongTable\"),\n        function(object, x, y, target=x, ..., metadata=FALSE) {\n    checkmate::qassert(target, \"S1\")\n    z <- .merge_longtable_assays(object, x=x, y=y, ...,\n        metadata=metadata)\n    object[[target]] <- z\n    object\n})"
      },
      {
        "partial": ".merge_longtable_assays <- function(object, x, y, ..., metadata=FALSE) {\n    checkmate::qassert(x, \"S1\")\n    checkmate::qassert(y, \"S1\")\n    checkmate::assertChoice(x, assayNames(object))\n    checkmate::assertChoice(x, assayNames(object))\n    checkmate::qassert(metadata, c(\"B1\", \"B2\"))\n    if (length(metadata) == 1) metadata <- c(metadata, metadata)\n\n    x_ <- assay(object, x, summarize=TRUE, metadata=metadata[1])\n    y_ <- if (x == y) x_ else\n        assay(object, y, summarize=TRUE, metadata=metadata[2])\n\n    by <- NA\n    by_args <- c(\"by\", \"by.x\", \"by.y\")\n    if (!(any(by_args %in% ...names())))  {\n        by <- assayKeys(object, y)\n    }\n\n    if (!is.character(by))\n        merge.data.table(x=x_, y=y_, ...)\n    else\n        merge.data.table(x=x_, y=y_, by=by, ...)\n}",
        "complete": ".merge_longtable_assays <- function(object, x, y, ..., metadata=FALSE) {\n    checkmate::qassert(x, \"S1\")\n    checkmate::qassert(y, \"S1\")\n    checkmate::assertChoice(x, assayNames(object))\n    checkmate::assertChoice(y, assayNames(object))\n    checkmate::qassert(metadata, c(\"B1\", \"B2\"))\n    if (length(metadata) == 1) metadata <- c(metadata, metadata)\n\n    x_ <- assay(object, x, summarize=TRUE, metadata=metadata[1])\n    y_ <- if (x == y) x_ else\n        assay(object, y, summarize=TRUE, metadata=metadata[2])\n\n    by <- NA\n    by_args <- c(\"by\", \"by.x\", \"by.y\")\n    if (!(any(by_args %in% ...names())))  {\n        by <- assayKeys(object, y)\n    }\n\n    if (!is.character(by))\n        merge.data.table(x=x_, y=y_, ...)\n    else\n        merge.data.table(x=x_, y=y_, by=by, ...)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-coerce.R",
    "language": "R",
    "content": "# ==== LongTable Class\n\n#' @include LongTableDataMapper-class.R\n#' @include DataMapper-class.R\n#' @include TreatmentResponseExperiment-class.R\nNULL\n\n#' @title LongTable to data.table conversion\n#' @name as\n#'\n#' @examples\n#' as(merckLongTable, 'data.table')\n#'\n#' @description Coerce a LongTable into a `data.table`.\n#'\n#' @param from `LongTable` Object to coerce.\n#'\n#' @return A `data.table` with the data from a LongTable.\n#'\n#' @import data.table\n#' @export\nsetAs('LongTable', 'data.table', def=function(from) {\n\n    # extract the assay data\n    longTableData <- assays(from, withDimnames=FALSE, key=TRUE)\n\n    # join assays into a single table\n    DT <- longTableData[[1]]\n    longTableData[[1]] <- NULL\n    for (i in seq_along(longTableData)) {\n        DT <- merge.data.table(DT, longTableData[[i]],\n            suffixes=c('', paste0('._', i)), by=.EACHI, all.x=TRUE, all.y=TRUE)\n    }\n\n    # extract assay columns\n    assayCols <- assayCols(from)\n\n    # fix assayCols if there are duplicate column names between assays\n    # the join will append '._n' where n is the assay index - 1\n    ## TODO:: Make this a helper since it is reused in multiple functions\n    .greplAny <- function(...) any(grepl(...))\n    .paste0IfElse <- function(vector, suffix, isIn=c('rowKey', 'colKey'))\n        ifelse(vector %in% isIn, vector, paste0(vector, suffix))\n    hasSuffixes <- unlist(lapply(paste0('._', seq_along(longTableData)),\n        FUN=.greplAny, x=colnames(DT)))\n    if (any(hasSuffixes)) {\n        whichHasSuffixes <- which(hasSuffixes) + 1\n        assayCols[whichHasSuffixes] <-\n            Map(FUN=.paste0IfElse,\n                vector=assayCols[whichHasSuffixes],\n                suffix=paste0('._', seq_along(longTableData))[hasSuffixes]\n            )\n    }\n\n    # join the row and column data\n    DT <- merge.data.table(DT, rowData(from, key=TRUE), by='rowKey')\n    DT <- merge.data.table(DT, colData(from, key=TRUE), by='colKey')\n    setkeyv(DT, c('rowKey', 'colKey'))\n\n    # drop interal key columns\n    DT[, c('rowKey', 'colKey') := NULL]\n\n    # organize the returned columns\n    colOrder <- unique(c(setdiff(\n        colnames(DT), unlist(assayCols)),\n        unlist(assayCols)\n    ))\n    setcolorder(DT, colOrder)\n\n    aMap <- lapply(assayCols, FUN=setdiff,\n        y=c(idCols(from), rowMeta(from), colMeta(from)))\n    aMap <- Map(list, mutable(getIntern(from, \"assayKeys\")), aMap)\n\n    DT <- cbind(DT, metadata(from)$experiment_metadata)\n\n    metaCols <- names(metadata(from)$experiment_metadata)\n    longTableMapper <- LongTableDataMapper(\n        rowDataMap=list(rowIDs(from), rowMeta(from)),\n        colDataMap=list(colIDs(from), colMeta(from)),\n        assayMap=aMap,\n        metadataMap=if (is.character(metaCols)) list(metaCols) else list()\n    )\n    metadata(longTableMapper) <- metadata(from)[names(metadata(from) != \"experiment_metadata\")]\n    attr(DT, 'longTableDataMapper') <- longTableMapper\n\n    # return the data.table\n    return(DT)\n})\n# #' @title Coerce a LongTable into a `data.table`\n# #' @name as\n# #'\n# #' @description S3 version of coerce method for convenience.\n# #'\n# #' @param from `LongTable` to coerce to a `data.table`\n# #'\n# #' @return A `data.table` containing the data from the LongTable, as well\n# #'   as the `longTableDataMapper' attribute which contains the data needed to\n# #'   reverse the coercion.\n# #' @export\n# as.data.table.long.table <- function(from, keep.rownames=FALSE,...) as(from, 'data.table')\n\n#' @title Coerce a LongTable into a `data.frame`\n#' @name as\n#'\n#' @description Currently only supports coercing to data.table or data.frame\n#'\n#' @param from `LongTable` Object to coerce.\n#'\n#' @return `data.table` containing the data from the LongTable, with the\n#'   `longTableDataMapper' attribute containg the metadata needed to reverse\n#'   the coercing operation.\n#'\n#' @importFrom data.table data.table setDF\n#' @export\nsetAs('LongTable', 'data.frame', def=function(from) {\n    DT <- as(from, 'data.table')\n    setDF(DT)\n    return(DT)\n})\n\n# #' @title Coerce a LongTable to a data.frame\n# #' @name as\n# #'\n# #' @examples\n# #' as(merckLongTable, 'data.frame')\n# #'\n# #' @description S3 version of coerce method fro convenience.\n# #'\n# #' @param x `LongTable` to coerce to `data.frame`.\n# #' @param row.names An optional `character` vector of rownames. We do not\n# #'   recommend using this parameter, it is included for S3 method consistency\n# #'   with `as.data.frame`.\n# #' @param optional `logical` Is it optional for row and column names to be\n# #'   valid R names? If FALSE will use the make.names function to ensure the\n# #'   row and column names are valid R names. Defaults to TRUE.\n# #' @param ... Does nothing.\n# #'\n# #' @param from `LongTable` Object to coerce.\n# #' \n# #' @return `data.frame` containing the data from the LongTable, with the\n# #'   `longTableDataMapper' attribute containg the metadata needed to reverse\n# #'   the coercion operation.\n# #'\n# #' @importFrom data.table data.table\n# #' @export\n# as.data.frame.long.table <- function(x, row.names, optional=TRUE, ...) {\n#     DF <- as(x, 'data.frame')\n#     if (!missing(row.names)) {\n#         if (!is.character(x) || length(row.names) != nrow(DF))\n#             stop(.errorMsg('[CoreGx::as.data.frame.LongTable] The row.names ',\n#                 'argument must be a character vector with length equal to ',\n#                 nrow(DF)))\n#         if (!optional) {\n#             row.names <- make.names(row.names)\n#             colnames(DF) <- make.names(colnames(DF))\n#         }\n#         rownames(DF) <- row.names\n#     }\n#     DF\n# }\n\n\n#' @title Coerce to data.table to LongTable\n#' @name as\n#'\n#' @examples\n#' dataTable <- as(merckLongTable, 'data.table')\n#' print(attr(dataTable, 'longTableDataMapper')) # Method doesn't work without this\n#' as(dataTable, 'LongTable')\n#'\n#' @description Coerce a data.table with the proper configuration attributes\n#'   back to a LongTable\n#'\n#' @param from A `data.table` with the 'longTableDataMapper' attribute, containing\n#'   three lists named assayCols, rowDataCols and colDataCols. This attribute is\n#'   automatically created when coercing from a `LongTable` to a `data.table`.\n#'\n#' @return `LongTable` object configured with the longTableDataMapper\n#'\n#' @export\nsetAs('data.table', 'LongTable', def=function(from) {\n\n    if (!('longTableDataMapper' %in% names(attributes(from))))\n        stop(.errorMsg('[CoreGx::as,data.table,LongTable] Coercing from ',\n            'data.table to LongTable only works if the longTableMapper ',\n            'attribute has been set!'))\n\n    longTableMapper <- attr(from, 'longTableDataMapper')\n\n    requiredConfig <- c('assayMap', 'rowDataMap', 'colDataMap')\n    hasRequiredConfig <- vapply(requiredConfig,\n        FUN=\\(x, f) length(do.call(f, list(x)))[[1]] > 0,\n        x=longTableMapper, FUN.VALUE=logical(1))\n    if (!all(hasRequiredConfig))\n        stop(.errorMsg('The longTableDataMapper object is missing data from',\n            'the ', paste0(requiredConfig[!hasRequiredConfig], collapse=', '),\n            ' slots! Check attributes(from).'))\n\n    rawdata(longTableMapper) <- from\n    return(metaConstruct(longTableMapper))\n})\n#' @name as.long.table\n#' @title Coerce from data.table to LongTable\n#'\n#' @examples\n#' dataTable <- as(merckLongTable, 'data.table')\n#' print(attr(dataTable, 'longTableDataMapper')) # Method doesn't work without this\n#' as.long.table(dataTable)\n#'\n#' @description Coerce a data.table with the proper configuration attributes\n#'   back to a LongTable\n#'\n#' @param x A `data.frame` with the 'longTableDataMapper' attribute, containing\n#'  three lists named assayCols, rowDataCols and colDataCols. This attribute\n#'  is automatically created when coercing from a LongTable to a data.table.\n#'\n#' @return `LongTable` object configured with the longTableDataMapper\n#' @export\nas.long.table <- function(x) as(x, 'LongTable')\n\n\n#' @name as\n#' @title Coerce a SummarizedExperiment to a data.table\n#'\n#' @examples\n#' SE <- molecularProfilesSlot(clevelandSmall_cSet)[[1]]\n#' as(SE, 'data.table')\n#'\n#' @param from `SummarizedExperiment` object.\n#'\n#' @return `data.table` with long format of data in `from`\n#'\n#' @importFrom data.table as.data.table melt.data.table merge.data.table\n#' @export\nsetAs(from='SummarizedExperiment', to='data.table', function(from) {\n    # -- extract sample metadata\n    colDT <- as.data.table(colData(from), keep.rownames='.sample')\n    # -- extract feature metadata\n    rowDT <- as.data.table(rowData(from), keep.rownames='.feature')\n    # -- extract and process assays\n    assayL <- assays(from)\n    assayDtL <- lapply(assayL, as.data.table, keep.rownames='.feature')\n    meltDtL <- lapply(assayDtL, melt, id.vars='.feature',\n        variable.name='.sample', variable.factor=FALSE)\n    assayDT <- meltDtL[[1]][, .(.sample, .feature)]\n    for (i in seq_along(meltDtL))\n        assayDT[[names(assayL)[[i]]]] <- meltDtL[[i]][['value']]\n    # -- merge into a single long format table\n    DT <- merge.data.table(assayDT, colDT, by='.sample')\n    DT <- merge.data.table(DT, rowDT, by='.feature')\n    # -- add metadata\n    metadata <- metadata(from)\n    notS4 <- !vapply(metadata, isS4, logical(1))\n    if (!all(notS4))\n        .warning('Dropped S4 metadata during coercion to data.table!')\n    for (name in names(metadata)[notS4]) assayDT[[name]] <- metadata[[name]]\n    return(DT)\n})\n\n#' @name as\n#' @title Coerce a SummarizedExperiment to a data.frame\n#'\n#' @examples\n#' SE <- molecularProfilesSlot(clevelandSmall_cSet)[[1]]\n#' as(SE, 'data.frame')\n#'\n#' @param from `SummarizedExperiment` object.\n#'\n#' @return `data.frame` with long format of data in `from`.\n#'\n#' @importFrom data.table as.data.table melt.data.table merge.data.table\n#' @export\nsetAs(from='SummarizedExperiment', to='data.frame', function(from) {\n    setDF(as(from, 'data.table'))\n})\n\n\n#' @title Coerce a `LongTable` into a `SummarizedExperiment`\n#' @name as\n#'\n#' @param from `LongTable` object coerce to a `SummarizedExperiment`. Assays\n#'   are converted to `BumpyMatrix`es to allow treatment combination support\n#'   and integration with the `gDR` package.\n#'\n#' @return `SummarizedExperiment` with each assay as a `BumpyMatrix`\n#'\n#' @seealso [`BumpyMatrix::BumpyMatrix`]\n#'\n#' @md\n#' @importFrom SummarizedExperiment SummarizedExperiment\n#' @export\nsetAs(\"LongTable\", \"SummarizedExperiment\", def=function(from) {\n    .longTableToSummarizedExperiment(from, assay_names=assayNames(from))\n})\n\n\n#' @title Convert a LongTable assay into a BumpyMatrix object\n#'\n#' @param LT `LongTable` with assay to convert into `BumpyMatrix`\n#' @param assay `character(1)` A valid assay name in `LT`, as returned by\n#'     `assayNames(LT)`.\n#' @param rows `character()` The rownames associated with the assay rowKey\n#' @param cols `character()` The names associated with the assay colKey\n#' @param sparse `logical(1)` Should the `BumpyMatrix` be sparse (i.e., is the\n#'   assay sparse).\n#'\n#' @return `BumpyMatrix` containing the data from `assay`.\n#'\n#' @md\n#' @importFrom data.table data.table\n#' @importFrom BumpyMatrix splitAsBumpyMatrix\n.assayToBumpyMatrix <- function(LT, assay, rows, cols, sparse=TRUE) {\n    assay_data <- assay(LT, assay, key=TRUE)\n    assay_data[, rownames := rows[rowKey]]\n    assay_data[, colnames := cols[colKey]]\n    assay_data[, c('rowKey', 'colKey') := NULL]\n    splitAsBumpyMatrix(assay_data[, -c('rownames', 'colnames')],\n        row=assay_data$rownames, column=assay_data$colnames, sparse)\n}\n\n#' Convert LongTable to gDR Style SummarizedExperiment\n#'\n#' @param LT `LongTable` to convert to gDR `SummarizedExperiment` format.\n#' @param assay_names `character()` Names to rename the assays to. These\n#'   are assumed to be in the same order as `assayNames(LT)`.\n#'\n#' @return `SummarizedExperiment` object with all assay from `LT` as\n#'   `BumpyMatrix`es.\n#'\n#' @md\n#' @importFrom data.table setnames\n#' @importFrom SummarizedExperiment SummarizedExperiment\n.longTableToSummarizedExperiment <- function(LT, assay_names) {\n    assay_list <- lapply(assayNames(LT), FUN=.assayToBumpyMatrix,\n        LT=LT, rows=rownames(LT), cols=colnames(LT))\n    if (!missing(assay_names) && length(assay_names) == length(assayNames(LT)))\n        names(assay_list) <- assay_names\n    SummarizedExperiment(\n        assays=assay_list, rowData=rowData(LT), colData=colData(LT),\n            metadata=c(metadata(LT), list(.intern=as.list(getIntern(LT))))\n    )\n}\n\n#' @name as\n#'\n#' @title\n#' Coerce a `LongTableDataMapper` to a `TREDataMapper`\n#'\n#' @param from A `LongTableDataMapper` to coerce.\n#'\n#' @return A `TREDataMapper` object.\n#'\n#' @md\n#' @export\nsetAs(\"LongTableDataMapper\", \"TREDataMapper\", def=function(from) {\n    TREDataMapper(from)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `setAs('LongTable', 'data.table', ...)` method in this code?",
        "answer": "The `setAs('LongTable', 'data.table', ...)` method is used to coerce a LongTable object into a data.table. It extracts assay data, joins multiple assays into a single table, merges row and column data, and organizes the columns. The resulting data.table includes a 'longTableDataMapper' attribute for reverse coercion."
      },
      {
        "question": "How does the code handle duplicate column names between assays when coercing a LongTable to a data.table?",
        "answer": "The code handles duplicate column names by appending suffixes to the duplicate columns. It uses a helper function `.paste0IfElse` to add '._n' suffixes (where n is the assay index minus 1) to duplicate column names. This ensures that all column names in the resulting data.table are unique."
      },
      {
        "question": "What is the purpose of the `longTableDataMapper` attribute in the resulting data.table, and how is it created?",
        "answer": "The `longTableDataMapper` attribute is created to store metadata needed for reverse coercion from data.table back to LongTable. It is an instance of `LongTableDataMapper` class, containing mappings for row data, column data, assays, and metadata. This attribute is essential for preserving the structure and relationships of the original LongTable when converting back from data.table."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setAs('LongTable', 'data.table', def=function(from) {\n    longTableData <- assays(from, withDimnames=FALSE, key=TRUE)\n    DT <- longTableData[[1]]\n    longTableData[[1]] <- NULL\n    for (i in seq_along(longTableData)) {\n        DT <- merge.data.table(DT, longTableData[[i]],\n            suffixes=c('', paste0('._', i)), by=.EACHI, all.x=TRUE, all.y=TRUE)\n    }\n    assayCols <- assayCols(from)\n    # TODO: Complete the function\n})",
        "complete": "setAs('LongTable', 'data.table', def=function(from) {\n    longTableData <- assays(from, withDimnames=FALSE, key=TRUE)\n    DT <- longTableData[[1]]\n    longTableData[[1]] <- NULL\n    for (i in seq_along(longTableData)) {\n        DT <- merge.data.table(DT, longTableData[[i]],\n            suffixes=c('', paste0('._', i)), by=.EACHI, all.x=TRUE, all.y=TRUE)\n    }\n    assayCols <- assayCols(from)\n    .greplAny <- function(...) any(grepl(...))\n    .paste0IfElse <- function(vector, suffix, isIn=c('rowKey', 'colKey'))\n        ifelse(vector %in% isIn, vector, paste0(vector, suffix))\n    hasSuffixes <- unlist(lapply(paste0('._', seq_along(longTableData)),\n        FUN=.greplAny, x=colnames(DT)))\n    if (any(hasSuffixes)) {\n        whichHasSuffixes <- which(hasSuffixes) + 1\n        assayCols[whichHasSuffixes] <-\n            Map(FUN=.paste0IfElse,\n                vector=assayCols[whichHasSuffixes],\n                suffix=paste0('._', seq_along(longTableData))[hasSuffixes]\n            )\n    }\n    DT <- merge.data.table(DT, rowData(from, key=TRUE), by='rowKey')\n    DT <- merge.data.table(DT, colData(from, key=TRUE), by='colKey')\n    setkeyv(DT, c('rowKey', 'colKey'))\n    DT[, c('rowKey', 'colKey') := NULL]\n    colOrder <- unique(c(setdiff(\n        colnames(DT), unlist(assayCols)),\n        unlist(assayCols)\n    ))\n    setcolorder(DT, colOrder)\n    aMap <- lapply(assayCols, FUN=setdiff,\n        y=c(idCols(from), rowMeta(from), colMeta(from)))\n    aMap <- Map(list, mutable(getIntern(from, \"assayKeys\")), aMap)\n    DT <- cbind(DT, metadata(from)$experiment_metadata)\n    metaCols <- names(metadata(from)$experiment_metadata)\n    longTableMapper <- LongTableDataMapper(\n        rowDataMap=list(rowIDs(from), rowMeta(from)),\n        colDataMap=list(colIDs(from), colMeta(from)),\n        assayMap=aMap,\n        metadataMap=if (is.character(metaCols)) list(metaCols) else list()\n    )\n    metadata(longTableMapper) <- metadata(from)[names(metadata(from) != \"experiment_metadata\")]\n    attr(DT, 'longTableDataMapper') <- longTableMapper\n    return(DT)\n})"
      },
      {
        "partial": "setAs('data.table', 'LongTable', def=function(from) {\n    if (!('longTableDataMapper' %in% names(attributes(from))))\n        stop(.errorMsg('[CoreGx::as,data.table,LongTable] Coercing from ',\n            'data.table to LongTable only works if the longTableMapper ',\n            'attribute has been set!'))\n    longTableMapper <- attr(from, 'longTableDataMapper')\n    # TODO: Complete the function\n})",
        "complete": "setAs('data.table', 'LongTable', def=function(from) {\n    if (!('longTableDataMapper' %in% names(attributes(from))))\n        stop(.errorMsg('[CoreGx::as,data.table,LongTable] Coercing from ',\n            'data.table to LongTable only works if the longTableMapper ',\n            'attribute has been set!'))\n    longTableMapper <- attr(from, 'longTableDataMapper')\n    requiredConfig <- c('assayMap', 'rowDataMap', 'colDataMap')\n    hasRequiredConfig <- vapply(requiredConfig,\n        FUN=\\(x, f) length(do.call(f, list(x)))[[1]] > 0,\n        x=longTableMapper, FUN.VALUE=logical(1))\n    if (!all(hasRequiredConfig))\n        stop(.errorMsg('The longTableDataMapper object is missing data from',\n            'the ', paste0(requiredConfig[!hasRequiredConfig], collapse=', '),\n            ' slots! Check attributes(from).'))\n    rawdata(longTableMapper) <- from\n    return(metaConstruct(longTableMapper))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/rankGeneRadSensitivity.R",
    "language": "R",
    "content": "#' Rank genes based on radiation effect in the Connectivity Map\n#'\n#' @param data gene expression data matrix\n#' @param drugpheno sensititivity values fo thr drug of interest\n#' @param type cell or tissue type for each experiment\n#' @param batch experiment batches\n#' @param single.type Should the statitsics be computed for each cell/tissue\n#'   type separately?\n#' @param standardize How to standardize the data? Currently only supports \"SD\"\n#' @param nthread  number of parallel threads (bound to the maximum number of cores available)\n#' @param verbose Should details of function operation be printed to console?\n#'\n#' @return A \\code{list} of data.frames with the statistics for each gene, for\n#'   each type\n#'\n#' @importFrom stats complete.cases\n#' @importFrom stats p.adjust\n#'\n#' @noRd\nrankGeneRadSensitivity <- function(data,\n                                     drugpheno,\n                                     type, batch,\n                                     single.type=FALSE,\n                                     standardize = \"SD\",\n                                     nthread=1,\n                                     verbose=FALSE)\n{\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n    drugpheno <- data.frame(drugpheno)\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  res <- NULL\n  utype <- sort(unique(as.character(type)))\n  ltype <- list(\"all\"=utype)\n  if (single.type) {\n    ltype <- c(ltype, as.list(utype))\n    names(ltype)[-1] <- utype\n  }\n  res <- NULL\n  ccix <- complete.cases(data, type, batch, drugpheno)\n  nn <- sum(ccix)\n  if(!any(unlist(lapply(drugpheno,is.factor)))){\n     if(ncol(drugpheno)>1){\n      ##### FIX NAMES!!!\n      nc <- lapply(seq_len(ncol(drugpheno)), function(i){\n\n        est <- paste(\"estimate\", i, sep=\".\")\n        se <-  paste(\"se\", i, sep=\".\")\n        tstat <- paste(\"tstat\", i, sep=\".\")\n\n        nc <- c(est, se, tstat)\n        return(nc)\n\n      })\n      #nc <- do.call(c, rest)\n      nc  <- c(nc, n=nn, \"fstat\"=NA, \"pvalue\"=NA, \"fdr\")\n    } else {\n      nc  <- c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\", \"fdr\")\n    }\n  } else {\n    nc  <- c(\"estimate\", \"se\", \"n\", \"pvalue\", \"fdr\")\n  }\n\n  for (ll in seq_along(ltype)) {\n    iix <- !is.na(type) & is.element(type, ltype[[ll]])\n\n    data.not.all.na <- apply(data[iix,,drop=FALSE], 1, function(x) {\n      any(!is.na(x))\n    })\n    drugpheno.not.all.na <- apply(drugpheno[iix,,drop=FALSE], 1, function(x) {\n      any(!is.na(x))\n    })\n    type.not.na <- !is.na(type[iix])\n    batch.not.na <- !is.na(batch[iix])\n\n    ccix <- data.not.all.na & drugpheno.not.all.na & type.not.na & batch.not.na\n\n    if (sum(ccix) < 3) {\n      ## not enough experiments\n      rest <- list(matrix(NA, nrow=ncol(data), ncol=length(nc), dimnames=list(colnames(data), nc)))\n      res <- c(res, rest)\n    } else {\n      splitix <- parallel::splitIndices(nx=ncol(data), ncl=nthread)\n      splitix <- splitix[vapply(splitix, length, numeric(1)) > 0]\n      mcres <- BiocParallel::bplapply(splitix, function(x, data, type, batch, drugpheno, standardize) {\n        res <- t(apply(data[ , x, drop=FALSE], 2, geneRadSensitivity, type=type, batch=batch, drugpheno=drugpheno, verbose=verbose, standardize=standardize))\n        return(res)\n      }, data=data[iix, , drop=FALSE], type=type[iix], batch=batch[iix], drugpheno=drugpheno[iix,,drop=FALSE], standardize=standardize)\n      rest <- do.call(rbind, mcres)\n      rest <- cbind(rest, \"fdr\"=p.adjust(rest[ , \"pvalue\"], method=\"fdr\"))\n      res <- c(res, list(rest))\n    }\n  }\n  names(res) <- names(ltype)\n  return(res)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `rankGeneRadSensitivity` function, and what are its main input parameters?",
        "answer": "The `rankGeneRadSensitivity` function is designed to rank genes based on radiation effect in the Connectivity Map. Its main input parameters are:\n1. `data`: gene expression data matrix\n2. `drugpheno`: sensitivity values for the drug of interest\n3. `type`: cell or tissue type for each experiment\n4. `batch`: experiment batches\n5. `single.type`: boolean to determine if statistics should be computed for each cell/tissue type separately\n6. `standardize`: method to standardize the data (currently only supports 'SD')\n7. `nthread`: number of parallel threads for computation\n8. `verbose`: boolean to control printing of operation details to console"
      },
      {
        "question": "How does the function handle parallel processing, and what precautions are taken regarding the number of threads?",
        "answer": "The function handles parallel processing by:\n1. Checking if `nthread` is not 1\n2. Detecting available cores using `parallel::detectCores()`\n3. Setting `nthread` to the number of available cores if it's missing, less than 1, or greater than available cores\n4. Setting multicore options using `options(mc.cores=nthread)`\n5. Using `on.exit(options(op))` to restore original options when the function exits\n\nPrecautions:\n- The function ensures that the number of threads doesn't exceed the available cores\n- It temporarily modifies global options for multicore processing and restores them afterward"
      },
      {
        "question": "Explain the purpose of the `splitix` variable and how it's used in the parallel computation of gene radiation sensitivity.",
        "answer": "The `splitix` variable is used to divide the computation workload for parallel processing:\n\n1. It's created using `parallel::splitIndices(nx=ncol(data), ncl=nthread)`, which splits the column indices of the data matrix into chunks based on the number of threads.\n\n2. Empty chunks are removed with `splitix <- splitix[vapply(splitix, length, numeric(1)) > 0]`.\n\n3. It's then used in `BiocParallel::bplapply()` to apply the `geneRadSensitivity` function to subsets of the data columns in parallel:\n   ```R\n   mcres <- BiocParallel::bplapply(splitix, function(x, data, type, batch, drugpheno, standardize) {\n     res <- t(apply(data[ , x, drop=FALSE], 2, geneRadSensitivity, type=type, batch=batch, drugpheno=drugpheno, verbose=verbose, standardize=standardize))\n     return(res)\n   }, data=data[iix, , drop=FALSE], type=type[iix], batch=batch[iix], drugpheno=drugpheno[iix,,drop=FALSE], standardize=standardize)\n   ```\n\nThis approach allows for efficient parallel computation of gene radiation sensitivity across the entire dataset."
      }
    ],
    "completion_tasks": [
      {
        "partial": "rankGeneRadSensitivity <- function(data, drugpheno, type, batch, single.type=FALSE, standardize = \"SD\", nthread=1, verbose=FALSE) {\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n    drugpheno <- data.frame(drugpheno)\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  # Complete the function here\n}",
        "complete": "rankGeneRadSensitivity <- function(data, drugpheno, type, batch, single.type=FALSE, standardize = \"SD\", nthread=1, verbose=FALSE) {\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n    drugpheno <- data.frame(drugpheno)\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  res <- NULL\n  utype <- sort(unique(as.character(type)))\n  ltype <- list(\"all\"=utype)\n  if (single.type) {\n    ltype <- c(ltype, as.list(utype))\n    names(ltype)[-1] <- utype\n  }\n\n  ccix <- complete.cases(data, type, batch, drugpheno)\n  nn <- sum(ccix)\n  nc <- if(!any(unlist(lapply(drugpheno,is.factor)))) {\n    if(ncol(drugpheno)>1) {\n      c(unlist(lapply(seq_len(ncol(drugpheno)), function(i) {\n        c(paste0(c(\"estimate\", \"se\", \"tstat\"), \".\", i))\n      })), \"n\", \"fstat\", \"pvalue\", \"fdr\")\n    } else {\n      c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\", \"fdr\")\n    }\n  } else {\n    c(\"estimate\", \"se\", \"n\", \"pvalue\", \"fdr\")\n  }\n\n  res <- lapply(ltype, function(lt) {\n    iix <- !is.na(type) & is.element(type, lt)\n    ccix <- apply(data[iix,,drop=FALSE], 1, function(x) any(!is.na(x))) &\n            apply(drugpheno[iix,,drop=FALSE], 1, function(x) any(!is.na(x))) &\n            !is.na(type[iix]) & !is.na(batch[iix])\n    \n    if (sum(ccix) < 3) {\n      return(matrix(NA, nrow=ncol(data), ncol=length(nc), dimnames=list(colnames(data), nc)))\n    }\n    \n    splitix <- parallel::splitIndices(nx=ncol(data), ncl=nthread)\n    mcres <- BiocParallel::bplapply(splitix[lengths(splitix) > 0], function(x) {\n      t(apply(data[iix, x, drop=FALSE], 2, geneRadSensitivity, type=type[iix], batch=batch[iix], drugpheno=drugpheno[iix,,drop=FALSE], verbose=verbose, standardize=standardize))\n    })\n    rest <- do.call(rbind, mcres)\n    cbind(rest, \"fdr\"=p.adjust(rest[, \"pvalue\"], method=\"fdr\"))\n  })\n\n  return(res)\n}"
      },
      {
        "partial": "geneRadSensitivity <- function(x, type, batch, drugpheno, verbose=FALSE, standardize=\"SD\") {\n  # Implement the function body here\n}",
        "complete": "geneRadSensitivity <- function(x, type, batch, drugpheno, verbose=FALSE, standardize=\"SD\") {\n  ccix <- complete.cases(x, type, batch, drugpheno)\n  x <- x[ccix]\n  type <- type[ccix]\n  batch <- batch[ccix]\n  drugpheno <- drugpheno[ccix, , drop=FALSE]\n\n  if (length(x) < 3) return(rep(NA, 7))\n\n  if (standardize == \"SD\") {\n    x <- scale(x)\n  }\n\n  if (is.factor(drugpheno[,1])) {\n    fit <- try(summary(lm(x ~ drugpheno[,1] + type + batch)))\n  } else {\n    fit <- try(summary(lm(x ~ drugpheno + type + batch)))\n  }\n\n  if (inherits(fit, \"try-error\")) return(rep(NA, 7))\n\n  coef <- fit$coefficients[2, ]\n  c(coef[1:2], n=nrow(fit$model), coef[3:4], fit$fstatistic[1], fit$df[2])\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/summarizeMolecularProfiles-methods.R",
    "language": "R",
    "content": "#' Takes molecular data from a RadioSet, and summarises them\n#' into one entry per drug\n#'\n#' Given a RadioSet with molecular data, this function will summarize\n#' the data into one profile per cell line, using the chosed summary.stat. Note\n#' that this does not really make sense with perturbation type data, and will\n#' combine experiments and controls when doing the summary if run on a\n#' perturbation dataset.\n#'\n#' @examples\n#' data(clevelandSmall)\n#' clevelandSmall <- summarizeMolecularProfiles(clevelandSmall,\n#'                     mDataType = \"rna\", cell.lines=sampleNames(clevelandSmall),\n#'                     summary.stat = 'median', fill.missing = TRUE, verbose=TRUE)\n#' clevelandSmall\n#'\n#' @param object \\code{RadioSet} The RadioSet to summarize\n#' @param mDataType \\code{character} which one of the molecular data types\n#' to use in the analysis, out of all the molecular data types available for the rSet\n#' for example: rna, rnaseq, snp\n#' @param cell.lines \\code{character} The cell lines to be summarized.\n#'   If any cell.line has no data, missing values will be created\n#' @param features \\code{caracter} A vector of the feature names to include in the summary\n#' @param summary.stat \\code{character} which summary method to use if there are repeated\n#'   cell.lines? Choices are \"mean\", \"median\", \"first\", or \"last\"\n#'   In case molecular data type is mutation or fusion \"and\" and \"or\" choices are available\n#' @param fill.missing \\code{boolean} should the missing cell lines not in the\n#'   molecular data object be filled in with missing values?\n#' @param summarize A flag which when set to FALSE (defaults to TRUE) disables\n#'   summarizing and returns the data unchanged as a ExpressionSet\n#' @param verbose \\code{boolean} should messages be printed\n#' @return \\code{matrix} An updated RadioSet with the molecular data summarized\n#'   per cell line.\n#'\n#' @importMethodsFrom CoreGx summarizeMolecularProfiles\n#' @export\nsetMethod('summarizeMolecularProfiles',\n          signature(object='RadioSet'),\n          function(object, mDataType, cell.lines, features, summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                   fill.missing=TRUE, summarize=TRUE, verbose=TRUE) {\n              .summarizeMolecularProfilesRadioSet(object=object, mDataType=mDataType, cell.lines=cell.lines,\n                                                   features=features, summary.stat=summary.stat,\n                                                   fill.missing=fill.missing, summarize=summarize, verbose=verbose)\n          })\n\n# Takes molecular data from a RadioSet, and summarises them\n# into one entry per drug\n#\n# Given a RadioSet with molecular data, this function will summarize\n# the data into one profile per cell line, using the chosed summary.stat. Note\n# that this does not really make sense with perturbation type data, and will\n# combine experiments and controls when doing the summary if run on a\n# perturbation dataset.\n#\n# @examples\n# data(clevelandSmall)\n# clevelandSmall <- summarizeMolecularProfiles(clevelandSmall,\n#                     mDataType = \"rna\", cell.lines=sampleNames(clevelandSmall),\n#                     summary.stat = 'median', fill.missing = TRUE, verbose=TRUE)\n# clevelandSmall\n#\n# @param object \\code{RadioSet} The RadioSet to summarize\n# @param mDataType \\code{character} which one of the molecular data types\n# to use in the analysis, out of all the molecular data types available for the rSet\n# for example: rna, rnaseq, snp\n# @param cell.lines \\code{character} The cell lines to be summarized.\n#   If any cell.line has no data, missing values will be created\n# @param features \\code{caracter} A vector of the feature names to include in the summary\n# @param summary.stat \\code{character} which summary method to use if there are repeated\n#   cell.lines? Choices are \"mean\", \"median\", \"first\", or \"last\"\n#   In case molecular data type is mutation or fusion \"and\" and \"or\" choices are available\n# @param fill.missing \\code{boolean} should the missing cell lines not in the\n#   molecular data object be filled in with missing values?\n# @param summarize A flag which when set to FALSE (defaults to TRUE) disables\n#   summarizing and returns the data unchanged as a ExpressionSet\n# @param verbose \\code{boolean} should messages be printed\n# @return \\code{matrix} An updated RadioSet with the molecular data summarized\n#   per cell line.\n#\n#' @importFrom utils setTxtProgressBar txtProgressBar\n#' @importFrom SummarizedExperiment SummarizedExperiment rowData rowData<- colData colData<- assays assays<- assayNames assayNames<-\n#' @importFrom Biobase AnnotatedDataFrame\n#' @importFrom matrixStats rowMeans2 rowMedians\n#' @keywords internal\n.summarizeMolecularProfilesRadioSet <- function(object,\n                                       mDataType,\n                                       cell.lines,\n                                       features,\n                                       summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                                       fill.missing=TRUE,\n                                       summarize=TRUE,\n                                       verbose=TRUE) {\n\n\n  ### Placed here to make sure the object argument gets checked first by R.\n  mDataTypes <- names(molecularProfilesSlot(object))\n  if (!(mDataType %in% mDataTypes)) {\n    stop (sprintf(\"Invalid mDataType, choose among: %s\", paste(names(molecularProfilesSlot(object)), collapse=\", \")))\n  }\n\n  if(summarize==FALSE){\n    return(molecularProfilesSlot(object)[[mDataType]])\n  }\n\n  if (missing(features)) {\n    features <- rownames(featureInfo(object, mDataType))\n  } else {\n    fix <- is.element(features, rownames(featureInfo(object, mDataType)))\n    if (verbose && !all(fix)) {\n      warning (sprintf(\"Only %i/%i features can be found\", sum(fix), length(features)))\n    }\n    features <- features[fix]\n  }\n\n  summary.stat <- match.arg(summary.stat)\n  if((!S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation %in% c(\"mutation\",\"fusion\")) & (!summary.stat %in% c(\"mean\", \"median\", \"first\", \"last\"))) {\n    stop (\"Invalid summary.stat, choose among: mean, median, first, last\" )\n  }\n  if((S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation %in% c(\"mutation\",\"fusion\")) & (!summary.stat %in% c(\"and\", \"or\"))) {\n    stop (\"Invalid summary.stat, choose among: and, or\" )\n  }\n\n  if (missing(cell.lines)) {\n    cell.lines <- sampleNames(object)\n  }\n\n  dd <- molecularProfiles(object, mDataType)\n  pp <- phenoInfo(object, mDataType)\n\n  if(S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation == \"mutation\") {\n    tt <- dd\n    tt[which(!is.na(dd) & dd ==\"wt\")] <- FALSE\n    tt[which(!is.na(dd) & dd !=\"wt\")] <- TRUE\n    tt <- apply(tt, 2, as.logical)\n    dimnames(tt) <- dimnames(dd)\n    dd <- tt\n  }\n  if(S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation == \"fusion\") {\n    tt <- dd\n    tt[which(!is.na(dd) & dd ==\"0\")] <- FALSE\n    tt[which(!is.na(dd) & dd !=\"0\")] <- TRUE\n    tt <- apply(tt, 2, as.logical)\n    dimnames(tt) <- dimnames(dd)\n    dd <- tt\n  }\n  if (any(colnames(dd) != rownames(pp))) {\n    warning (\"Samples in phenodata and expression matrices must be ordered the same way\")\n    dd <- dd[ , rownames(pp), drop=FALSE]\n  }\n  if (!fill.missing) {\n    cell.lines <- intersect(cell.lines, unique(pp[!is.na(pp[ , \"sampleid\"]), \"sampleid\"]))\n  }\n  if (length(cell.lines) == 0) {\n    stop (\"No cell lines in common\")\n  }\n\n  ## select profiles with no replicates\n  duplix <- unique(pp[!is.na(pp[ , \"sampleid\"]) & duplicated(pp[ , \"sampleid\"]), \"sampleid\"])\n  ucell <- setdiff(cell.lines, duplix)\n\n  ## keep the non ambiguous cases\n  dd2 <- dd[ , match(ucell, pp[ , \"sampleid\"]), drop=FALSE]\n  pp2 <- pp[match(ucell, pp[ , \"sampleid\"]), , drop=FALSE]\n  if (length(duplix) > 0) {\n    if (verbose) {\n      message(sprintf(\"Summarizing %s molecular data for:\\t%s\", mDataType, annotation(object)$name))\n      total <- length(duplix)\n      # create progress bar\n      pb <- utils::txtProgressBar(min=0, max=total, style=3)\n      i <- 1\n    }\n    ## replace factors by characters to allow for merging duplicated experiments\n    pp2 <- apply(pp2, 2, function (x) {\n      if (is.factor(x)) {\n        return (as.character(x))\n      } else {\n        return (x)\n      }\n    })\n    ## there are some replicates to collapse\n    for (x in duplix) {\n      myx <- which(!is.na(pp[ , \"sampleid\"]) & is.element(pp[ , \"sampleid\"], x))\n      switch(summary.stat,\n        \"mean\" = {\n          ddt <- rowMeans2(dd[ , myx, drop=FALSE])\n        },\n        \"median\"={\n          ddt <- rowMedians(dd[ , myx, drop=FALSE])\n        },\n        \"first\"={\n          ddt <- dd[ , myx[1], drop=FALSE]\n        },\n        \"last\" = {\n          ddt <- dd[ , myx[length(myx)], drop=FALSE]\n        },\n        \"and\" = {\n          ddt <- apply(dd[ , myx, drop=FALSE], 1, function(x) do.call(`&`, as.list(x)))\n        },\n        \"or\" = {\n          ddt <- apply(dd[ , myx, drop=FALSE], 1, function(x) do.call(`|`, as.list(x)))\n        }\n      )\n      ppt <- apply(pp[myx, , drop=FALSE], 2, function (x) {\n        x <- paste(unique(as.character(x[!is.na(x)])), collapse=\"///\")\n        return (x)\n      })\n      ppt[!is.na(ppt) & ppt == \"\"] <- NA\n      dd2 <- cbind(dd2, ddt)\n      pp2 <- rbind(pp2, ppt)\n      if (verbose){\n        utils::setTxtProgressBar(pb, i)\n        i <- i + 1\n      }\n    }\n    if (verbose) {\n      close(pb)\n    }\n  }\n  colnames(dd2) <- rownames(pp2) <- c(ucell, duplix)\n\n  ## reorder cell lines\n  dd2 <- dd2[ , cell.lines, drop=FALSE]\n  pp2 <- pp2[cell.lines, , drop=FALSE]\n  pp2[ , \"sampleid\"] <- cell.lines\n  res <- molecularProfilesSlot(object)[[mDataType]]\n  if(S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation %in% c(\"mutation\", \"fusion\")) {\n    tt <- dd2\n    tt[which(!is.na(dd2) & dd2)] <- \"1\"\n    tt[which(!is.na(dd2) & !dd2)] <- \"0\"\n    dd2 <- tt\n  }\n  res <- SummarizedExperiment::SummarizedExperiment(dd2)\n  pp2 <- S4Vectors::DataFrame(pp2, row.names=rownames(pp2))\n  pp2$tissueid <- sampleInfo(object)[pp2$sampleid, \"tissueid\"]\n  SummarizedExperiment::colData(res) <- pp2\n  SummarizedExperiment::rowData(res) <- featureInfo(object, mDataType)\n  ##TODO:: Generalize this to multiple assay SummarizedExperiments!\n  if(!is.null(SummarizedExperiment::assay(res, 1))) {\n    SummarizedExperiment::assay(res, 2) <-\n      matrix(rep(NA, length(assay(res, 1))),\n             nrow=nrow(assay(res, 1)),\n             ncol=ncol(assay(res, 1)),\n             dimnames=dimnames(assay(res, 1))\n      )\n  }\n  assayNames(res) <- assayNames(molecularProfilesSlot(object)[[mDataType]])\n  res <- res[features,]\n  S4Vectors::metadata(res) <- S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])\n  return(res)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `summarizeMolecularProfiles` function in the given code snippet?",
        "answer": "The `summarizeMolecularProfiles` function is designed to summarize molecular data from a RadioSet object into one profile per cell line. It takes molecular data and condenses it using a specified summary statistic (e.g., mean, median, first, or last). This function is particularly useful for summarizing data when there are repeated cell lines, allowing for a more concise representation of the molecular profiles."
      },
      {
        "question": "How does the function handle different types of molecular data, particularly for mutation and fusion data?",
        "answer": "For mutation and fusion data, the function uses a different approach. Instead of using mean, median, first, or last as summary statistics, it offers 'and' and 'or' options. For mutation data, it converts 'wt' (wild type) to FALSE and any other value to TRUE. For fusion data, it converts '0' to FALSE and any other value to TRUE. This boolean representation allows for logical operations ('and' or 'or') to be applied when summarizing the data across replicates."
      },
      {
        "question": "What is the significance of the `fill.missing` parameter in the `summarizeMolecularProfiles` function?",
        "answer": "The `fill.missing` parameter is a boolean flag that determines how the function handles cell lines that are not present in the molecular data object. When set to TRUE (default), the function will create entries with missing values for these cell lines, ensuring that all specified cell lines are represented in the output. If set to FALSE, the function will only include cell lines that have data in the molecular profiles, potentially resulting in fewer cell lines in the output than initially specified."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('summarizeMolecularProfiles',\n          signature(object='RadioSet'),\n          function(object, mDataType, cell.lines, features, summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                   fill.missing=TRUE, summarize=TRUE, verbose=TRUE) {\n              # Complete the function body\n          })",
        "complete": "setMethod('summarizeMolecularProfiles',\n          signature(object='RadioSet'),\n          function(object, mDataType, cell.lines, features, summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                   fill.missing=TRUE, summarize=TRUE, verbose=TRUE) {\n              .summarizeMolecularProfilesRadioSet(object=object, mDataType=mDataType, cell.lines=cell.lines,\n                                                   features=features, summary.stat=summary.stat,\n                                                   fill.missing=fill.missing, summarize=summarize, verbose=verbose)\n          })"
      },
      {
        "partial": ".summarizeMolecularProfilesRadioSet <- function(object, mDataType, cell.lines, features,\n                                       summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                                       fill.missing=TRUE, summarize=TRUE, verbose=TRUE) {\n  # Implement the function body\n}",
        "complete": ".summarizeMolecularProfilesRadioSet <- function(object, mDataType, cell.lines, features,\n                                       summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"and\", \"or\"),\n                                       fill.missing=TRUE, summarize=TRUE, verbose=TRUE) {\n  mDataTypes <- names(molecularProfilesSlot(object))\n  if (!(mDataType %in% mDataTypes)) {\n    stop(sprintf(\"Invalid mDataType, choose among: %s\", paste(names(molecularProfilesSlot(object)), collapse=\", \")))\n  }\n  if(summarize==FALSE) return(molecularProfilesSlot(object)[[mDataType]])\n  if (missing(features)) features <- rownames(featureInfo(object, mDataType))\n  else {\n    fix <- is.element(features, rownames(featureInfo(object, mDataType)))\n    if (verbose && !all(fix)) warning(sprintf(\"Only %i/%i features can be found\", sum(fix), length(features)))\n    features <- features[fix]\n  }\n  summary.stat <- match.arg(summary.stat)\n  if ((!S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation %in% c(\"mutation\",\"fusion\")) && (!summary.stat %in% c(\"mean\", \"median\", \"first\", \"last\"))) {\n    stop(\"Invalid summary.stat, choose among: mean, median, first, last\")\n  }\n  if ((S4Vectors::metadata(molecularProfilesSlot(object)[[mDataType]])$annotation %in% c(\"mutation\",\"fusion\")) && (!summary.stat %in% c(\"and\", \"or\"))) {\n    stop(\"Invalid summary.stat, choose among: and, or\")\n  }\n  if (missing(cell.lines)) cell.lines <- sampleNames(object)\n  dd <- molecularProfiles(object, mDataType)\n  pp <- phenoInfo(object, mDataType)\n  # ... (rest of the function implementation)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/gwc.R",
    "language": "R",
    "content": "## - http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient#Calculating_a_weighted_correlation\n## http://www.mathworks.com/matlabcentral/fileexchange/20846-weighted-correlation-matrix F. Pozzi, T. Di Matteo, T. Aste, 'Exponential\n## smoothing weighted correlations', The European Physical Journal B, Vol. 85, No 6, 2012. DOI: 10.1140/epjb/e2012-20697-x TODO:: Give\n## this function a more descriptive name\n#' GWC Score\n#' \n#' Calculate the gwc score between two vectors, using either a weighted spearman \n#'  or pearson correlation\n#'\n#' @examples\n#' data(clevelandSmall_cSet)\n#' x <- molecularProfiles(clevelandSmall_cSet,'rna')[,1]\n#' y <- molecularProfiles(clevelandSmall_cSet,'rna')[,2]\n#' x_p <- rep(0.05, times=length(x))\n#' y_p <- rep(0.05, times=length(y))\n#' names(x_p) <- names(x)\n#' names(y_p) <- names(y)\n#' gwc(x,x_p,y,y_p, nperm=100)\n#'\n#'@param x1 \\code{numeric} vector of effect sizes (e.g., fold change or t statitsics) for the first experiment\n#'@param p1 \\code{numeric} vector of p-values for each corresponding effect size for the first experiment\n#'@param x2 \\code{numeric} effect size (e.g., fold change or t statitsics) for the second experiment\n#'@param p2 \\code{numeric} vector of p-values for each corresponding effect size for the second experiment\n#'@param method.cor \\code{character} string identifying if a \\code{pearson} or\n#'\\code{spearman} correlation should be used\n#'@param nperm \\code{numeric} how many permutations should be done to determine\n#'@param truncate.p \\code{numeric} Truncation value for extremely low p-values\n#'@param ... Other passed down to internal functions\n#'\n#'@return \\code{numeric} a vector of two values, the correlation and associated p-value.\n#'@export\ngwc <- function(x1, p1, x2, p2, method.cor = c(\"pearson\", \"spearman\"), nperm = 10000, truncate.p = 1e-16, ...) {\n    method.cor <- match.arg(method.cor)\n    ## intersection between x and y\n    ii <- .intersectList(names(x1), names(p1), names(x2), names(p2))\n    if (length(ii) < 10) {\n        stop(\"Less than 10 probes/genes in common between x and y\")\n    }\n    x1 <- x1[ii]\n    p1 <- p1[ii]\n    x2 <- x2[ii]\n    p2 <- p2[ii]\n    ## truncate extremely low p-values\n    p1[!is.na(p1) & p1 < truncate.p] <- truncate.p\n    p2[!is.na(p2) & p2 < truncate.p] <- truncate.p\n    ## scaled weights\n    p1 <- -log10(p1)\n    p1 <- p1/sum(p1, na.rm = TRUE)\n    p2 <- -log10(p2)\n    p2 <- p2/sum(p2, na.rm = TRUE)\n    w <- p1 + p2\n    ## compute genome-wide connectivity score\n    res <- .corWeighted(x = x1, y = x2, w = w, method = method.cor, nperm = nperm, ...)\n    return(res)\n}\n\n#### Compute a weighted correlation coefficient inspired from package boot - TODO:: Write function documentation?\n#' @importFrom stats cov.wt complete.cases\n.corWeighted <- function(x, y, w, method = c(\"pearson\", \"spearman\"), alternative = c(\"two.sided\", \"greater\", \"less\"), nperm = 0, nthread = 1, \n    na.rm = FALSE) {\n    \n    ###################### \n    wcor <- function(d, w, na.rm = TRUE) {\n        CovM <- cov.wt(d, wt = w)[[\"cov\"]]\n        res <- CovM[1, 2]/sqrt(CovM[1, 1] * CovM[2, 2])\n        return(res)\n    }\n    \n    ###################### \n    \n    if (missing(w)) {\n        w <- rep(1, length(x))/length(x)\n    }\n    if (length(x) != length(y) || length(x) != length(w)) {\n        stop(\"x, y, and w must have the same length\")\n    }\n    method <- match.arg(method)\n    if (method == \"spearman\") {\n        x <- rank(x)\n        y <- rank(y)\n    }\n    alternative <- match.arg(alternative)\n    \n    res <- c(rho = NA, p = NA)\n    \n    ## remove missing values\n    ccix <- complete.cases(x, y, w)\n    if (!all(ccix) && !na.rm) {\n        warning(\"Missing values are present\")\n    }\n    if (sum(ccix) < 3) {\n        return(res)\n    }\n    x <- x[ccix]\n    y <- y[ccix]\n    w <- w[ccix]\n    \n    wc <- wcor(d = cbind(x, y), w = w)\n    res[\"rho\"] <- wc\n    if (nperm > 1) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        if (!is.list(splitix)) {\n            splitix <- list(splitix)\n        }\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy, ww) {\n            pres <- vapply(x, function(x, xx, yy, ww) {\n                ## permute the data and the weights\n                d2 <- cbind(xx[sample(seq_len(length(xx)))], yy[sample(seq_len(length(yy)))])\n                w2 <- ww[sample(seq_len(length(ww)))]\n                return(wcor(d = d2, w = w2))\n            }, xx = xx, yy = yy, ww = ww, FUN.VALUE = double(1))\n            return(pres)\n        }, xx = x, yy = y, ww = w)\n        perms <- do.call(c, mcres)\n        \n        switch(alternative, two.sided = {\n            if (res[\"rho\"] < 0) {\n                p <- sum(perms <= res, na.rm = TRUE)\n            } else {\n                p <- sum(perms >= res, na.rm = TRUE)\n            }\n            if (p == 0) {\n                p <- 1/(nperm + 1)\n            } else {\n                p <- p/nperm\n            }\n            p <- p * 2\n        }, greater = {\n            p <- sum(perms >= res, na.rm = TRUE)\n            if (p == 0) {\n                p <- 1/(nperm + 1)\n            } else {\n                p <- p/nperm\n            }\n        }, less = {\n            p <- sum(perms <= res, na.rm = TRUE)\n            if (p == 0) {\n                p <- 1/(nperm + 1)\n            } else {\n                p <- p/nperm\n            }\n        })\n        res[\"p\"] <- p\n    }\n    return(res)\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `gwc` function and what are its main input parameters?",
        "answer": "The `gwc` function calculates the genome-wide connectivity (GWC) score between two vectors using either a weighted Spearman or Pearson correlation. Its main input parameters are:\n- x1 and x2: numeric vectors of effect sizes for two experiments\n- p1 and p2: corresponding p-values for the effect sizes\n- method.cor: specifies whether to use Pearson or Spearman correlation\n- nperm: number of permutations for determining statistical significance\n- truncate.p: value for truncating extremely low p-values"
      },
      {
        "question": "How does the `.corWeighted` function handle missing values and what is the minimum number of non-missing values required for the function to proceed?",
        "answer": "The `.corWeighted` function handles missing values by using the `complete.cases` function to identify and remove any rows with missing values in x, y, or w. If the `na.rm` parameter is set to `FALSE` and missing values are present, a warning is issued. The function requires at least 3 non-missing values to proceed with the calculation. If there are fewer than 3 complete cases, the function returns a result vector with NA values for both the correlation coefficient (rho) and p-value."
      },
      {
        "question": "Explain the permutation process used in the `.corWeighted` function to calculate the p-value.",
        "answer": "The permutation process in `.corWeighted` function works as follows:\n1. It performs `nperm` number of permutations.\n2. For each permutation, it randomly shuffles the data (x and y) and weights.\n3. It calculates the weighted correlation for each permuted dataset.\n4. It then compares the original correlation to the distribution of permuted correlations.\n5. The p-value is calculated based on the proportion of permuted correlations that are as extreme as or more extreme than the original correlation.\n6. The calculation method depends on the specified alternative hypothesis (two.sided, greater, or less).\n7. If no permuted correlations are more extreme, it uses a conservative p-value of 1/(nperm+1).\nThis process allows for empirical estimation of the statistical significance of the weighted correlation."
      }
    ],
    "completion_tasks": [
      {
        "partial": "gwc <- function(x1, p1, x2, p2, method.cor = c(\"pearson\", \"spearman\"), nperm = 10000, truncate.p = 1e-16, ...) {\n    method.cor <- match.arg(method.cor)\n    ii <- .intersectList(names(x1), names(p1), names(x2), names(p2))\n    if (length(ii) < 10) {\n        stop(\"Less than 10 probes/genes in common between x and y\")\n    }\n    x1 <- x1[ii]\n    p1 <- p1[ii]\n    x2 <- x2[ii]\n    p2 <- p2[ii]\n    p1[!is.na(p1) & p1 < truncate.p] <- truncate.p\n    p2[!is.na(p2) & p2 < truncate.p] <- truncate.p\n    # Complete the function by adding the remaining steps\n}",
        "complete": "gwc <- function(x1, p1, x2, p2, method.cor = c(\"pearson\", \"spearman\"), nperm = 10000, truncate.p = 1e-16, ...) {\n    method.cor <- match.arg(method.cor)\n    ii <- .intersectList(names(x1), names(p1), names(x2), names(p2))\n    if (length(ii) < 10) {\n        stop(\"Less than 10 probes/genes in common between x and y\")\n    }\n    x1 <- x1[ii]\n    p1 <- p1[ii]\n    x2 <- x2[ii]\n    p2 <- p2[ii]\n    p1[!is.na(p1) & p1 < truncate.p] <- truncate.p\n    p2[!is.na(p2) & p2 < truncate.p] <- truncate.p\n    p1 <- -log10(p1)\n    p1 <- p1/sum(p1, na.rm = TRUE)\n    p2 <- -log10(p2)\n    p2 <- p2/sum(p2, na.rm = TRUE)\n    w <- p1 + p2\n    res <- .corWeighted(x = x1, y = x2, w = w, method = method.cor, nperm = nperm, ...)\n    return(res)\n}"
      },
      {
        "partial": ".corWeighted <- function(x, y, w, method = c(\"pearson\", \"spearman\"), alternative = c(\"two.sided\", \"greater\", \"less\"), nperm = 0, nthread = 1, na.rm = FALSE) {\n    wcor <- function(d, w, na.rm = TRUE) {\n        CovM <- cov.wt(d, wt = w)[[\"cov\"]]\n        res <- CovM[1, 2]/sqrt(CovM[1, 1] * CovM[2, 2])\n        return(res)\n    }\n    # Complete the function by adding the remaining steps\n}",
        "complete": ".corWeighted <- function(x, y, w, method = c(\"pearson\", \"spearman\"), alternative = c(\"two.sided\", \"greater\", \"less\"), nperm = 0, nthread = 1, na.rm = FALSE) {\n    wcor <- function(d, w, na.rm = TRUE) {\n        CovM <- cov.wt(d, wt = w)[[\"cov\"]]\n        res <- CovM[1, 2]/sqrt(CovM[1, 1] * CovM[2, 2])\n        return(res)\n    }\n    if (missing(w)) w <- rep(1, length(x))/length(x)\n    if (length(x) != length(y) || length(x) != length(w)) stop(\"x, y, and w must have the same length\")\n    method <- match.arg(method)\n    if (method == \"spearman\") {\n        x <- rank(x)\n        y <- rank(y)\n    }\n    alternative <- match.arg(alternative)\n    res <- c(rho = NA, p = NA)\n    ccix <- complete.cases(x, y, w)\n    if (!all(ccix) && !na.rm) warning(\"Missing values are present\")\n    if (sum(ccix) < 3) return(res)\n    x <- x[ccix]; y <- y[ccix]; w <- w[ccix]\n    wc <- wcor(d = cbind(x, y), w = w)\n    res[\"rho\"] <- wc\n    if (nperm > 1) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        if (!is.list(splitix)) splitix <- list(splitix)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy, ww) {\n            vapply(x, function(x, xx, yy, ww) {\n                d2 <- cbind(xx[sample(seq_len(length(xx)))], yy[sample(seq_len(length(yy)))])\n                w2 <- ww[sample(seq_len(length(ww)))]\n                wcor(d = d2, w = w2)\n            }, xx = xx, yy = yy, ww = ww, FUN.VALUE = double(1))\n        }, xx = x, yy = y, ww = w)\n        perms <- do.call(c, mcres)\n        p <- switch(alternative,\n            two.sided = 2 * min(sum(perms <= wc), sum(perms >= wc)) / nperm,\n            greater = sum(perms >= wc) / nperm,\n            less = sum(perms <= wc) / nperm\n        )\n        res[\"p\"] <- max(p, 1 / (nperm + 1))\n    }\n    return(res)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/LongTable-class.R",
    "language": "R",
    "content": "#' @include immutable-class.R\n#' @include allGenerics.R\nNULL\n\n#' @title LongTable class definition\n#'\n#' @description Define a private constructor method to be used to build a\n#'   `LongTable` object.\n#'\n#' @slot rowData See Slots section.\n#' @slot colData See Slots section.\n#' @slot assays See Slots section.\n#' @slot metadata See Slots section.\n#' @slot .intern See Slots section.\n#'\n#' @section Slots:\n#' - *rowData*: A `data.table` containing the metadata associated with the\n#'   row dimension of a `LongTable`.\n#' - *colData*: A `data.table` containing the metadata associated with the\n#'   column dimension of a `LongTable`.\n#' - *assays*: A `list` of `data.table`s, one for each assay in a\n#'   `LongTable`.\n#' - *metadata*: An optional `list` of additional metadata for a `LongTable`\n#'   which doesn't map to one of the dimensions.\n#' - *.intern*: An `immutable` `list` that holds internal structural metadata\n#'   about a LongTable object, such as which columns are required to key\n#'   the object.\n#'\n#' @return `LongTable` object containing the assay data from a treatment\n#'   response experiment\n#'\n#' @md\n#' @import data.table\n#' @keywords internal\n#' @rdname LongTable-class\n#' @aliases .LongTable\n#' @exportClass LongTable\n.LongTable <- setClass(\"LongTable\",\n    slots=list(\n        rowData='data.table',\n        colData='data.table',\n        assays='list',\n        metadata='list',\n        .intern='immutable_list')\n)\n\n\n#' @title LongTable constructor method\n#'\n#' @rdname LongTable\n#'\n#' @param rowData `data.frame` A rectangular object coercible to a `data.table`.\n#' @param rowIDs `character` A vector of `rowData` column names needed to\n#'   uniquely identify each row in a `LongTable`.\n#' @param colData `data.frame` A rectangular object coercible to a `data.table.`\n#' @param colIDs `chacter` A vector of `colData` column names needed to uniquely\n#'   identify each column in a `LongTable`.\n#' @param assays `list` A list of rectangular objects, each coercible to\n#'   a `data.table`. Must be named and item names must match the `assayIDs`\n#'   list.\n#' @param assayIDs `list` A list of `character` vectors specifying the columns\n#'   needed to uniquely identify each row in an `assay`. Names must match the\n#'   `assays` list.\n#' @param metadata `list` A list of one or more metadata items associated with\n#'   a LongTable experiment.\n#' @param keep.rownames `logical(1)` or `character(1)` Should rownames be\n#'   retained when coercing to `data.table` inside the constructor. Default\n#'   is FALSE. If TRUE, adds a 'rn' column to each rectangular object that\n#'   gets coerced from `data.frame` to `data.table`. If a string, that becomes\n#'   the name of the rownames column.\n#'\n#' @return A `LongTable` object containing the data for a treatment response\n#'   experiment and configured according to the rowIDs and colIDs arguments.\n#'\n#' @examples\n#' \"See vignette('The LongTable Class', package='CoreGx')\"\n#'\n#' @importFrom data.table key setkeyv\n#' @export\nLongTable <- function(rowData, rowIDs, colData, colIDs, assays, assayIDs,\n        metadata=list(), keep.rownames=FALSE) {\n\n    # handle missing parameters\n    isMissing <- c(rowData=missing(rowData), rowIDs=missing(rowIDs),\n        colIDs=missing(colIDs), colData=missing(colData), assays=missing(assays),\n        assayIDs=missing(assayIDs))\n\n    if (any(isMissing)) stop(.errorMsg('\\nRequired parameter(s) missing: ',\n        names(isMissing)[isMissing], collapse='\\n\\t'))\n\n    # check parameter types and coerce or error\n    if (!is(colData, \"data.table\")) {\n        tryCatch({\n            colData <- data.table(colData, keep.rownames=keep.rownames)\n        }, error=function(e)\n            stop(.errorMsg(\"colData must be coercible to a data.frame!\"))\n        )\n    } else {\n        colData <- copy(colData)\n    }\n\n    if (!is(rowData, \"data.table\")) {\n        tryCatch({\n            rowData <- data.table(rowData, keep.rownames=keep.rownames) },\n        error=function(e)\n            stop(.errorMsg(\"rowData must be coerceible to a data.frame!\"))\n        )\n    } else {\n        rowData <- copy(rowData)\n    }\n\n    isDT <- is.items(assays, FUN=is.data.table)\n    isDF <- is.items(assays, FUN=is.data.frame) & !isDT\n    if (!all(isDT)) {\n        tryCatch({\n            for (i in which(isDF))\n                assays[[i]] <- data.table(assays[[i]], keep.rownames)\n        }, error = function(e, assays) {\n            message(e)\n            types <- lapply(assays, typeof)\n            stop(.errorMsg(\n                '\\nList items are types: ',\n                types, '\\nPlease ensure all items in the assays list are ',\n                'coerceable to a data.frame!'), collapse=', ')\n        })\n    }\n    assays <- copy(assays)\n\n    ## FIXME:: Move all validity checks to top of the function to prevent wasted\n    ## computation or into class validity method\n\n    # capture row internal metadata\n    if (is.numeric(rowIDs) || is.logical(rowIDs))\n        rowIDs <- colnames(rowData)[rowIDs]\n    if (!all(rowIDs %in% colnames(rowData)))\n        stop(.errorMsg('\\nRow IDs not in rowData: ',\n            setdiff(rowIDs, colnames(rowData)), collapse=', '))\n\n    # Create the row and column keys for LongTable internal mappings\n    if (!('rowKey' %in% colnames(rowData)))\n        rowData[, c('rowKey') := .GRP, keyby=c(rowIDs)]\n    if (!('colKey' %in% colnames(colData)))\n        colData[, c('colKey') := .GRP, keyby=c(colIDs)]\n\n    # initialize the internals object to store private metadata for a LongTable\n    internals <- setNames(vector(\"list\", length=6),\n        c(\"rowIDs\", \"rowMeta\", \"colIDs\", \"colMeta\", \"assayKeys\", \"assayIndex\"))\n    internals$rowIDs <- rowIDs\n    internals$rowMeta <- setdiff(colnames(rowData[, -'rowKey']), rowIDs)\n\n    # capture column internal metadata\n    if (is.numeric(colIDs) || is.logical(colIDs))\n        colIDs <- colnames(colData)[colIDs]\n    if (!all(colIDs %in% colnames(colData)))\n        stop(.errorMsg('\\nColumn IDs not in colData: ',\n            setdiff(colIDs, colnames(colData)), collapse=', '),\n            call.=FALSE)\n    internals$colIDs <- colIDs\n    internals$colMeta <- setdiff(colnames(colData[, -'colKey']), colIDs)\n\n    # -- capture assays internal metadata\n    # sort such that rowIDs are first, then colIDs; ensures reindex returns\n    # the same order as construtor\n    for (i in seq_along(assayIDs)) {\n        rids <- intersect(rowIDs, assayIDs[[i]])\n        cids <- intersect(colIDs, assayIDs[[i]])\n        assayIDs[[i]] <- c(rids, cids)\n    }\n    internals$assayKeys <- assayIDs\n\n    # ensure names of assays and assayIDs match\n    hasMatchingAssayNames <- names(assays) == names(assayIDs)\n    if (!all(hasMatchingAssayNames)) stop(.errorMsg(\n        \"Mismatched names between assays and assayIDs for:\\n\\t\",\n        paste0(names(assays)[!hasMatchingAssayNames], collapse=\", \")),\n        call.=FALSE)\n    # set keys for join with metadata\n    for (nm in names(assays)) {\n        setkeyv(assays[[nm]], assayIDs[[nm]])\n        .nm <- paste0(\".\", nm)\n        assays[[nm]][, (.nm) := .I]\n    }\n    \n    # build the index mapping assay rows to rowKey and colKey\n    cat(.infoMsg(\"Building assay index...\\n\", time=TRUE))\n    assayIndex <- expand.grid(rowKey=rowData$rowKey, colKey=colData$colKey)\n    setDT(assayIndex)\n    # setkeyv(assayIndex, c(\"rowKey\", \"colKey\"))\n    \n    cat(.infoMsg(\"Joining rowData to assayIndex...\\n\", time=TRUE))\n    setkeyv(rowData, \"rowKey\")\n    setkeyv(assayIndex, \"rowKey\")\n    # assayIndex <- assayIndex[\n    #     rowData[, c(rowIDs, \"rowKey\"), with=FALSE], ,\n    #     on=\"rowKey\", allow.cartesian=FALSE\n    # ]\n    rd <- rowData[, c(rowIDs, \"rowKey\"), with=FALSE]\n    assayIndex <- merge(\n        assayIndex, rd,\n        by=\"rowKey\", all.x=TRUE, allow.cartesian=FALSE\n    )\n\n    # print if rowKey in rowData is not unique\n    if(nrow(rowData) != uniqueN(rowData$rowKey)) {\n        cat(.warnMsg(\"rowData rowKey is not unique!\"))\n        show(assayIndex)\n        show(rowData)\n    }\n    rm(rd)\n    gc()\n    cat(.infoMsg(\"Joining colData to assayIndex...\\n\", time=TRUE))\n    setkeyv(colData, \"colKey\")\n    # assayIndex <- assayIndex[\n    #     colData[, c(colIDs, \"colKey\"), with=FALSE], ,\n    #     on=\"colKey\", allow.cartesian=FALSE\n    # ]\n    cd <- colData[, c(colIDs, \"colKey\"), with=FALSE]\n    assayIndex <- merge(\n        assayIndex, cd,\n        by=\"colKey\", all.x=TRUE, allow.cartesian=FALSE\n    )\n    rm(cd)\n    gc()\n    cat(.infoMsg(\"Joining assays to assayIndex...\\n\", time=TRUE))\n\n    # Set the key variables for the assayIndex using rowIDs and colIDs\n    setkeyv(assayIndex, c(rowIDs, colIDs))\n\n\n    for (nm in names(assays)) {\n        .nm <- paste0(\".\", nm)\n        assayIndex[assays[[nm]], (.nm) := get(.nm)]\n    }\n    gc()\n    assayIndex[, (c(rowIDs, colIDs)) := NULL]\n    assayIndex <- assayIndex[\n        which(rowAnys(!is.na(assayIndex[, paste0(\".\", names(assays)), with=FALSE]))),\n    ]\n    gc()\n    cat(.infoMsg(\"Setting assayIndex key...\\n\", time=TRUE))\n    setkeyv(assayIndex, paste0(\".\", names(assays)))\n    internals$assayIndex <- assayIndex\n\n\n    # make internals immutable to prevent users from modifying structural metadata\n    internals <- immutable(internals)\n\n    gc()\n    cat(.infoMsg(\"Building LongTable...\\n\", time=TRUE))\n    # Drop extra assay columns and key by the assay key in the assay index\n    for (i in seq_along(assays)) {\n        assays[[i]][, (assayIDs[[i]]) := NULL]\n        setkeyv(assays[[i]], paste0(\".\", names(assays)[i]))\n    }\n\n    # Reorder columns to match the keys, this prevents issues in unit tests\n    # caused by different column orders\n    setkeyv(rowData, \"rowKey\")\n    setkeyv(colData, \"colKey\")\n    setcolorder(rowData, unlist(internals[c(\"rowIDs\", \"rowMeta\")]))\n    setcolorder(colData, unlist(internals[c('colIDs', 'colMeta')]))\n\n    ## Assemble  the pseudo row and column names for the LongTable\n    .pasteColons <- function(...) paste(..., collapse=':')\n    rowData[, `:=`(.rownames=mapply(.pasteColons, transpose(.SD))),\n        .SDcols=rowIDs]\n    colData[, `:=`(.colnames=mapply(.pasteColons, transpose(.SD))),\n        .SDcols=colIDs]\n    return(CoreGx:::.LongTable(rowData=rowData, colData=colData, assays=assays,\n        metadata=metadata, .intern=internals))\n}\n\n#' Function to combine two LongTables into a single LongTable\n#' @param x A `LongTable` object\n#' @param y A `LongTable` object\n#' \n\n# ---- Class unions for CoreSet slots\n#' A class union to allow multiple types in a CoreSet slot\n#'\n#' @include LongTable-class.R\nsetClassUnion('list_OR_LongTable', c('list', 'LongTable'))\n\n# #' Ensure that all rowID and colID keys are valid\n# #'\n# #' @param rowData A `data.table` containing row level annotations.\n# #' @param colData A `data.table` containing column level annotations for a\n# #'   `LongTable`.\n# #' @param assays A `list` of `data.table`s, one for each assay in an\n# #'   `LongTable`.\n# #'\n# #' @keywords internal\n### FIXME:: Finish this and implement class validity methods for LongTable!\n#.verifyKeyIntegrity <- function(rowData, colData, assays) {\n#    if (!('rowKey' %in% colnames(rowData)) || !is.numeric(rowData$rowID))\n#        message(blue('The rowKey column is missing from rowData! Please try\n#            rebuilding the LongTable object with the constructor.'))\n#    if (!('colKey' %in% colnames(colData)) || !is.numeric(colData$colID))\n#        stop()\n#}\n\n# ---- LongTable Class Methods\n\n#' Helper function to print slot information\n#' @param slotName `character` The name of the slot to print.\n#' @param slotData `data.table` The data to print.\n#' \n#' @keywords internal\nprintSlot <- function(slotName, slotData) {\n    slotCols <- ncol(slotData)\n    slotString <- paste0(slotName, '(', slotCols, '): ')\n    slotColnames <- colnames(slotData)\n    slotNamesString <-\n        if (length(slotColnames) > 6) {\n            paste0(.collapse(head(slotColnames, 3)), ' ... ', .collapse(tail(slotColnames, 3)))\n        } else {\n            .collapse(slotColnames)\n        }\n    cat(\"  \", yellow$bold(slotString) %+% green(slotNamesString), '\\n')\n}\n\n#' Show method for the LongTable class\n#'\n#' @examples\n#' show(merckLongTable)\n#'\n#' @param object A `LongTable` object to print the results for.\n#'\n#' @return `invisible` Prints to console.\n#'\n#' @importFrom crayon %+% yellow red green blue cyan magenta\n#' @import data.table\n#' @export\nsetMethod('show', signature(object='LongTable'), function(object) {\n\n    ## FIXME:: Function too long. Can I refactor to a helper that prints each slot?\n\n    # ---- class descriptions\n    cat(yellow$bold$italic(paste0(\"<\", class(object)[1], \">\"), '\\n'))\n    cat(\"  \", yellow$bold('dim: ', .collapse(dim(object)), '\\n'))\n\n    # --- assays slot\n    assayLength <- length(assayNames(object))\n    assaysString <- paste0('assays(', assayLength, '): ')\n    assayNames <- assayNames(object)\n    assayNamesString <- .collapse(assayNames(object))\n    if (nchar(assayNamesString) > options(\"width\")) {\n        assayNamesString <- paste0(strwrap(assayNamesString), collapse=\"\\n  \")\n    }\n    cat(\"  \", yellow$bold(assaysString) %+% red(assayNamesString), '\\n')\n\n    # --- rownames\n    rows <- nrow(rowData(object))\n    rowsString <- paste0('rownames(', rows, '): ')\n    rowNames <- rownames(object)\n    rownamesString <-\n        if (length(rowNames) > 6) {\n            paste0(.collapse(head(rowNames, 2)), ' ... ', .collapse(tail(rowNames, 2)))\n        } else {\n            .collapse(rowNames)\n        }\n    cat(\"  \", yellow$bold(rowsString) %+% green(rownamesString), '\\n')\n\n    # ---- rowData slot\n    printSlot('rowData', rowData(object))\n\n    # ---- colnames\n    cols <- nrow(colData(object))\n    colsString <- paste0('colnames(', cols, '): ')\n    colnames <- colnames(object)\n    colnamesString <-\n        if (length(colnames) > 6) {\n            paste0(.collapse(head(colnames, 3)), ' ... ', .collapse(tail(colnames, 3)))\n        } else {\n            .collapse(colnames)\n        }\n    cat(\"  \", yellow$bold(colsString) %+% green(colnamesString), '\\n')\n\n    # ---- colData slot\n    printSlot('colData', colData(object))\n\n    # --- metadata slot\n    metadataString <- paste0('metadata(', length(metadata(object)), '): ')\n    metadataNames <- names(metadata(object))\n    metadataNamesString <-\n        if (length(metadataNames) > 6) {\n            paste0(.collapse(head(metadataNames, 3), ' ... ', .collapse(tail(metadataNames, 3))))\n        } else if (length(metadataNames) >= 1) {\n            .collapse(metadataNames)\n        } else {\n            'none'\n        }\n    cat(\"  \", yellow$bold(metadataString) %+% green(metadataNamesString), '\\n')\n})\n\n\n# ==== LongTable Accessor Methods\n\n#' Get the id column names for the rowData slot of a LongTable\n#'\n#' @examples\n#' rowIDs(merckLongTable)\n#'\n#' @param object A `LongTable` to get the rowData id columns for.\n#' @param data `logical` Should the rowData for the id columns be returned\n#' instead of the column names? Default is FALSE.\n#' @param key `logical` Should the key column also be returned?\n#'\n#' @return A `character` vector of rowData column names if data is FALSE,\n#' otherwise a `data.table` with the data from the rowData id columns.\n#'\n#' @rdname LongTable-class\n#' @family LongTable-class\n#' @family LongTable-accessors\n#'\n#' @import data.table\n#' @export\nsetMethod('rowIDs', signature(object='LongTable'),\n        function(object, data=FALSE, key=FALSE) {\n    cols <- mutable(getIntern(object, 'rowIDs'))\n    if (key) cols <- c(cols, 'rowKey')\n    if (data) rowData(object, key=key)[, ..cols] else cols\n})\n\n#' Get the id column names for the rowData slot of a LongTable\n#'\n#' @examples\n#' rowMeta(merckLongTable)\n#'\n#' @describeIn LongTable Get the names of the non-id columns from rowData.\n#'\n#' @param object A `LongTable` to get the rowData metadata columns for.\n#' @param data `logical` Should the rowData for the metadata columns be returned\n#' instead of the column names? Default is FALSE.\n#' @param key `logical` Should the key column also be returned? Default is FALSE\n#'\n#' @return A `character` vector of rowData column names if data is FALSE,\n#' otherwise a `data.table` with the data from the rowData metadta columns.\n#'\n#' @import data.table\n#' @export\nsetMethod('rowMeta', signature(object='LongTable'),\n        function(object, data=FALSE, key=FALSE) {\n    cols <- mutable(getIntern(object, 'rowMeta'))\n    cols <- cols[!grepl('^\\\\.', cols)]\n    if (key) cols <- c(cols, 'rowKey')\n    if (data) rowData(object, key=key)[, ..cols] else cols\n})\n\n#' Get the id column names for the colData slot of a LongTable\n#'\n#' @examples\n#' colIDs(merckLongTable)\n#'\n#' @describeIn LongTable Get the names of the columns in colData required to\n#' uniquely identify each row.\n#'\n#' @param object A `LongTable` to get the colData id columns for.\n#' @param data `logical` Should the colData for the id columns be returned\n#' instead of the column names? Default is FALSE.\n#' @param key `logical` Should the key column also be returned? Default is FALSE.\n#'\n#' @return A `character` vector of colData column names if data is FALSE,\n#' otherwise a `data.table` with the data from the colData id columns.\n#'\n#' @import data.table\n#' @export\nsetMethod('colIDs', signature(object='LongTable'),\n        function(object, data=FALSE, key=FALSE) {\n\n    cols <- mutable(getIntern(object, 'colIDs'))\n    if (key) cols <- c(cols, 'colKey')\n    if (data) colData(object, key=TRUE)[, ..cols] else cols\n\n})\n\n#' Get the id column names for the colData slot of a LongTable\n#'\n#' @examples\n#' colMeta(merckLongTable)\n#'\n#' @describeIn LongTable Get the names of the non-id columns in the colData\n#'   `data.table`.\n#'\n#' @param object A `LongTable` to get the colData metadata columns for.\n#' @param data `logical` Should the colData for the metadata columns be returned\n#'   instead of the column names? Default is FALSE.\n#' @param key `logical` Should the key column also be returned?\n#'\n#' @return A `character` vector of colData column names if data is FALSE,\n#'   otherwise a `data.table` with the data from the colData metadta columns.\n#'\n#' @import data.table\n#' @export\nsetMethod('colMeta', signature(object='LongTable'),\n    function(object, data=FALSE, key=FALSE) {\n\n    cols <- mutable(getIntern(object, 'colMeta'))\n    cols <- cols[!grepl('^\\\\.', cols)]\n    if (key) cols <- c(cols, 'colKey')\n    if (data) colData(object, key=TRUE)[, ..cols] else cols\n})\n\n\n\n#' Retrieve the unique identifier columns used for primary keys in rowData and\n#'    colData.\n#'\n#' @describeIn LongTable Get the names of all id columns.\n#'\n#' @examples\n#' idCols(merckLongTable)\n#'\n#' @param object `LongTable`\n#'\n#' @return `character` A character vector containing the unique rowIDs and\n#'   colIDs in a LongTable object.\n#'\n#' @export\nsetMethod('idCols', signature('LongTable'),\n    function(object) {\n    return(unique(c(rowIDs(object), colIDs(object))))\n})\n\n#' Retrieve a copy of the assayIndex from the `@.intern` slot.\n#'\n#' @describeIn LongTable Get the assayIndex item from the objects internal metadata.\n#'\n#' @param `x` A `LongTable` or inheriting class.\n#'\n#' @return A `mutable` copy of the \"assayIndex\" for `x`\n#'\n#' @examples\n#' assayIndex(nci_TRE_small)\n#'\n#' @aliases assayIndex,LongTable-method\n#' @export\nsetMethod(\"assayIndex\", signature(\"LongTable\"), function(x) {\n    mutable(getIntern(x, \"assayIndex\"))\n})\n\n#' Retrieve a copy of the assayKeys from the `@.intern` slot.\n#'\n#' @describeIn LongTable Get the assayKeys item from the objects internal metadata.\n#'\n#' @param `x` A `LongTable` or inheriting class.\n#' @param `i` An optional valid assay name or index in `x`.\n#'\n#' @return A `mutable` copy of the \"assyKeys\" for `x`\n#'\n#' @examples\n#' assayKeys(nci_TRE_small)\n#' assayKeys(nci_TRE_small, \"sensitivity\")\n#' assayKeys(nci_TRE_small, 1)\n#'\n#' @aliases assayKeys,LongTable-method\n#' @export\nsetMethod(\"assayKeys\", signature(\"LongTable\"), function(x, i) {\n    keys <- mutable(getIntern(x, \"assayKeys\"))\n    # error handling occurs in `[[`\n    if (!missing(i)) keys[[i]] else keys\n})\n\n\n#' Retrieve the value columns for the assays in a LongTable\n#'\n#' @examples\n#' assayCols(merckLongTable)\n#'\n#' @describeIn LongTable Get a list of column names for each assay in the object.\n#'\n#' @param object `LongTable`\n#' @param i Optional parameter specifying the `character` name or `integer`\n#' index of the assay to get the column names for. If missing, returns a\n#' list of value column names for all the assays.\n#'\n#' @return A `list` of `character` vectors containing the value column names for\n#' each assay if i is missing, otherwise a `character` vector of value column\n#' names for the selected assay.\n#'\n#' @import data.table\n#' @export\nsetMethod('assayCols', signature(object='LongTable'),\n        function(object, i) {\n    if (!missing(i)) {\n        stopifnot(is.numeric(i) || is.character(i))\n        stopifnot(length(i) == 1)\n        stopifnot(i %in% assayNames(object) ||\n            i %in% seq_along(assayNames(object)))\n    }\n    keys <- assayKeys(object)\n    assayColnames <- Map(setdiff,\n        x=lapply(assays(object, raw=TRUE), FUN=colnames),\n        y=as.list(paste0(\".\", assayNames(object)))\n    )\n    assayCols <- Map(c, keys, assayColnames)\n    if (!missing(i)) assayCols[[i]] else assayCols\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.LongTable` function in this code snippet?",
        "answer": "The `.LongTable` function is used to define the `LongTable` class. It sets up the class structure with specific slots for rowData, colData, assays, metadata, and internal data. This function is marked as internal and is used as a private constructor for building `LongTable` objects."
      },
      {
        "question": "How does the `LongTable` constructor handle the case when required parameters are missing?",
        "answer": "The `LongTable` constructor checks for missing required parameters using the `missing()` function. It creates a logical vector `isMissing` for each required parameter. If any of these parameters are missing (i.e., `any(isMissing)` is true), it stops execution and throws an error message listing the missing parameters."
      },
      {
        "question": "What is the purpose of the `assayIndex` in the `LongTable` constructor, and how is it built?",
        "answer": "The `assayIndex` is a data structure that maps the relationships between rowKeys, colKeys, and assay data. It's built by first creating a grid of all possible rowKey and colKey combinations using `expand.grid()`. Then, it joins this grid with rowData and colData, and finally adds references to the actual assay data. This index allows for efficient querying and manipulation of the LongTable data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "LongTable <- function(rowData, rowIDs, colData, colIDs, assays, assayIDs,\n        metadata=list(), keep.rownames=FALSE) {\n\n    # handle missing parameters\n    isMissing <- c(rowData=missing(rowData), rowIDs=missing(rowIDs),\n        colIDs=missing(colIDs), colData=missing(colData), assays=missing(assays),\n        assayIDs=missing(assayIDs))\n\n    if (any(isMissing)) stop(.errorMsg('\\nRequired parameter(s) missing: ',\n        names(isMissing)[isMissing], collapse='\\n\\t'))\n\n    # check parameter types and coerce or error\n    if (!is(colData, \"data.table\")) {\n        tryCatch({\n            colData <- data.table(colData, keep.rownames=keep.rownames)\n        }, error=function(e)\n            stop(.errorMsg(\"colData must be coercible to a data.frame!\"))\n        )\n    } else {\n        colData <- copy(colData)\n    }\n\n    if (!is(rowData, \"data.table\")) {\n        tryCatch({\n            rowData <- data.table(rowData, keep.rownames=keep.rownames) },\n        error=function(e)\n            stop(.errorMsg(\"rowData must be coerceible to a data.frame!\"))\n        )\n    } else {\n        rowData <- copy(rowData)\n    }\n\n    # TODO: Complete the function\n}",
        "complete": "LongTable <- function(rowData, rowIDs, colData, colIDs, assays, assayIDs,\n        metadata=list(), keep.rownames=FALSE) {\n\n    # handle missing parameters\n    isMissing <- c(rowData=missing(rowData), rowIDs=missing(rowIDs),\n        colIDs=missing(colIDs), colData=missing(colData), assays=missing(assays),\n        assayIDs=missing(assayIDs))\n\n    if (any(isMissing)) stop(.errorMsg('\\nRequired parameter(s) missing: ',\n        names(isMissing)[isMissing], collapse='\\n\\t'))\n\n    # check parameter types and coerce or error\n    if (!is(colData, \"data.table\")) {\n        tryCatch({\n            colData <- data.table(colData, keep.rownames=keep.rownames)\n        }, error=function(e)\n            stop(.errorMsg(\"colData must be coercible to a data.frame!\"))\n        )\n    } else {\n        colData <- copy(colData)\n    }\n\n    if (!is(rowData, \"data.table\")) {\n        tryCatch({\n            rowData <- data.table(rowData, keep.rownames=keep.rownames) },\n        error=function(e)\n            stop(.errorMsg(\"rowData must be coerceible to a data.frame!\"))\n        )\n    } else {\n        rowData <- copy(rowData)\n    }\n\n    isDT <- is.items(assays, FUN=is.data.table)\n    isDF <- is.items(assays, FUN=is.data.frame) & !isDT\n    if (!all(isDT)) {\n        tryCatch({\n            for (i in which(isDF))\n                assays[[i]] <- data.table(assays[[i]], keep.rownames)\n        }, error = function(e, assays) {\n            message(e)\n            types <- lapply(assays, typeof)\n            stop(.errorMsg(\n                '\\nList items are types: ',\n                types, '\\nPlease ensure all items in the assays list are ',\n                'coerceable to a data.frame!'), collapse=', ')\n        })\n    }\n    assays <- copy(assays)\n\n    # capture row internal metadata\n    if (is.numeric(rowIDs) || is.logical(rowIDs))\n        rowIDs <- colnames(rowData)[rowIDs]\n    if (!all(rowIDs %in% colnames(rowData)))\n        stop(.errorMsg('\\nRow IDs not in rowData: ',\n            setdiff(rowIDs, colnames(rowData)), collapse=', '))\n\n    # Create the row and column keys for LongTable internal mappings\n    if (!('rowKey' %in% colnames(rowData)))\n        rowData[, c('rowKey') := .GRP, keyby=c(rowIDs)]\n    if (!('colKey' %in% colnames(colData)))\n        colData[, c('colKey') := .GRP, keyby=c(colIDs)]\n\n    # initialize the internals object to store private metadata for a LongTable\n    internals <- setNames(vector(\"list\", length=6),\n        c(\"rowIDs\", \"rowMeta\", \"colIDs\", \"colMeta\", \"assayKeys\", \"assayIndex\"))\n    internals$rowIDs <- rowIDs\n    internals$rowMeta <- setdiff(colnames(rowData[, -'rowKey']), rowIDs)\n\n    # capture column internal metadata\n    if (is.numeric(colIDs) || is.logical(colIDs))\n        colIDs <- colnames(colData)[colIDs]\n    if (!all(colIDs %in% colnames(colData)))\n        stop(.errorMsg('\\nColumn IDs not in colData: ',\n            setdiff(colIDs, colnames(colData)), collapse=', '),\n            call.=FALSE)\n    internals$colIDs <- colIDs\n    internals$colMeta <- setdiff(colnames(colData[, -'colKey']), colIDs)\n\n    # capture assays internal metadata\n    for (i in seq_along(assayIDs)) {\n        rids <- intersect(rowIDs, assayIDs[[i]])\n        cids <- intersect(colIDs, assayIDs[[i]])\n        assayIDs[[i]] <- c(rids, cids)\n    }\n    internals$assayKeys <- assayIDs\n\n    # ensure names of assays and assayIDs match\n    hasMatchingAssayNames <- names(assays) == names(assayIDs)\n    if (!all(hasMatchingAssayNames)) stop(.errorMsg(\n        \"Mismatched names between assays and assayIDs for:\\n\\t\",\n        paste0(names(assays)[!hasMatchingAssayNames], collapse=\", \")),\n        call.=FALSE)\n    # set keys for join with metadata\n    for (nm in names(assays)) {\n        setkeyv(assays[[nm]], assayIDs[[nm]])\n        .nm <- paste0(\".\", nm)\n        assays[[nm]][, (.nm) := .I]\n    }\n    \n    # build the index mapping assay rows to rowKey and colKey\n    cat(.infoMsg(\"Building assay index...\\n\", time=TRUE))\n    assayIndex <- expand.grid(rowKey=rowData$rowKey, colKey=colData$colKey)\n    setDT(assayIndex)\n    \n    cat(.infoMsg(\"Joining rowData to assayIndex...\\n\", time=TRUE))\n    setkeyv(rowData, \"rowKey\")\n    setkeyv(assayIndex, \"rowKey\")\n    rd <- rowData[, c(rowIDs, \"rowKey\"), with=FALSE]\n    assayIndex <- merge(\n        assayIndex, rd,\n        by=\"rowKey\", all.x=TRUE, allow.cartesian=FALSE\n    )\n\n    if(nrow(rowData) != uniqueN(rowData$rowKey)) {\n        cat(.warnMsg(\"rowData rowKey is not unique!\"))\n        show(assayIndex)\n        show(rowData)\n    }\n    rm(rd)\n    gc()\n    cat(.infoMsg(\"Joining colData to assayIndex...\\n\", time=TRUE))\n    setkeyv(colData, \"colKey\")\n    cd <- colData[, c(colIDs, \"colKey\"), with=FALSE]\n    assayIndex <- merge(\n        assayIndex, cd,\n        by=\"colKey\", all.x=TRUE, allow.cartesian=FALSE\n    )\n    rm(cd)\n    gc()\n    cat(.infoMsg(\"Joining assays to assayIndex...\\n\", time=TRUE))\n\n    # Set the key variables for the assayIndex using rowIDs and colIDs\n    setkeyv(assayIndex, c(rowIDs, colIDs))\n\n    for (nm in names(assays)) {\n        .nm <- paste0(\".\", nm)\n        assayIndex[assays[[nm]], (.nm) := get(.nm)]\n    }\n    gc()\n    assayIndex[, (c(rowIDs, colIDs)) := NULL]\n    assayIndex <- assayIndex[\n        which(rowAnys(!is.na(assayIndex[, paste0(\".\", names(assays)), with=FALSE]))),\n    ]\n    gc()\n    cat(.infoMsg(\"Setting assayIndex key...\\n\", time=TRUE))\n    setkeyv(assayIndex, paste0(\".\", names(assays)))\n    internals$assayIndex <- assayIndex\n\n    # make internals immutable to prevent users from modifying structural metadata\n    internals <- immutable(internals)\n\n    gc()\n    cat(.infoMsg(\"Building LongTable...\\n\", time=TRUE))\n    # Drop extra assay columns and key by the assay key in the assay index\n    for (i in seq_along(assays)) {\n        assays[[i]][, (assayIDs[[i]]) := NULL]\n        setkeyv(assays[[i]], paste0(\".\", names(assays)[i]))\n    }\n\n    # Reorder columns to match the keys, this prevents issues in unit tests\n    # caused by different column orders\n    setkeyv(rowData, \"rowKey\")\n    setkeyv(colData, \"colKey\")\n    setcolorder(rowData, unlist(internals[c(\"rowIDs\", \"rowMeta\")]))\n    setcolorder(colData, unlist(internals[c('colIDs', 'colMeta')]))\n\n    ## Assemble  the pseudo row and column names for the LongTable\n    .pasteColons <- function(...) paste(..., collapse=':')\n    rowData[, `:=`(.rownames=mapply(.pasteColons, transpose(.SD))),\n        .SDcols=rowIDs]\n    colData[, `:=`(.colnames=mapply(.pasteColons, transpose(.SD))),\n        .SDcols=colIDs]\n    return(CoreGx:::.LongTable(rowData=rowData, colData=colData, assays=assays,\n        metadata=metadata, .intern=internals))\n}"
      },
      {
        "partial": "setMethod('show', signature(object='LongTable'), function(object) {\n    cat(yellow$bold$italic(paste0(\"<\", class(object)[1], \">\", '\\n')))\n    cat(\"  \", yellow$bold('dim: ', .collapse(dim(object)), '\\n'))\n\n    # --- assays slot\n    assayLength <- length(assayNames(object))\n    assaysString <- paste0('assays(', assayLength, '): ')\n    assayNames <- assayNames(object)\n    assayNamesString <- .collapse(assayNames(object))\n    if (nchar(assayNamesString) > options(\"width\")) {\n        assayNamesString <- paste0(strwrap(assayNamesString), collapse=\"\\n  \")\n    }\n    cat(\"  \", yellow$bold(assaysString) %+% red(assayNamesString), '\\n')\n\n    # TODO: Complete the show method\n})",
        "complete": "setMethod('show', signature(object='LongTable'), function(object) {\n    cat(yellow$bold$italic(paste0(\"<\", class(object)[1], \">\", '\\n')))\n    cat(\"  \", yellow$bold('dim: ', .collapse(dim(object)), '\\n'))\n\n    # --- assays slot\n    assayLength <- length(assayNames(object))\n    assaysString <- paste0('assays(', assayLength, '): ')\n    assayNames <- assayNames(object)\n    assayNamesString <- .collapse(assayNames(object))\n    if (nchar(assayNamesString) > options(\"width\")) {\n        assayNamesString <- paste0(strwrap(assayNamesString), collapse=\"\\n  \")\n    }\n    cat(\"  \", yellow$bold(assaysString) %+% red(assayNamesString), '\\n')\n\n    # --- rownames\n    rows <- nrow(rowData(object))\n    rowsString <- paste0('rownames(', rows, '): ')\n    rowNames <- rownames(object)\n    rownamesString <-\n        if (length(rowNames) > 6) {\n            paste"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/CoreSet-class.R",
    "language": "R",
    "content": "#' @include CoreSet-class.R LongTable-class.R\n#' @importClassesFrom MultiAssayExperiment MultiAssayExperiment\n#' @importFrom MultiAssayExperiment MultiAssayExperiment\n#' @import checkmate\nNULL\n\nsetClassUnion('list_OR_MAE', c('list', 'MultiAssayExperiment'))\n\n.local_class <- 'CoreSet'\n.local_data <- \"clevelandSmall_cSet\"\n\n#' @title\n#' CoreSet - A generic data container for molecular profiles and\n#'   treatment response data\n#'\n#' @slot annotation See Slots section.\n#' @slot molecularProfiles See Slots section.\n#' @slot sample See Slots section.\n#' @slot treatment See Slots section.\n#' @slot treatmentResponse See Slots section.\n#' @slot perturbation See Slots section.\n#' @slot curation See Slots section.\n#' @slot datasetType See Slots section.\n#'\n#' @details\n#' The CoreSet (cSet) class was developed as a superclass for pSets in the\n#' PharmacoGx and RadioGx packages to contain the data generated in screens\n#' of cancer sample lines for their genetic profile and sensitivities to therapy\n#' (Pharmacological or Radiation). This class is meant to be a superclass which\n#' is contained within the PharmacoSet (pSet) and RadioSet (rSet) objects\n#' exported by PharmacoGx and RadioGx. The format of the data is similar for\n#' both pSets and rSets, allowing much of the code to be abstracted into\n#' the CoreSet super-class. However, the models involved with quantifying\n#' sampleular response to Pharmacological and Radiation therapy are widely\n#' different, and extension of the cSet class allows the\n#' packages to apply the correct model for the given data.\n#'\n#' @section Slots:\n#' * annotation: A `list` of annotation data about the ``r .local_class``,\n#'   including the `$name` and the session information for how the object\n#'   was created, detailing the exact versions of R and all the packages used.\n#' * molecularProfiles: A `list` or `MultiAssayExperiment` containing\n#    a set of `SummarizedExperiment`s with molecular profile data for a given\n#'   ``r .local_class`` object.\n#' * sample: A `data.frame` containg the annotations for all the samples\n#'   profiled in the data set, across all molecular data types and\n#'   treatment response experiments.\n#' * treatment: A `data.frame` containing the annotations for all treatments\n#'   in the dataset, including the mandatory 'treatmentid' column to uniquely\n#'   identify each treatment.\n#' * treatmentResponse: A `list` or `LongTable` containing all the data for the\n#'   treatment response experiment, including `$info`, a `data.frame`\n#'   containing the experimental info, `$raw` a 3D `array` containing raw data,\n#'   `$profiles`, a `data.frame` containing sensitivity profiles\n#'   statistics, and `$n`, a `data.frame` detailing the number of\n#'   experiments for each sample-drug/radiationInfo pair\n#' * perturbation: `list` containing `$n`, a `data.frame`\n#'   summarizing the available perturbation data. This slot is currently\n#'   being deprecated.\n#' * curation: `list` containing mappings for `treatment`,\n#'   `sample` and `tissue` names used in the data set to universal\n#'   identifiers used between different ``r .local_class`` objects.\n#' * datasetType: `character` string of 'sensitivity',\n#'   'perturbation', or both detailing what type of data can be found in the\n#'   ``r .local_class``, for proper processing of the data\n#'\n#' @seealso [`CoreSet-accessors`]\n#'\n#' @md\n#' @aliases CoreSet-class\n#' @exportClass CoreSet\n.CoreSet <- setClass(\"CoreSet\",\n    slots=list(\n        treatmentResponse=\"list_OR_LongTable\",\n        annotation=\"list\",\n        molecularProfiles=\"list_OR_MAE\",\n        sample=\"data.frame\",\n        treatment=\"data.frame\",\n        datasetType=\"character\",\n        perturbation=\"list\",\n        curation=\"list\"\n    )\n)\n\n# The default constructor above does a poor job of explaining the required structure of a CoreSet.\n# The constructor function defined below guides the user into providing the required components of the curation and senstivity lists\n# and hides the annotation slot which the user does not need to manually fill.\n# This also follows the design of the Expression Set class.\n\n## ==========================\n## CONSTRUCTOR\n## --------------------------\n\n#' CoreSet constructor\n#'\n#' A constructor that simplifies the process of creating CoreSets, as well\n#' as creates empty objects for data not provided to the constructor. Only\n#' objects returned by this constructor are expected to work with the CoreSet\n#' methods.\n#'\n#' ## __WARNING__:\n#' Parameters to this function have been renamed!\n#' * cell is now sample\n#' * drug is now treatment\n#'\n#' @param name A \\code{character} string detailing the name of the dataset\n#' @param molecularProfiles A \\code{list} of SummarizedExperiment objects containing\n#'   molecular profiles for each molecular data type.\n#' @param sample A \\code{data.frame} containing the annotations for all the sample\n#'   profiled in the data set, across all data types. Must contain the mandatory\n#'   `sampleid` column which uniquely identifies each sample in the object.\n#' @param treatment A `data.frame` containing annotations for all treatments\n#'   profiled in the dataset. Must contain the mandatory `treatmentid` column\n#'   which uniquely identifies each treatment in the object.\n#' @param sensitivityInfo A \\code{data.frame} containing the information for the\n#'   sensitivity experiments. Must contain a 'sampleid' column with unique\n#'   identifiers to each sample, matching the `sample` object and a 'treatmentid'\n#'   columns with unique indenifiers for each treatment, matching the `treatment`\n#'   object.\n#' @param sensitivityRaw A 3 Dimensional \\code{array} contaning the raw drug\n#'   dose response data for the sensitivity experiments\n#' @param sensitivityProfiles \\code{data.frame} containing drug sensitivity profile\n#'   statistics such as IC50 and AUC\n#' @param sensitivityN,perturbationN A \\code{data.frame} summarizing the\n#'   available sensitivity/perturbation data\n#' @param curationSample,curationTissue,curationTreatment A \\code{data.frame} mapping\n#'   the names for samples, tissues and treatments used in the data set to\n#'   universal identifiers used between different CoreSet objects\n#' @param datasetType A `character(1)` string of 'sensitivity',\n#'   'preturbation', or 'both' detailing what type of data can be found in the\n#'   `CoreSet`, for proper processing of the data\n#' @param verify `logical(1)`Should the function verify the CoreSet and\n#'   print out any errors it finds after construction?\n#' @param ... Catch and parse any renamed constructor arguments.\n#'\n#' @return An object of class `CoreSet`\n#'\n#' @examples\n#' data(clevelandSmall_cSet)\n#' clevelandSmall_cSet\n#'\n#' @export\n#'\n#' @include LongTable-class.R\n#' @import methods\n#' @importFrom utils sessionInfo\n#' @importFrom stats na.omit\n#' @importFrom SummarizedExperiment rowData colData assays\nCoreSet <- function(name, molecularProfiles=list(), sample=data.frame(),\n    sensitivityInfo=data.frame(), sensitivityRaw=array(dim=c(0,0,0)),\n    sensitivityProfiles=matrix(), sensitivityN=matrix(nrow=0, ncol=0),\n    perturbationN=array(NA, dim=c(0,0,0)), curationSample=data.frame(),\n    curationTissue=data.frame(), curationTreatment=data.frame(),\n    treatment=data.frame(), datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n    verify=TRUE, ...\n) {\n\n    # .Deprecated(\"CoreSet2\", package=packageName(), msg=\"The CoreSet class is\n    #     being redesigned. Please use the new constructor to ensure forwards\n    #     compatibility with future releases! Old objects can be updated with\n    #     the updateObject method.\", old=\"CoreSet\")\n\n    # parse deprecated parameters to ensure changes don't break old code\n    dotnames <- ...names()\n    if (\"cell\" %in% dotnames) {\n        .warning(\"The cell parameter is deprecated, assigning to sample...\")\n        sample <- cell\n    }\n    if (\"drug\" %in% dotnames) {\n        .warning(\"The drug paramter is deprecated, assigning to treatment...\")\n        treatment <- drug\n    }\n\n    # ensure new sampleid and treatmentid identifiers are honoured\n    sample <- .checkForSampleId(sample)\n    treatment <- .checkForTreatmentId(treatment)\n    sensitivityInfo <- .checkForSampleId(sensitivityInfo)\n    sensitivityInfo <- .checkForTreatmentId(sensitivityInfo)\n    curationSample <- .checkForIdColumn(curationSample, c(\"sampleid\", \"unique.sampleid\"), \"cellid\")\n    curationTreatment <- .checkForIdColumn(curationTreatment, c(\"treatmentid\", \"unique.treatmentid\"), \"drugid\")\n    for (nm in names(molecularProfiles)) {\n        colData(molecularProfiles[[nm]]) <- .checkForSampleId(\n            colData(molecularProfiles[[nm]]))\n        # handle perturbation case\n        colData(molecularProfiles[[nm]]) <- .checkForIdColumn(\n            colData(molecularProfiles[[nm]]), \"treatmentid\", \"drugid\",\n            error=FALSE)\n    }\n\n    datasetType <- match.arg(datasetType)\n\n    annotation <- list()\n    annotation$name <- as.character(name)\n    annotation$dateCreated <- date()\n    annotation$sessionInfo <- sessionInfo()\n    annotation$call <- match.call()\n\n    for (i in seq_len(length(molecularProfiles))){\n        if (!is(molecularProfiles[[i]], \"SummarizedExperiment\")) {\n            stop(sprintf(\"Please provide the %s data as a SummarizedExperiment\",\n                names(molecularProfiles[i])))\n        } else {\n            rowData(molecularProfiles[[i]]) <-\n                rowData(molecularProfiles[[i]])[\n                    rownames(assays(molecularProfiles[[i]])[[1]]), , drop=FALSE\n            ]\n            colData(molecularProfiles[[i]]) <- colData(molecularProfiles[[i]])[\n                colnames(assays(molecularProfiles[[i]])[[1]]), , drop=FALSE\n            ]\n        }\n    }\n\n    sensitivity <- list()\n\n    if (!all(rownames(sensitivityInfo) == rownames(sensitivityProfiles) &\n        rownames(sensitivityInfo) == dimnames(sensitivityRaw)[[1]])) {\n        stop(\"Please ensure all the row names match between the sensitivity data.\")\n    }\n\n    sensitivity$info <- as.data.frame(sensitivityInfo, stringsAsFactors=FALSE)\n    sensitivity$raw <- sensitivityRaw\n    sensitivity$profiles <- as.data.frame(sensitivityProfiles,\n        stringsAsFactors=FALSE)\n    sensitivity$n <- sensitivityN\n\n    curation <- list()\n    curation$sample <- as.data.frame(curationSample, stringsAsFactors=FALSE)\n    curation$tissue <- as.data.frame(curationTissue, stringsAsFactors=FALSE)\n\n    perturbation <- list()\n    perturbation$n <- perturbationN\n    if (datasetType == \"perturbation\" || datasetType == \"both\") {\n        perturbation$info <- \"The metadata for the perturbation experiments is\n            available for each molecular type by calling the appropriate info\n            function. \\n For example, for RNA transcriptome perturbations, the\n            metadata can be accessed using rnaInfo(cSet).\"\n    } else {\n        perturbation$info <- \"Not a perturbation dataset.\"\n    }\n\n    object  <- .CoreSet(annotation=annotation,\n        molecularProfiles=molecularProfiles,\n        sample=as.data.frame(sample), datasetType=datasetType,\n        treatmentResponse=sensitivity, perturbation=perturbation,\n        curation=curation, treatment=treatment)\n    if (verify) { checkCsetStructure(object)}\n\n    ## TODO:: Are these functions identitical in inheriting packages?\n    if(length(sensitivityN) == 0 &&\n            datasetType %in% c(\"sensitivity\", \"both\")) {\n        sensNumber(object) <- .summarizeSensitivityNumbers(object)\n    }\n    if(length(perturbationN) == 0  &&\n            datasetType %in% c(\"perturbation\", \"both\")) {\n        pertNumber(object) <- .summarizePerturbationNumbers(object)\n    }\n    return(object)\n}\n\n\n#' Utility to help identify and fix deprecated identifiers\n#'\n#' @param new_col `character(1)` The new identifier.\n#' @param old_col `character(1)` A regex matching any old identifers to\n#' replace.\n#'\n#' @return `rectangular` object, with old_col updated to new_col if it exists.\n#'\n#' @noRd\n.checkForIdColumn <- function(df, new_col, old_col, error=TRUE) {\n    if (nrow(df) == 0 || ncol(df) == 0) return(df)\n    name <- as.character(substitute(df))\n    if (!any(colnames(df) %in% new_col)) {\n        if (old_col %in% colnames(df)) {\n            .warning(\"The \", old_col, \"identifier is deprecated, updating to\",\n                new_col, \" in \", name, \"!\")\n            colnames(df) <- gsub(old_col, new_col[1], colnames(df))\n        } else {\n            if (error)\n                .error(\"The \", new_col[1], \" identifier is mandatory in \", name, \"!\")\n        }\n        return(df)\n    }\n    return(df)\n}\n\n#' @noRd\n.checkForTreatmentId <- function(df)\n    .checkForIdColumn(df, new_col=\"treatmentid\", old_col=\"drugid\")\n\n#' @noRd\n.checkForSampleId <- function(df)\n    .checkForIdColumn(df, new_col=\"sampleid\", old_col=\"cellid\")\n\n\n#' @noRd\n.docs_CoreSet2_constructor <- function(...) .parseToRoxygen(\n    \"\n    @title Make a CoreSet with the updated class structure\n\n    @description\n    New implementation of the CoreSet constructor to support MAE and TRE. This\n    constructor will be swapped with the original `CoreSet` constructor as\n    part of an overhaul of the CoreSet class structure.\n\n    @param name A `character(1)` vector with the `{class_}` objects name.\n    @param treatment A `data.frame` with treatment level metadata. {tx_}\n    @param sample A `data.frame` with sample level metadata for the union\n        of samples in `treatmentResponse` and `molecularProfiles`. {sx_}\n    @param molecularProfiles A `MultiAssayExperiment` containing one\n        `SummarizedExperiment` object for each molecular data type.\n    @param treatmentResponse A `LongTable` or `LongTableDataMapper` object\n        containing all treatment response data associated with the `{class_}`\n        object.\n    @param curation {cx_}\n    @param perturbation A deprecated slot in a `{class_}` object included\n    for backwards compatibility. This may be removed in future releases.\n    @param datasetType A deprecated slot in a `{class_}` object included\n    for backwards compatibility. This may be removed in future releases.\n\n    @examples\n    data({data_})\n    {data_}\n\n    @return A `CoreSet` object storing standardized and curated treatment\n        response and multiomic profile data associated with a given publication.\n\n    @importFrom MultiAssayExperiment MultiAssayExperiment\n    @importFrom checkmate assertCharacter assertDataFrame assertClass assert\n    assertList assertSubset\n    \",\n    ...\n)\n\n#' @eval .docs_CoreSet2_constructor(class_=.local_class,\n#' tx_=\"\",\n#' sx_=\"\",\n#' cx_=\"A `list(2)` object with two items named `treatment` and `sample` with\n#' mappings from publication identifiers to standardized identifiers for\n#' both annotations, respectively.\",\n#' data_=.local_data)\n#' @md\n#' @export\nCoreSet2 <- function(name=\"emptySet\", treatment=data.frame(),\n    sample=data.frame(), molecularProfiles=MultiAssayExperiment(),\n    treatmentResponse=LongTable(), datasetType=\"sensitivity\",\n    perturbation=list(n=array(dim=3), info=\"No perturbation data!\"),\n    curation=list(sample=data.frame(), treatment=data.frame())\n) {\n\n    # -- update old curation names\n    names(curation) <- gsub(\"drug|radiation\", \"treatment\", names(curation))\n    names(curation) <- gsub(\"cell\", \"sample\", names(curation))\n\n    ## -- input validation\n    assertCharacter(name, len=1)\n    assertDataFrame(treatment)\n    assertDataFrame(sample)\n    assertClass(molecularProfiles, \"MultiAssayExperiment\")\n    assert(\n        checkClass(treatmentResponse, \"LongTable\"),\n        checkClass(treatmentResponse, \"LongTableDataMapper\")\n    )\n    assertList(curation, min.len=2)\n    assertSubset(c(\"sample\", \"treatment\"), choices=names(curation))\n\n    ## -- capture object creation environment\n    annotation <- list(name=name, dateCreated=date(),\n        sessionInfo=sessionInfo(), call=match.call())\n\n    ## -- conditionally materialize DataMapper\n    if (is(treatmentResponse, 'LongTableDataMapper'))\n        treatmentResponse <- metaConstruct(treatmentResponse)\n\n\n    ## -- handle missing rownames for sample\n    if (!all(sample$sampleid == rownames(sample)))\n        rownames(sample) <- sample$sampleid\n\n    object <- .CoreSet(\n        annotation=annotation,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        treatmentResponse=treatmentResponse,\n        datasetType=datasetType,\n        curation=curation,\n        perturbation=perturbation\n    )\n\n    ## -- data integrity checks\n    # molecularProfiles\n    validProfiles <- .checkMolecularProfiles(object)\n\n    # treatmentResponse\n    validTreatments <- .checkTreatmentResponse(object)\n\n    diagnosis <- c(!isTRUE(validProfiles), !isTRUE(validTreatments))\n    if (any(diagnosis)) {\n        .error(paste0(list(validProfiles, validTreatments)[diagnosis],\n            collapse=\"\\n\", sep=\"\\n\"))\n    }\n    return(object)\n}\n\n#' Show a CoreSet\n#'\n#' @param object `CoreSet` object to show via `cat`.\n#'\n#' @seealso [`cat`]\n#'\n#' @examples\n#' show(clevelandSmall_cSet)\n#'\n#' @return Prints the CoreSet object to the output stream, and returns\n#'   invisible NULL.\n#' \n#' @importFrom crayon %+% yellow red green blue cyan magenta\n#' \n#' @md\n#' @export\nsetMethod(\"show\", signature=signature(object=\"CoreSet\"), function(object) {\n\n    if (!.hasSlot(object, \"sample\") || !.hasSlot(object, \"treatment\"))\n        stop(.errorMsg(\"This \", class(object)[1], \" object appears to be out\",\n            \"of date! Please run object <- updateObject(object) to update \",\n            \"the object for compatibility with the current release.\"),\n            call.=FALSE)\n\n    cat(yellow$bold$italic(paste0(\"<\", class(object)[1], \">\\n\")))\n    space <- \"  \"\n    cat(yellow$bold$italic(\"Name: \") %+% green(name(object)), \"\\n\")\n\n    cat(yellow$bold$italic(\"Date Created: \") %+% green(dateCreated(object)), \"\\n\")\n\n    # cat(\"Number of samples: \", nrow(sampleInfo(object)), \"\\n\")\n    cat(yellow$bold$italic(\"Number of samples: \"), green(nrow(sampleInfo(object))), \"\\n\")\n\n    mProfiles <- molecularProfilesSlot(object)\n    mProfileNames <- names(mProfiles)\n    if (is(mProfiles, \"MultiAssayExperiment\")) {\n        cat(yellow$bold$italic(\"Molecular profiles: \"))\n        cat(yellow$bold$italic(paste0(\"<\", class(mProfiles)[1], \">\"), '\\n'))\n\n        # changing this to just experiments() as its cleaner\n        # showMAE <- capture.output(show(mProfiles))\n        # dropAfter <- which(grepl(\"Functionality\", showMAE)) - 1\n        # showCompactMAE <- showMAE[1:dropAfter]\n        # cat(space, paste0(showCompactMAE, collapse=\"\\n  \"), \"\\n\")\n\n        showExp <- capture.output(experiments(mProfiles))\n        cat(space, yellow$bold(showExp[1], '\\n'))\n\n        # iterate through rest of experiments \n        # split by \":\" and print the first element in yellow, the rest in cyan\n        for (i in 2:length(showExp)) {\n            splitExp <- strsplit(showExp[i], \":\")[[1]]\n            \n            # print the first 5 characters in splitExp[1] in yellow\n            cat(space, yellow$bold(substr(splitExp[1], 1, 5)))\n            # print after the first 5 characters in spllitExp[1] in cyan\n            cat(\n                red(substr(splitExp[1], 6, nchar(splitExp[1]))),\n                green(paste0(\":\", splitExp[2:length(splitExp)], collapse=\":\"),'\\n'))\n        }\n\n        # samplenames <- sort(sampleNames(object))\n        # samplenames <- \n        #     if (length(samplenames) > 6) {\n        #         paste0(.collapse(head(samplenames, 3)), ' ... ', .collapse(tail(samplenames, 3)))\n        #     } else {\n        #         .collapse(samplenames)\n        #     }\n        # x <- yellow$bold(paste0(\"colnames(\", length(sampleNames(object)), \"):\"))\n        # cat(space, x, green(samplenames), \"\\n\")\n    } else {\n        cat(yellow$bold$italic(\"Molecular profiles: \\n\"))\n        if (!length(mProfileNames)) cat(space, \"None\\n\")\n        for (item in mProfileNames) {\n            title <- switch(item,\n                \"dna\"=\"DNA\",\n                \"rna\"=\"RNA\",\n                \"rnaseq\"=\"RNAseq\",\n                \"snp\"=\"SNP\",\n                \"cnv\"=\"CNV\",\n                item\n            )\n            cat(title, \":\\n\")\n            cat(paste0(space, \"Dim: \",\n                paste0(dim(molecularProfiles(object, mDataType=item)), collapse=\", \")),\n                \"\\n\"\n            )\n        }\n    }\n    cat(yellow$bold$italic(\"Treatment response: \"))\n    if (is(treatmentResponse(object), \"LongTable\")) {\n        show(treatmentResponse(object))\n        # showLT <- capture.output(show(treatmentResponse(object)))\n        # cat(space, paste0(showLT, collapse=\"\\n  \"), \"\\n\")\n    } else {\n        cat(\"Drug pertubation:\\n\")\n        cat(space,\n            \"Please look at pertNumber(cSet) to determine number of experiments\",\n            \" for each drug-sample combination.\\n\")\n        cat(\"Drug sensitivity:\\n\")\n        cat(space, \"Number of Experiments: \", nrow(sensitivityInfo(object)), \"\\n\")\n        cat(space, \"Please look at sensNumber(cSet) to determine number of \",\n            \"experiments for each drug-sample combination.\\n\")\n    }\n})\n\n\n#' Update the sample ids in a cSet object\n#'\n#' @examples\n#' updateSampleId(clevelandSmall_cSet, sampleNames(clevelandSmall_cSet))\n#'\n#' @param object The object for which the sample ids will be updated\n#' @param new.ids The new ids to assign to the object\n#'\n#' @return \\code{CoreSet} The modified CoreSet object\n#'\n#' @keywords internal\n#' @importFrom S4Vectors endoapply\n#' @importFrom SummarizedExperiment colData rowData\n#' @export\nupdateSampleId <- function(object, new.ids=vector(\"character\")) {\n\n    if (length(new.ids) != nrow(sampleInfo(object))){\n        stop(\"Wrong number of sample identifiers\")\n    }\n\n    if (datasetType(object) == \"sensitivity\" || datasetType(object) == \"both\") {\n        myx <- match(sensitivityInfo(object)[, \"sampleid\"],\n            rownames(sampleInfo(object)))\n        if (is(treatmentResponse(object), 'LongTable')) {\n            LT <- treatmentResponse(object)\n            whichSampleIds <- which(colData(LT)$sampleid %in% sampleNames(object))\n            colData(LT)$sampleid <- new.ids[whichSampleIds]\n            treatmentResponse(object) <- LT\n        } else {\n            sensitivityInfo(object)[, \"sampleid\"] <- new.ids[myx]\n        }\n    }\n\n    molecularProfilesSlot(object) <- lapply(molecularProfilesSlot(object), function(SE) {\n        myx <- match(colData(SE)[[\"sampleid\"]],\n            rownames(sampleInfo(object)))\n        colData(SE)[[\"sampleid\"]]  <- new.ids[myx]\n        return(SE)\n    })\n\n    if (any(duplicated(new.ids))) {\n        warning(\"Duplicated ids passed to updateSampleId. Merging old ids into\",\n            \" the same identifier\")\n\n        if(ncol(sensNumber(object)) > 0) {\n            sensMatch <- match(rownames(sensNumber(object)),\n                rownames(sampleInfo(object)))\n        }\n        if(dim(pertNumber(object))[[2]] > 0) {\n            pertMatch <- match(dimnames(pertNumber(object))[[1]],\n                rownames(sampleInfo(object)))\n        }\n\n        curMatch <- match(rownames(curation(object)$sample),\n            rownames(sampleInfo(object)))\n        duplId <- unique(new.ids[duplicated(new.ids)])\n\n        for(id in duplId){\n            if (ncol(sensNumber(object)) > 0) {\n                myx <- which(new.ids[sensMatch] == id)\n                sensNumber(object)[myx[1],] <- apply(sensNumber(object)[myx, ],\n                    2, sum)\n                sensNumber(object) <- sensNumber(object)[-myx[-1], ]\n                # sensMatch <- sensMatch[-myx[-1]]\n        }\n        if (dim(pertNumber(object))[[1]] > 0) {\n            myx <- which(new.ids[pertMatch] == id)\n            pertNumber(object)[myx[1], , ] <- apply(pertNumber(object)[myx, , ],\n                c(1,3), sum)\n            pertNumber(object) <- pertNumber(object)[-myx[-1], , ]\n        }\n\n        myx <- which(new.ids[curMatch] == id)\n        curation(object)$sample[myx[1],] <- apply(curation(object)$sample[myx, ], 2,\n            FUN=paste, collapse=\"///\")\n        curation(object)$sample <- curation(object)$sample[-myx[-1], ]\n        curation(object)$tissue[myx[1],] <- apply(curation(object)$tissue[myx, ],\n            2, FUN=paste, collapse=\"///\")\n        curation(object)$tissue <- curation(object)$tissue[-myx[-1], ]\n\n        myx <- which(new.ids == id)\n        sampleInfo(object)[myx[1],] <- apply(sampleInfo(object)[myx,], 2,\n            FUN=paste, collapse=\"///\")\n        sampleInfo(object) <- sampleInfo(object)[-myx[-1], ]\n        new.ids <- new.ids[-myx[-1]]\n        if(ncol(sensNumber(object)) > 0){\n            sensMatch <- match(rownames(sensNumber(object)),\n                rownames(sampleInfo(object)))\n        }\n        if(dim(pertNumber(object))[[1]] > 0){\n            pertMatch <- match(dimnames(pertNumber(object))[[1]],\n                rownames(sampleInfo(object)))\n        }\n        curMatch <- match(rownames(curation(object)$sample),\n            rownames(sampleInfo(object)))\n        }\n    } else {\n        if (dim(pertNumber(object))[[1]] > 0) {\n            pertMatch <- match(dimnames(pertNumber(object))[[1]],\n                rownames(sampleInfo(object)))\n        }\n        if (ncol(sensNumber(object)) > 0) {\n            sensMatch <- match(rownames(sensNumber(object)),\n                rownames(sampleInfo(object)))\n        }\n        curMatch <- match(rownames(curation(object)$sample),\n            rownames(sampleInfo(object)))\n    }\n    if (dim(pertNumber(object))[[1]] > 0) {\n        dimnames(pertNumber(object))[[1]] <- new.ids[pertMatch]\n    }\n    if (ncol(sensNumber(object)) > 0) {\n        rownames(sensNumber(object)) <- new.ids[sensMatch]\n    }\n    rownames(curation(object)$sample) <- new.ids[curMatch]\n    rownames(curation(object)$tissue) <- new.ids[curMatch]\n    rownames(sampleInfo(object)) <- new.ids\n    return(object)\n}\n\n# updateFeatureNames <- function(object, new.ids=vector(\"character\")){\n#\n#   if (length(new.ids)!=nrow(sampleInfo(object))){\n#     stop(\"Wrong number of sample identifiers\")\n#   }\n#\n#   if(datasetType(object)==\"sensitivity\"|datasetType(object)==\"both\"){\n#     myx <- match(sensitivityInfo(object)[,\"sampleid\"],rownames(sampleInfo(object)))\n#     sensitivityInfo(object)[,\"sampleid\"] <- new.ids[myx]\n#\n#   }\n#\n#   molecularProfilesSlot(object) <- lapply(molecularProfilesSlot(object), function(eset){\n#\n#     myx <- match(colData(eset)[[\"sampleid\"]],rownames(sampleInfo(object)))\n#     colData(eset)[[\"sampleid\"]]  <- new.ids[myx]\n#     return(eset)\n#       })\n#   myx <- match(rownames(curation(object)$sample),rownames(sampleInfo(object)))\n#   rownames(curation(object)$sample) <- new.ids[myx]\n#   rownames(curation(object)$tissue) <- new.ids[myx]\n#   if (dim(pertNumber(object))[[1]]>0){\n#     myx <- match(dimnames(pertNumber(object))[[1]], rownames(sampleInfo(object)))\n#     dimnames(pertNumber(object))[[1]] <- new.ids[myx]\n#   }\n#   if (nrow(sensNumber(object))>0){\n#     myx <- match(rownames(sensNumber(object)), rownames(sampleInfo(object)))\n#     rownames(sensNumber(object)) <- new.ids[myx]\n#   }\n#   rownames(sampleInfo(object)) <- new.ids\n#   return(object)\n#\n# }\n\n\n### TODO:: Add updating of sensitivity Number tables\n#' Update the treatment ids in a cSet object\n#'\n#' @examples\n#' updateTreatmentId(clevelandSmall_cSet, treatmentNames(clevelandSmall_cSet))\n#'\n#' @param object The object for which the treatment ids will be updated\n#' @param new.ids The new ids to assign to the object\n#'\n#' @return `CoreSet` The modified CoreSet object\n#'\n#' @keywords internal\n#' @importFrom S4Vectors endoapply\n#' @importFrom SummarizedExperiment colData rowData\n#' @export\nupdateTreatmentId <- function(object, new.ids = vector('character')){\n\n    if (nrow(treatmentInfo(object)) < 1) {\n        message(\"No treatments in this object! Returning without modification.\")\n        return(object)\n    }\n\n    if (length(new.ids) != nrow(treatmentInfo(object))) {\n        stop('Wrong number of drug identifiers')\n    }\n    if (datasetType(object) == 'sensitivity' || datasetType(object) == 'both') {\n        myx <- match(sensitivityInfo(object)[, \"treatmentid\"], rownames(treatmentInfo(object)))\n        sensitivityInfo(object)[, \"treatmentid\"] <- new.ids[myx]\n    }\n    if (datasetType(object) == 'perturbation' || datasetType(object) == 'both') {\n        molecularProfilesSlot(object) <- lapply(molecularProfilesSlot(object),\n                function(SE) {\n            myx <- match(\n                SummarizedExperiment::colData(SE)[[\"treatmentid\"]],\n                rownames(treatmentInfo(object))\n            )\n            SummarizedExperiment::colData(SE)[[\"treatmentid\"]] <- new.ids[myx]\n            return(SE)\n        })\n    }\n    if (any(duplicated(new.ids))) {\n        warning('Duplicated ids passed to updateTreatmentId. Merging old ids ',\n            'into the same identifier')\n        if (ncol(sensNumber(object)) > 0){\n            sensMatch <- match(colnames(sensNumber(object)),\n                rownames(treatmentInfo(object)))\n        }\n        if (dim(pertNumber(object))[[2]] > 0) {\n            pertMatch <- match(dimnames(pertNumber(object))[[2]],\n                rownames(treatmentInfo(object)))\n        }\n        if (\"treatment\" %in% names(curation(object))) {\n            curMatch <- match(rownames(curation(object)$treatment),\n                rownames(treatmentInfo(object)))\n        }\n        duplId <- unique(new.ids[duplicated(new.ids)])\n        for(id in duplId) {\n            if (ncol(sensNumber(object))>0){\n                myx <- which(new.ids[sensMatch] == id)\n                sensNumber(object)[, myx[1]] <- apply(sensNumber(object)[, myx], 1, sum)\n                sensNumber(object) <- sensNumber(object)[, -myx[-1]]\n                # sensMatch <- sensMatch[-myx[-1]]\n            }\n            if (dim(pertNumber(object))[[2]] > 0) {\n                myx <- which(new.ids[pertMatch] == id)\n                pertNumber(object)[,myx[1],] <- apply(pertNumber(object)[,myx,],\n                    c(1,3), sum)\n                pertNumber(object) <- pertNumber(object)[,-myx[-1], ]\n                # pertMatch <- pertMatch[-myx[-1]]\n            }\n            if (\"treatment\" %in% names(curation(object))) {\n                myx <- which(new.ids[curMatch] == id)\n                curation(object)$treatment[myx[1], ] <-\n                    apply(curation(object)$treatment[myx, ], 2, paste,\n                        collapse='///')\n                curation(object)$treatment <- curation(object)$treatment[-myx[-1], ]\n                # curMatch <- curMatch[-myx[-1]]\n            }\n\n            myx <- which(new.ids == id)\n            treatmentInfo(object)[myx[1],] <- apply(treatmentInfo(object)[myx,],\n                2, paste, collapse='///')\n            treatmentInfo(object) <- treatmentInfo(object)[-myx[-1], ]\n            new.ids <- new.ids[-myx[-1]]\n            if (ncol(sensNumber(object)) > 0) {\n                sensMatch <- match(colnames(sensNumber(object)),\n                    rownames(treatmentInfo(object)))\n            }\n            if (dim(pertNumber(object))[[2]] > 0) {\n                pertMatch <- match(dimnames(pertNumber(object))[[2]],\n                    rownames(treatmentInfo(object)))\n            }\n            if (\"treatment\" %in% names(curation(object))) {\n                curMatch <- match(rownames(curation(object)$treatment),\n                    rownames(treatmentInfo(object)))\n            }\n        }\n    } else {\n        if (dim(pertNumber(object))[[2]]>0){\n            pertMatch <- match(dimnames(pertNumber(object))[[2]],\n                rownames(treatmentInfo(object)))\n        }\n        if (ncol(sensNumber(object))>0){\n            sensMatch <- match(colnames(sensNumber(object)),\n                rownames(treatmentInfo(object)))\n        }\n        if (\"treatment\" %in% names(curation(object))) {\n            curMatch <- match(rownames(curation(object)$treatment),\n                rownames(treatmentInfo(object)))\n        }\n    }\n    if (dim(pertNumber(object))[[2]]>0){\n        dimnames(pertNumber(object))[[2]] <- new.ids[pertMatch]\n    }\n    if (ncol(sensNumber(object))>0){\n        colnames(sensNumber(object)) <- new.ids[sensMatch]\n    }\n    if (\"treatment\" %in% names(curation(object))) {\n        rownames(curation(object)$treatment) <- new.ids[curMatch]\n    }\n    rownames(treatmentInfo(object)) <- new.ids\n    return(object)\n}\n\n\n.summarizeSensitivityNumbers <- function(object) {\n\n    if (datasetType(object) != \"sensitivity\" && datasetType(object) != \"both\") {\n        stop (\"Data type must be either sensitivity or both\")\n    }\n\n    ## unique drug identifiers\n    # drugn <- sort(unique(treatmentResponse(object)$info[ , \"treatmentid\"]))\n\n    ## consider all drugs\n    drugn <- rownames(treatmentInfo(object))\n\n    ## unique drug identifiers\n    # samplen <- sort(unique(treatmentResponse(object)$info[ , \"sampleid\"]))\n\n    ## consider all sample\n    samplen <- rownames(sampleInfo(object))\n\n    sensitivity.info <- matrix(0, nrow=length(samplen), ncol=length(drugn),\n        dimnames=list(samplen, drugn))\n    drugids <- sensitivityInfo(object)[, \"treatmentid\"]\n    sampleids <- sensitivityInfo(object)[, \"sampleid\"]\n    sampleids <- sampleids[grep(\"///\", drugids, invert=TRUE)]\n    drugids <- drugids[grep(\"///\", drugids, invert=TRUE)]\n\n    tt <- table(sampleids, drugids)\n    sensitivity.info[rownames(tt), colnames(tt)] <- tt\n\n    return(sensitivity.info)\n}\n\n#' @export\n#' @keywords internal\n.summarizeMolecularNumbers <- function(object) {\n\n    ## consider all molecular types\n    mDT <- mDataNames(object)\n\n    ## consider all sample lines\n    samplen <- rownames(sampleInfo(object))\n\n    molecular.info <- matrix(0, nrow=length(samplen), ncol=length(mDT),\n        dimnames=list(samplen, mDT))\n\n    for(mDataType in mDT) {\n        tt <- table(phenoInfo(object, mDataType)$sampleid)\n        molecular.info[names(tt), mDataType] <- tt\n    }\n    return(molecular.info)\n}\n\n#' @importFrom SummarizedExperiment colData rowData\n.summarizePerturbationNumbers <- function(object) {\n\n    if (datasetType(object) != \"perturbation\" && datasetType(object) != \"both\") {\n        stop (\"Data type must be either perturbation or both\")\n    }\n\n    ## consider all drugs\n    drugn <- rownames(treatmentInfo(object))\n\n    ## consider all sample lines\n    samplen <- rownames(sampleInfo(object))\n\n    perturbation.info <- array(0, dim=c(length(samplen), length(drugn),\n        length(molecularProfilesSlot(object))),\n        dimnames=list(samplen, drugn, names((molecularProfilesSlot(object)))))\n\n    for (i in seq_len(length(molecularProfilesSlot(object)))) {\n        if (nrow(colData(molecularProfilesSlot(object)[[i]])) > 0 &&\n                all(is.element(c(\"sampleid\", \"treatmentid\"),\n                    colnames(colData(molecularProfilesSlot(object)[[i]]))))) {\n            tt <- table(colData(molecularProfilesSlot(object)[[i]])[ , \"sampleid\"],\n                colData(molecularProfilesSlot(object)[[i]])[ , \"treatmentid\"])\n            perturbation.info[rownames(tt), colnames(tt),\n                names(molecularProfilesSlot(object))[i]] <- tt\n        }\n    }\n\n    return(perturbation.info)\n}\n\n#' A function to verify the structure of a CoreSet\n#'\n#' This function checks the structure of a PharamcoSet, ensuring that the\n#' correct annotations are in place and all the required slots are filled so\n#' that matching of samples and drugs can be properly done across different types\n#' of data and with other studies.\n#'\n#' @examples\n#' checkCsetStructure(clevelandSmall_cSet)\n#'\n#' @param object A `CoreSet` to be verified\n#' @param plotDist Should the function also plot the distribution of molecular\n#'   data?\n#' @param result.dir The path to the directory for saving the plots as a string.\n#'   Defaults to this R sessions `tempdir()`.\n#'\n#' @return Prints out messages whenever describing the errors found in the\n#'   structure of the cSet object passed in.\n#'\n#' @export\n#'\n#' @md\n#' @importFrom graphics hist\n#' @importFrom grDevices dev.off pdf\n#' @importFrom SummarizedExperiment assay rowData colData\n#' @importFrom S4Vectors metadata\ncheckCsetStructure <- function(object, plotDist=FALSE, result.dir=tempdir()) {\n\n    msg <- c()\n\n    # Make directory to store results if it doesn't exist\n    if (!file.exists(result.dir) && plotDist) {\n        dir.create(result.dir, showWarnings=FALSE, recursive=TRUE)\n    }\n\n    ####\n    ## Checking molecularProfiles\n    ####\n    for (i in seq_along(molecularProfilesSlot(object))) {\n        profile <- molecularProfilesSlot(object)[[i]]\n        nn <- names(molecularProfilesSlot(object))[i]\n\n        # Testing plot rendering for rna and rnaseq\n        if ((metadata(profile)$annotation == \"rna\" ||\n                metadata(profile)$annotation == \"rnaseq\") && plotDist) {\n            pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n            hist(assay(profile, 'exprs'), breaks=100)\n            dev.off()\n        }\n\n        ## Test if sample and feature annotations dimensions match the assay\n        if (nrow(rowData(profile)) != nrow(assays(profile)$exprs)) {\n            msg <- c(msg, paste0(nn, \" number of features in rowData is \",\n                \"different from SummarizedExperiment slots\"))\n        }\n        if (nrow(colData(profile)) != ncol(assays(profile)$exprs)) {\n            msg <- c(msg, paste0(nn, \"number of samples in colData is \",\n                \"different from expression slots\", nn))\n        }\n\n        # Checking sample metadata for required columns\n        if (!(\"sampleid\" %in% colnames(colData(profile)))) {\n            msg <- c(msg, paste0(nn, \" sampleid does not exist in colData \",\n                \"(samples) columns\"))\n        }\n        if (!(\"batchid\" %in% colnames(colData(profile)))) {\n            msg <- c(msg, sprintf(nn, \" batchid does not exist in colData \",\n                \"(samples) columns\"))\n        }\n\n        # Checking mDataType of the SummarizedExperiment for required columns\n        if (metadata(profile)$annotation == \"rna\" ||\n                metadata(profile)$annotation == \"rnaseq\") {\n            if (!(\"BEST\" %in% colnames(rowData(profile)))) {\n                msg <- c(msg, paste0(nn, \" BEST does not exist in rowData \",\n                    \"(features) columns\"))\n            }\n            if (!(\"Symbol\" %in% colnames(rowData(profile)))) {\n                msg <- c(msg, paste0(nn, \" Symbol does not exist in rowData \",\n                    \"(features) columns\"))\n            }\n        }\n\n        # Check that all sampleids from the cSet are included in molecularProfiles\n        if (\"sampleid\" %in% colnames(rowData(profile))) {\n            if (!all(colData(profile)[, \"sampleid\"] %in% rownames(sampleInfo(object)))) {\n                msg <- c(msg, paste0(nn, \" not all the sample lines in this \",\n                    \"profile are in sample lines slot\"))\n            }\n        } else {\n            msg <- c(msg, paste0(nn, \" sampleid does not exist in colData \",\n                \"(samples)\"))\n        }\n    }\n\n    #####\n    # Checking sample\n    #####\n    if (\"tissueid\" %in% colnames(sampleInfo(object))) {\n        if (\"unique.tissueid\" %in% colnames(curation(object)$tissue)) {\n            if (length(intersect(rownames(curation(object)$tissue),\n                    rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n                msg <- c(msg, paste0(\"rownames of curation tissue slot should\",\n                    \" be the same as sample slot (curated sample ids)\"))\n            } else {\n                if (length(intersect(sampleInfo(object)$tissueid,\n                        curation(object)$tissue$unique.tissueid)) !=\n                            length(table(sampleInfo(object)$tissueid))) {\n                    msg <- c(msg, paste0(\"tissueid should be the same as unique\",\n                        \" tissue id from tissue curation slot\"))\n                }\n            }\n        } else {\n            msg <- c(msg, paste0(\"unique.tissueid which is curated tissue id\",\n                \" across data set should be a column of tissue curation slot\"))\n        }\n        if (any(is.na(sampleInfo(object)[,\"tissueid\"]) |\n                sampleInfo(object)[, \"tissueid\"] == \"\", na.rm=TRUE)) {\n            msg <- c(msg, paste0(\n                    \"There is no tissue type for these samples\",\n                    paste(\n                        rownames(sampleInfo(object))[\n                            which(is.na(sampleInfo(object)[,\"tissueid\"]) |\n                                sampleInfo(object)[,\"tissueid\"] == \"\")\n                            ],\n                        collapse=\" \")))\n        }\n    } else {\n        msg <- c(msg, \"tissueid does not exist in sample slot\")\n    }\n\n    if(\"unique.sampleid\" %in% colnames(curation(object)$sample)) {\n        if (length(intersect(curation(object)$sample$unique.sampleid,\n                rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n            msg <- c(msg, \"rownames of sample slot should be curated sample ids\")\n        }\n    } else {\n        msg <- c(msg, paste0(\"unique.sampleid which is curated sample id across\",\n            \" data set should be a column of sample curation slot\"))\n    }\n\n    if (length(intersect(rownames(curation(object)$sample),\n            rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n        msg <- c(msg, paste0(\"rownames of curation sample slot should be the\",\n            \" same as sample slot (curated sample ids)\"))\n    }\n\n    if (!is(sampleInfo(object), \"data.frame\")) {\n        msg <- c(msg, \"sample slot class type should be dataframe\")\n    }\n    if (length(msg)) return(paste0(msg, collapse=\"\\n\")) else TRUE\n}\n\n#' @importFrom MultiAssayExperiment MultiAssayExperiment experiments\n#' @importFrom S4Vectors List\n#' @importFrom BiocGenerics %in% match\n.checkMolecularProfiles <- function(object) {\n    msg <- character()\n    # ---- Make a MutliAssayExperiment, if it isn't one already\n    molecProf <- molecularProfilesSlot(object)\n    isSummarizedExperiment <- all(as(lapply(experiments(molecProf), is,\n        'SummarizedExperiment'), 'List'))\n    if (!all(isSummarizedExperiment)) {\n        nmsg <- .formatMessage('All molecular profiles must be stored as\n            SummarizedExperiment objects. The following are not ',\n            paste(names(which(!isSummarizedExperiment)), collapse=', '))\n        msg <- c(msg, nmsg)\n    }\n    tryCatch({\n        MAE <- if (is(molecProf, 'MultiAssayExperiment')) molecProf else\n            MultiAssayExperiment(molecProf)\n    }, error=function(e) msg <- c(msg, paste0('Failed coercing to\n        MultiAssayExperiment: ', as.character(e))))\n\n    # ---- Check for correct metadata columns\n    # -- sample identifiers\n    colDataL <- lapply(experiments(MAE), FUN=colData)\n    colColNameL <- as(lapply(colDataL, FUN=colnames), 'List')\n    hasSampleId <- any(colColNameL %in%  'sampleid')\n    if (!all(hasSampleId)) {\n        nmsg <- .formatMessage('All SummarizedExperiments must have a sampleid\n            column. This is not the case for ',\n            paste(names(which(!hasSampleId)), collapse=', '), '!')\n        msg <- c(msg, nmsg)\n    }\n    hasBatchId <- any(colColNameL %in% 'batchid')\n    if (!all(hasBatchId)) {\n        nmsg <- .formatMessage('All SummarizedExpeirments must have a batchid\n            column. This is not the case for ',\n            paste(names(which(!hasBatchId)), collapse=', '), '!')\n        msg <- c(msg, nmsg)\n    }\n    # -- feature identifiers\n    rowDataL <- lapply(experiments(MAE), FUN=rowData)\n    rowColNameL <- as(lapply(rowDataL, colnames), 'List')\n    # hasGeneId <- rowColNameL %in% 'geneid'\n    hasSymbol <- rowColNameL %in% 'Symbol'\n    hasBEST <- rowColNameL %in% 'BEST'\n    # hasEnsemblId <- rowColNamesL %in% 'ensemblid'\n\n    # ---- Check all samples are in the @sample slot\n    samples <- sampleNames(object)\n\n    \n    sampleIdL <- as(lapply(colDataL, `[[`, i='sampleid'), 'List')\n    hasValidSamples <- sampleIdL %in% samples\n    if (!all(all(hasValidSamples))) {\n        nmsg <- .formatMessage('All sampleids in the @molecularProfiles slot\n            must also be in the @sample slot. This is not the case\n            for ', paste(names(which(all(hasValidSamples))), collapse=', '))\n        msg <- c(msg, nmsg)\n    }\n\n    # ---- Return messages if something is wrong, or TRUE if everything is good\n    return(if (length(msg)) msg else TRUE)\n}\n\n.checkTreatmentResponse <- function(object) {\n    msg <- character()\n    # ---- Extract sensitivity data\n    samples <- sampleNames(object)\n    sensSlot <- treatmentResponse(object)\n    if (!is(sensSlot, \"TreatmentResponseExperiment\")) {\n        nmsg <- \"The treatmentReponse parameter must be a\n            TreatmentResponseExperiment!\"\n        msg <- c(msg, nmsg)\n        return(msg)\n    }\n    return(if (length(msg)) msg else TRUE)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the CoreSet class?",
        "answer": "The CoreSet (cSet) class is designed as a superclass for pSets in the PharmacoGx and RadioGx packages to contain data generated in screens of cancer sample lines for their genetic profile and sensitivities to therapy (Pharmacological or Radiation). It provides a standardized data structure for storing and analyzing molecular profiles and treatment response data."
      },
      {
        "question": "What are the main slots in the CoreSet class?",
        "answer": "The main slots in the CoreSet class are: annotation, molecularProfiles, sample, treatment, treatmentResponse, perturbation, curation, and datasetType. These slots store various types of data and metadata related to the molecular profiles, samples, treatments, and experimental results."
      },
      {
        "question": "How does the CoreSet constructor handle missing or empty data?",
        "answer": "The CoreSet constructor creates empty objects for data not provided. It also performs checks on the structure of the provided data, ensures proper formatting, and creates summary statistics for sensitivity and perturbation data if they are not provided but the datasetType indicates they should be present."
      }
    ],
    "completion_tasks": [
      {
        "partial": "CoreSet <- function(name, molecularProfiles=list(), sample=data.frame(),\n    sensitivityInfo=data.frame(), sensitivityRaw=array(dim=c(0,0,0)),\n    sensitivityProfiles=matrix(), sensitivityN=matrix(nrow=0, ncol=0),\n    perturbationN=array(NA, dim=c(0,0,0)), curationSample=data.frame(),\n    curationTissue=data.frame(), curationTreatment=data.frame(),\n    treatment=data.frame(), datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n    verify=TRUE, ...\n) {\n    # Parse deprecated parameters\n    dotnames <- ...names()\n    if (\"cell\" %in% dotnames) {\n        .warning(\"The cell parameter is deprecated, assigning to sample...\")\n        sample <- cell\n    }\n    if (\"drug\" %in% dotnames) {\n        .warning(\"The drug paramter is deprecated, assigning to treatment...\")\n        treatment <- drug\n    }\n\n    # Ensure new sampleid and treatmentid identifiers are honoured\n    sample <- .checkForSampleId(sample)\n    treatment <- .checkForTreatmentId(treatment)\n    sensitivityInfo <- .checkForSampleId(sensitivityInfo)\n    sensitivityInfo <- .checkForTreatmentId(sensitivityInfo)\n    curationSample <- .checkForIdColumn(curationSample, c(\"sampleid\", \"unique.sampleid\"), \"cellid\")\n    curationTreatment <- .checkForIdColumn(curationTreatment, c(\"treatmentid\", \"unique.treatmentid\"), \"drugid\")\n    for (nm in names(molecularProfiles)) {\n        colData(molecularProfiles[[nm]]) <- .checkForSampleId(\n            colData(molecularProfiles[[nm]]))\n        colData(molecularProfiles[[nm]]) <- .checkForIdColumn(\n            colData(molecularProfiles[[nm]]), \"treatmentid\", \"drugid\",\n            error=FALSE)\n    }\n\n    datasetType <- match.arg(datasetType)\n\n    # Create annotation list\n    annotation <- list(\n        name = as.character(name),\n        dateCreated = date(),\n        sessionInfo = sessionInfo(),\n        call = match.call()\n    )\n\n    # TODO: Complete the rest of the function\n}",
        "complete": "CoreSet <- function(name, molecularProfiles=list(), sample=data.frame(),\n    sensitivityInfo=data.frame(), sensitivityRaw=array(dim=c(0,0,0)),\n    sensitivityProfiles=matrix(), sensitivityN=matrix(nrow=0, ncol=0),\n    perturbationN=array(NA, dim=c(0,0,0)), curationSample=data.frame(),\n    curationTissue=data.frame(), curationTreatment=data.frame(),\n    treatment=data.frame(), datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n    verify=TRUE, ...\n) {\n    # Parse deprecated parameters\n    dotnames <- ...names()\n    if (\"cell\" %in% dotnames) {\n        .warning(\"The cell parameter is deprecated, assigning to sample...\")\n        sample <- cell\n    }\n    if (\"drug\" %in% dotnames) {\n        .warning(\"The drug paramter is deprecated, assigning to treatment...\")\n        treatment <- drug\n    }\n\n    # Ensure new sampleid and treatmentid identifiers are honoured\n    sample <- .checkForSampleId(sample)\n    treatment <- .checkForTreatmentId(treatment)\n    sensitivityInfo <- .checkForSampleId(sensitivityInfo)\n    sensitivityInfo <- .checkForTreatmentId(sensitivityInfo)\n    curationSample <- .checkForIdColumn(curationSample, c(\"sampleid\", \"unique.sampleid\"), \"cellid\")\n    curationTreatment <- .checkForIdColumn(curationTreatment, c(\"treatmentid\", \"unique.treatmentid\"), \"drugid\")\n    for (nm in names(molecularProfiles)) {\n        colData(molecularProfiles[[nm]]) <- .checkForSampleId(\n            colData(molecularProfiles[[nm]]))\n        colData(molecularProfiles[[nm]]) <- .checkForIdColumn(\n            colData(molecularProfiles[[nm]]), \"treatmentid\", \"drugid\",\n            error=FALSE)\n    }\n\n    datasetType <- match.arg(datasetType)\n\n    # Create annotation list\n    annotation <- list(\n        name = as.character(name),\n        dateCreated = date(),\n        sessionInfo = sessionInfo(),\n        call = match.call()\n    )\n\n    # Process molecular profiles\n    for (i in seq_len(length(molecularProfiles))){\n        if (!is(molecularProfiles[[i]], \"SummarizedExperiment\")) {\n            stop(sprintf(\"Please provide the %s data as a SummarizedExperiment\",\n                names(molecularProfiles[i])))\n        } else {\n            rowData(molecularProfiles[[i]]) <-\n                rowData(molecularProfiles[[i]])[\n                    rownames(assays(molecularProfiles[[i]])[[1]]), , drop=FALSE\n                ]\n            colData(molecularProfiles[[i]]) <- colData(molecularProfiles[[i]])[\n                colnames(assays(molecularProfiles[[i]])[[1]]), , drop=FALSE\n            ]\n        }\n    }\n\n    # Create sensitivity list\n    sensitivity <- list(\n        info = as.data.frame(sensitivityInfo, stringsAsFactors=FALSE),\n        raw = sensitivityRaw,\n        profiles = as.data.frame(sensitivityProfiles, stringsAsFactors=FALSE),\n        n = sensitivityN\n    )\n\n    # Create curation list\n    curation <- list(\n        sample = as.data.frame(curationSample, stringsAsFactors=FALSE),\n        tissue = as.data.frame(curationTissue, stringsAsFactors=FALSE)\n    )\n\n    # Create perturbation list\n    perturbation <- list(\n        n = perturbationN,\n        info = if (datasetType %in% c(\"perturbation\", \"both\")) {\n            \"The metadata for the perturbation experiments is available for each molecular type by calling the appropriate info function.\"\n        } else {\n            \"Not a perturbation dataset.\"\n        }\n    )\n\n    # Create CoreSet object\n    object <- .CoreSet(\n        annotation = annotation,\n        molecularProfiles = molecularProfiles,\n        sample = as.data.frame(sample),\n        datasetType = datasetType,\n        treatmentResponse = sensitivity,\n        perturbation = perturbation,\n        curation = curation,\n        treatment = treatment\n    )\n\n    # Verify object structure if requested\n    if (verify) { checkCsetStructure(object) }\n\n    # Update sensitivity and perturbation numbers if necessary\n    if (length(sensitivityN) == 0 && datasetType %in% c(\"sensitivity\", \"both\")) {\n        sensNumber(object) <- .summarizeSensitivityNumbers(object)\n    }\n    if (length(perturbationN) == 0 && datasetType %in% c(\"perturbation\", \"both\")) {\n        pertNumber(object) <- .summarizePerturbationNumbers(object)\n    }\n\n    return(object)\n}"
      },
      {
        "partial": "CoreSet2 <- function(name=\"emptySet\", treatment=data.frame(),\n    sample=data.frame(), molecularProfiles=MultiAssayExperiment(),\n    treatmentResponse=LongTable(), datasetType=\"sensitivity\",\n    perturbation=list(n=array(dim=3), info=\"No perturbation data!\"),\n    curation=list(sample=data.frame(), treatment=data.frame())\n) {\n    # Update old curation names\n    names(curation) <- gsub(\"drug|radiation\", \"treatment\", names(curation))\n    names(curation) <- gsub(\"cell\", \"sample\", names(curation))\n\n    # Input validation\n    assertCharacter(name, len=1)\n    assertDataFrame(treatment)\n    assertDataFrame(sample)\n    assertClass(molecularProfiles, \"MultiAssayExperiment\")\n    assert(\n        checkClass(treatmentResponse, \"LongTable\"),\n        checkClass(treatmentResponse, \"LongTableDataMapper\")\n    )\n    assertList(curation, min.len=2)\n    assertSubset(c(\"sample\", \"treatment\"), choices=names(curation))\n\n    # Capture object creation environment\n    annotation <- list(name=name, dateCreated=date(),\n        sessionInfo=sessionInfo(), call=match.call())\n\n    # Conditionally materialize DataMapper\n    if (is(treatmentResponse, 'LongTableDataMapper'))\n        treatmentResponse <- metaConstruct(treatmentResponse)\n\n    # Handle missing rownames for sample\n    if (!all(sample$sampleid == rownames(sample)))\n        rownames(sample) <- sample$sampleid\n\n    # TODO: Complete the rest of the function\n}",
        "complete": "CoreSet2 <- function(name=\"emptySet\", treatment=data.frame(),\n    sample=data.frame(), molecularProfiles=MultiAssayExperiment(),\n    treatmentResponse=LongTable(), datasetType=\"sensitivity\",\n    perturbation=list(n=array(dim=3), info=\"No perturbation data!\"),\n    curation=list(sample=data.frame(), treatment=data.frame())\n) {\n    # Update old curation names\n    names(curation) <- gsub(\"drug|radiation\", \"treatment\", names(curation))\n    names(curation) <- gsub(\"cell\", \"sample\", names(curation))\n\n    # Input validation\n    assertCharacter(name, len=1)\n    assertDataFrame(treatment)\n    assertDataFrame(sample)\n    assertClass(molecularProfiles, \"MultiAssayExperiment\")\n    assert(\n        checkClass(treatmentResponse, \"LongTable\"),\n        checkClass(treatmentResponse, \"LongTableDataMapper\")\n    )\n    assertList(curation, min.len=2)\n    assertSubset(c(\"sample\", \"treatment\"), choices=names(curation))\n\n    # Capture object creation environment\n    annotation <- list(name=name, dateCreated=date(),\n        sessionInfo=sessionInfo(), call=match.call())\n\n    # Conditionally materialize DataMapper\n    if (is(treatmentResponse, 'LongTableDataMapper'))\n        treatmentResponse <- metaConstruct(treatmentResponse)\n\n    # Handle missing rownames for sample\n    if (!all(sample$sampleid == rownames(sample)))\n        rownames(sample) <- sample$sampleid\n\n    # Create CoreSet object\n    object <- .CoreSet(\n        annotation = annotation,\n        sample = sample,\n        treatment = treatment,\n        molecularProfiles = molecularProfiles,\n        treatmentResponse = treatmentResponse,\n        datasetType = datasetType,\n        curation = curation,\n        perturbation = perturbation\n    )\n\n    # Data integrity checks\n    validProfiles <- .checkMolecularProfiles(object)\n    validTreatments <- .checkTreatmentResponse(object)\n\n    diagnosis <- c(!isTRUE(validProfiles), !isTRUE(validTreatments))\n    if (any(diagnosis)) {\n        .error(paste0(list(validProfiles, validTreatments)[diagnosis],\n            collapse=\"\\n\", sep=\"\\n\"))\n    }\n\n    return(object)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/deprecated.R",
    "language": "R",
    "content": "#' @title List of `deprecated` or `defunct` methods in the `CoreGx` R package.\n#'\n#' @details\n#' ## deprecated\n#' `CoreSet`: The `CoreSet` constructor is being updated to have a new API. This\n#' API is currently available via the `CoreSet2` constructor. In Bioconductor\n#' 3.16, the old constructor will be renamed `CoreSet2` and the new constructor\n#' will be renamed `CoreSet`.\n#'\n#' ## defunct\n#' `buildLongTable`: This function no longer works as building a `LongTable` or\n#' `TreatmentResponseExperiment` now uses a `DataMapper` and the `metaConstruct`\n#' method. See `vignette(\"LongTable\")` for a detailed description of how\n#' to create a LongTable object.\n#'\n#' @name CoreGx-deprecated\n#' @aliases\n#' CoreGx-defunct\nNULL\n\n\n# ===== Deprecated\n\n\n# ===== Defunct\n\n# -- buildLongTableClass\n\n# ==== LongTable Class\n\n#' LongTable build method\n#'\n#' @description Create a LongTable object from a single data.table or\n#'   data.frame object.\n#'\n#' @param from `character` Path to the .csv file containing the data and\n#'   metadata from which to build the `LongTable`.\n#' @param colDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as column identifiers (e.g.,\n#'   drug name columns) and the second containing any additional metadata\n#'   columns related to the column identifiers. If you wish to rename any of\n#'   these columns, assign the new names to their respective character vectors.\n#' @param rowDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as cell identifiers (e.g.,\n#'   cell-line name columns) and the second containing any additional metadata\n#'   columns related to the cell identifiers. If you wish to rename any of\n#'   these columns, assign the new names to their respective character vectors.\n#' @param assayCols `list` A named list of character vectors specifying how to\n#'   parse assay columns into a list of `data.table`s. Each list data.table\n#'   will be named for the name of corresponding list item and contain the columns\n#'   specified in the character vector of column names in each list item. If\n#'   there are no names for assayCols, the assays will be numbered by instead.\n#'\n#' @return A `LongTable` object containing one or more assays, indexed by\n#'   rowID and colID.\n#'\n#' @import data.table\n#' @export\nsetMethod('buildLongTable', signature(from='data.frame'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    .Defunct(\"metaConstruct\", msg=\"This method has been deprecated\n        in favour of use of the LongTableDataMapper metadata object\n        with the metaConstruct method to build a LongTable object!\")\n\n    # -- local helpers\n    .unlist <- function(x) unlist(x, recursive=TRUE, use.names=FALSE)\n\n    # -- handle missing params\n    missingParams <- c(missing(rowDataCols), missing(colDataCols), missing(assayCols))\n    if (any(missingParams))\n        stop(.errorMsg('[CoreGx::buildLongTable,data.frame] The following',\n            ' parameters are required:',\n            .collapse(c('rowDataCols', 'colDataCols', 'assayCols')[missingParams])))\n\n    # -- validate input and return useful messages if invalid\n    ## TODO:: Check input parameters are valid\n\n    # -- convert to data.table by reference\n    if (!is.data.table(from))\n        from <- data.table(from)\n\n    # -- build drug and cell metadata tables and index by the appropriate ID\n    colData <- unique(from[, .unlist(colDataCols), with=FALSE])\n    setorderv(colData, colDataCols[[1]])  # order by id columns\n    colData[, colKey := seq_len(.N)]\n    rowData <- unique(from[, .unlist(rowDataCols), with=FALSE])\n    setorderv(rowData, rowDataCols[[1]])  # order by id columns\n    rowData[, rowKey := seq_len(.N)]\n\n    # -- add the row and column ids to the value data\n    assayData <- from[rowData, on=.unlist(rowDataCols)][colData, on=as.character(unlist(colDataCols))]\n    rm(from)\n    assayData[, as.character(unique(c(.unlist(rowDataCols), .unlist(colDataCols)))) := NULL]\n    # row reason to prevent sort in join because key sorts\n    setkey(assayData, rowKey, colKey)\n\n    setkey(rowData, rowKey)\n    setkey(colData, colKey)\n\n    # -- rename columns, if necessary\n    rowDataColnames <- lapply(rowDataCols, names)\n    notNullRownames <- !vapply(rowDataColnames, FUN=is.null, FUN.VALUE=logical(1))\n    if (any(notNullRownames))\n        for (i in which(notNullRownames)) {\n            setnames(rowData, rowDataCols[[i]], names(rowDataCols[[i]]))\n            rowDataCols[[i]] <- names(rowDataCols[[i]])\n        }\n\n    colDataColnames <- lapply(colDataCols, names)\n    notNullColnames <- !vapply(colDataColnames, FUN=is.null, FUN.VALUE=logical(1))\n    if (any(notNullColnames))\n        for (i in which(notNullColnames)) {\n            setnames(colData, colDataCols[[i]], names(colDataCols[[i]]))\n            colDataCols[[i]] <- names(colDataCols[[i]])\n        }\n\n    # -- drop colKey or rowKey from assayCols, since we are adding it back in the\n    # next step\n    ## TODO:: Add a check to see if the keys are there to avoid dropping/re-adding\n    .drop.in <- function(x, y) x[!(x %in% y)]\n    assayCols <- lapply(assayCols, .drop.in, y=c('colKey', 'rowKey'))\n\n    # -- add the index columns to the different assay column vectors\n    # this allows the .selectDataTable helper to be more general\n    .prependToVector <- function(vector, values) c(values, vector)\n    assayCols <- lapply(assayCols, FUN=.prependToVector, values=c('rowKey', 'colKey'))\n    if (is.null(names(assayCols))) names(assayCols) <- paste0('assay', seq_along(assayCols))\n    assays <- lapply(assayCols, .selectDataTable, DT=assayData)\n\n    # -- remove the colname suffixes by reference from assays which had the same\n    # colnames prior to joining into a single DT\n    for (assay in assays) {\n        setnames(assay, colnames(assay), gsub('\\\\._\\\\d+$', '', colnames(assay)))\n    }\n\n    return(LongTable(rowData=rowData, rowIDs=rowDataCols[[1]],\n                     colData=colData, colIDs=colDataCols[[1]],\n                     assays=assays))\n})\n\n#' LongTable build method from character\n#'\n#' @description LongTable Create a LongTable object from a single .csv file\n#'\n#' @param from `character` Path to the .csv file containing the data and\n#'   metadata from which to build the `LongTable`.\n#' @param colDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as column identifiers (e.g.,\n#'   drug name columns) and the second containing any additional metadata\n#'   columns related to the column identifiers.\n#' @param rowDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as cell identifiers (e.g.,\n#'   cell-line name columns) and the second containing any additional metadata\n#'   columns related to the cell identifiers.\n#' @param assayCols `list` A named list of character vectors specifying how to\n#'   parse assay columns into a list of `data.table`s. Each list data.table\n#'   will be named for the name of corresponding list item and contain the columns\n#'   specified in the character vector of column names in each list item.\n#'\n#' @return A `LongTable` object containing one or more assays, indexed by\n#'   rowID and colID.\n#'\n#' @import data.table\n#' @importFrom crayon magenta\n#' @export\nsetMethod('buildLongTable', signature(from='character'),\n          function(from, rowDataCols, colDataCols, assayCols)\n{\n    if (length(from) > 1)  # Call list subsetting method\n        buildLongTable(as.list(from), rowDataCols, colDataCols, assayCols)\n    if (!file.exists(from))\n        stop(magenta$bold(\"The is no file at path: \", from, '. Please double\n            check the location of the source file!'))\n\n    # read in data\n    tableData <- .freadNA(from)\n\n    return(buildLongTable(from=tableData, rowDataCols, colDataCols, assayCols))\n})\n\n#' LongTable build method from list\n#'\n#' @description Create a LongTable object from a list containing file paths,\n#'   data.frames and data.tables.\n#'\n#' @examples\n#' \\dontrun{\n#' assayList <- assays(merckLongTable, withDimnames=TRUE)\n#' rowDataCols <- list(rowIDs(merckLongTable), rowMeta(merckLongTable))\n#' colDataCols <- list(colIDs(merckLongTable), colMeta(merckLongTable))\n#' assayCols <- assayCols(merckLongTable)\n#' longTable <- buildLongTable(from=assayList, rowDataCols, colDataCols, assayCols)\n#' }\n#'\n#' @param from `list` A list containing any combination of character file paths,\n#'  data.tables and data.frames which will be used to construct the LongTable.\n#' @param colDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as column identifiers (e.g.,\n#'   drug name columns) and the second containing any additional metadata\n#'   columns related to the column identifiers.\n#' @param rowDataCols `list` List with two `character` vectors, the first\n#'   specifying one or more columns to be used as cell identifiers (e.g.,\n#'   cell-line name columns) and the second containing any additional metadata\n#'   columns related to the cell identifiers.\n#' @param assayCols `list` A named list of character vectors specifying how to\n#'   parse assay columns into a list of `data.table`s. Each list data.table\n#'   will be named for the name of corresponding list item and contain the columns\n#'   specified in the character vector of column names in each list item.\n#'\n#' @return A `LongTable` object constructed with the data in `from`.\n#'\n#' @import data.table\n#' @importFrom crayon magenta cyan\n#' @export\nsetMethod('buildLongTable', signature(from='list'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    # Prevent modify by reference for data.tables in list\n    from <- copy(from)\n\n    # local helpers\n    ##FIXME:: This is exactly what the Map function is (an alias for mapply with\n    ##   SIMPLIFY=FALSE)\n    .mapply <- function(...) mapply(..., SIMPLIFY=FALSE)\n\n    # preprocess from list\n    isChar <- is.items(from, 'character')\n    isDT <- is.items(from, FUN=is.data.table)\n    isDF <- is.items(from, FUN=is.data.frame) & !isDT\n\n    if (!all(isChar | isDT | isDF))\n        stop(.errorMsg('\\n[CoreGx::buildLongTable,list-method] List items at',\n            ' indexes ', .collapse(which(!(isChar | isDT | isDF ))),\n            ' are not character, data.table or data.frame.', collapse=', '))\n\n    if (any(isChar)) from <- c(from[!isChar], lapply(from[isChar], FUN=.freadNA))\n    if (any(isDF)) for (i in which(isDF)) from[[i]] <- data.table(from[[i]])\n\n    # validate mappings\n    ## TODO:: Ensure there is no case where joining on rowMeta or colMeta gives\n    #  different results than just ids\n    joinCols <- unique(unlist(c(rowDataCols, colDataCols)))\n    dataColNames <- lapply(from, FUN=colnames)\n    joinColsIn <- lapply(dataColNames, `%in%`, x=joinCols)\n    hasAllIdCols <- unlist(lapply(joinColsIn, FUN=all))\n    if (!all(hasAllIdCols)) {\n        missingCols <- unique(unlist(.mapply(`[`, x=joinCols, i=joinColsIn)))\n        stop(.errorMsg('[CoreGx::buildLongTable,list] Assay(s) ',\n            .collapse(which(hasAllIdCols)), ' are missing one or more id ',\n            'columns: ', .collapse(missingCols), collapse=', '))\n    }\n\n    # Set keys for faster joins\n    for (i in seq_along(from)) setkeyv(from[[i]], cols=joinCols)\n\n    # join assays into a single table\n    DT <- from[[1]]\n    from[[1]] <- NULL\n    for (i in seq_along(from))\n        DT <- merge.data.table(DT, from[[i]], suffixes=c('', paste0('._', i)))\n\n    # fix assayCols if there are duplicate column names between assays\n    # the join will append '._n' where n is the assay index - 1\n    nonDataCols <- setdiff(colnames(DT), unique(c(unlist(rowDataCols), unlist(colDataCols))))\n    assaySuffixCols <- lapply(paste0('\\\\._', seq_along(from)), grep, x=nonDataCols, value=TRUE)\n    .length.gt.0 <- function(x) length(x) > 0\n    hasSuffixes <- unlist(lapply(assaySuffixCols, FUN=.length.gt.0))\n    duplicatedCols <- lapply(assaySuffixCols[hasSuffixes], gsub,\n        pattern='\\\\._\\\\d+', replacement='')\n\n    .which.in <- function(x, y) which(x %in% y)\n    whichHasSuffixes <- which(hasSuffixes) + 1\n    whichDuplicated <- .mapply(.which.in,\n        x=assayCols[whichHasSuffixes], y=duplicatedCols)\n    assayCols[whichHasSuffixes] <-\n        .mapply(replace, x=assayCols[whichHasSuffixes],\n            list=whichDuplicated, values=assaySuffixCols[hasSuffixes])\n\n    # construct new LongTable\n    buildLongTable(from=DT, rowDataCols, colDataCols, assayCols)\n})\n\n\n# ---- Helper Methods\n\n#' fread with more default na.strings\n#'\n#' @keywords internal\n#' @noRd\n.freadNA <- function(...) {\n    as.na <- unique(c(getOption('datatable.na.string'),\n        c('NA', 'NULL', 'NaN', 'missing', 'None',\n            'none', 'na', 'null', 'Null', 'Na')))\n    fread(..., na.strings=as.na)\n}\n\n\n#' Select a set of column names from a data.table, returning a copy of the\n#'   data.table with duplicate rows removed\n#'\n#' @param colNames `character` The column names to select from the data.table\n#' @param DT `data.table`, `data.frame`, `matrix` An object coercible to a `data.table`.\n#'   Please note rownames will be dropped by default.\n#' @param keep.rownames `logical` or `character` Passed through to the data.table coercing if DT is not a\n#'   `data.table`. If TRUE, rownames will be caputured in the `rn` column; if FALSE (default) rownames will\n#'   be dropped; if `character`, rownames will be captured in a column with the same name.\n#'\n#' @return `data.table` Copy of `DT` containing only the specified columns, with duplicate rows removed.\n#'\n#' @import data.table\n#' @keywords internal\n#' @noRd\n.selectDataTable <- function(colNames, DT, keep.rownames=FALSE) {\n    # validate input\n    if (!is.data.table(DT)) {\n        tryCatch({\n            DT <- data.table(DT, keep.rownames=keep.rownames)\n        }, warning=function(w) {\n            warning(w)\n        }, error=function(e) {\n            message(e)\n            stop(\"Argument to DT parameter must be coercible to a data.table!\")\n        })\n    }\n    if (!is.character(colnames(DT))) stop(\"Currently only character column ids are supported!\")\n    missingColumns <- setdiff(colNames, colnames(DT))\n    if (length(missingColumns) > 0)\n        warning(paste0(\"There are no columns named \", paste0(missingColumns, collapse=\", \"), 'in DT.\n            Continuing subset without these columns.'))\n\n    # perform subset and copy to prevent modify by refence issues\n    selectedDT <- copy(unique(DT[, .SD, .SDcols=colnames(DT) %in% colNames]))\n\n    return(selectedDT)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `buildLongTable` method in this code snippet?",
        "answer": "The `buildLongTable` method is used to create a LongTable object from various input types such as data frames, character file paths, or lists. It organizes data into a structured format with row data, column data, and assays, which is useful for storing and manipulating large datasets in a standardized way."
      },
      {
        "question": "How does the code handle different input types for the `buildLongTable` method?",
        "answer": "The code uses method dispatch with different signatures for `from` parameter: 'data.frame', 'character', and 'list'. For data frames, it directly processes the input. For character inputs (file paths), it reads the file using `.freadNA`. For list inputs, it handles a combination of file paths, data frames, and data tables, converting them as needed before processing."
      },
      {
        "question": "What is the purpose of the `.selectDataTable` helper function in this code?",
        "answer": "The `.selectDataTable` helper function is used to select a set of columns from a data table, remove duplicate rows, and return a copy of the resulting data table. It handles input validation, converts non-data.table objects to data tables, and performs the column selection and row deduplication operations. This function is likely used internally to process and prepare data for the LongTable object."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('buildLongTable', signature(from='data.frame'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    .Defunct(\"metaConstruct\", msg=\"This method has been deprecated\n        in favour of use of the LongTableDataMapper metadata object\n        with the metaConstruct method to build a LongTable object!\")\n\n    # -- local helpers\n    .unlist <- function(x) unlist(x, recursive=TRUE, use.names=FALSE)\n\n    # -- handle missing params\n    missingParams <- c(missing(rowDataCols), missing(colDataCols), missing(assayCols))\n    if (any(missingParams))\n        stop(.errorMsg('[CoreGx::buildLongTable,data.frame] The following',\n            ' parameters are required:',\n            .collapse(c('rowDataCols', 'colDataCols', 'assayCols')[missingParams])))\n\n    # -- convert to data.table by reference\n    if (!is.data.table(from))\n        from <- data.table(from)\n\n    # -- build drug and cell metadata tables and index by the appropriate ID\n    colData <- unique(from[, .unlist(colDataCols), with=FALSE])\n    setorderv(colData, colDataCols[[1]])  # order by id columns\n    colData[, colKey := seq_len(.N)]\n    rowData <- unique(from[, .unlist(rowDataCols), with=FALSE])\n    setorderv(rowData, rowDataCols[[1]])  # order by id columns\n    rowData[, rowKey := seq_len(.N)]\n\n    # -- add the row and column ids to the value data\n    assayData <- from[rowData, on=.unlist(rowDataCols)][colData, on=as.character(unlist(colDataCols))]\n    rm(from)\n    assayData[, as.character(unique(c(.unlist(rowDataCols), .unlist(colDataCols)))) := NULL]\n    # row reason to prevent sort in join because key sorts\n    setkey(assayData, rowKey, colKey)\n\n    setkey(rowData, rowKey)\n    setkey(colData, colKey)\n\n    # -- rename columns, if necessary\n    rowDataColnames <- lapply(rowDataCols, names)\n    notNullRownames <- !vapply(rowDataColnames, FUN=is.null, FUN.VALUE=logical(1))\n    if (any(notNullRownames))\n        for (i in which(notNullRownames)) {\n            setnames(rowData, rowDataCols[[i]], names(rowDataCols[[i]]))\n            rowDataCols[[i]] <- names(rowDataCols[[i]])\n        }\n\n    colDataColnames <- lapply(colDataCols, names)\n    notNullColnames <- !vapply(colDataColnames, FUN=is.null, FUN.VALUE=logical(1))\n    if (any(notNullColnames))\n        for (i in which(notNullColnames)) {\n            setnames(colData, colDataCols[[i]], names(colDataCols[[i]]))\n            colDataCols[[i]] <- names(colDataCols[[i]])\n        }\n\n    # -- drop colKey or rowKey from assayCols, since we are adding it back in the\n    # next step\n    .drop.in <- function(x, y) x[!(x %in% y)]\n    assayCols <- lapply(assayCols, .drop.in, y=c('colKey', 'rowKey'))\n\n    # -- add the index columns to the different assay column vectors\n    # this allows the .selectDataTable helper to be more general\n    .prependToVector <- function(vector, values) c(values, vector)\n    assayCols <- lapply(assayCols, FUN=.prependToVector, values=c('rowKey', 'colKey'))\n    if (is.null(names(assayCols))) names(assayCols) <- paste0('assay', seq_along(assayCols))\n    assays <- lapply(assayCols, .selectDataTable, DT=assayData)\n\n    # -- remove the colname suffixes by reference from assays which had the same\n    # colnames prior to joining into a single DT\n    for (assay in assays) {\n        setnames(assay, colnames(assay), gsub('\\\\._\\\\d+$', '', colnames(assay)))\n    }\n\n    return(LongTable(rowData=rowData, rowIDs=rowDataCols[[1]],\n                     colData=colData, colIDs=colDataCols[[1]],\n                     assays=assays))\n})",
        "complete": "setMethod('buildLongTable', signature(from='data.frame'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    .Defunct(\"metaConstruct\", msg=\"This method has been deprecated\n        in favour of use of the LongTableDataMapper metadata object\n        with the metaConstruct method to build a LongTable object!\")\n\n    .unlist <- function(x) unlist(x, recursive=TRUE, use.names=FALSE)\n\n    missingParams <- c(missing(rowDataCols), missing(colDataCols), missing(assayCols))\n    if (any(missingParams))\n        stop(.errorMsg('[CoreGx::buildLongTable,data.frame] The following',\n            ' parameters are required:',\n            .collapse(c('rowDataCols', 'colDataCols', 'assayCols')[missingParams])))\n\n    if (!is.data.table(from)) from <- data.table(from)\n\n    colData <- unique(from[, .unlist(colDataCols), with=FALSE])\n    setorderv(colData, colDataCols[[1]])\n    colData[, colKey := seq_len(.N)]\n    rowData <- unique(from[, .unlist(rowDataCols), with=FALSE])\n    setorderv(rowData, rowDataCols[[1]])\n    rowData[, rowKey := seq_len(.N)]\n\n    assayData <- from[rowData, on=.unlist(rowDataCols)][colData, on=as.character(unlist(colDataCols))]\n    rm(from)\n    assayData[, as.character(unique(c(.unlist(rowDataCols), .unlist(colDataCols)))) := NULL]\n    setkey(assayData, rowKey, colKey)\n\n    setkey(rowData, rowKey)\n    setkey(colData, colKey)\n\n    for (i in which(!vapply(lapply(rowDataCols, names), is.null, logical(1)))) {\n        setnames(rowData, rowDataCols[[i]], names(rowDataCols[[i]]))\n        rowDataCols[[i]] <- names(rowDataCols[[i]])\n    }\n\n    for (i in which(!vapply(lapply(colDataCols, names), is.null, logical(1)))) {\n        setnames(colData, colDataCols[[i]], names(colDataCols[[i]]))\n        colDataCols[[i]] <- names(colDataCols[[i]])\n    }\n\n    assayCols <- lapply(assayCols, function(x) x[!(x %in% c('colKey', 'rowKey'))])\n    assayCols <- lapply(assayCols, function(vector) c('rowKey', 'colKey', vector))\n    if (is.null(names(assayCols))) names(assayCols) <- paste0('assay', seq_along(assayCols))\n    assays <- lapply(assayCols, .selectDataTable, DT=assayData)\n\n    for (assay in assays) {\n        setnames(assay, colnames(assay), gsub('\\\\._\\\\d+$', '', colnames(assay)))\n    }\n\n    return(LongTable(rowData=rowData, rowIDs=rowDataCols[[1]],\n                     colData=colData, colIDs=colDataCols[[1]],\n                     assays=assays))\n})"
      },
      {
        "partial": "setMethod('buildLongTable', signature(from='list'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    from <- copy(from)\n\n    isChar <- is.items(from, 'character')\n    isDT <- is.items(from, FUN=is.data.table)\n    isDF <- is.items(from, FUN=is.data.frame) & !isDT\n\n    if (!all(isChar | isDT | isDF))\n        stop(.errorMsg('\\n[CoreGx::buildLongTable,list-method] List items at',\n            ' indexes ', .collapse(which(!(isChar | isDT | isDF ))),\n            ' are not character, data.table or data.frame.', collapse=', '))\n\n    if (any(isChar)) from <- c(from[!isChar], lapply(from[isChar], FUN=.freadNA))\n    if (any(isDF)) for (i in which(isDF)) from[[i]] <- data.table(from[[i]])\n\n    joinCols <- unique(unlist(c(rowDataCols, colDataCols)))\n    dataColNames <- lapply(from, FUN=colnames)\n    joinColsIn <- lapply(dataColNames, `%in%`, x=joinCols)\n    hasAllIdCols <- unlist(lapply(joinColsIn, FUN=all))\n    if (!all(hasAllIdCols)) {\n        missingCols <- unique(unlist(mapply(`[`, x=joinCols, i=joinColsIn, SIMPLIFY=FALSE)))\n        stop(.errorMsg('[CoreGx::buildLongTable,list] Assay(s) ',\n            .collapse(which(hasAllIdCols)), ' are missing one or more id ',\n            'columns: ', .collapse(missingCols), collapse=', '))\n    }\n\n    for (i in seq_along(from)) setkeyv(from[[i]], cols=joinCols)\n\n    DT <- from[[1]]\n    from[[1]] <- NULL\n    for (i in seq_along(from))\n        DT <- merge.data.table(DT, from[[i]], suffixes=c('', paste0('._', i)))\n\n    nonDataCols <- setdiff(colnames(DT), unique(c(unlist(rowDataCols), unlist(colDataCols))))\n    assaySuffixCols <- lapply(paste0('\\\\._', seq_along(from)), grep, x=nonDataCols, value=TRUE)\n    hasSuffixes <- unlist(lapply(assaySuffixCols, function(x) length(x) > 0))\n    duplicatedCols <- lapply(assaySuffixCols[hasSuffixes], gsub,\n        pattern='\\\\._\\\\d+', replacement='')\n\n    whichHasSuffixes <- which(hasSuffixes) + 1\n    whichDuplicated <- mapply(function(x, y) which(x %in% y),\n        x=assayCols[whichHasSuffixes], y=duplicatedCols, SIMPLIFY=FALSE)\n    assayCols[whichHasSuffixes] <-\n        mapply(replace, x=assayCols[whichHasSuffixes],\n            list=whichDuplicated, values=assaySuffixCols[hasSuffixes], SIMPLIFY=FALSE)\n\n    buildLongTable(from=DT, rowDataCols, colDataCols, assayCols)\n})",
        "complete": "setMethod('buildLongTable', signature(from='list'),\n        function(from, rowDataCols, colDataCols, assayCols) {\n\n    from <- copy(from)\n\n    isChar <- is.items(from, 'character')\n    isDT <- is.items(from, FUN=is.data.table)\n    isDF <- is.items(from, FUN=is.data.frame) & !isDT\n\n    if (!all(isChar | isDT | isDF))\n        stop(.errorMsg('\\n[CoreGx::buildLongTable,list-method] List items at',\n            ' indexes ', .collapse(which(!(isChar | isDT | isDF ))),\n            ' are not character, data.table or data.frame.', collapse=', '))\n\n    if (any(isChar)) from <- c(from[!isChar], lapply(from[isChar], FUN=.freadNA))\n    if (any(isDF)) for (i in which(isDF)) from[[i]] <- data.table(from[[i]])\n\n    joinCols <- unique(unlist(c(rowDataCols, colDataCols)))\n    dataColNames <- lapply(from, FUN=colnames)\n    joinColsIn <- lapply(dataColNames, `%in%`, x=joinCols)\n    hasAllIdCols <- unlist(lapply(joinColsIn, FUN=all))\n    if (!all(hasAllIdCols)) {\n        missingCols <- unique(un"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/updateObject-methods.R",
    "language": "R",
    "content": "#' Update the `CoreSet` class after changes in it struture or API\n#'\n#' @param object A `CoreSet` object to update the class structure for.\n#' @param verify A `logical(1)` indicating is `validObject` should be called\n#' after updating the object. Defaults to `TRUE`, only set `FALSE` for debugging.\n#' @param verbose TRUE or FALSE, indicating whether information about the update\n#' should be reported\n#' @return `CoreSet` with update class structure.\n#'\n#' @md\n#'\n#' @importFrom MultiAssayExperiment MultiAssayExperiment\n#' @importMethodsFrom BiocGenerics updateObject\n#' @export\nsetMethod('updateObject', signature(object=\"CoreSet\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n\n    if (verbose) {\n        message(\"updateObject object = 'CoreSet'\")\n    }\n    \n    if (!.hasSlot(object, \"sample\")) {\n        cell <- object@cell\n        sample_ <- cell\n    } else {\n        sample_ <- object@sample\n    }\n    colnames(sample_) <- gsub(\"cellid\", \"sampleid\", colnames(sample_))\n\n    if (!.hasSlot(object, \"treatment\")) {\n        if (.hasSlot(object, \"drug\")) {\n            treatment <- object@drug\n        } else if (.hasSlot(object, \"radiation\")) {\n            treatment <- object@radiation\n        } else  {\n            treatment <- data.frame()\n        }\n    } else {\n        treatment <- object@treatment\n    }\n    colnames(treatment) <- gsub(\"drugid\", \"treatmentid\", colnames(treatment))\n\n    if (!.hasSlot(object, \"treatmentResponse\")) {\n        treatmentResponse <- object@sensitivity\n    } else {\n        treatmentResponse <- object@treatmentResponse\n    }\n\n    if (is(treatmentResponse, \"LongTable\")) {\n        treatmentResponse <- updateObject(treatmentResponse)\n        mutableIntern <- mutable(getIntern(treatmentResponse))\n    } else {\n        colnames(treatmentResponse$info) <- gsub(\"cellid\", \"sampleid\",\n            colnames(treatmentResponse$info))\n        colnames(treatmentResponse$info) <- gsub(\"drugid\",\n            \"treatmentid\", colnames(treatmentResponse$info))\n    }\n\n    mProf <- object@molecularProfiles\n    for (i in seq_along(mProf)) {\n        colnames(colData(mProf[[i]])) <- gsub(\"cellid\", \"sampleid\",\n            colnames(colData(mProf[[i]])))\n        colnames(colData(mProf[[i]])) <- gsub(\"drugid\", \"treatmentid\",\n            colnames(colData(mProf[[i]])))\n    }\n    curation_ <- object@curation\n    names(curation_) <- gsub(\"cell\", \"sample\", names(curation_))\n    names(curation_) <- gsub(\"drug\", \"treatment\", names(curation_))\n    colnames(curation_$sample) <- gsub(\"cellid\", \"sampleid\",\n        colnames(curation_$sample))\n    if (\"treatment\" %in% names(curation_)) {\n        colnames(curation_$treatment) <- gsub(\"drugid\",\n            \"treatmentid\", colnames(curation_$treatment))\n    }\n\n    cSet <- .CoreSet(\n        sample=sample_,\n        treatment=treatment,\n        treatmentResponse=treatmentResponse,\n        molecularProfiles=mProf,\n        annotation=object@annotation,\n        curation=curation_,\n        perturbation=object@perturbation,\n        datasetType=object@datasetType\n    )\n\n    if (verify) isValid(cSet)\n\n    return(cSet)\n})\n\n#' Update the `LongTable` class after changes in it struture or API\n#'\n#' @param object A `LongTable` object to update the class structure for.\n#' @param verify A `logical(1)` indicating is `validObject` should be called\n#' after updating the object. Defaults to `TRUE`, only set `FALSE` for debugging.\n#' @param verbose TRUE or FALSE, indicating whether information about the update\n#' should be reported\n#' @return `LongTable` with update class structure.\n#'\n#' @md\n#'\n#' @importMethodsFrom BiocGenerics updateObject\n#' @export\nsetMethod(\"updateObject\", signature(object=\"LongTable\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n\n     if (verbose) {\n        message(\"updateObject object = 'CoreSet'\")\n    }\n    if (is.environment(getIntern(object))) {\n        rData <- rowData(object, key=TRUE)\n        rIDs <- rowIDs(object)\n        cData <- colData(object, key=TRUE)\n        cIDs <- colIDs(object)\n        id_cols <- c(rIDs, cIDs)\n        assays_ <- assays(object, raw=TRUE)\n        setkeyv(rData, \"rowKey\")\n        assays_ <- lapply(assays_, merge.data.table,\n            y=rData[, c(\"rowKey\", rIDs), with=FALSE],\n            by=\"rowKey\"\n        )\n        setkeyv(cData, \"colKey\")\n        assays_ <- lapply(assays_, merge.data.table,\n            y=cData[, c(\"colKey\", cIDs), with=FALSE],\n            by=\"colKey\"\n        )\n        rData[, rowKey := NULL]\n        cData[, colKey := NULL]\n        for (a_ in assays_) a_[, c(\"rowKey\", \"colKey\") := NULL]\n        mdata <- metadata(object)\n        assayMap <- lapply(assays_, function(x, y) y, y=id_cols)\n        oclass <- class(object)[1]\n        object <- LongTable(\n            rowData=rData, rowIDs=rIDs,\n            colData=cData, colIDs=cIDs,\n            assays=assays_, assayIDs=assayMap,\n            metadata=mdata\n        )\n        object <- as(object, oclass)  # Coerce to inherting class if needed\n    }\n    if (verify) isValid(object)\n    return(object)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `updateObject` method for the `CoreSet` class, and how does it handle changes in the object's structure?",
        "answer": "The `updateObject` method for the `CoreSet` class is designed to update the class structure after changes in its structure or API. It handles changes by checking for the existence of certain slots (e.g., 'sample', 'treatment', 'treatmentResponse') and updating them accordingly. It also renames columns to maintain consistency (e.g., changing 'cellid' to 'sampleid' and 'drugid' to 'treatmentid'). The method creates a new `CoreSet` object with the updated structure and returns it."
      },
      {
        "question": "How does the `updateObject` method for the `LongTable` class differ from the one for `CoreSet`, and what specific operations does it perform?",
        "answer": "The `updateObject` method for the `LongTable` class focuses on updating the internal structure of the `LongTable` object. It performs the following operations: 1) Extracts row and column data, including IDs. 2) Merges assay data with row and column information. 3) Removes unnecessary keys. 4) Creates a new `LongTable` object with the updated structure. 5) Coerces the object back to its original class if it was inheriting from `LongTable`. This method is specifically designed to handle changes in the internal representation of `LongTable` objects, particularly when transitioning from an environment-based to a more structured data representation."
      },
      {
        "question": "What are the common parameters shared by both `updateObject` methods, and how do they affect the function's behavior?",
        "answer": "Both `updateObject` methods share three common parameters: 1) `object`: The object to be updated (either `CoreSet` or `LongTable`). 2) `verify`: A logical value indicating whether to call `validObject` (for `CoreSet`) or `isValid` (for `LongTable`) after updating. It defaults to `FALSE`. 3) `verbose`: A logical value indicating whether to report information about the update process. These parameters allow for flexibility in the update process, enabling verification of the updated object and providing optional logging for debugging purposes."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('updateObject', signature(object=\"CoreSet\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n    if (verbose) {\n        message(\"updateObject object = 'CoreSet'\")\n    }\n    \n    if (!.hasSlot(object, \"sample\")) {\n        cell <- object@cell\n        sample_ <- cell\n    } else {\n        sample_ <- object@sample\n    }\n    colnames(sample_) <- gsub(\"cellid\", \"sampleid\", colnames(sample_))\n\n    # TODO: Update treatment and treatmentResponse\n\n    # TODO: Update molecularProfiles and curation\n\n    cSet <- .CoreSet(\n        sample=sample_,\n        # TODO: Add remaining parameters\n    )\n\n    if (verify) isValid(cSet)\n\n    return(cSet)\n})",
        "complete": "setMethod('updateObject', signature(object=\"CoreSet\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n    if (verbose) message(\"updateObject object = 'CoreSet'\")\n    \n    sample_ <- if (.hasSlot(object, \"sample\")) object@sample else object@cell\n    colnames(sample_) <- gsub(\"cellid\", \"sampleid\", colnames(sample_))\n\n    treatment <- if (.hasSlot(object, \"treatment\")) object@treatment else\n                 if (.hasSlot(object, \"drug\")) object@drug else\n                 if (.hasSlot(object, \"radiation\")) object@radiation else data.frame()\n    colnames(treatment) <- gsub(\"drugid\", \"treatmentid\", colnames(treatment))\n\n    treatmentResponse <- if (.hasSlot(object, \"treatmentResponse\")) object@treatmentResponse else object@sensitivity\n    if (is(treatmentResponse, \"LongTable\")) {\n        treatmentResponse <- updateObject(treatmentResponse)\n    } else {\n        colnames(treatmentResponse$info) <- gsub(\"cellid|drugid\", c(\"sampleid\", \"treatmentid\"), colnames(treatmentResponse$info))\n    }\n\n    mProf <- object@molecularProfiles\n    for (i in seq_along(mProf)) {\n        colnames(colData(mProf[[i]])) <- gsub(\"cellid|drugid\", c(\"sampleid\", \"treatmentid\"), colnames(colData(mProf[[i]])))\n    }\n\n    curation_ <- object@curation\n    names(curation_) <- gsub(\"cell|drug\", c(\"sample\", \"treatment\"), names(curation_))\n    colnames(curation_$sample) <- gsub(\"cellid\", \"sampleid\", colnames(curation_$sample))\n    if (\"treatment\" %in% names(curation_)) {\n        colnames(curation_$treatment) <- gsub(\"drugid\", \"treatmentid\", colnames(curation_$treatment))\n    }\n\n    cSet <- .CoreSet(\n        sample=sample_,\n        treatment=treatment,\n        treatmentResponse=treatmentResponse,\n        molecularProfiles=mProf,\n        annotation=object@annotation,\n        curation=curation_,\n        perturbation=object@perturbation,\n        datasetType=object@datasetType\n    )\n\n    if (verify) isValid(cSet)\n    return(cSet)\n})"
      },
      {
        "partial": "setMethod(\"updateObject\", signature(object=\"LongTable\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n    if (verbose) message(\"updateObject object = 'CoreSet'\")\n    \n    if (is.environment(getIntern(object))) {\n        rData <- rowData(object, key=TRUE)\n        rIDs <- rowIDs(object)\n        cData <- colData(object, key=TRUE)\n        cIDs <- colIDs(object)\n        id_cols <- c(rIDs, cIDs)\n        assays_ <- assays(object, raw=TRUE)\n        \n        # TODO: Update assays_, rData, and cData\n        \n        # TODO: Create new LongTable object\n        \n        # TODO: Coerce to inheriting class if needed\n    }\n    if (verify) isValid(object)\n    return(object)\n})",
        "complete": "setMethod(\"updateObject\", signature(object=\"LongTable\"),\n        function(object, verify=FALSE, verbose = FALSE) {\n    if (verbose) message(\"updateObject object = 'CoreSet'\")\n    \n    if (is.environment(getIntern(object))) {\n        rData <- rowData(object, key=TRUE)\n        rIDs <- rowIDs(object)\n        cData <- colData(object, key=TRUE)\n        cIDs <- colIDs(object)\n        id_cols <- c(rIDs, cIDs)\n        assays_ <- assays(object, raw=TRUE)\n        \n        setkeyv(rData, \"rowKey\")\n        assays_ <- lapply(assays_, merge.data.table,\n            y=rData[, c(\"rowKey\", rIDs), with=FALSE],\n            by=\"rowKey\"\n        )\n        setkeyv(cData, \"colKey\")\n        assays_ <- lapply(assays_, merge.data.table,\n            y=cData[, c(\"colKey\", cIDs), with=FALSE],\n            by=\"colKey\"\n        )\n        rData[, rowKey := NULL]\n        cData[, colKey := NULL]\n        for (a_ in assays_) a_[, c(\"rowKey\", \"colKey\") := NULL]\n        \n        mdata <- metadata(object)\n        assayMap <- lapply(assays_, function(x, y) y, y=id_cols)\n        oclass <- class(object)[1]\n        object <- LongTable(\n            rowData=rData, rowIDs=rIDs,\n            colData=cData, colIDs=cIDs,\n            assays=assays_, assayIDs=assayMap,\n            metadata=mdata\n        )\n        object <- as(object, oclass)\n    }\n    if (verify) isValid(object)\n    return(object)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-subsetTo.R",
    "language": "R",
    "content": "#' Subset a CoreSet object based on various parameters, such as cell lines, molecular features\n#'\n#' @param object An object inheriting from the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A subsetted version of the original `object`\n#'\n#' @examples\n#' \"Generics shouldn't need examples!\"\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"subsetTo\", function(object, ...) standardGeneric(\"subsetTo\"))\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `setGeneric` function in this code snippet, and how does it relate to object-oriented programming in R?",
        "answer": "The `setGeneric` function is used to define a new generic function in R's S4 object-oriented programming system. It creates a function that can have multiple methods for different classes. In this case, it defines a generic function called 'subsetTo' that can be implemented differently for various classes inheriting from the CoreSet class. This allows for polymorphic behavior, where the same function name can have different implementations depending on the type of object it's called on."
      },
      {
        "question": "What is the significance of the `standardGeneric` function used within the generic function definition?",
        "answer": "The `standardGeneric` function is a crucial part of defining a generic function in R's S4 system. It serves as a placeholder for the actual method dispatch mechanism. When the generic function is called, `standardGeneric` ensures that the appropriate method is selected and executed based on the class of the arguments passed to the function. This allows for the implementation of polymorphism, where the behavior of the function can vary depending on the types of objects it's called with."
      },
      {
        "question": "Why does the Roxygen comment for this function include the line '@keywords internal', and what effect does this have on the documentation?",
        "answer": "The '@keywords internal' Roxygen tag is used to mark functions that are intended for internal use within a package and not part of the public API. When generating documentation, functions marked as internal are typically excluded from the main package documentation and are not prominently displayed to users. This helps to keep the public-facing documentation clean and focused on the functions that package users are expected to interact with directly. However, the function is still exported (as indicated by the '@export' tag), so it can be used by other packages or advanced users if necessary."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' Subset a CoreSet object based on various parameters, such as cell lines, molecular features\n#'\n#' @param object An object inheriting from the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A subsetted version of the original `object`\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"subsetTo\", function(object, ...) {\n    # Complete the function body\n})",
        "complete": "#' Subset a CoreSet object based on various parameters, such as cell lines, molecular features\n#'\n#' @param object An object inheriting from the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A subsetted version of the original `object`\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"subsetTo\", function(object, ...) standardGeneric(\"subsetTo\"))"
      },
      {
        "partial": "#' Subset a CoreSet object based on various parameters, such as cell lines, molecular features\n#'\n#' @param object An object inheriting from the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A subsetted version of the original `object`\n#'\n# Complete the roxygen documentation and function definition\n",
        "complete": "#' Subset a CoreSet object based on various parameters, such as cell lines, molecular features\n#'\n#' @param object An object inheriting from the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A subsetted version of the original `object`\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"subsetTo\", function(object, ...) standardGeneric(\"subsetTo\"))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/Data.cpp",
    "language": "cpp",
    "content": "#include \"Data.h\"\n#include <sys/time.h>\n\nData::Data(double* const pData, Matrix const* const pPriorsMatrix, double const priorsWeight,\n        unsigned int const sampleCount, unsigned int const featureCount,\n        int const* const pSampleStrata, double const* const pSampleWeights,\n        int const* const pFeatureTypes, unsigned int const sampleStratumCount,\n        unsigned int const continuousEstimator, bool const outX, unsigned int const bootstrapCount) :\n        mpDataMatrix(new Matrix(pData, sampleCount, featureCount)), mpOrderMatrix(\n                continuousEstimator ? new Matrix(sampleCount, featureCount) : 0), mpPriorsMatrix(\n                pPriorsMatrix), mpHasOrderCached(new bool[mpDataMatrix->getColumnCount()]), mpSampleStrata(\n                pSampleStrata), mpSampleWeights(pSampleWeights), mpFeatureTypes(pFeatureTypes), mSampleStratumCount(\n                sampleStratumCount), mpSampleIndicesPerStratum(\n                new unsigned int*[sampleStratumCount]), mpMasterSampleIndicesPerStratum(\n                new unsigned int*[sampleStratumCount]), mpSampleCountPerStratum(\n                new unsigned int[sampleStratumCount]), mContinuousEstimator(continuousEstimator), mOutX(\n                outX), mBootstrapCount(bootstrapCount), mPriorsWeight(priorsWeight)\n{\n    for (unsigned int i = 0; i < mpDataMatrix->getColumnCount(); ++i)\n        mpHasOrderCached[i] = false;\n\n    Math::placeStratificationData(mpSampleStrata, mpSampleWeights, mpSampleIndicesPerStratum,\n            mpSampleCountPerStratum, mSampleStratumCount, sampleCount);\n\n    for (unsigned int i = 0; i < mSampleStratumCount; ++i)\n    {\n        mpMasterSampleIndicesPerStratum[i] = new unsigned int[mpSampleCountPerStratum[i]];\n        for (unsigned int j = 0; j < mpSampleCountPerStratum[i]; ++j)\n            mpMasterSampleIndicesPerStratum[i][j] = mpSampleIndicesPerStratum[i][j];\n    }\n}\n\nData::~Data()\n{\n    delete mpDataMatrix;\n    delete mpOrderMatrix;\n    delete[] mpHasOrderCached;\n    for (unsigned int i = 0; i < mSampleStratumCount; ++i)\n    {\n        delete[] mpSampleIndicesPerStratum[i];\n        delete[] mpMasterSampleIndicesPerStratum[i];\n    }\n    delete[] mpSampleIndicesPerStratum;\n    delete[] mpMasterSampleIndicesPerStratum;\n    delete[] mpSampleCountPerStratum;\n}\n\nvoid const\nData::bootstrap()\n{\n    // unsigned int seed = std::time(NULL); too long for small datasets\n    struct timeval start;\n    gettimeofday(&start, NULL);\n    unsigned int seed = start.tv_usec; //microseconds\n    \n    for (unsigned int i = 0; i < mSampleStratumCount; ++i)\n        for (unsigned int j = 0; j < mpSampleCountPerStratum[i]; ++j)\n        {\n            unsigned int index = Math::computeRandomNumber(&seed) % mpSampleCountPerStratum[i];\n            mpSampleIndicesPerStratum[i][j] = mpMasterSampleIndicesPerStratum[i][index];\n        }\n}\n\nvoid const\nData::computeMiBetweenFeatures(unsigned int const i, unsigned int const j, double* const mi_ij,\n        double* const mi_ji) const\n{\n    double val_ij = std::numeric_limits<double>::quiet_NaN();\n    double val_ji = std::numeric_limits<double>::quiet_NaN();\n\n    bool const A_is_continuous = mpFeatureTypes[i] == FEATURE_CONTINUOUS;\n    bool const A_is_discrete = mpFeatureTypes[i] == FEATURE_DISCRETE;\n    bool const A_is_survival_event = mpFeatureTypes[i] == FEATURE_SURVIVAL_EVENT;\n\n    bool const B_is_continuous = mpFeatureTypes[j] == FEATURE_CONTINUOUS;\n    bool const B_is_discrete = mpFeatureTypes[j] == FEATURE_DISCRETE;\n    bool const B_is_survival_event = mpFeatureTypes[j] == FEATURE_SURVIVAL_EVENT;\n\n    if (A_is_continuous && B_is_continuous)\n    {\n        switch (mContinuousEstimator)\n        {\n        case PEARSON_ESTIMATOR:\n        {\n            val_ij = val_ji = Math::computePearsonCorrelation(&(mpDataMatrix->at(0, i)),\n                    &(mpDataMatrix->at(0, j)), mpSampleWeights, mpSampleIndicesPerStratum,\n                    mpSampleCountPerStratum, mSampleStratumCount, mBootstrapCount);\n        }\n            break;\n\n        case SPEARMAN_ESTIMATOR:\n        {\n            if (!mpHasOrderCached[i])\n            {\n                Math::placeOrders(&(mpDataMatrix->at(0, i)), &(mpOrderMatrix->at(0, i)),\n                        mpSampleIndicesPerStratum, mpSampleCountPerStratum, mSampleStratumCount);\n                mpHasOrderCached[i] = true;\n            }\n\n            if (!mpHasOrderCached[j])\n            {\n                Math::placeOrders(&(mpDataMatrix->at(0, j)), &(mpOrderMatrix->at(0, j)),\n                        mpSampleIndicesPerStratum, mpSampleCountPerStratum, mSampleStratumCount);\n                mpHasOrderCached[j] = true;\n            }\n\n            double* const p_ranked_samples_x = new double[getSampleCount()];\n            double* const p_ranked_samples_y = new double[getSampleCount()];\n            Math::placeRanksFromOrders(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                    &(mpOrderMatrix->at(0, i)), &(mpOrderMatrix->at(0, j)), p_ranked_samples_x,\n                    p_ranked_samples_y, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                    mSampleStratumCount);\n            val_ij = val_ji = Math::computePearsonCorrelation(p_ranked_samples_x,\n                    p_ranked_samples_y, mpSampleWeights, mpSampleIndicesPerStratum,\n                    mpSampleCountPerStratum, mSampleStratumCount, mBootstrapCount);\n            delete[] p_ranked_samples_x;\n            delete[] p_ranked_samples_y;\n        }\n            break;\n\n        case KENDALL_ESTIMATOR:\n        {\n            val_ij =  Math::computeSomersD(\n              Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)),\n                                            &(mpDataMatrix->at(0, j)), mpSampleWeights, mpSampleIndicesPerStratum,\n                                            mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n            val_ji = Math::computeSomersD(\n              Math::computeConcordanceIndex(&(mpDataMatrix->at(0, j)),\n                                            &(mpDataMatrix->at(0, i)), mpSampleWeights, mpSampleIndicesPerStratum,\n                                            mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n        }\n            break;\n\n        case FREQUENCY_ESTIMATOR:\n        {\n            val_ij = Math::computeFrequency(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                    mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                    mSampleStratumCount, mBootstrapCount);\n            val_ji = 1 - val_ij;\n        }\n            break;\n        }\n    }\n    else if (A_is_discrete && B_is_continuous) // Not symmetrical\n        val_ij = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                        mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                        mSampleStratumCount, mOutX));\n    else if (A_is_continuous && B_is_discrete) // Not symmetrical\n        val_ij = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, j)), &(mpDataMatrix->at(0, i)),\n                        mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                        mSampleStratumCount, mOutX));\n    else if (A_is_discrete && B_is_discrete)\n        val_ij = val_ji = Math::computeCramersV(&(mpDataMatrix->at(0, i)),\n                &(mpDataMatrix->at(0, j)), mpSampleWeights, mpSampleIndicesPerStratum,\n                mpSampleCountPerStratum, mSampleStratumCount, mBootstrapCount);\n    else if (A_is_survival_event && B_is_continuous)\n        val_ij = val_ji = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                        &(mpDataMatrix->at(0, i + 1)), mpSampleWeights, mpSampleIndicesPerStratum,\n                        mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n    else if (A_is_continuous && B_is_survival_event)\n        val_ij = val_ji = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, j)), &(mpDataMatrix->at(0, i)),\n                        &(mpDataMatrix->at(0, j + 1)), mpSampleWeights, mpSampleIndicesPerStratum,\n                        mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n    else if (A_is_survival_event && B_is_discrete)\n        val_ij = val_ji = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                        &(mpDataMatrix->at(0, i + 1)), mpSampleWeights, mpSampleIndicesPerStratum,\n                        mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n    else if (A_is_discrete && B_is_survival_event)\n        val_ij = val_ji = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, j)), &(mpDataMatrix->at(0, i)),\n                        &(mpDataMatrix->at(0, j + 1)), mpSampleWeights, mpSampleIndicesPerStratum,\n                        mpSampleCountPerStratum, mSampleStratumCount, mOutX));\n    else if (A_is_survival_event && B_is_survival_event) // Not symmetrical for some reason\n        val_ij = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                        &(mpDataMatrix->at(0, i + 1)), &(mpDataMatrix->at(0, j + 1)),\n                        mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                        mSampleStratumCount, mOutX));\n\n    if (mpPriorsMatrix != 0)\n    {\n        val_ij = (std::fabs(1.0 - mPriorsWeight) * val_ij)\n                \t+ (mPriorsWeight * mpPriorsMatrix->at(i, j));\n\n        val_ji = (std::fabs(1.0 - mPriorsWeight) * val_ji)\n                \t+ (mPriorsWeight * mpPriorsMatrix->at(j, i));\n    }\n\n    if (val_ij == val_ij)\n        *mi_ij = val_ij;\n\n    if (val_ji == val_ji)\n        *mi_ji = val_ji;\n}\n\nunsigned int const\nData::getSampleCount() const\n{\n    return mpDataMatrix->getRowCount();\n}\n\nunsigned int const\nData::getFeatureCount() const\n{\n    return mpDataMatrix->getColumnCount();\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `bootstrap()` method in the `Data` class, and how does it generate random numbers?",
        "answer": "The `bootstrap()` method is used to create a bootstrapped sample of the data. It generates random numbers using the microseconds from the current time as a seed. For each stratum, it randomly selects indices from the master sample indices and assigns them to the current sample indices. This creates a new random sample of the data while maintaining the original stratification."
      },
      {
        "question": "How does the `computeMiBetweenFeatures()` method handle different combinations of feature types (continuous, discrete, and survival event)?",
        "answer": "The `computeMiBetweenFeatures()` method uses different algorithms to compute mutual information (MI) based on the types of features being compared. For continuous-continuous pairs, it uses the specified continuous estimator (Pearson, Spearman, Kendall, or Frequency). For discrete-discrete pairs, it uses Cramer's V. For combinations involving survival events, it uses Somers' D with concordance index. The method also handles asymmetric cases, such as discrete-continuous pairs, differently in each direction."
      },
      {
        "question": "What is the purpose of the `mpHasOrderCached` array in the `Data` class, and how is it used in the `computeMiBetweenFeatures()` method?",
        "answer": "The `mpHasOrderCached` array is used to keep track of which features have their orders cached in the `mpOrderMatrix`. In the `computeMiBetweenFeatures()` method, when using the Spearman estimator for continuous-continuous pairs, it checks if the orders for each feature have been cached. If not, it computes and caches the orders. This optimization prevents redundant calculations of feature orders across multiple calls to the method."
      }
    ],
    "completion_tasks": [
      {
        "partial": "Data::Data(double* const pData, Matrix const* const pPriorsMatrix, double const priorsWeight,\n        unsigned int const sampleCount, unsigned int const featureCount,\n        int const* const pSampleStrata, double const* const pSampleWeights,\n        int const* const pFeatureTypes, unsigned int const sampleStratumCount,\n        unsigned int const continuousEstimator, bool const outX, unsigned int const bootstrapCount) :\n        mpDataMatrix(new Matrix(pData, sampleCount, featureCount)),\n        mpOrderMatrix(continuousEstimator ? new Matrix(sampleCount, featureCount) : 0),\n        mpPriorsMatrix(pPriorsMatrix),\n        mpHasOrderCached(new bool[mpDataMatrix->getColumnCount()]),\n        mpSampleStrata(pSampleStrata),\n        mpSampleWeights(pSampleWeights),\n        mpFeatureTypes(pFeatureTypes),\n        mSampleStratumCount(sampleStratumCount),\n        mpSampleIndicesPerStratum(new unsigned int*[sampleStratumCount]),\n        mpMasterSampleIndicesPerStratum(new unsigned int*[sampleStratumCount]),\n        mpSampleCountPerStratum(new unsigned int[sampleStratumCount]),\n        mContinuousEstimator(continuousEstimator),\n        mOutX(outX),\n        mBootstrapCount(bootstrapCount),\n        mPriorsWeight(priorsWeight)\n{\n    // Initialize mpHasOrderCached\n    // TODO: Complete the initialization of other data structures\n}",
        "complete": "Data::Data(double* const pData, Matrix const* const pPriorsMatrix, double const priorsWeight,\n        unsigned int const sampleCount, unsigned int const featureCount,\n        int const* const pSampleStrata, double const* const pSampleWeights,\n        int const* const pFeatureTypes, unsigned int const sampleStratumCount,\n        unsigned int const continuousEstimator, bool const outX, unsigned int const bootstrapCount) :\n        mpDataMatrix(new Matrix(pData, sampleCount, featureCount)),\n        mpOrderMatrix(continuousEstimator ? new Matrix(sampleCount, featureCount) : 0),\n        mpPriorsMatrix(pPriorsMatrix),\n        mpHasOrderCached(new bool[mpDataMatrix->getColumnCount()]),\n        mpSampleStrata(pSampleStrata),\n        mpSampleWeights(pSampleWeights),\n        mpFeatureTypes(pFeatureTypes),\n        mSampleStratumCount(sampleStratumCount),\n        mpSampleIndicesPerStratum(new unsigned int*[sampleStratumCount]),\n        mpMasterSampleIndicesPerStratum(new unsigned int*[sampleStratumCount]),\n        mpSampleCountPerStratum(new unsigned int[sampleStratumCount]),\n        mContinuousEstimator(continuousEstimator),\n        mOutX(outX),\n        mBootstrapCount(bootstrapCount),\n        mPriorsWeight(priorsWeight)\n{\n    std::fill(mpHasOrderCached, mpHasOrderCached + mpDataMatrix->getColumnCount(), false);\n\n    Math::placeStratificationData(mpSampleStrata, mpSampleWeights, mpSampleIndicesPerStratum,\n            mpSampleCountPerStratum, mSampleStratumCount, sampleCount);\n\n    for (unsigned int i = 0; i < mSampleStratumCount; ++i)\n    {\n        mpMasterSampleIndicesPerStratum[i] = new unsigned int[mpSampleCountPerStratum[i]];\n        std::copy(mpSampleIndicesPerStratum[i], mpSampleIndicesPerStratum[i] + mpSampleCountPerStratum[i],\n                  mpMasterSampleIndicesPerStratum[i]);\n    }\n}"
      },
      {
        "partial": "void const\nData::computeMiBetweenFeatures(unsigned int const i, unsigned int const j, double* const mi_ij,\n        double* const mi_ji) const\n{\n    double val_ij = std::numeric_limits<double>::quiet_NaN();\n    double val_ji = std::numeric_limits<double>::quiet_NaN();\n\n    bool const A_is_continuous = mpFeatureTypes[i] == FEATURE_CONTINUOUS;\n    bool const A_is_discrete = mpFeatureTypes[i] == FEATURE_DISCRETE;\n    bool const A_is_survival_event = mpFeatureTypes[i] == FEATURE_SURVIVAL_EVENT;\n\n    bool const B_is_continuous = mpFeatureTypes[j] == FEATURE_CONTINUOUS;\n    bool const B_is_discrete = mpFeatureTypes[j] == FEATURE_DISCRETE;\n    bool const B_is_survival_event = mpFeatureTypes[j] == FEATURE_SURVIVAL_EVENT;\n\n    // TODO: Implement the logic for different feature type combinations\n\n    // Apply priors if available\n    if (mpPriorsMatrix != 0)\n    {\n        // TODO: Apply priors to val_ij and val_ji\n    }\n\n    if (val_ij == val_ij)\n        *mi_ij = val_ij;\n\n    if (val_ji == val_ji)\n        *mi_ji = val_ji;\n}",
        "complete": "void const\nData::computeMiBetweenFeatures(unsigned int const i, unsigned int const j, double* const mi_ij,\n        double* const mi_ji) const\n{\n    double val_ij = std::numeric_limits<double>::quiet_NaN();\n    double val_ji = std::numeric_limits<double>::quiet_NaN();\n\n    bool const A_is_continuous = mpFeatureTypes[i] == FEATURE_CONTINUOUS;\n    bool const A_is_discrete = mpFeatureTypes[i] == FEATURE_DISCRETE;\n    bool const A_is_survival_event = mpFeatureTypes[i] == FEATURE_SURVIVAL_EVENT;\n\n    bool const B_is_continuous = mpFeatureTypes[j] == FEATURE_CONTINUOUS;\n    bool const B_is_discrete = mpFeatureTypes[j] == FEATURE_DISCRETE;\n    bool const B_is_survival_event = mpFeatureTypes[j] == FEATURE_SURVIVAL_EVENT;\n\n    if (A_is_continuous && B_is_continuous)\n    {\n        switch (mContinuousEstimator)\n        {\n        case PEARSON_ESTIMATOR:\n            val_ij = val_ji = Math::computePearsonCorrelation(&(mpDataMatrix->at(0, i)),\n                    &(mpDataMatrix->at(0, j)), mpSampleWeights, mpSampleIndicesPerStratum,\n                    mpSampleCountPerStratum, mSampleStratumCount, mBootstrapCount);\n            break;\n        case SPEARMAN_ESTIMATOR:\n            // Implement Spearman estimator\n            break;\n        case KENDALL_ESTIMATOR:\n            // Implement Kendall estimator\n            break;\n        case FREQUENCY_ESTIMATOR:\n            // Implement Frequency estimator\n            break;\n        }\n    }\n    else if (A_is_discrete && B_is_continuous)\n        val_ij = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, i)), &(mpDataMatrix->at(0, j)),\n                        mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                        mSampleStratumCount, mOutX));\n    else if (A_is_continuous && B_is_discrete)\n        val_ij = Math::computeSomersD(\n                Math::computeConcordanceIndex(&(mpDataMatrix->at(0, j)), &(mpDataMatrix->at(0, i)),\n                        mpSampleWeights, mpSampleIndicesPerStratum, mpSampleCountPerStratum,\n                        mSampleStratumCount, mOutX));\n    else if (A_is_discrete && B_is_discrete)\n        val_ij = val_ji = Math::computeCramersV(&(mpDataMatrix->at(0, i)),\n                &(mpDataMatrix->at(0, j)), mpSampleWeights, mpSampleIndicesPerStratum,\n                mpSampleCountPerStratum, mSampleStratumCount, mBootstrapCount);\n    // Implement other combinations (survival event)\n\n    if (mpPriorsMatrix != 0)\n    {\n        val_ij = (std::fabs(1.0 - mPriorsWeight) * val_ij) + (mPriorsWeight * mpPriorsMatrix->at(i, j));\n        val_ji = (std::fabs(1.0 - mPriorsWeight) * val_ji) + (mPriorsWeight * mpPriorsMatrix->at(j, i));\n    }\n\n    if (val_ij == val_ij)\n        *mi_ij = val_ij;\n\n    if (val_ji == val_ji)\n        *mi_ji = val_ji;\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/R/generics.R",
    "language": "R",
    "content": "setGeneric(\"featureData\", function(object) standardGeneric(\"featureData\"))\n\nsetGeneric(\"subsetData\", function(object, ...) standardGeneric(\"subsetData\"))\n\nsetGeneric(\"sampleNames\", function(object) standardGeneric(\"sampleNames\"))\n\nsetGeneric(\"sampleCount\", function(object) standardGeneric(\"sampleCount\"))\n\nsetGeneric(\"featureCount\", function(object) standardGeneric(\"featureCount\"))\n\nsetGeneric(\"featureNames\", function(object) standardGeneric(\"featureNames\"))\n\nsetGeneric(\"sampleStrata\", function(object) standardGeneric(\"sampleStrata\"))\n\nsetGeneric(\"sampleStrata<-\", function(object, value) standardGeneric(\"sampleStrata<-\"))\n\nsetGeneric(\"sampleWeights\", function(object) standardGeneric(\"sampleWeights\"))\n\nsetGeneric(\"sampleWeights<-\", function(object, value) standardGeneric(\"sampleWeights<-\"))\n\nsetGeneric(\"priors\", function(object) standardGeneric(\"priors\"))\n\nsetGeneric(\"priors<-\", function(object, value) standardGeneric(\"priors<-\"))\n\nsetGeneric(\"mim\", function(object, method = c(\"mi\", \"cor\"), ...)\n{\n    method <- match.arg(method)\n    matrix <- standardGeneric(\"mim\")\n    \n    if (method == \"mi\")\n        matrix <- -.5 * log(1 - (matrix^2))\n    \n    return(matrix)\n})\n\nsetGeneric(\".expandFeatureMatrix\", function(object, ...) standardGeneric(\".expandFeatureMatrix\"))\n\nsetGeneric(\".compressFeatureMatrix\", function(object, ...) standardGeneric(\".compressFeatureMatrix\"))\n\nsetGeneric(\".expandFeatureIndices\", function(object, ...) standardGeneric(\".expandFeatureIndices\"))\n\nsetGeneric(\".compressFeatureIndices\", function(object, ...) standardGeneric(\".compressFeatureIndices\"))\n\nsetGeneric(\"solutions\", function(object, ...) standardGeneric(\"solutions\"))\n\nsetGeneric(\"scores\", function(object, ...) standardGeneric(\"scores\"))\n\nsetGeneric(\"causality\", function(object, ...) standardGeneric(\"causality\"))\n\nsetGeneric(\"target\", function(object) standardGeneric(\"target\"))\n\nsetGeneric(\"adjacencyMatrix\", function(object) standardGeneric(\"adjacencyMatrix\"))\n\nsetGeneric(\"adjacencyMatrixSum\", function(object) standardGeneric(\"adjacencyMatrixSum\"))\n\nsetGeneric(\"visualize\", function(object) standardGeneric(\"visualize\"))\n\n`.map.continuous.estimator` <- function(continuous_estimator)\n{\n    value <- switch(continuous_estimator, \"pearson\" = 0L, \"spearman\" = 1L, \"kendall\" = 2L, \"frequency\" = 3L, -1L)\n    \n    if (value < 0L || value > 4L || !is.character(continuous_estimator))\n        stop(\"estimator must be of the following: pearson, spearman, kendall, frequency\")\n    \n    return(value)\n}\n\n`correlate` <- function(X, Y, method = c(\"pearson\", \"spearman\", \"kendall\", \"frequency\", \"cramersv\", \"cindex\"), strata, weights, outX = TRUE, bootstrap_count = 0, alpha = 0.05, alternative=c(\"two.sided\", \"less\", \"greater\"))\n{\n    method <- match.arg(method)\n    alternative <- match.arg(alternative)\n    \n    if((is.Surv(X) || is.Surv(Y)) && method != \"cindex\") { stop(\"method should be cindex when dealing with survival data\") }\n    \n    if (method == \"pearson\" || method == \"spearman\" || method == \"kendall\" || method == \"frequency\")\n    {\n        X <- as.numeric(X)\n        Y <- as.numeric(Y)\n    }\n    else if (method == \"cramersv\")\n    {\n        X <- as.factor(X)\n        Y <- as.factor(Y)\n    }\n    else if (method != \"cindex\")\n        stop(\"estimator must be of the following: pearson, spearman, kendall, frequency, cramersv, cindex\")\n    \n    if(is.Surv(X)) { ll <- nrow(X) } else { ll <- length(X) }\n\n    if (missing(strata)) {\n      strata <- factor(rep(0, ll))\n      names(strata) <- names(X)\n    }\n    \n    if (missing(weights)) {\n      weights <- rep(1, ll)\n      names(weights) <- names(X)\n    } \n    \n    data <- mRMR.data(data = data.frame(X, Y), strata = strata, weights = weights)\n\n    if (method == \"cindex\")\n    {\n        empty <- vector(mode = \"numeric\", length = 0)\n        \n        if (length(data@feature_types) == 2)\n            input <- list(data@data[, 1], data@data[, 2], empty, empty)\n        else if (length(data@feature_types) == 3)\n        {\n            if (data@feature_types[[1]] == 2)\n                input <- list(data@data[, 1], data@data[, 3], data@data[, 2], empty)\n            else if (data@feature_types[[2]] == 2)\n                input <- list(data@data[, 2], data@data[, 1], data@data[, 3], empty)\n        }\n        else if (length(data@feature_types) == 4)\n            input <- list(data@data[, 1], data@data[, 3], data@data[, 2], data@data[, 4])\n        \n\t\t\t\tratio <- vector(mode = \"numeric\", length = 1)\n\t\t\t\tch <- vector(mode = \"numeric\", length = length(input[[1]]))\n\t\t\t\tdh <- vector(mode = \"numeric\", length = length(input[[1]]))\n\t\t\t\tuh <- vector(mode = \"numeric\", length = length(input[[1]]))\n\t\t\t\trh <- vector(mode = \"numeric\", length = length(input[[1]]))\n\n        .Call(.C_export_concordance_index, as.numeric(input[[1]]), as.numeric(input[[2]]),\n                as.numeric(input[[3]]), as.numeric(input[[4]]), as.integer(data@strata), as.numeric(data@weights),\n                as.integer(length(unique(data@strata))), outX, ratio, ch, dh, uh, rh)  \n        \n              cindex <- ratio\n              myx <- complete.cases(featureData(data), sampleStrata(data), sampleWeights(data))\n              N <- sum(weights[myx])\n              \n              cscount <- sum(ch + dh) ## comparable pairs\n              if (sum(ch) == 0 || sum (dh) ==0 || sum(ch * (ch - 1)) == 0 || sum(dh * (dh - 1)) == 0 || sum(ch * dh) == 0 || cscount < 10)\n                return(list(\"cindex\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p\"=NA, \"n\"=N))\n              \n              ## FIXME: N and subsequent calculation should be done withing strata\n              pc <- (1 / (N * (N - 1))) * sum(ch)\n              pd  <- (1 / (N * (N - 1))) * sum(dh)\n              pcc <- (1 / (N * (N - 1) * (N - 2))) * sum(ch * (ch - 1))\n              pdd <- (1 / (N * (N - 1) * (N - 2))) * sum(dh * (dh - 1))\n              pcd <- (1 / (N * (N - 1) * (N - 2))) * sum(ch * dh)\n              varp <- (4 / (pc + pd)^4) * (pd^2 * pcc - 2 * pc * pd * pcd + pc^2 * pdd)\n              if((varp / N) > 0) {\n                se <- sqrt(varp / N)\n                ci <- qnorm(p=alpha / 2, lower.tail=FALSE) * se\n                lower <- cindex - ci\n                upper <- cindex + ci\n                switch(alternative, \n                \"two.sided\"={ p <- pnorm((cindex - 0.5) / se, lower.tail=cindex < 0.5) * 2 }, \n                \"less\"={ p <- pnorm((cindex - 0.5) / se, lower.tail=TRUE) }, \n                \"greater\"={  p <- pnorm((cindex - 0.5) / se, lower.tail=FALSE) }\n                )\n              } else { se <- lower <- upper <- p <- NA } \n        \n        return(list(\"estimate\"=cindex, \"se\"=se, \"lower\"=lower, \"upper\"=upper, \"p\"=p, \"n\"=N))\n    }\n    else if (method == \"cramersv\")\n        return(list(statistic = mim(data, method = \"cor\", outX = outX, bootstrap_count = bootstrap_count)[1, 2]))\n    else\n        return(list(statistic = mim(data, method = \"cor\", continuous_estimator = method, outX = outX,\n                            bootstrap_count = bootstrap_count)[1, 2]))\n}\n\n`get.thread.count` <- function()\n{\n    thread_count <- vector(mode = \"integer\", length = 1)\n    \n    .Call(.C_get_thread_count, thread_count)\n    \n    return(thread_count)\n}\n\n`set.thread.count` <- function(thread_count)\n{\n    thread_count <- as.integer(thread_count)\n    \n    .Call(.C_set_thread_count, thread_count)\n    \n    return(thread_count)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `setGeneric` function calls at the beginning of the code snippet?",
        "answer": "The `setGeneric` function calls are used to define generic functions in R's S4 object-oriented programming system. These calls create a standardized interface for methods that can be implemented differently for various classes. They allow for method dispatch based on the class of the arguments, enabling polymorphism in R."
      },
      {
        "question": "Explain the purpose and functionality of the `mim` generic function in this code.",
        "answer": "The `mim` generic function is designed to compute a matrix, likely a mutual information matrix or correlation matrix. It takes an object, a method ('mi' or 'cor'), and additional arguments. If the method is 'mi', it transforms the resulting matrix using the formula -.5 * log(1 - (matrix^2)), which converts correlation coefficients to mutual information values. This function allows for flexible computation of information-theoretic or correlation-based matrices."
      },
      {
        "question": "What is the purpose of the `correlate` function, and how does it handle different correlation methods?",
        "answer": "The `correlate` function is a versatile correlation calculator that supports multiple methods: Pearson, Spearman, Kendall, frequency, Cramer's V, and concordance index (c-index). It handles different data types (numeric, categorical, survival) and can incorporate stratification and weights. The function uses method dispatch to call the appropriate correlation calculation based on the specified method and data types, returning the correlation statistic along with additional information like standard error and p-value for some methods."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setGeneric(\"mim\", function(object, method = c(\"mi\", \"cor\"), ...)\n{\n    method <- match.arg(method)\n    matrix <- standardGeneric(\"mim\")\n    \n    if (method == \"mi\")\n        matrix <- -.5 * log(1 - (matrix^2))\n    \n    return(matrix)\n})",
        "complete": "setGeneric(\"mim\", function(object, method = c(\"mi\", \"cor\"), ...)\n{\n    method <- match.arg(method)\n    matrix <- standardGeneric(\"mim\")\n    \n    if (method == \"mi\")\n        matrix <- -.5 * log(1 - (matrix^2))\n    \n    return(matrix)\n})"
      },
      {
        "partial": "`.map.continuous.estimator` <- function(continuous_estimator)\n{\n    value <- switch(continuous_estimator,\n                    \"pearson\" = 0L,\n                    \"spearman\" = 1L,\n                    \"kendall\" = 2L,\n                    \"frequency\" = 3L,\n                    -1L)\n    \n    if (value < 0L || value > 4L || !is.character(continuous_estimator))\n        stop(\"estimator must be one of the following: pearson, spearman, kendall, frequency\")\n    \n    return(value)\n}",
        "complete": "`.map.continuous.estimator` <- function(continuous_estimator)\n{\n    value <- switch(continuous_estimator,\n                    \"pearson\" = 0L,\n                    \"spearman\" = 1L,\n                    \"kendall\" = 2L,\n                    \"frequency\" = 3L,\n                    -1L)\n    \n    if (value < 0L || value > 4L || !is.character(continuous_estimator))\n        stop(\"estimator must be one of the following: pearson, spearman, kendall, frequency\")\n    \n    return(value)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/RadioSet-class.R",
    "language": "R",
    "content": "#' A Class to Contain RadioGenomic datasets together with their curations\n#'\n#' The RadioSet (RSet) class was developed to contain and organise large\n#' RadioGenomic datasets, and aid in their metanalysis. It was designed\n#' primarily to allow bioinformaticians and biologists to work with data at the\n#' level of genes and cell lines, providing a more naturally intuitive\n#' interface and simplifying analyses between several datasets. As such, it was\n#' designed to be flexible enough to hold datasets of two different natures\n#' while providing a common interface. The class can accomidate datasets\n#' containing both radiation dose response data, as well as datasets contaning\n#' genetic profiles of cell lines pre and post treatement with compounds, known\n#' respecitively as sensitivity and perturbation datasets.\n#'\n#' @slot annotation A \\code{list} of annotation data about the RadioSet,\n#'    including the \\code{$name} and the session information for how the object\n#'    was creating, detailing the exact versions of R and all the packages used\n#' @slot molecularProfiles A \\code{list} containing 4 \\code{SummarizedExperiment}\n#'   type object for holding data for RNA, DNA, SNP and Copy Number Variation\n#'   measurements respectively, with associated \\code{fData} and \\code{pData}\n#'   containing the row and column metadata\n#' @slot sample A \\code{data.frame} containg the annotations for all the cell\n#'   lines profiled in the data set, across all data types\n#' @slot treatment A \\code{data.frame} containg the annotations for all the\n#'   radiation treatment types used in the in the dataset, across all data types\n#' @slot sensitivity A \\code{list} containing all the data for the sensitivity\n#'   experiments, including \\code{$info}, a \\code{data.frame} containing the\n#'   experimental info,\\code{$raw} a 3D \\code{array} containing raw data,\n#'   \\code{$profiles}, a \\code{data.frame} containing sensitivity profiles\n#'   statistics, and \\code{$n}, a \\code{data.frame} detailing the number of\n#'   experiments for each cell-radiation type pair\n#' @slot perturbation A \\code{list} containting \\code{$n}, a \\code{data.frame}\n#'   summarizing the available perturbation data,\n#' @slot curation A \\code{list} containing mappings for\n#'   \\code{cell} and \\code{tissue} names used in the data set to universal\n#'   identifiers used between different RadioSet objects\n#' @slot datasetType A \\code{character} string of 'sensitivity',\n#'   'perturbation', or both detailing what type of data can be found in the\n#'   RadioSet, for proper processing of the data\n#'\n#' @return An object of the RadioSet class\n#'\n#' @importClassesFrom CoreGx CoreSet\n.RadioSet <- setClass(\"RadioSet\", slots=list(radiation=\"data.frame\"),\n                      contains = \"CoreSet\")\n\n# The default constructor above does a poor job of explaining the required structure of a RadioSet.\n# The constructor function defined below guides the user into providing the required components of the curation and senstivity lists\n# and hides the annotation slot which the user does not need to manually fill.\n# This also follows the design of the Expression Set class.\n\n### -------------------------------------------------------------------------\n### Constructor -------------------------------------------------------------\n### -------------------------------------------------------------------------\n\n#' RadioSet constructor\n#'\n#' A constructor that simplifies the process of creating RadioSets, as well\n#' as creates empty objects for data not provided to the constructor. Only\n#' objects returned by this constructor are expected to work with the RadioSet\n#' methods. For a much more detailed instruction on creating RadioSets, please\n#' see the \"CreatingRadioSet\" vignette.\n#'\n#' @inheritParams CoreGx::CoreSet\n#'\n#' @return An object of class `RadioSet``\n#'\n#' @import methods\n#' @importFrom utils sessionInfo\n#' @importFrom stats na.omit\n#' @importFrom SummarizedExperiment rowData colData assay assays assayNames Assays\n#' @importFrom S4Vectors DataFrame SimpleList metadata\n#' @importFrom CoreGx CoreSet\n#'\n#' @export\nRadioSet <-  function(name,\n                      molecularProfiles=list(),\n                      sample=data.frame(),\n                      treatment=data.frame(),\n                      sensitivityInfo=data.frame(),\n                      sensitivityRaw=array(dim=c(0,0,0)),\n                      sensitivityProfiles=matrix(),\n                      sensitivityN=matrix(nrow=0, ncol=0),\n                      perturbationN=array(NA, dim=c(0,0,0)),\n                      curationSample = data.frame(),\n                      curationTissue = data.frame(),\n                      curationTreatment = data.frame(),\n                      datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                      verify = TRUE)\n{\n    cSet <- CoreGx::CoreSet(\n        name=name,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        sensitivityInfo=sensitivityInfo,\n        sensitivityRaw=sensitivityRaw,\n        sensitivityProfiles=sensitivityProfiles,\n        sensitivityN=sensitivityN,\n        perturbationN=perturbationN,\n        curationTreatment=curationTreatment,\n        curationSample=curationSample,\n        curationTissue=curationTissue,\n        datasetType=datasetType,\n        verify=verify\n    )\n\n    rSet <- .RadioSet(\n        annotation=cSet@annotation,\n        molecularProfiles=cSet@molecularProfiles,\n        sample=cSet@sample,\n        treatment=cSet@treatment,\n        datasetType=cSet@datasetType,\n        treatmentResponse=cSet@treatmentResponse,\n        perturbation=cSet@perturbation,\n        curation=cSet@curation\n    )\n    if (verify) { checkRSetStructure(rSet)}\n    if (length(sensitivityN) == 0 && datasetType %in% c(\"sensitivity\", \"both\")) {\n      sensNumber(rSet) <- .summarizeSensitivityNumbers(rSet)\n    }\n      if (length(perturbationN) == 0  && datasetType %in% c(\"perturbation\", \"both\")) {\n        pertNumber(rSet) <- .summarizePerturbationNumbers(rSet)\n      }\n    return(rSet)\n}\n\n\n# Constructor Helper Functions ----------------------------------------------\n\n.summarizeSensitivityNumbers <- function(object) {\n\n  if (datasetType(object) != \"sensitivity\" && datasetType(object) != \"both\") {\n    stop (\"Data type must be either sensitivity or both\")\n  }\n\n  ## unique radiation identifiers\n  # radiationn <- sort(unique(sensitivityInfo(object)[ , \"treatmentid\"]))\n\n  ## consider all radiations\n  radiationn <- rownames(treatmentInfo(object))\n\n  ## unique radiation identifiers\n  # celln <- sort(unique(sensitivityInfo(object)[ , \"sampleid\"]))\n\n  ## consider all cell lines\n  celln <- rownames(sampleInfo(object))\n\n  sensitivity.info <- matrix(0, nrow=length(celln), ncol=length(radiationn), dimnames=list(celln, radiationn))\n  radiation.types <- sensitivityInfo(object)[ , \"treatmentid\"]\n  cellids <- sensitivityInfo(object)[ , \"sampleid\"]\n  cellids <- cellids[grep(\"///\", radiation.types, invert=TRUE)]\n  radiation.types <- radiation.types[grep(\"///\", radiation.types, invert=TRUE)]\n\n\n  tt <- table(cellids, radiation.types)\n  sensitivity.info[rownames(tt), colnames(tt)] <- tt\n\n  return(sensitivity.info)\n}\n\n\n.summarizeMolecularNumbers <- function(object) {\n\n  ## consider all molecular types\n  mDT <- mDataNames(object)\n\n  ## consider all cell lines\n  celln <- rownames(sampleInfo(object))\n\n  molecular.info <- matrix(0, nrow=length(celln), ncol=length(mDT), dimnames=list(celln, mDT))\n\n  for(mDataType in mDT) {\n    tt <- table(phenoInfo(object, mDataType)$sampleid)\n    molecular.info[names(tt), mDataType] <- tt\n\n  }\n  return(molecular.info)\n}\n\n\n.summarizePerturbationNumbers <- function(object) {\n\n  if (datasetType(object) != \"perturbation\" && datasetType(object) != \"both\") {\n    stop (\"Data type must be either perturbation or both\")\n  }\n\n  radiationn <- rownames(treatmentInfo(object))\n\n  celln <- rownames(sampleInfo(object))\n\n  perturbation.info <- array(0, dim=c(length(celln), length(radiationn), length(molecularProfilesSlot(object))), dimnames=list(celln, radiationn, names((molecularProfilesSlot(object)))))\n\n  for (i in seq_len(length(molecularProfilesSlot(object)))) {\n    if (nrow(SummarizedExperiment::colData(molecularProfilesSlot(object)[[i]])) > 0 && all(is.element(c(\"sampleid\", \"treatmentid\"), colnames(SummarizedExperiment::colData(molecularProfilesSlot(object)[[i]]))))) {\n      tt <- table(SummarizedExperiment::colData(molecularProfilesSlot(object)[[i]])[ , \"sampleid\"], SummarizedExperiment::colData(molecularProfilesSlot(object)[[i]])[ , \"treatmentid\"])\n      perturbation.info[rownames(tt), colnames(tt), names(molecularProfilesSlot(object))[i]] <- tt\n    }\n  }\n\n  return(perturbation.info)\n}\n\n### -------------------------------------------------------------------------\n### Class Validity ----------------------------------------------------------\n### -------------------------------------------------------------------------\n\n#' A function to verify the structure of a RadioSet\n#'\n#' This function checks the structure of a PharamcoSet, ensuring that the\n#' correct annotations are in place and all the required slots are filled so\n#' that matching of cells and radiations can be properly done across different\n#' types of data and with other studies.\n#'\n#' @examples\n#' checkRSetStructure(clevelandSmall)\n#'\n#' @param object A \\code{RadioSet} object\n#' @param plotDist Should the function also plot the distribution of molecular\n#'     data?\n#' @param result.dir The path to the directory for saving the plots as a string,\n#'     defaults to `tempdir()``\n#'\n#' @return Prints out messages whenever describing the errors found in the\n#'     structure of the pset object passed in.\n#'\n#' @importFrom graphics hist\n#' @importFrom grDevices dev.off pdf\n#' @export\ncheckRSetStructure <- function(object, plotDist=FALSE, result.dir=tempdir()) {\n    # Make directory to store results if it doesn't exist\n    if(!file.exists(result.dir) & plotDist) { dir.create(result.dir, showWarnings=FALSE, recursive=TRUE) }\n\n    #####\n    # Checking molecularProfiles\n    #####\n    # Can this be parallelized or does it mess with the order of printing warnings?\n    for( i in seq_along(molecularProfilesSlot(object))) {\n      profile <- molecularProfilesSlot(object)[[i]]\n      nn <- names(molecularProfilesSlot(object))[i]\n\n      # Testing plot rendering for rna and rnaseq\n      if((S4Vectors::metadata(profile)$annotation == \"rna\" | S4Vectors::metadata(profile)$annotation == \"rnaseq\") & plotDist)\n      {\n        pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n        hist(assays(profile)[[1]], breaks = 100)\n        dev.off()\n      }\n\n\n      ## Test if sample and feature annotations dimensions match the assay\n      warning(ifelse(nrow(rowData(profile)) != nrow(assays(profile)[[1]]),\n                     sprintf(\"%s: number of features in fData is different from\n                             SummarizedExperiment slots\", nn),\n                     sprintf(\"%s: rowData dimension is OK\", nn)\n      )\n      )\n      warning(ifelse(nrow(colData(profile)) != ncol(assays(profile)[[1]]),\n                     sprintf(\"%s: number of cell lines in pData is different\n                             from expression slots\", nn),\n                     sprintf(\"%s: colData dimension is OK\", nn)\n      )\n      )\n\n\n      # Checking sample metadata for required columns\n      warning(ifelse(\"sampleid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: sampleid does not exist in colData (samples)\n                             columns\", nn)))\n      warning(ifelse(\"batchid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: batchid does not exist in colData (samples)\n                             columns\", nn)))\n\n      # Checking mDataType of the SummarizedExperiment for required columns\n      if(S4Vectors::metadata(profile)$annotation == \"rna\" |\n         S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n      {\n        warning(ifelse(\"BEST\" %in% colnames(rowData(profile)), \"BEST is OK\",\n                       sprintf(\"%s: BEST does not exist in rowData (features)\n                               columns\", nn)))\n        warning(ifelse(\"Symbol\" %in% colnames(rowData(profile)), \"Symbol is OK\",\n                       sprintf(\"%s: Symbol does not exist in rowData (features)\n                               columns\", nn)))\n      }\n\n      # Check that all cellids from the object are included in molecularProfiles\n      if(\"sampleid\" %in% colnames(rowData(profile))) {\n        if(!all(colData(profile)[,\"sampleid\"] %in% rownames(sampleInfo(object)))) {\n          warning(sprintf(\"%s: not all the cell lines in this profile are in\n                          cell lines slot\", nn))\n        }\n      }else {\n        warning(sprintf(\"%s: sampleid does not exist in colData (samples)\", nn))\n      }\n    }\n\n    ###\n    # CHECKING CELL\n    ###\n    if(\"tissueid\" %in% colnames(sampleInfo(object))) {\n      if(\"unique.tissueid\" %in% colnames(curation(object)$tissue))\n      {\n        if(length(intersect(rownames(curation(object)$tissue), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n          message(\"rownames of curation tissue slot should be the same as cell slot (curated cell ids)\")\n        } else{\n          if(length(intersect(sampleInfo(object)$tissueid, curation(object)$tissue$unique.tissueid)) != length(table(sampleInfo(object)$tissueid))){\n            message(\"tissueid should be the same as unique tissue id from tissue curation slot\")\n          }\n        }\n      } else {\n        message(\"unique.tissueid which is curated tissue id across data set should be a column of tissue curation slot\")\n      }\n      if(any(is.na(sampleInfo(object)[,\"tissueid\"]) | sampleInfo(object)[,\"tissueid\"]==\"\", na.rm=TRUE)){\n        message(sprintf(\"There is no tissue type for this cell line(s): %s\", paste(rownames(sampleInfo(object))[which(is.na(sampleInfo(object)[,\"tissueid\"]) | sampleInfo(object)[,\"tissueid\"]==\"\")], collapse=\" \")))\n      }\n    } else {\n      warning(\"tissueid does not exist in cell slot\")\n    }\n\n    if(\"unique.sampleid\" %in% colnames(curation(object)$sample)) {\n      if(length(intersect(curation(object)$sample$unique.sampleid, rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n        message(\"rownames of cell slot should be curated cell ids\")\n      }\n    } else {\n      message(\"unique.sampleid which is curated cell id across data set should be a column of cell curation slot\")\n    }\n\n    if(length(intersect(rownames(curation(object)$sample), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n      message(\"rownames of curation cell slot should be the same as cell slot (curated cell ids)\")\n    }\n\n    if(length(intersect(rownames(curation(object)$sample), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n      message(\"rownames of curation radiation slot should be the same as radiation slot (curated radiation ids)\")\n    }\n\n    if(!is(sampleInfo(object), \"data.frame\")) {\n      warning(\"cell slot class type should be dataframe\")\n    }\n    if(!is(treatmentInfo(object), \"data.frame\")) {\n      warning(\"radiation slot class type should be dataframe\")\n    }\n    if(datasetType(object) %in% c(\"sensitivity\", \"both\"))\n    {\n      if(!is(sensitivityInfo(object), \"data.frame\")) {\n        warning(\"sensitivity info slot class type should be dataframe\")\n      }\n      if(\"sampleid\" %in% colnames(sensitivityInfo(object))) {\n        if(!all(sensitivityInfo(object)[,\"sampleid\"] %in% rownames(sampleInfo(object)))) {\n          warning(\"not all the cell lines in sensitivity data are in cell slot\")\n        }\n      }else {\n        warning(\"sampleid does not exist in sensitivity info\")\n      }\n\n      ###\n      # CHECKING RADIATION\n      ###\n      if(\"treatmentid\" %in% colnames(sensitivityInfo(object))) {\n        radiation.ids <- unique(sensitivityInfo(object)[,\"treatmentid\"])\n        radiation.ids <- radiation.ids[grep(\"///\",radiation.ids, invert=TRUE)]\n        if(!all(radiation.ids %in% rownames(treatmentInfo(object)))) {\n          message(\"not all the radiations in sensitivity data are in radiation slot\")\n        }\n      }else {\n        warning(\"treatmentid does not exist in sensitivity info\")\n      }\n\n      if(any(!is.na(sensitivityRaw(object)))) {\n        if(!all(dimnames(sensitivityRaw(object))[[1]] %in% rownames(sensitivityInfo(object)))) {\n          warning(\"For some experiments there is raw sensitivity data but no experimet information in sensitivity info\")\n        }\n      }\n      if(!all(rownames(sensitivityProfiles(object)) %in% rownames(sensitivityInfo(object)))) {\n        warning(\"For some experiments there is sensitivity profiles but no experimet information in sensitivity info\")\n      }\n    }\n  }\n\n### -------------------------------------------------------------------------\n### Method Definitions ------------------------------------------------------\n### -------------------------------------------------------------------------\n\n#' Show a RadioSet\n#'\n#' @examples\n#' data(clevelandSmall)\n#' clevelandSmall\n#'\n#' @param object A \\code{RadioSet} object\n#'\n#' @return Prints the RadioSet object to the output stream, and returns\n#'   invisible NULL.\n#'\n#' @export\nsetMethod(\"show\", signature=signature(object=\"RadioSet\"),\n      function(object) {\n    callNextMethod(object)\n})\n\n#' Get the dimensions of a RadioSet\n#'\n#' @examples\n#' data(clevelandSmall)\n#' dim(clevelandSmall)\n#'\n#' @param x RadioSet\n#' @return A named vector with the number of Cells and Drugs in the RadioSet\n#' @export\nsetMethod(\"dim\", signature=signature(x=\"RadioSet\"), function(x){\n  return(c(Cells=length(sampleNames(x)), Radiation=length(treatmentNames(x))))\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the RadioSet class and what types of data can it accommodate?",
        "answer": "The RadioSet class is designed to contain and organize large RadioGenomic datasets and aid in their metanalysis. It can accommodate two types of datasets: 1) radiation dose response data, and 2) genetic profiles of cell lines pre and post treatment with compounds, known as sensitivity and perturbation datasets respectively. It provides a common interface for bioinformaticians and biologists to work with data at the level of genes and cell lines."
      },
      {
        "question": "What are the key slots in the RadioSet class and what do they contain?",
        "answer": "The key slots in the RadioSet class include: 1) annotation: contains metadata about the RadioSet, 2) molecularProfiles: holds data for RNA, DNA, SNP, and Copy Number Variation measurements, 3) sample: contains annotations for cell lines, 4) treatment: contains annotations for radiation treatment types, 5) sensitivity: holds data for sensitivity experiments, 6) perturbation: contains perturbation data, 7) curation: contains mappings for cell and tissue names, and 8) datasetType: specifies the type of data in the RadioSet."
      },
      {
        "question": "How does the RadioSet constructor function simplify the process of creating RadioSets?",
        "answer": "The RadioSet constructor function simplifies the creation process by: 1) guiding users to provide required components of the curation and sensitivity lists, 2) hiding the annotation slot which users don't need to manually fill, 3) creating empty objects for data not provided to the constructor, 4) verifying the structure of the created RadioSet object, and 5) automatically summarizing sensitivity and perturbation numbers if not provided. This approach ensures that only properly structured RadioSet objects are created and work with the RadioSet methods."
      }
    ],
    "completion_tasks": [
      {
        "partial": "RadioSet <- function(name,\n                      molecularProfiles=list(),\n                      sample=data.frame(),\n                      treatment=data.frame(),\n                      sensitivityInfo=data.frame(),\n                      sensitivityRaw=array(dim=c(0,0,0)),\n                      sensitivityProfiles=matrix(),\n                      sensitivityN=matrix(nrow=0, ncol=0),\n                      perturbationN=array(NA, dim=c(0,0,0)),\n                      curationSample = data.frame(),\n                      curationTissue = data.frame(),\n                      curationTreatment = data.frame(),\n                      datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                      verify = TRUE)\n{\n    cSet <- CoreGx::CoreSet(\n        name=name,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        sensitivityInfo=sensitivityInfo,\n        sensitivityRaw=sensitivityRaw,\n        sensitivityProfiles=sensitivityProfiles,\n        sensitivityN=sensitivityN,\n        perturbationN=perturbationN,\n        curationTreatment=curationTreatment,\n        curationSample=curationSample,\n        curationTissue=curationTissue,\n        datasetType=datasetType,\n        verify=verify\n    )\n\n    rSet <- .RadioSet(\n        annotation=cSet@annotation,\n        molecularProfiles=cSet@molecularProfiles,\n        sample=cSet@sample,\n        treatment=cSet@treatment,\n        datasetType=cSet@datasetType,\n        treatmentResponse=cSet@treatmentResponse,\n        perturbation=cSet@perturbation,\n        curation=cSet@curation\n    )\n    if (verify) { checkRSetStructure(rSet)}\n    # Complete the function here",
        "complete": "RadioSet <- function(name,\n                      molecularProfiles=list(),\n                      sample=data.frame(),\n                      treatment=data.frame(),\n                      sensitivityInfo=data.frame(),\n                      sensitivityRaw=array(dim=c(0,0,0)),\n                      sensitivityProfiles=matrix(),\n                      sensitivityN=matrix(nrow=0, ncol=0),\n                      perturbationN=array(NA, dim=c(0,0,0)),\n                      curationSample = data.frame(),\n                      curationTissue = data.frame(),\n                      curationTreatment = data.frame(),\n                      datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                      verify = TRUE)\n{\n    cSet <- CoreGx::CoreSet(\n        name=name,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        sensitivityInfo=sensitivityInfo,\n        sensitivityRaw=sensitivityRaw,\n        sensitivityProfiles=sensitivityProfiles,\n        sensitivityN=sensitivityN,\n        perturbationN=perturbationN,\n        curationTreatment=curationTreatment,\n        curationSample=curationSample,\n        curationTissue=curationTissue,\n        datasetType=datasetType,\n        verify=verify\n    )\n\n    rSet <- .RadioSet(\n        annotation=cSet@annotation,\n        molecularProfiles=cSet@molecularProfiles,\n        sample=cSet@sample,\n        treatment=cSet@treatment,\n        datasetType=cSet@datasetType,\n        treatmentResponse=cSet@treatmentResponse,\n        perturbation=cSet@perturbation,\n        curation=cSet@curation\n    )\n    if (verify) { checkRSetStructure(rSet)}\n    if (length(sensitivityN) == 0 && datasetType %in% c(\"sensitivity\", \"both\")) {\n      sensNumber(rSet) <- .summarizeSensitivityNumbers(rSet)\n    }\n    if (length(perturbationN) == 0  && datasetType %in% c(\"perturbation\", \"both\")) {\n      pertNumber(rSet) <- .summarizePerturbationNumbers(rSet)\n    }\n    return(rSet)\n}"
      },
      {
        "partial": "checkRSetStructure <- function(object, plotDist=FALSE, result.dir=tempdir()) {\n    if(!file.exists(result.dir) & plotDist) { dir.create(result.dir, showWarnings=FALSE, recursive=TRUE) }\n\n    for( i in seq_along(molecularProfilesSlot(object))) {\n      profile <- molecularProfilesSlot(object)[[i]]\n      nn <- names(molecularProfilesSlot(object))[i]\n\n      if((S4Vectors::metadata(profile)$annotation == \"rna\" | S4Vectors::metadata(profile)$annotation == \"rnaseq\") & plotDist)\n      {\n        pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n        hist(assays(profile)[[1]], breaks = 100)\n        dev.off()\n      }\n\n      warning(ifelse(nrow(rowData(profile)) != nrow(assays(profile)[[1]]),\n                     sprintf(\"%s: number of features in fData is different from\n                             SummarizedExperiment slots\", nn),\n                     sprintf(\"%s: rowData dimension is OK\", nn)\n      ))\n      warning(ifelse(nrow(colData(profile)) != ncol(assays(profile)[[1]]),\n                     sprintf(\"%s: number of cell lines in pData is different\n                             from expression slots\", nn),\n                     sprintf(\"%s: colData dimension is OK\", nn)\n      ))\n\n      warning(ifelse(\"sampleid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: sampleid does not exist in colData (samples)\n                             columns\", nn)))\n      warning(ifelse(\"batchid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: batchid does not exist in colData (samples)\n                             columns\", nn)))\n\n      if(S4Vectors::metadata(profile)$annotation == \"rna\" |\n         S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n      {\n        warning(ifelse(\"BEST\" %in% colnames(rowData(profile)), \"BEST is OK\",\n                       sprintf(\"%s: BEST does not exist in rowData (features)\n                               columns\", nn)))\n        warning(ifelse(\"Symbol\" %in% colnames(rowData(profile)), \"Symbol is OK\",\n                       sprintf(\"%s: Symbol does not exist in rowData (features)\n                               columns\", nn)))\n      }\n\n      if(\"sampleid\" %in% colnames(rowData(profile))) {\n        if(!all(colData(profile)[,\"sampleid\"] %in% rownames(sampleInfo(object)))) {\n          warning(sprintf(\"%s: not all the cell lines in this profile are in\n                          cell lines slot\", nn))\n        }\n      }else {\n        warning(sprintf(\"%s: sampleid does not exist in colData (samples)\", nn))\n      }\n    }\n\n    # Complete the function here",
        "complete": "checkRSetStructure <- function(object, plotDist=FALSE, result.dir=tempdir()) {\n    if(!file.exists(result.dir) & plotDist) { dir.create(result.dir, showWarnings=FALSE, recursive=TRUE) }\n\n    for( i in seq_along(molecularProfilesSlot(object))) {\n      profile <- molecularProfilesSlot(object)[[i]]\n      nn <- names(molecularProfilesSlot(object))[i]\n\n      if((S4Vectors::metadata(profile)$annotation == \"rna\" | S4Vectors::metadata(profile)$annotation == \"rnaseq\") & plotDist)\n      {\n        pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n        hist(assays(profile)[[1]], breaks = 100)\n        dev.off()\n      }\n\n      warning(ifelse(nrow(rowData(profile)) != nrow(assays(profile)[[1]]),\n                     sprintf(\"%s: number of features in fData is different from\n                             SummarizedExperiment slots\", nn),\n                     sprintf(\"%s: rowData dimension is OK\", nn)\n      ))\n      warning(ifelse(nrow(colData(profile)) != ncol(assays(profile)[[1]]),\n                     sprintf(\"%s: number of cell lines in pData is different\n                             from expression slots\", nn),\n                     sprintf(\"%s: colData dimension is OK\", nn)\n      ))\n\n      warning(ifelse(\"sampleid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: sampleid does not exist in colData (samples)\n                             columns\", nn)))\n      warning(ifelse(\"batchid\" %in% colnames(colData(profile)), \"\",\n                     sprintf(\"%s: batchid does not exist in colData (samples)\n                             columns\", nn)))\n\n      if(S4Vectors::metadata(profile)$annotation == \"rna\" |\n         S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n      {\n        warning(ifelse(\"BEST\" %in% colnames(rowData(profile)), \"BEST is OK\",\n                       sprintf(\"%s: BEST does not exist in rowData (features)\n                               columns\", nn)))\n        warning(ifelse(\"Symbol\" %in% colnames(rowData(profile)), \"Symbol is OK\",\n                       sprintf(\"%s: Symbol does not exist in rowData (features)\n                               columns\", nn)))\n      }\n\n      if(\"sampleid\" %in% colnames(rowData(profile))) {\n        if(!all(colData(profile)[,\"sampleid\"] %in% rownames(sampleInfo(object)))) {\n          warning(sprintf(\"%s: not all the cell lines in this profile are in\n                          cell lines slot\", nn))\n        }\n      }else {\n        warning(sprintf(\"%s: sampleid does not exist in colData (samples)\", nn))\n      }\n    }\n\n    if(\"tissueid\" %in% colnames(sampleInfo(object))) {\n      if(\"unique.tissueid\" %in% colnames(curation(object)$tissue))\n      {\n        if(length(intersect(rownames(curation(object)$tissue), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n          message(\"rownames of curation tissue slot should be the same as cell slot (curated cell ids)\")\n        } else{\n          if(length(intersect(sampleInfo(object)$tissueid, curation(object)$tissue$unique.tissueid)) != length(table(sampleInfo(object)$tissueid))){\n            message(\"tissueid should be the same as unique tissue id from tissue curation slot\")\n          }\n        }\n      } else {\n        message(\"unique.tissueid which is curated tissue id across data set should be a column of tissue curation slot\")\n      }\n      if(any(is.na(sampleInfo(object)[,\"tissueid\"]) | sampleInfo(object)[,\"tissueid\"]==\"\", na.rm=TRUE)){\n        message(sprintf(\"There is no tissue type for this cell line(s): %s\", paste(rownames(sampleInfo(object))[which(is.na(sampleInfo(object)[,\"tissueid\"]) | sampleInfo(object)[,\"tissueid\"]==\"\")], collapse=\" \")))\n      }\n    } else {\n      warning(\"tissueid does not exist in cell slot\")\n    }\n\n    if(\"unique.sampleid\" %in% colnames(curation(object)$sample)) {\n      if(length(intersect(curation(object)$sample$unique.sampleid, rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n        message(\"rownames of cell slot should be curated cell ids\")\n      }\n    } else {\n      message(\"unique.sampleid which is curated cell id across data set should be a column of cell curation slot\")\n    }\n\n    if(length(intersect(rownames(curation(object)$sample), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n      message(\"rownames of curation cell slot should be the same as cell slot (curated cell ids)\")\n    }\n\n    if(length(intersect(rownames(curation(object)$sample), rownames(sampleInfo(object)))) != nrow(sampleInfo(object))) {\n      message(\"rownames of curation radiation slot should be the same as radiation slot (curated radiation ids)\")\n    }\n\n    if(!is(sampleInfo(object), \"data"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/utilities.R",
    "language": "R",
    "content": "# rSet molecularProfiles from ESets to SEs\n#\n# Converts all ExpressionSet objects within the molecularProfiles slot of a\n#  RadioSet to SummarizedExperiments\n#\n# @param rSet \\code{S4} A RadioSet containing molecular data in ExpressionSets\n#\n# @return \\code{S4} A RadioSet containing molecular data in a SummarizedExperiments\n#\n#' @importFrom SummarizedExperiment assay assays assayNames\n#' @importClassesFrom SummarizedExperiment SummarizedExperiment Assays\n#' @importFrom Biobase exprs fData pData annotation protocolData assayData experimentData\n#' @importFrom S4Vectors SimpleList DataFrame\n#' @importFrom stats setNames\n#' @export\n#' @keywords internal\n.convertRsetMolecularProfilesToSE <- function(rSet) {\n\n  eSets <- molecularProfilesSlot(rSet) # Extract eSet data\n\n  molecularProfilesSlot(rSet) <-\n    lapply(eSets,\n           function(eSet){\n\n             # Change rownames from probes to EnsemblGeneId for rna data type\n             if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n               rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n             }\n\n             # Build summarized experiment from eSet\n             SE <- SummarizedExperiment::SummarizedExperiment(\n               ## TODO:: Do we want to pass an environment for better memory efficiency?\n               assays=SimpleList(as.list(Biobase::assayData(eSet))\n               ),\n               # Switch rearrange columns so that IDs are first, probes second\n               rowData=S4Vectors::DataFrame(Biobase::fData(eSet),\n                                            rownames=rownames(Biobase::fData(eSet))\n               ),\n               colData=S4Vectors::DataFrame(Biobase::pData(eSet),\n                                            rownames=rownames(Biobase::pData(eSet))\n               ),\n               metadata=list(\"experimentData\" = eSet@experimentData,\n                             \"annotation\" = Biobase::annotation(eSet),\n                             \"protocolData\" = Biobase::protocolData(eSet)\n               )\n             )\n             ## TODO:: Determine if this can be done in the SE constructor?\n             # Extract names from expression set\n             SummarizedExperiment::assayNames(SE) <- Biobase::assayDataElementNames(eSet)\n             # Assign SE to rSet\n             mDataType <- Biobase::annotation(eSet)\n             molecularProfilesSlot(rSet)[[mDataType]] <- SE\n           })\n  setNames(molecularProfilesSlot(rSet), names(eSets))\n  rSet\n}\n\n## Validate rSet molecularProfiles Conversion\n##\n## Checks that all the information contained in an ExpressionSet molecularProfile\n##   was successfully tranferred to the SummarizedExperiment molecularProfile\n##\n## @param rSet_new \\code{S4} a rSet containing molecularProfiles as SummarizedExperiments\n## @param rSet_old \\code{S4} a rSet containing molecularProfiles as ExpressionSets\n##\n## @return \\code{message} Any slots which are not the same\n##\n#' @importFrom assertthat are_equal\n#' @importFrom SummarizedExperiment SummarizedExperiment Assays assay\n#'   assayNames assayNames<-\n#' @importFrom Biobase exprs fData pData annotation protocolData\n#'   assayDataElementNames experimentData assayData\n#' @keywords internal\n.validateRsetMolecularProfilesToSEConversion <- function(rSet_old, rSet_new) {\n\n  # Testing that rSets are in correct order\n  message(\"Checking is rSet structures are correct\")\n\n  if(!all(vapply(rSet_old@molecularProfiles,\n                 function(x) { is(x, \"ExpressionSet\") }, FUN.VALUE = logical(1)))\n  ) message(\"Old rSet doesn't contain ExpressionSet objects, maybe argument order is wrong?\")\n\n  if(\n    !all(vapply(molecularProfilesSlot(rSet_new),\n                function(x) { is(x, \"SummarizedExperiment\") }, FUN.VALUE = logical(1)))\n  ) message(\"New rSet doesn't contain SummarizedExperiment objects, maybe argument order is wrong?\")\n\n  # Comparing molecularProfiles slot data\n  message(\"Checking molecularProfiles slots hold equivalent data.\")\n\n  for (i in seq_len(length(rSet_old@molecularProfiles))) {\n    for (j in seq_along(assays(molecularProfilesSlot(rSet_new)[[i]]))) {\n      if(!all(\n          as.list(assayData(rSet_old@molecularProfiles[[i]]))[[j]],\n            assay(molecularProfilesSlot(rSet_new)[[i]], j),\n          na.rm = TRUE)) message(\"The assay data is not equivalent\")\n    }\n  }\n  ## TODO:: Rewrite this as an apply statement\n  for (i in seq_len(length(rSet_old@molecularProfiles))) { # Have to compare like this due to NAs in data\n    # Checking phenoData\n    if(\n      !(if (nrow(pData(rSet_old@molecularProfiles[[i]])) > 0) {\n        all(\n          as(rSet_old@molecularProfiles[[i]]@phenoData, \"data.frame\") ==\n            as.data.frame(molecularProfilesSlot(rSet_new)[[i]]@colData[\n              seq_len(length(molecularProfilesSlot(rSet_new)[[i]]@colData) -1)]),\n          na.rm = TRUE)\n      } else { FALSE })\n    ) message(\"The phenoData is not equivalent\")\n    # Checking featureData\n    if(\n      !(if (nrow(fData(rSet_old@molecularProfiles[[i]])) > 0) {\n        all(\n          as(rSet_old@molecularProfiles[[i]]@featureData, \"data.frame\") ==\n            as.data.frame(molecularProfilesSlot(rSet_new)[[i]]@elementMetadata[\n              seq_len(length(molecularProfilesSlot(rSet_new)[[i]]@elementMetadata) - 1)]),\n          na.rm = TRUE)\n      } else { FALSE })\n    ) message(\"The featureData is not equivalent\")\n    # Checking protocolData\n    if(\n      !all(\n        as(rSet_old@molecularProfiles[[i]]@protocolData, \"data.frame\") ==\n          as(molecularProfilesSlot(rSet_new)[[i]]@metadata$protocolData, \"data.frame\"),\n        na.rm = TRUE)\n      ) message(\"The protocolData is not equivalent\")\n  }\n\n  if(!assertthat::are_equal(\n    lapply(rSet_old@molecularProfiles, function(x) { annotation(x) }),\n    lapply(molecularProfilesSlot(rSet_new), function(x) { metadata(x)$annotation }))\n  )  message(\"The annotation is not equivalent\")\n\n  if(!assertthat::are_equal(\n    lapply(rSet_old@molecularProfiles, function(x) { experimentData(x) }),\n    lapply(molecularProfilesSlot(rSet_new), function(x) { metadata(x)$experimentData })\n    )\n  ) message(\"The experimentData is not equivalent\")\n\n  # Comparing remainder of rSet slots; should not be affect by conversion\n  message(\"Comparing remainder of rSet slots\")\n\n  if (!assertthat::are_equal(rSet_old@annotation, rSet_new@annotation))\n    message(\"annotation slots not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@sample, rSet_new@sample))\n    message(\"cell slots are not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@radiation, rSet_new@radiation))\n    message(\"radiation slots are not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@treatmentResponse, treatmentResponse(rSet_new)))\n    message(\"sensitivty slots are not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@datasetType, datasetType(rSet_new)))\n    message(\"datasetType slots are not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@perturbation, rSet_new@perturbation))\n    message(\"perturbation slots are not equal!\")\n\n  if (!assertthat::are_equal(rSet_old@curation, rSet_new@curation))\n    message(\"curation slots are not equal\")\n}",
    "qa_pairs": [
      {
        "question": "What is the main purpose of the `.convertRsetMolecularProfilesToSE` function?",
        "answer": "The main purpose of the `.convertRsetMolecularProfilesToSE` function is to convert all ExpressionSet objects within the molecularProfiles slot of a RadioSet to SummarizedExperiments. It takes a RadioSet containing molecular data in ExpressionSets as input and returns a RadioSet with molecular data in SummarizedExperiments."
      },
      {
        "question": "How does the function handle RNA data types when converting from ExpressionSet to SummarizedExperiment?",
        "answer": "For RNA data types (identified by the annotation starting with 'rna'), the function changes the rownames from probes to EnsemblGeneId. This is done by assigning `Biobase::fData(eSet)$EnsemblGeneId` to the rownames of the ExpressionSet before converting it to a SummarizedExperiment."
      },
      {
        "question": "What is the purpose of the `.validateRsetMolecularProfilesToSEConversion` function and how does it work?",
        "answer": "The `.validateRsetMolecularProfilesToSEConversion` function checks that all the information contained in an ExpressionSet molecularProfile was successfully transferred to the SummarizedExperiment molecularProfile. It compares various components of the old and new RadioSets, including assay data, phenoData, featureData, protocolData, annotation, and experimentData. If any discrepancies are found, it outputs messages indicating which parts are not equivalent."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Convert ExpressionSet to SummarizedExperiment\n.convertRsetMolecularProfilesToSE <- function(rSet) {\n  eSets <- molecularProfilesSlot(rSet)\n  molecularProfilesSlot(rSet) <- lapply(eSets, function(eSet) {\n    if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n      rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n    }\n    SE <- SummarizedExperiment::SummarizedExperiment(\n      assays = SimpleList(as.list(Biobase::assayData(eSet))),\n      rowData = S4Vectors::DataFrame(Biobase::fData(eSet), rownames = rownames(Biobase::fData(eSet))),\n      colData = S4Vectors::DataFrame(Biobase::pData(eSet), rownames = rownames(Biobase::pData(eSet))),\n      metadata = list(\n        \"experimentData\" = eSet@experimentData,\n        \"annotation\" = Biobase::annotation(eSet),\n        \"protocolData\" = Biobase::protocolData(eSet)\n      )\n    )\n    SummarizedExperiment::assayNames(SE) <- Biobase::assayDataElementNames(eSet)\n    # Complete the function by adding the missing line\n  })\n  setNames(molecularProfilesSlot(rSet), names(eSets))\n  rSet\n}",
        "complete": "# Convert ExpressionSet to SummarizedExperiment\n.convertRsetMolecularProfilesToSE <- function(rSet) {\n  eSets <- molecularProfilesSlot(rSet)\n  molecularProfilesSlot(rSet) <- lapply(eSets, function(eSet) {\n    if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n      rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n    }\n    SE <- SummarizedExperiment::SummarizedExperiment(\n      assays = SimpleList(as.list(Biobase::assayData(eSet))),\n      rowData = S4Vectors::DataFrame(Biobase::fData(eSet), rownames = rownames(Biobase::fData(eSet))),\n      colData = S4Vectors::DataFrame(Biobase::pData(eSet), rownames = rownames(Biobase::pData(eSet))),\n      metadata = list(\n        \"experimentData\" = eSet@experimentData,\n        \"annotation\" = Biobase::annotation(eSet),\n        \"protocolData\" = Biobase::protocolData(eSet)\n      )\n    )\n    SummarizedExperiment::assayNames(SE) <- Biobase::assayDataElementNames(eSet)\n    molecularProfilesSlot(rSet)[[Biobase::annotation(eSet)]] <- SE\n  })\n  setNames(molecularProfilesSlot(rSet), names(eSets))\n  rSet\n}"
      },
      {
        "partial": "# Validate rSet molecularProfiles Conversion\n.validateRsetMolecularProfilesToSEConversion <- function(rSet_old, rSet_new) {\n  message(\"Checking if rSet structures are correct\")\n  if (!all(vapply(rSet_old@molecularProfiles, function(x) is(x, \"ExpressionSet\"), logical(1)))) {\n    message(\"Old rSet doesn't contain ExpressionSet objects, maybe argument order is wrong?\")\n  }\n  if (!all(vapply(molecularProfilesSlot(rSet_new), function(x) is(x, \"SummarizedExperiment\"), logical(1)))) {\n    message(\"New rSet doesn't contain SummarizedExperiment objects, maybe argument order is wrong?\")\n  }\n  message(\"Checking molecularProfiles slots hold equivalent data.\")\n  # Add the missing validation checks here\n  \n  message(\"Comparing remainder of rSet slots\")\n  if (!assertthat::are_equal(rSet_old@annotation, rSet_new@annotation)) message(\"annotation slots not equal!\")\n  if (!assertthat::are_equal(rSet_old@sample, rSet_new@sample)) message(\"cell slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@radiation, rSet_new@radiation)) message(\"radiation slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@treatmentResponse, treatmentResponse(rSet_new))) message(\"sensitivity slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@datasetType, datasetType(rSet_new))) message(\"datasetType slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@perturbation, rSet_new@perturbation)) message(\"perturbation slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@curation, rSet_new@curation)) message(\"curation slots are not equal\")\n}",
        "complete": "# Validate rSet molecularProfiles Conversion\n.validateRsetMolecularProfilesToSEConversion <- function(rSet_old, rSet_new) {\n  message(\"Checking if rSet structures are correct\")\n  if (!all(vapply(rSet_old@molecularProfiles, function(x) is(x, \"ExpressionSet\"), logical(1)))) {\n    message(\"Old rSet doesn't contain ExpressionSet objects, maybe argument order is wrong?\")\n  }\n  if (!all(vapply(molecularProfilesSlot(rSet_new), function(x) is(x, \"SummarizedExperiment\"), logical(1)))) {\n    message(\"New rSet doesn't contain SummarizedExperiment objects, maybe argument order is wrong?\")\n  }\n  message(\"Checking molecularProfiles slots hold equivalent data.\")\n  for (i in seq_along(rSet_old@molecularProfiles)) {\n    for (j in seq_along(assays(molecularProfilesSlot(rSet_new)[[i]]))) {\n      if (!all(as.list(assayData(rSet_old@molecularProfiles[[i]]))[[j]] == assay(molecularProfilesSlot(rSet_new)[[i]], j), na.rm = TRUE)) {\n        message(\"The assay data is not equivalent\")\n      }\n    }\n    if (nrow(pData(rSet_old@molecularProfiles[[i]])) > 0 && !all(as(rSet_old@molecularProfiles[[i]]@phenoData, \"data.frame\") == as.data.frame(molecularProfilesSlot(rSet_new)[[i]]@colData[seq_len(length(molecularProfilesSlot(rSet_new)[[i]]@colData) - 1)]), na.rm = TRUE)) {\n      message(\"The phenoData is not equivalent\")\n    }\n    if (nrow(fData(rSet_old@molecularProfiles[[i]])) > 0 && !all(as(rSet_old@molecularProfiles[[i]]@featureData, \"data.frame\") == as.data.frame(molecularProfilesSlot(rSet_new)[[i]]@elementMetadata[seq_len(length(molecularProfilesSlot(rSet_new)[[i]]@elementMetadata) - 1)]), na.rm = TRUE)) {\n      message(\"The featureData is not equivalent\")\n    }\n    if (!all(as(rSet_old@molecularProfiles[[i]]@protocolData, \"data.frame\") == as(molecularProfilesSlot(rSet_new)[[i]]@metadata$protocolData, \"data.frame\"), na.rm = TRUE)) {\n      message(\"The protocolData is not equivalent\")\n    }\n  }\n  if (!assertthat::are_equal(lapply(rSet_old@molecularProfiles, annotation), lapply(molecularProfilesSlot(rSet_new), function(x) metadata(x)$annotation))) {\n    message(\"The annotation is not equivalent\")\n  }\n  if (!assertthat::are_equal(lapply(rSet_old@molecularProfiles, experimentData), lapply(molecularProfilesSlot(rSet_new), function(x) metadata(x)$experimentData))) {\n    message(\"The experimentData is not equivalent\")\n  }\n  message(\"Comparing remainder of rSet slots\")\n  if (!assertthat::are_equal(rSet_old@annotation, rSet_new@annotation)) message(\"annotation slots not equal!\")\n  if (!assertthat::are_equal(rSet_old@sample, rSet_new@sample)) message(\"cell slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@radiation, rSet_new@radiation)) message(\"radiation slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@treatmentResponse, treatmentResponse(rSet_new))) message(\"sensitivity slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@datasetType, datasetType(rSet_new))) message(\"datasetType slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@perturbation, rSet_new@perturbation)) message(\"perturbation slots are not equal!\")\n  if (!assertthat::are_equal(rSet_old@curation, rSet_new@curation)) message(\"curation slots are not equal\")\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utils-optimization.R",
    "language": "R",
    "content": "#' Curve fitting via `stats::optim` L-BFGS-B with fall-back grid/pattern search\n#'   if convergence is not achieved.\n#'\n#' @description Function to fit curve via stats::optim\n#'\n#' @param par `numeric` Vector of intial guesses for the parameters. For each\n#'    index `i` of `par`, par\\[i\\] must be within the range (`lower\\[i\\]`,\n#'   `upper\\[i\\]`). If only a single `upper` or `lower` value is present,\n#'   that range is used for all parameters in `par`.\n#' @param x `numeric` Values to evaluate `fn` for.\n#' @param y `numeric` Target output values to optimze `fn` against.\n#' @param fn `function` A function to optimize. Any `fn` arguments passed via\n#'   `...` will be treated as constant and removed from the optimization. It\n#'   is assumed that the first argument is the x value to optimize over and\n#'   any subsequent arguments are free parameters to be optimized. Transformed\n#'   to be optim compatible via `make_optim_function` is the first arguement\n#'   isn't already `par`.\n#' @param loss `character(1)` or `function` Either the name of one of the bundled\n#'   loss functions (see details) or a custom loss function to compute for\n#'   the output of `fn` over `x`.\n#' @param lower `numeric(1)` Lower bound for parameters. Parallel to `par`.\n#' @param upper `numeric(1)` Upper bound for paramteres. Parallel to `par`.\n#' @param density `numeric` how many points in the dimension of each parameter\n#'   should be evaluated (density of the grid)\n#' @param step initial step size for pattern search.\n#' @param precision `numeric` smallest step size used in pattern search, once\n#'   step size drops below this value, the search terminates.\n#' @param span `numeric` Can be safely kept at 1, multiplicative ratio for\n#'   initial step size in pattern search. Must be larger than precision.\n#' @param ... `pairlist` Fall through arguments to `fn`.\n#' @param loss_args `list` Additional argument to the `loss` function.\n#'   These get passed to losss via `do.call` analagously to using `...`.\n#' @param optim_only `logical(1)` Should the fall back methods when optim fails\n#'   be skipped? Default is `FALSE`.\n#' @param control `list` List of control parameters to pass to `optim`. See\n#'   `?optim` for details.\n#'\n#' @examples\n#' \\dontrun{\n#'   # Four parameter hill curve equation\n#'   hillEqn <- function(x, Emin, Emax, EC50, lambda) {\n#'       (Emin + Emax * (x / EC50)^lambda) / (1 + (x / EC50)^lambda)\n#'   }\n#'   # Make some dummy data\n#'   doses <- rev(1000 / (2^(1:20)))\n#'   lambda <- 1\n#'   Emin <- 1\n#'   Emax <- 0.1\n#'   EC50 <- median(doses)\n#'   response <- hillEqn(doses, Emin=Emin, lambda=lambda, Emax=Emax, EC50=EC50)\n#'   nresponse <- response + rnorm(length(response), sd=sd(response)*0.1) # add noise\n#'   # 3-parameter optimization\n#'   3par <- .fitCurve2(\n#'       par=c(Emax, EC50, lambda),\n#'       x=doses,\n#'       y=nresponse,\n#'       fn=hillEqn,\n#'       Emin=Emin, # set this as constant in the function being optimized (via ...)\n#'       loss=.normal_loss,\n#'       loss_args=list(trunc=FALSE, n=1, scale=0.07),\n#'       upper=c(1, max(doses), 6),\n#'       lower=c(0, min(doses), 0)\n#'   )\n#'   # 2-parameter optimization\n#'   2par <- .fitCurve2(\n#'       par=c(Emax, EC50),\n#'       x=doses,\n#'       y=nresponse,\n#'       fn=hillEqn,\n#'       Emin=Emin, # set this as constant in the function being optimized (via ...)\n#'       lambda=1,\n#'       loss=.normal_loss,\n#'       loss_args=list(trunc=FALSE, n=1, scale=0.07),\n#'       upper=c(1, max(doses)),\n#'       lower=c(0, min(doses))\n#'   )\n#' }\n#'\n#' @details\n#' TODO\n#'\n#' @return `numeric` Vector of optimal parameters for `fn` fit against `y`\n#'   on the values of `x`.\n#'\n#' @importFrom stats optim\n#' @export\n.fitCurve2 <- function(par, x, y, fn, loss, lower=-Inf, upper=Inf,\n        precision=1e-4, density=c(2, 10, 5), step= 0.5 / density, ...,\n        loss_args=list(), span=1, optim_only=FALSE,\n        control=list(factr=1e-08, ndeps=rep(1e-4, times=length(par)), trace = 0)\n        ) {\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    stopifnot(\n        (length(par) == length(upper) && length(par) == length(lower)) ||\n        (length(upper) == 1 && length(lower) == 1)\n    )\n    stopifnot(span > precision)\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n    guess <- optim(\n        par=par,\n        fn=function(p)\n            do.call(loss,\n                args=c(\n                    list(par=p, x=x, y=y, fn=optim_fn), # mandatory loss args\n                    loss_args # additional args to loss\n                )\n            ),\n        upper=upper,\n        lower=lower,\n        control=control,\n        method=\"L-BFGS-B\"\n    )\n\n    failed <- guess[[\"convergence\"]] != 0\n    if (failed) guess <- list(par=par, convergence=(-1))\n    guess <- guess[[\"par\"]]\n\n    guess_residual <- do.call(loss,\n        args=c(list(par=guess, x=x, y=y, fn=optim_fn), loss_args))\n    gritty_guess_residual <- do.call(loss,\n        args=c(list(par=par, x=x, y=y, fn=optim_fn), loss_args))\n\n    if (\n        (failed || any(is.na(guess)) || guess_residual >= gritty_guess_residual)\n        && !optim_only\n    ) {\n        guess <- .meshEval2(density=density, par=guess, x=x, y=y, fn=optim_fn,\n            lower=lower, upper=upper, ..., loss=loss,loss_args=loss_args)\n        guess_residual <- do.call(loss,\n            args=c(list(par=guess, x=x, y=y, fn=optim_fn), loss_args))\n\n        guess <- .patternSearch2(span=span, precision=precision, step=step,\n            par=guess, par_residual=guess_residual, x=x, y=y, fn=optim_fn,\n            loss=loss, lower=lower, upper=upper, ..., loss_args=loss_args)\n    }\n\n    y_hat <- optim_fn(par=guess, x=x)\n\n    Rsqr <- 1 - (var(y - y_hat) / var(y))\n    attr(guess, \"Rsquare\") <- Rsqr\n\n    return(guess)\n}\n\n\n#' Compute the loss using the expectation of the likelihood of the median\n#'   for N samples from a probability density function.\n#'\n#' @param .pdf `function` Probability density function to use for computing loss.\n#' @param .edf `function` Expected likelihood function for the median of `n`\n#'   random samples from `.pdf`.\n#' @inheritParams .fitCurve2\n#' @param n `numeric(1)`\n#' @param scale `numeric(1)`\n#' @param trunc `logical(1)`\n#'\n#' @return `numeric(1)` Loss of `fn` on `x` relative to `y`.\n#'\n#' @keywords interal\n#' @noRd\n.sampling_loss <- function(.pdf, .edf, par, x, y, fn, ..., n=1, scale=0.07,\n        trunc=FALSE) {\n    diffs <- fn(par=par, x=x, ...) - y\n    if (trunc == FALSE) {\n        if (n == 1 && grepl(\"normals\", deparse(substitute(.pdf))))\n            return(sum(diffs^2))\n        return(sum(-log(.pdf(diffs, n, scale))))\n    } else {\n        down_truncated <- abs(y) >= 1\n        up_truncated <- abs(y) <= 0\n        return(\n            sum(-log(.pdf(diffs[!(down_truncated | up_truncated)], n, scale))) +\n            sum(-log(.edf(-diffs[up_truncated | down_truncated], n, scale)))\n        )\n    }\n}\n\n\n#' See docs for `.sampling_loss`\n#' @keywords interal\n#' @noRd\n.normal_loss <- function(par, x, y, fn, ..., n=1, scale=0.07,\n        trunc=FALSE) {\n    .sampling_loss(.pdf=.dmednnormals, .edf=.edmednnormals, par=par, x=x, y=y,\n        fn=fn, ..., n=n, scale=scale, trunc=trunc)\n}\n\n\n\n#' See docs for `.sampling_loss`\n#' @keywords internal\n#' @noRd\n.cauchy_loss <- function(par, x, y, fn, ..., n=1, scale=0.07,\n        trunc=FALSE) {\n    .sampling_loss(.pdf=.dmedncauchys, .edf=.edmedncauchys, par=par, x=x, y=y,\n        fn=fn, ..., n=n, scale=scale, trunc=trunc)\n}\n\n#' @export\n#' @keywords internal\n#' @noRd\n.meshEval2 <- function(density, par, x, y, fn,\n        loss=.normal_loss, lower, upper, ..., loss_args=list()) {\n    # input validation\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    # make function amenable to use via optim\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n    par_loss <- do.call(loss,\n        args=c(list(par=par, x=x, y=y, fn=optim_fn), loss_args))\n\n    periods <- matrix(NA, nrow = length(par), ncol = 1)\n    names(periods) <- names(par)\n    periods[1] <- 1\n\n    if (length(par) > 1) {\n        for (p in seq(2, length(par))) {\n            ## the par-1 is because we want 1 increment of par variable once\n            ##   all previous variables have their values tested once.\n            periods[p] <- periods[p - 1] * (density[p - 1] *\n                (upper[p - 1] - lower[p - 1]) + 1)\n        }\n    }\n\n    currentPars <- lower\n\n    ## The plus one is because we include endpoints.\n    for (point in seq_len(prod((upper - lower) * density + 1))) {\n\n        test_par_loss <- do.call(loss,\n            c(list(par=currentPars, x=x, y=y, fn=optim_fn), loss_args))\n\n        ## Check for something catastrophic going wrong\n        if (\n            !length(test_par_loss) ||\n            (!is.finite(test_par_loss) && test_par_loss != Inf)\n        ) {\n            stop(paste0(\" Test Guess Loss is: \", test_par_loss, \"\\n\",\n                \"Other Pars:\\n\", \"x: \", paste(x, collapse = \", \"), \"\\n\",\n                \"y: \", paste(y, collapse = \", \"), \"\\n\", \"n: \", n, \"\\n\",\n                \"pars: \", currentPars, \"\\n\", \"scale: \", scale, \"\\n\",\n                \"family : \", family, \"\\n\", \"Trunc \", trunc))\n        }\n        ## save the guess if its an improvement\n        if (test_par_loss < par_loss) {\n            par <- currentPars\n            par_loss <- test_par_loss\n        }\n        ## increment the variable(s) that should be incremented this loop\n        for (p in seq_along(par)) {\n            if (point %% periods[p] == 0) {\n                currentPars[p] <- currentPars[p] + 1 / density[p]\n                if (currentPars[p] > upper[p]) {\n                    currentPars[p] <- lower[p]\n                }\n            }\n        }\n    }\n\n    return(par)\n}\n\n\n#' @export\n#' @keywords internal\n#' @noRd\n.patternSearch2 <- function(span, precision, step, par, par_residual, x, y,\n        lower, upper, fn, loss, ..., loss_args=list()) {\n    # input validation\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    # make function amenable to use via optim\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n    # setup matrix for searching the parameter space\n    neighbours <- matrix(nrow = 2 * length(par), ncol = length(par))\n    neighbour_loss <- matrix(NA, nrow = 1, ncol = nrow(neighbours))\n\n    while (span > precision) {\n        for (neighbour in seq_len(nrow(neighbours))) {\n            neighbours[neighbour, ] <- par\n            dimension <- ceiling(neighbour / 2)\n            if (neighbour %% 2 == 1) {\n                neighbours[neighbour, dimension] <- pmin(\n                    par[dimension] + span * step[dimension],\n                    upper[dimension]\n                )\n            } else {\n                neighbours[neighbour, dimension] <- pmax(\n                    par[dimension] - span * step[dimension],\n                    lower[dimension]\n                )\n            }\n\n            neighbour_loss[neighbour] <- do.call(loss, args=c(\n                list(par=neighbours[neighbour, ], x=x, y=y, fn=optim_fn),\n                    loss_args))\n        }\n\n        if (min(neighbour_loss) < par_residual) {\n            par <- neighbours[which.min(neighbour_loss)[1], ]\n            par_residual <- min(neighbour_loss)\n        } else {\n            span <- span / 2\n        }\n    }\n    return(par)\n}\n\n\n\n#' Drop parameters from a function and replace them with constants\n#'   inside the function body.\n#'\n#' @param fn `function` A non-primitive function to remove parameters from\n#'   (via `base::formals(fn)`).\n#' @param args `list` A list where names are the function arguments (parameters)\n#'   to remove and the values are the appopriate value to replace the parameter\n#'   with in the function body.\n#'\n#' @return `function` A new non-primitize function with the parameters named in\n#'   `args` deleted and their values fixed with the values from `args` in the\n#'   function body.\n#'\n#' @importFrom compiler cmpfun\n#' @export\ndrop_fn_params <- function(fn, args) {\n    stopifnot(is.function(fn) && !is.primitive(fn))\n    if (length(args) == 0) return(fn)\n    stopifnot(all(names(args) %in% formalArgs(fn)))\n    stopifnot(is.list(args))\n    # Delete the arguments we are deparamterizing\n    formals(fn)[formalArgs(fn) %in% names(args)] <- NULL\n    # Replace the symbols with the new fixed value inside the fuction body\n    deparse_body <- deparse(body(fn))\n    for (i in seq_along(args)) {\n        deparse_body <- gsub(names(args)[i], args[[i]], deparse_body)\n    }\n    # Parse the new function body back to a call\n    body(fn, envir=parent.frame()) <- str2lang(paste0(deparse_body, collapse=\"\\n\"))\n    fn <- compiler::cmpfun(fn)\n    return(fn)\n}\n\n#' Collects all function arguments other than the first into a single list\n#'   parameter.\n#'\n#' @description\n#' Useful for converting a regular function into a function amenable to\n#' optimization via `stats::optim`, which requires all free parameters be\n#' passed as a single vector `par`.\n#'\n#' @details\n#' Takes a function of the form f(x, ...), where ... is any number of additional\n#'   function parameters (bot not literal `...`!) and parses it to a function of\n#'   the form f(par, x) where `par` is a vector of values for ... in\n#'   the same order as the arguments appear in `fn`.\n#'\n#' @param fn `function` A non-primitive function to refactor such that the first\n#'   argument becomes the second argument and all other parameters must be\n#'   passed as a vector to the first argument of the new function via the `par`\n#'   parameter.\n#'\n#' @return `function` A new non-primitive function where the first argument is\n#'   `par`, which takes a vector of parameters being optimized, and the\n#'   second argument is the old first argument to `fn` (usually `x` since this\n#'   is the independent variable to optimize the function over).\n#'\n#' @export\ncollect_fn_params <- function(fn) {\n    stopifnot(is.function(fn) && !is.primitive(fn))\n    # Capture the current formal args\n    formal_args <- formalArgs(fn)\n    if (\"...\" %in% formalArgs(fn))\n        stop(\"No support for fn with ... in signature!\")\n    # Replace args other than the first with a list\n    args <- paste0(\"par[[\", seq_along(formal_args[-1]), \"]]\") |>\n        as.list() |>\n        setNames(formal_args[-1])\n    fn <- drop_fn_params(fn, args=args)\n    # Add the `par` list to the formal args of the function\n    formals(fn) <- c(alist(par=), formals(fn))\n    return(fn)\n}\n\n\n#' Takes a non-primitive R function and refactors it to be compatible with\n#'   optimization via `stats::optim`.\n#'\n#' @description Takes a non-primitive R function and refactors it to be compatible with optimization via `stats::optim`.\n#'\n#'\n#' @param fn `function` A non-primitive function\n#' @param ... Arguments to `fn` to fix for before building the\n#'   function to be optimized. Useful for reducing the number of free parameters\n#'   in an optimization if there are insufficient degrees of freedom.\n#'\n#' @seealso [`drop_fn_params`], [`collect_fn_params`]\n#'\n#' @export\nmake_optim_function <- function(fn, ...) {\n    # NOTE: error handling done inside helper methods!\n    fn1 <- drop_fn_params(fn, args=list(...))\n    fn2 <- collect_fn_params(fn1)\n    return(fn2)\n}\n\n\n#' Check whether a function signature is amenable to optimization via `stats::optim`.\n#'\n#' @description\n#' Functions compatible with `optim` have the parameter named `par` as their\n#' first formal argument where each value is a respective free parameter to\n#' be optimized.\n#'\n#' @param fn `function` A non-primitive function.\n#'\n#' @return `logical(1)` `TRUE` if the first value of `formalArg(fn)` is \"par\",\n#'   otherwise `FALSE`.\n#'\n#' @export\nis_optim_compatible <- function(fn) formalArgs(fn)[1] == \"par\"\n\n\n\n\n\n\n# ======================\n# ==== Deprecating =====\n\n#' .fitCurve\n#'\n#' Curve optimization from 1 variable to 1 variable, using L-BFSG-B from optim,\n#' with fallback to pattern search if optimization fails to converge.\n#'\n#' @param x `numeric` input/x values for function\n#' @param y `numeric` output/y values for function\n#' @param f `function` function f, parameterized by parameters to optimize\n#' @param density `numeric` how many points in the dimension of each parameter\n#'   should be evaluated (density of the grid)\n#' @param step initial step size for pattern search.\n#' @param precision `numeric` smallest step size used in pattern search, once\n#'   step size drops below this value, the search terminates.\n#' @param lower_bounds `numeric` lower bounds for the paramater search space\n#' @param upper_bounds `numeric` upper bounds for the parameter search space\n#' @param median_n `integer` number of technical replicates per measured point\n#'   in x. Used to evaluate the proper median distribution for the normal and\n#'   cauchy error models\n#' @param scale `numeric` scale on which to measure probability for the error\n#'   model (roughly SD of error)\n#' @param family `character` which error family to use. Currently, \"normal\"\n#'   and \"Cauchy\" are implemented\n#' @param trunc `logical` Whether or not to truncate the values at 100% (1.0)\n#' @param verbose `logical` should diagnostic messages be printed?\n#' @param gritty_guess `numeric` intitial, uninformed guess on parameter\n#'   values (usually heuristic)\n#' @param span ['numeric'] can be safely kept at 1, multiplicative ratio for\n#'   initial step size in pattern search. Must be larger than precision.\n#'\n#' @keywords internal\n#' @noRd\n#'\n#' @importFrom stats optim var\n#' @export\n.fitCurve <- function(x, y, f, density, step, precision, lower_bounds,\n    upper_bounds, scale, family, median_n, trunc, verbose, gritty_guess,\n    span = 1) {\n\n    guess <- tryCatch(optim(par = gritty_guess, fn = function(t) {\n        .residual(\n            x = x, y = y, n = median_n, pars = t, f = f,\n            scale = scale, family = family, trunc = trunc\n        )\n    }, lower = lower_bounds, upper = upper_bounds, control = list(\n        factr = 1e-08,\n        ndeps = rep(1e-4, times = length(gritty_guess)),\n        trace = 0\n    ), method = \"L-BFGS-B\"), error = function(e) {\n        list(par = gritty_guess, convergence = -1)\n    })\n\n    failed <- guess[[\"convergence\"]] != 0\n    guess <- guess[[\"par\"]]\n\n    guess_residual <- .residual(x = x, y = y, n = median_n, pars = guess, f = f, scale = scale, family = family, trunc = trunc)\n    gritty_guess_residual <- .residual(x = x, y = y, n = median_n, pars = gritty_guess, f = f, scale = scale, family = family, trunc = trunc)\n\n    if (failed || any(is.na(guess)) || guess_residual >= gritty_guess_residual) {\n        guess <- .meshEval(x = x, y = y, f = f, guess = gritty_guess, lower_bounds = lower_bounds, upper_bounds = upper_bounds, density = density,\n            n = median_n, scale = scale, family = family, trunc = trunc)\n        guess_residual <- .residual(x = x, y = y, n = median_n, pars = guess, f = f, scale = scale, family = family, trunc = trunc)\n\n        guess <- .patternSearch(x = x, y = y, f = f, guess = guess, n = median_n, guess_residual = guess_residual, lower_bounds = lower_bounds,\n            upper_bounds = upper_bounds, span = span, precision = precision, step = step, scale = scale, family = family, trunc = trunc)\n    }\n\n    y_hat <- do.call(f, list(x, par=guess))\n\n    Rsqr <- 1 - (var(y - y_hat) / var(y))\n    attr(guess, \"Rsquare\") <- Rsqr\n\n    return(guess)\n}\n\n\n\n# meshEval ----------------------------------------------------------------\n#' meshEval\n#'\n#' Generate an initial guess for dose-response curve parameters by evaluating\n#' the residuals at different lattice points of the search space\n#'\n#' @export\n#' @keywords internal\n#' @noRd\n# ##FIXME:: Why is this different in PharmacoGx?\n.meshEval <- function(x, y, f, guess, lower_bounds, upper_bounds, density, n,\n        scale, family, trunc) {\n    pars <- NULL\n    guess_residual <- .residual(x = x, y = y, n = n, pars = guess, f = f,\n        scale = scale, family = family, trunc = trunc)\n\n    periods <- matrix(NA, nrow = length(guess), ncol = 1)\n    names(periods) <- names(guess)\n    periods[1] <- 1\n\n    if (length(guess) > 1) {\n        for (par in 2:length(guess)) {\n            ## the par-1 is because we want 1 increment of par variable once all previous variables have their values tested once.\n            periods[par] <- periods[par - 1] * (density[par - 1] * (upper_bounds[par - 1] - lower_bounds[par - 1]) + 1)\n        }\n    }\n\n    currentPars <- lower_bounds\n\n    ## The plus one is because we include endpoints.\n    for (point in seq_len(prod((upper_bounds - lower_bounds) * density + 1))) {\n\n        test_guess_residual <- .residual(x = x, y = y, n = n, pars = currentPars, f = f, scale = scale, family = family, trunc = trunc)\n\n        ## Check for something catastrophic going wrong\n        if (!length(test_guess_residual) || (!is.finite(test_guess_residual) && test_guess_residual != Inf)) {\n            stop(paste0(\" Test Guess Residual is: \", test_guess_residual, \"\\n\", \"Other Pars:\\n\", \"x: \", paste(x, collapse = \", \"), \"\\n\",\n                \"y: \", paste(y, collapse = \", \"), \"\\n\", \"n: \", n, \"\\n\", \"pars: \", pars, \"\\n\", \"scale: \", scale, \"\\n\", \"family : \", family,\n                \"\\n\", \"Trunc \", trunc))\n        }\n        ## save the guess if its an improvement\n        if (test_guess_residual < guess_residual) {\n            guess <- currentPars\n            guess_residual <- test_guess_residual\n        }\n        ## increment the variable(s) that should be incremented this loop\n        for (par in seq_along(guess)) {\n            if (point%%periods[par] == 0) {\n                currentPars[par] <- currentPars[par] + 1/density[par]\n\n                if (currentPars[par] > upper_bounds[par]) {\n                    currentPars[par] <- lower_bounds[par]\n                }\n            }\n        }\n    }\n\n    return(guess)\n}\n\n#' @export\n#' @keywords internal\n#' @noRd\n.patternSearch <- function(x, y, f, guess, n, guess_residual, lower_bounds,\n        upper_bounds, span, precision, step, scale, family, trunc) {\n    neighbours <- matrix(nrow = 2 * length(guess), ncol = length(guess))\n    neighbour_residuals <- matrix(NA, nrow = 1, ncol = nrow(neighbours))\n\n    while (span > precision) {\n        for (neighbour in seq_len(nrow(neighbours))) {\n            neighbours[neighbour, ] <- guess\n            dimension <- ceiling(neighbour / 2)\n            if (neighbour %% 2 == 1) {\n                neighbours[neighbour, dimension] <- pmin(\n                    guess[dimension] + span * step[dimension],\n                    upper_bounds[dimension]\n                )\n            } else {\n                neighbours[neighbour, dimension] <- pmax(\n                    guess[dimension] - span * step[dimension],\n                    lower_bounds[dimension]\n                )\n            }\n\n            neighbour_residuals[neighbour] <- .residual(x = x, y = y,\n                f = f, pars = neighbours[neighbour, ], n = n, scale = scale,\n                family = family,\n                trunc = trunc)\n        }\n\n        if (min(neighbour_residuals) < guess_residual) {\n            guess <- neighbours[which.min(neighbour_residuals)[1], ]\n            guess_residual <- min(neighbour_residuals)\n        } else {\n            span <- span / 2\n        }\n    }\n    return(guess)\n}\n\n## TODO:: Write documentation\n## FIXME:: Why is this different from PharmacoGx?\n#' @title Residual calculation\n#'\n#' @return A \\code{numeric} containing the estimated residuals for the model\n#'   fit\n#'\n#' @export\n#' @keywords internal\n#' @noRd\n.residual <- function(x, y, n, pars, f, scale = 0.07, family = c(\"normal\", \"Cauchy\"), trunc = FALSE) {\n    family <- match.arg(family)\n    diffs <- f(x, par=pars) - y\n\n    if (family != \"Cauchy\") {\n        if (trunc == FALSE) {\n            if (n == 1) {\n                return(sum(diffs^2))\n            }\n            return(sum(-log(.dmednnormals(diffs, n, scale))))\n        } else {\n            down_truncated <- abs(y) >= 1\n            up_truncated <- abs(y) <= 0\n            return(sum(-log(.dmednnormals(diffs[!(down_truncated | up_truncated)], n, scale))) + sum(-log(.edmednnormals(-diffs[up_truncated |\n                down_truncated], n, scale))))\n        }\n    } else {\n        if (trunc == FALSE) {\n            return(sum(-log(.dmedncauchys(diffs, n, scale))))\n        } else {\n            down_truncated <- abs(y) >= 1\n            up_truncated <- abs(y) <= 0\n            return(sum(-log(.dmedncauchys(diffs[!(down_truncated | up_truncated)], n, scale))) + sum(-log(.edmedncauchys(-diffs[up_truncated |\n                down_truncated], n, scale))))\n        }\n    }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.fitCurve2` function and how does it handle optimization failures?",
        "answer": "The `.fitCurve2` function is designed to fit a curve using `stats::optim` with L-BFGS-B optimization. If convergence is not achieved, it falls back to grid/pattern search methods. It handles optimization failures by first attempting optimization with `optim`, and if that fails (convergence != 0), it uses `.meshEval2` for a grid search, followed by `.patternSearch2` for fine-tuning. This approach ensures robustness in curve fitting even when the initial optimization fails."
      },
      {
        "question": "How does the `make_optim_function` helper function transform a regular R function into one compatible with `stats::optim`?",
        "answer": "The `make_optim_function` helper transforms a regular R function into one compatible with `stats::optim` by performing two main steps: 1) It uses `drop_fn_params` to fix any constant parameters specified in the `...` argument. 2) It then applies `collect_fn_params` to restructure the function so that all remaining parameters are collected into a single `par` argument, which becomes the first argument of the new function. This transformation allows the function to be used with `optim`, which expects all parameters to be optimized to be passed as a single vector."
      },
      {
        "question": "What is the purpose of the `.sampling_loss` function and how does it relate to the `.normal_loss` and `.cauchy_loss` functions?",
        "answer": "The `.sampling_loss` function computes the loss using the expectation of the likelihood of the median for N samples from a probability density function. It's a generic function that can work with different probability distributions. The `.normal_loss` and `.cauchy_loss` functions are specific implementations of `.sampling_loss` for normal and Cauchy distributions respectively. They call `.sampling_loss` with the appropriate probability density function (`.dmednnormals` or `.dmedncauchys`) and expected likelihood function (`.edmednnormals` or `.edmedncauchys`) for their respective distributions. This design allows for flexible loss calculation with different error models."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Curve fitting via `stats::optim` L-BFGS-B with fall-back grid/pattern search\n#' if convergence is not achieved.\n#'\n#' @param par `numeric` Vector of intial guesses for the parameters.\n#' @param x `numeric` Values to evaluate `fn` for.\n#' @param y `numeric` Target output values to optimze `fn` against.\n#' @param fn `function` A function to optimize.\n#' @param loss `character(1)` or `function` Loss function to compute.\n#' @param lower `numeric(1)` Lower bound for parameters.\n#' @param upper `numeric(1)` Upper bound for paramteres.\n#' @param precision `numeric` smallest step size used in pattern search.\n#' @param density `numeric` how many points in the dimension of each parameter.\n#' @param step initial step size for pattern search.\n#' @param ... `pairlist` Fall through arguments to `fn`.\n#' @param loss_args `list` Additional argument to the `loss` function.\n#' @param span `numeric` Multiplicative ratio for initial step size.\n#' @param optim_only `logical(1)` Should fall back methods be skipped?\n#' @param control `list` List of control parameters to pass to `optim`.\n#'\n#' @return `numeric` Vector of optimal parameters for `fn` fit against `y`\n#'   on the values of `x`.\n#'\n#' @importFrom stats optim\n#' @export\n.fitCurve2 <- function(par, x, y, fn, loss, lower=-Inf, upper=Inf,\n        precision=1e-4, density=c(2, 10, 5), step= 0.5 / density, ...,\n        loss_args=list(), span=1, optim_only=FALSE,\n        control=list(factr=1e-08, ndeps=rep(1e-4, times=length(par)), trace = 0)\n        ) {\n    # Input validation\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    stopifnot(\n        (length(par) == length(upper) && length(par) == length(lower)) ||\n        (length(upper) == 1 && length(lower) == 1)\n    )\n    stopifnot(span > precision)\n\n    # Make function compatible with optim\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n\n    # Perform optimization\n    guess <- optim(\n        par=par,\n        fn=function(p)\n            do.call(loss,\n                args=c(\n                    list(par=p, x=x, y=y, fn=optim_fn),\n                    loss_args\n                )\n            ),\n        upper=upper,\n        lower=lower,\n        control=control,\n        method=\"L-BFGS-B\"\n    )\n\n    # Check for convergence\n    failed <- guess[\"convergence\"] != 0\n    if (failed) guess <- list(par=par, convergence=(-1))\n    guess <- guess[\"par\"]\n\n    # Calculate residuals\n    guess_residual <- do.call(loss,\n        args=c(list(par=guess, x=x, y=y, fn=optim_fn), loss_args))\n    gritty_guess_residual <- do.call(loss,\n        args=c(list(par=par, x=x, y=y, fn=optim_fn), loss_args))\n\n    # Fallback methods if optimization fails\n    if (\n        (failed || any(is.na(guess)) || guess_residual >= gritty_guess_residual)\n        && !optim_only\n    ) {\n        # Code for fallback methods goes here\n    }\n\n    # Calculate R-squared\n    y_hat <- optim_fn(par=guess, x=x)\n    Rsqr <- 1 - (var(y - y_hat) / var(y))\n    attr(guess, \"Rsquare\") <- Rsqr\n\n    return(guess)\n}",
        "complete": "# Curve fitting via `stats::optim` L-BFGS-B with fall-back grid/pattern search\n#' if convergence is not achieved.\n#'\n#' @param par `numeric` Vector of intial guesses for the parameters.\n#' @param x `numeric` Values to evaluate `fn` for.\n#' @param y `numeric` Target output values to optimze `fn` against.\n#' @param fn `function` A function to optimize.\n#' @param loss `character(1)` or `function` Loss function to compute.\n#' @param lower `numeric(1)` Lower bound for parameters.\n#' @param upper `numeric(1)` Upper bound for paramteres.\n#' @param precision `numeric` smallest step size used in pattern search.\n#' @param density `numeric` how many points in the dimension of each parameter.\n#' @param step initial step size for pattern search.\n#' @param ... `pairlist` Fall through arguments to `fn`.\n#' @param loss_args `list` Additional argument to the `loss` function.\n#' @param span `numeric` Multiplicative ratio for initial step size.\n#' @param optim_only `logical(1)` Should fall back methods be skipped?\n#' @param control `list` List of control parameters to pass to `optim`.\n#'\n#' @return `numeric` Vector of optimal parameters for `fn` fit against `y`\n#'   on the values of `x`.\n#'\n#' @importFrom stats optim\n#' @export\n.fitCurve2 <- function(par, x, y, fn, loss, lower=-Inf, upper=Inf,\n        precision=1e-4, density=c(2, 10, 5), step= 0.5 / density, ...,\n        loss_args=list(), span=1, optim_only=FALSE,\n        control=list(factr=1e-08, ndeps=rep(1e-4, times=length(par)), trace = 0)\n        ) {\n    # Input validation\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    stopifnot(\n        (length(par) == length(upper) && length(par) == length(lower)) ||\n        (length(upper) == 1 && length(lower) == 1)\n    )\n    stopifnot(span > precision)\n\n    # Make function compatible with optim\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n\n    # Perform optimization\n    guess <- optim(\n        par=par,\n        fn=function(p)\n            do.call(loss,\n                args=c(\n                    list(par=p, x=x, y=y, fn=optim_fn),\n                    loss_args\n                )\n            ),\n        upper=upper,\n        lower=lower,\n        control=control,\n        method=\"L-BFGS-B\"\n    )\n\n    # Check for convergence\n    failed <- guess[\"convergence\"] != 0\n    if (failed) guess <- list(par=par, convergence=(-1))\n    guess <- guess[\"par\"]\n\n    # Calculate residuals\n    guess_residual <- do.call(loss,\n        args=c(list(par=guess, x=x, y=y, fn=optim_fn), loss_args))\n    gritty_guess_residual <- do.call(loss,\n        args=c(list(par=par, x=x, y=y, fn=optim_fn), loss_args))\n\n    # Fallback methods if optimization fails\n    if (\n        (failed || any(is.na(guess)) || guess_residual >= gritty_guess_residual)\n        && !optim_only\n    ) {\n        guess <- .meshEval2(density=density, par=guess, x=x, y=y, fn=optim_fn,\n            lower=lower, upper=upper, ..., loss=loss,loss_args=loss_args)\n        guess_residual <- do.call(loss,\n            args=c(list(par=guess, x=x, y=y, fn=optim_fn), loss_args))\n\n        guess <- .patternSearch2(span=span, precision=precision, step=step,\n            par=guess, par_residual=guess_residual, x=x, y=y, fn=optim_fn,\n            loss=loss, lower=lower, upper=upper, ..., loss_args=loss_args)\n    }\n\n    # Calculate R-squared\n    y_hat <- optim_fn(par=guess, x=x)\n    Rsqr <- 1 - (var(y - y_hat) / var(y))\n    attr(guess, \"Rsquare\") <- Rsqr\n\n    return(guess)\n}"
      },
      {
        "partial": "#' @export\n#' @keywords internal\n#' @noRd\n.meshEval2 <- function(density, par, x, y, fn,\n        loss=.normal_loss, lower, upper, ..., loss_args=list()) {\n    # input validation\n    stopifnot(is.function(fn))\n    stopifnot(is.function(loss) || is.character(loss))\n    stopifnot(c(\"par\", \"x\", \"y\", \"fn\") %in% formalArgs(loss))\n    stopifnot(\n        is.null(names(loss_args)) || all(names(loss_args) %in% formalArgs(loss))\n    )\n    # make function amenable to use via optim\n    optim_fn <- if (is_optim_compatible(fn)) {\n        fn\n    } else {\n        make_optim_function(fn, ...)\n    }\n    par_loss <- do.call(loss,\n        args=c(list(par=par, x=x, y=y, fn=optim_fn), loss_args))\n\n    periods <- matrix(NA, nrow = length(par), ncol = 1)\n    names(periods) <- names(par)\n    periods[1] <- 1\n\n    if (length(par) > 1) {\n        for (p in seq(2, length(par))) {\n            periods[p] <- periods[p - 1] * (density[p - 1] *\n                (upper[p - 1] - lower[p - 1]) + 1)\n        }\n    }\n\n    currentPars <- lower\n\n    for (point in seq_len(prod((upper - lower) * density + 1))) {\n        test_par_loss <- do.call(loss,\n            c(list(par=currentPars, x=x, y=y, fn=optim_fn), loss_args))\n\n        if (\n            !length(test_par_loss) ||\n            (!is.finite(test_par_loss) && test_par_loss != Inf)\n        ) {\n            stop(paste0(\"Test Guess Loss is: \", test_par_loss, \"\\n\",\n                \"Other Pars:\\n\", \"x: \", paste(x, collapse = \", \"), \"\\n\",\n                \"y: \", paste(y, collapse = \", \"), \"\\n\", \"n: \", n, \"\\n\",\n                \"pars: \", currentPars, \"\\n\", \"scale: \", scale, \"\\n\",\n                \"family : \", family, \"\\n\", \"Trunc \", trunc))\n        }\n        if (test_par_loss < par_loss) {\n            par <- currentPars\n            par_loss <- test_par_loss\n        }\n        for (p in seq_along(par)) {\n            if (point %% periods[p] == 0) {\n                currentPars[p] <- currentPars[p] + 1 / density[p]\n                if (currentPars[p] > upper[p]) {\n                    currentPars[p] <- lower[p]\n                }\n            }\n        }\n    }\n\n    return(par)\n}",
        "complete": "#' @export\n#' @keywords internal\n#' @noRd\n.meshEval2 <- function(density, par, x, y, fn,\n        loss=.normal_loss, lower, upper, ..., loss_args=list())"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utils-iteration.R",
    "language": "R",
    "content": "#' @title lapply\n#' lapply method for `MultiAssayExperiment`\n#'\n#' @param X A `MultiAssayExperiment` object.\n#' @param FUN A function to be applied to each `SummarizedExperiment` in a\n#' in `X`.\n#' @param ... Fall through parameters to `FUN`\n#'\n#' @return A `MultiAssayExperiment` object, modifed such that\n#' `experiments(X) <- endoapply(experiments(X), FUN, ...)`.s\n#'\n#' @importMethodsFrom BiocGenerics lapply\n#' @importFrom S4Vectors endoapply\n#' @importFrom MultiAssayExperiment experiments experiments<-\n#' @exportMethod lapply\nsetMethod('lapply', signature(X='MultiAssayExperiment'),\n        function(X, FUN, ...) {\n    experiments(X) <- endoapply(experiments(X), FUN, ...)\n    return(X)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `lapply` method for `MultiAssayExperiment` objects?",
        "answer": "The `lapply` method for `MultiAssayExperiment` objects applies a given function `FUN` to each `SummarizedExperiment` in the `MultiAssayExperiment` object. It modifies the original object by updating its experiments using the `endoapply` function and returns the modified object."
      },
      {
        "question": "How does this implementation handle additional parameters passed to the `FUN` function?",
        "answer": "The implementation uses the `...` (ellipsis) argument to pass any additional parameters to the `FUN` function. These additional parameters are forwarded to both the `endoapply` function and the `FUN` function, allowing for flexible function calls."
      },
      {
        "question": "What is the significance of the `@importMethodsFrom`, `@importFrom`, and `@exportMethod` annotations in this code?",
        "answer": "These annotations are used for package documentation and management. `@importMethodsFrom` imports specific methods from other packages, `@importFrom` imports functions from other packages, and `@exportMethod` indicates that this method should be exported and made available to users of the package. They help manage dependencies and control which functions are visible to users."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' @title lapply\n#' lapply method for `MultiAssayExperiment`\n#'\n#' @param X A `MultiAssayExperiment` object.\n#' @param FUN A function to be applied to each `SummarizedExperiment` in a\n#' in `X`.\n#' @param ... Fall through parameters to `FUN`\n#'\n#' @return A `MultiAssayExperiment` object, modifed such that\n#' `experiments(X) <- endoapply(experiments(X), FUN, ...)`.\n#'\n#' @importMethodsFrom BiocGenerics lapply\n#' @importFrom S4Vectors endoapply\n#' @importFrom MultiAssayExperiment experiments experiments<-\n#' @exportMethod lapply\nsetMethod('lapply', signature(X='MultiAssayExperiment'),\n        function(X, FUN, ...) {\n    # Complete the function body\n})",
        "complete": "#' @title lapply\n#' lapply method for `MultiAssayExperiment`\n#'\n#' @param X A `MultiAssayExperiment` object.\n#' @param FUN A function to be applied to each `SummarizedExperiment` in a\n#' in `X`.\n#' @param ... Fall through parameters to `FUN`\n#'\n#' @return A `MultiAssayExperiment` object, modifed such that\n#' `experiments(X) <- endoapply(experiments(X), FUN, ...)`.\n#'\n#' @importMethodsFrom BiocGenerics lapply\n#' @importFrom S4Vectors endoapply\n#' @importFrom MultiAssayExperiment experiments experiments<-\n#' @exportMethod lapply\nsetMethod('lapply', signature(X='MultiAssayExperiment'),\n        function(X, FUN, ...) {\n    experiments(X) <- endoapply(experiments(X), FUN, ...)\n    X\n})"
      },
      {
        "partial": "#' @title lapply\n#' lapply method for `MultiAssayExperiment`\n#'\n#' @param X A `MultiAssayExperiment` object.\n#' @param FUN A function to be applied to each `SummarizedExperiment` in a\n#' in `X`.\n#' @param ... Fall through parameters to `FUN`\n#'\n#' @return A `MultiAssayExperiment` object, modifed such that\n#' `experiments(X) <- endoapply(experiments(X), FUN, ...)`.\n#'\n#' @importMethodsFrom BiocGenerics lapply\n#' @importFrom S4Vectors endoapply\n#' @importFrom MultiAssayExperiment experiments experiments<-\n#' @exportMethod lapply\nsetMethod('lapply', signature(X='MultiAssayExperiment'),\n        function(X, FUN, ...) {\n    # Complete the function body in a single line\n})",
        "complete": "#' @title lapply\n#' lapply method for `MultiAssayExperiment`\n#'\n#' @param X A `MultiAssayExperiment` object.\n#' @param FUN A function to be applied to each `SummarizedExperiment` in a\n#' in `X`.\n#' @param ... Fall through parameters to `FUN`\n#'\n#' @return A `MultiAssayExperiment` object, modifed such that\n#' `experiments(X) <- endoapply(experiments(X), FUN, ...)`.\n#'\n#' @importMethodsFrom BiocGenerics lapply\n#' @importFrom S4Vectors endoapply\n#' @importFrom MultiAssayExperiment experiments experiments<-\n#' @exportMethod lapply\nsetMethod('lapply', signature(X='MultiAssayExperiment'),\n        function(X, FUN, ...) {\n    `experiments<-`(X, endoapply(experiments(X), FUN, ...))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/computeSensitivity.R",
    "language": "R",
    "content": "## This function computes pars/AUC/SF2/D10 for the whole raw sensitivity data of a rset\n#' @importFrom BiocParallel bplapply\n.calculateFromRaw <- function(raw.sensitivity,\n                              trunc=TRUE,\n                              nthread=1,\n                              family=c(\"normal\", \"Cauchy\"),\n                              scale = 5,\n                              n = 1)\n  {\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n\n  family <- match.arg(family)\n\n  AUC <- vector(length=dim(raw.sensitivity)[1])\n  names(AUC) <- dimnames(raw.sensitivity)[[1]]\n\n  SF2 <- vector(length=dim(raw.sensitivity)[1])\n  names(SF2) <- dimnames(raw.sensitivity)[[1]]\n\n  D10 <- vector(length=dim(raw.sensitivity)[1])\n  names(D10) <- dimnames(raw.sensitivity)[[1]]\n\n  if (nthread ==1){\n    pars <- lapply(names(AUC), function(exp, raw.sensitivity, family, scale, n) {\n      if(length(grep(\"///\", raw.sensitivity[exp, , \"Dose\"])) > 0 | all(is.na(raw.sensitivity[exp, , \"Dose\"]))) {\n        NA\n      } else {\n        return(unlist(linearQuadraticModel(raw.sensitivity[exp, , \"Dose\"], raw.sensitivity[exp, , \"Response\"], trunc=trunc, family=family, scale=scale, median_n=n)))\n      }\n    },raw.sensitivity=raw.sensitivity, family = family, scale = scale, n = n)\n    names(pars) <- dimnames(raw.sensitivity)[[1]]\n    AUC <- unlist(lapply(names(pars), function(exp,raw.sensitivity, pars) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeAUC(D=raw.sensitivity[exp, , \"Dose\"], pars=pars[[exp]], trunc=trunc)\n      }\n    },raw.sensitivity=raw.sensitivity, pars=pars))\n    SF2 <- unlist(lapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeSF2(pars=pars[[exp]])\n      }\n    }, pars=pars))\n    D10 <- unlist(lapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeD10(pars=pars[[exp]])\n      }\n    }, pars=pars))\n\n  } else {\n    pars <- BiocParallel::bplapply(names(AUC), function(exp, raw.sensitivity, family, scale, n, trunc) {\n      if(length(grep(\"///\", raw.sensitivity[exp, , \"Dose\"])) > 0 | all(is.na(raw.sensitivity[exp, , \"Dose\"]))) {\n        NA\n      } else {\n        linearQuadraticModel(raw.sensitivity[exp, , \"Dose\"], raw.sensitivity[exp, , \"Response\"], trunc=trunc, family=family, scale=scale, median_n=n)\n      }\n    }, raw.sensitivity=raw.sensitivity, family = family, scale = scale, n = n, trunc = trunc)\n    names(pars) <- dimnames(raw.sensitivity)[[1]]\n    AUC <- unlist(BiocParallel::bplapply(names(pars), function(exp, raw.sensitivity, pars, trunc) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeAUC(D=raw.sensitivity[exp, , \"Dose\"], pars=pars[[exp]], trunc=trunc)\n      }\n    },raw.sensitivity=raw.sensitivity, pars=pars, trunc = trunc))\n    SF2 <- unlist(BiocParallel::bplapply(names(pars), function(exp, pars, trunc) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeSF2(pars=pars[[exp]])\n      }\n    }, pars=pars, trunc = trunc))\n    D10 <- unlist(BiocParallel::bplapply(names(pars), function(exp, pars, trunc) {\n      if(any(is.na(pars[[exp]]))) {\n        NA\n      } else {\n        computeD10(pars=pars[[exp]])\n      }\n    }, pars=pars, trunc = trunc))\n  }\n\n  names(AUC) <- dimnames(raw.sensitivity)[[1]]\n  names(SF2) <- dimnames(raw.sensitivity)[[1]]\n  names(D10) <- dimnames(raw.sensitivity)[[1]]\n\n  alpha <- vapply(pars, function(x) return(x[1]), numeric(1))\n  beta <- vapply(pars, function(x) return(x[2]), numeric(1))\n\n\n  return(list(\"AUC\"=AUC, \"SF2\"=SF2, \"D10\"=D10 ,\"alpha\"=alpha, \"beta\"=beta))\n}\n\nupdateMaxConc <- function(rSet) {\n  sensitivityInfo(rSet)$max.conc <- apply(sensitivityRaw(rSet)[,,\"Dose\"], 1, max, na.rm=TRUE)\n  return(rSet)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.calculateFromRaw` function and what are its main outputs?",
        "answer": "The `.calculateFromRaw` function computes various radiobiological parameters from raw sensitivity data. Its main outputs are AUC (Area Under the Curve), SF2 (Survival Fraction at 2 Gy), D10 (Dose for 10% survival), alpha, and beta parameters. These are returned as a list containing vectors for each parameter."
      },
      {
        "question": "How does the function handle parallel processing, and what condition determines whether parallel processing is used?",
        "answer": "The function uses parallel processing when `nthread` is greater than 1. It utilizes the `BiocParallel::bplapply` function for parallel computation. When `nthread` is 1, it uses regular `lapply` for sequential processing. The parallel processing is applied to the calculation of pars, AUC, SF2, and D10 values."
      },
      {
        "question": "What is the purpose of the `updateMaxConc` function and how does it modify the input `rSet`?",
        "answer": "The `updateMaxConc` function updates the maximum concentration information in the sensitivity data of the input `rSet`. It calculates the maximum dose for each experiment in the raw sensitivity data and stores this information in the `sensitivityInfo` slot of the `rSet` object under the `max.conc` field. The function then returns the updated `rSet`."
      }
    ],
    "completion_tasks": [
      {
        "partial": ".calculateFromRaw <- function(raw.sensitivity, trunc=TRUE, nthread=1, family=c(\"normal\", \"Cauchy\"), scale = 5, n = 1) {\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  family <- match.arg(family)\n\n  AUC <- vector(length=dim(raw.sensitivity)[1])\n  names(AUC) <- dimnames(raw.sensitivity)[[1]]\n\n  SF2 <- vector(length=dim(raw.sensitivity)[1])\n  names(SF2) <- dimnames(raw.sensitivity)[[1]]\n\n  D10 <- vector(length=dim(raw.sensitivity)[1])\n  names(D10) <- dimnames(raw.sensitivity)[[1]]\n\n  if (nthread == 1) {\n    # Complete the single-threaded computation here\n  } else {\n    # Complete the multi-threaded computation here\n  }\n\n  # Complete the function\n}",
        "complete": ".calculateFromRaw <- function(raw.sensitivity, trunc=TRUE, nthread=1, family=c(\"normal\", \"Cauchy\"), scale = 5, n = 1) {\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  family <- match.arg(family)\n\n  AUC <- vector(length=dim(raw.sensitivity)[1])\n  names(AUC) <- dimnames(raw.sensitivity)[[1]]\n\n  SF2 <- vector(length=dim(raw.sensitivity)[1])\n  names(SF2) <- dimnames(raw.sensitivity)[[1]]\n\n  D10 <- vector(length=dim(raw.sensitivity)[1])\n  names(D10) <- dimnames(raw.sensitivity)[[1]]\n\n  if (nthread == 1) {\n    pars <- lapply(names(AUC), function(exp, raw.sensitivity, family, scale, n) {\n      if(length(grep(\"///\", raw.sensitivity[exp, , \"Dose\"])) > 0 | all(is.na(raw.sensitivity[exp, , \"Dose\"]))) {\n        NA\n      } else {\n        unlist(linearQuadraticModel(raw.sensitivity[exp, , \"Dose\"], raw.sensitivity[exp, , \"Response\"], trunc=trunc, family=family, scale=scale, median_n=n))\n      }\n    }, raw.sensitivity=raw.sensitivity, family=family, scale=scale, n=n)\n    names(pars) <- dimnames(raw.sensitivity)[[1]]\n    AUC <- unlist(lapply(names(pars), function(exp, raw.sensitivity, pars) {\n      if(any(is.na(pars[[exp]]))) NA else computeAUC(D=raw.sensitivity[exp, , \"Dose\"], pars=pars[[exp]], trunc=trunc)\n    }, raw.sensitivity=raw.sensitivity, pars=pars))\n    SF2 <- unlist(lapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) NA else computeSF2(pars=pars[[exp]])\n    }, pars=pars))\n    D10 <- unlist(lapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) NA else computeD10(pars=pars[[exp]])\n    }, pars=pars))\n  } else {\n    pars <- BiocParallel::bplapply(names(AUC), function(exp, raw.sensitivity, family, scale, n, trunc) {\n      if(length(grep(\"///\", raw.sensitivity[exp, , \"Dose\"])) > 0 | all(is.na(raw.sensitivity[exp, , \"Dose\"]))) {\n        NA\n      } else {\n        linearQuadraticModel(raw.sensitivity[exp, , \"Dose\"], raw.sensitivity[exp, , \"Response\"], trunc=trunc, family=family, scale=scale, median_n=n)\n      }\n    }, raw.sensitivity=raw.sensitivity, family=family, scale=scale, n=n, trunc=trunc)\n    names(pars) <- dimnames(raw.sensitivity)[[1]]\n    AUC <- unlist(BiocParallel::bplapply(names(pars), function(exp, raw.sensitivity, pars, trunc) {\n      if(any(is.na(pars[[exp]]))) NA else computeAUC(D=raw.sensitivity[exp, , \"Dose\"], pars=pars[[exp]], trunc=trunc)\n    }, raw.sensitivity=raw.sensitivity, pars=pars, trunc=trunc))\n    SF2 <- unlist(BiocParallel::bplapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) NA else computeSF2(pars=pars[[exp]])\n    }, pars=pars))\n    D10 <- unlist(BiocParallel::bplapply(names(pars), function(exp, pars) {\n      if(any(is.na(pars[[exp]]))) NA else computeD10(pars=pars[[exp]])\n    }, pars=pars))\n  }\n\n  names(AUC) <- names(SF2) <- names(D10) <- dimnames(raw.sensitivity)[[1]]\n  alpha <- vapply(pars, function(x) x[1], numeric(1))\n  beta <- vapply(pars, function(x) x[2], numeric(1))\n\n  list(AUC=AUC, SF2=SF2, D10=D10, alpha=alpha, beta=beta)\n}"
      },
      {
        "partial": "updateMaxConc <- function(rSet) {\n  # Complete the function to update the maximum concentration\n}",
        "complete": "updateMaxConc <- function(rSet) {\n  sensitivityInfo(rSet)$max.conc <- apply(sensitivityRaw(rSet)[,,'Dose'], 1, max, na.rm=TRUE)\n  rSet\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/OERmodel.R",
    "language": "R",
    "content": "# OER function for a given hypoxic concentration by the user\n#\n# @param oxygenConc \\code{numeric} An oxygen concentratio between 0.1 and 10\n#\n# @return \\code{none} Generates a dose response curve for a given hypoxic\n#   concentration\n#\nOERmodel <- function(oxygenConc) {\n\n  pO2 <- oxygenConc\n  pO2 <- as.numeric(pO2)\n  if (is.na(pO2)) {\n    stop(\"Error: oxygenConc is NA!\")}\n\n  if (pO2<0.1 | pO2>10){\n    stop(\"Please enter an oxygenConc between 0.1 and 10!\")\n  }\n\n  OER_m = 3\n  K_m = 3\n  a = ((OER_m*pO2)+K_m)/(pO2+K_m)\n  OMF = (1/OER_m)*a\n\n  D <- seq(0, 10, 1)\n  SF1 = exp(-0.3*D*OMF-(0.03*D*D*OMF))\n  pdf(\"HyxpoxiaPlot.pdf\")\n  RadioGx::doseResponseCurve(Ds=list(\"Hypoxia\" = D),\n                              SFs=list(\"Hypoxia\" = SF1), plot.type=\"Actual\",\n                              legends.label = NULL,title = \"Effect of Hypoxia\",\n                              cex = 1.55,cex.main = 1.75,lwd = 2)\n  dev.off()\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `OERmodel` function and what are its input constraints?",
        "answer": "The `OERmodel` function generates a dose response curve for a given hypoxic concentration. It takes a single input parameter `oxygenConc`, which must be a numeric value between 0.1 and 10. The function will stop execution with an error message if the input is outside this range or if it's NA."
      },
      {
        "question": "How does the function calculate the Oxygen Modification Factor (OMF) and what variables are used in this calculation?",
        "answer": "The function calculates the Oxygen Modification Factor (OMF) using the formula: OMF = (1/OER_m) * ((OER_m * pO2 + K_m) / (pO2 + K_m)). The variables used are: OER_m (set to 3), K_m (set to 3), and pO2 (the input oxygen concentration)."
      },
      {
        "question": "What does the function do after calculating the OMF, and what external package does it use?",
        "answer": "After calculating the OMF, the function generates a sequence of dose values (D) from 0 to 10, calculates the survival fraction (SF1) using the OMF, and then creates a dose response curve plot. It uses the `RadioGx` package to generate this plot, specifically the `doseResponseCurve` function. The plot is saved as a PDF file named 'HyxpoxiaPlot.pdf'."
      }
    ],
    "completion_tasks": [
      {
        "partial": "OERmodel <- function(oxygenConc) {\n  pO2 <- as.numeric(oxygenConc)\n  if (is.na(pO2)) {\n    stop(\"Error: oxygenConc is NA!\")\n  }\n  if (pO2 < 0.1 | pO2 > 10) {\n    stop(\"Please enter an oxygenConc between 0.1 and 10!\")\n  }\n\n  OER_m <- 3\n  K_m <- 3\n  a <- ((OER_m * pO2) + K_m) / (pO2 + K_m)\n  OMF <- (1 / OER_m) * a\n\n  D <- seq(0, 10, 1)\n  SF1 <- exp(-0.3 * D * OMF - (0.03 * D * D * OMF))\n\n  # Complete the function to generate and save the plot\n}",
        "complete": "OERmodel <- function(oxygenConc) {\n  pO2 <- as.numeric(oxygenConc)\n  if (is.na(pO2)) {\n    stop(\"Error: oxygenConc is NA!\")\n  }\n  if (pO2 < 0.1 | pO2 > 10) {\n    stop(\"Please enter an oxygenConc between 0.1 and 10!\")\n  }\n\n  OER_m <- 3\n  K_m <- 3\n  a <- ((OER_m * pO2) + K_m) / (pO2 + K_m)\n  OMF <- (1 / OER_m) * a\n\n  D <- seq(0, 10, 1)\n  SF1 <- exp(-0.3 * D * OMF - (0.03 * D * D * OMF))\n\n  pdf(\"HyxpoxiaPlot.pdf\")\n  RadioGx::doseResponseCurve(Ds = list(\"Hypoxia\" = D),\n                            SFs = list(\"Hypoxia\" = SF1),\n                            plot.type = \"Actual\",\n                            legends.label = NULL,\n                            title = \"Effect of Hypoxia\",\n                            cex = 1.55, cex.main = 1.75, lwd = 2)\n  dev.off()\n}"
      },
      {
        "partial": "OERmodel <- function(oxygenConc) {\n  # Validate input\n  pO2 <- as.numeric(oxygenConc)\n  if (is.na(pO2) || pO2 < 0.1 || pO2 > 10) {\n    stop(\"Invalid oxygenConc. Please enter a value between 0.1 and 10.\")\n  }\n\n  # Calculate OER and OMF\n  OER_m <- 3\n  K_m <- 3\n  a <- ((OER_m * pO2) + K_m) / (pO2 + K_m)\n  OMF <- (1 / OER_m) * a\n\n  # Generate dose and survival fraction data\n  D <- seq(0, 10, 1)\n  SF1 <- exp(-0.3 * D * OMF - (0.03 * D * D * OMF))\n\n  # Complete the function to generate and save the plot\n}",
        "complete": "OERmodel <- function(oxygenConc) {\n  # Validate input\n  pO2 <- as.numeric(oxygenConc)\n  if (is.na(pO2) || pO2 < 0.1 || pO2 > 10) {\n    stop(\"Invalid oxygenConc. Please enter a value between 0.1 and 10.\")\n  }\n\n  # Calculate OER and OMF\n  OER_m <- 3\n  K_m <- 3\n  a <- ((OER_m * pO2) + K_m) / (pO2 + K_m)\n  OMF <- (1 / OER_m) * a\n\n  # Generate dose and survival fraction data\n  D <- seq(0, 10, 1)\n  SF1 <- exp(-0.3 * D * OMF - (0.03 * D * D * OMF))\n\n  # Generate and save the plot\n  pdf(\"HyxpoxiaPlot.pdf\")\n  RadioGx::doseResponseCurve(Ds = list(\"Hypoxia\" = D),\n                            SFs = list(\"Hypoxia\" = SF1),\n                            plot.type = \"Actual\",\n                            legends.label = NULL,\n                            title = \"Effect of Hypoxia\",\n                            cex = 1.55, cex.main = 1.75, lwd = 2)\n  dev.off()\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/unitest/test.R",
    "language": "R",
    "content": "## Size\n\nlibrary(mRMRe)\ndata(cgps)\ndata <- mRMR.data(data = as.data.frame(cgps.ge))\nsystem.time(filter <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1), feature_count = 200, solution_count = 160))\nprint(object.size(filter), units = \"Mb\")\n\n\nlibrary(mRMRe)\nload('~/Downloads/irinotecan_cgp_ccle.RData')\ndata <- mRMR.data(data = data.frame(data_cgp[, 1:10000]))\nsystem.time(mim(data))\n\n## Simple Test\n\nlibrary(mRMRe)\nset.seed(0)\n\nx <- rnorm(100, 0)\ndd <- data.frame(\n        \"cont1\" = x,\n        \"cont2\" = x + rnorm(100, 0.1),\n\t\t\"cont3\" = x + rnorm(100, 0.1),\n\t\t\"cont4\" = x + rnorm(100, 0.1),\n\t\t\"cont5\" = x + rnorm(100, 0.1),\n\t\t\"cont6\" = x + rnorm(100, 0.01))\n\t\t\ndata <- mRMR.data(data = dd)\nfilter <- mRMR.classic(\"mRMRe.Filter\", data = data, target_indices = 3:5, feature_count = 2)\nscores(filter)\nsolutions(filter)\n\nmim(filter)\n## NETWORK TEST\n\nlibrary(mRMRe)\nset.seed(0)\ndd <- data.frame(\n        \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont1\" = runif(100),\n        \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n        \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont2\" = runif(100),\n        \"cont3\" = runif(100),\n        \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cat2\"=factor(sample(1:5, 100, replace = TRUE), ordered = TRUE))\n\ndata <- mRMR.data(data = dd)\nnetwork <- new(\"mRMRe.Network\", data = data, target_indices = c(1, 2), levels = c(2, 1), layers = 1)\nnetwork@topologies\nadjacencyMatrix(network)\nvisualize(network)\n\n\ndata <- mRMR.data(data = dd,\n        strata = factor(sample(1:5, 100, replace=TRUE), ordered=TRUE),\n        weights = runif(100))\nmim(data) # Gives MI matrix\nmim(data, method = \"cor\") # Gives correlation matrix\n\n\n\nmim(filter_1)\n\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_index = 2, feature_count = 2, solution_count = 1)\nmim(filter_2)\n\nmim(data)\n\n# No wrapper just yet\nnetwork <- new(\"mRMRe.Network\", data = data, target_indices = c(1, 2), levels = c(1, 1, 1), layers = 1)\nmim(data)\nmim(network)\n\nadjacencyMatrix(network)\n\ncausality(network)[1, , ]\ncausality(filter_1)\n\ncausality(network)[2, , ]\ncausality(filter_2)\n\n# I have no idea how to get igraph to print out vertex names\n\nvisualize(network)\n\n## test for large network (1000 genes)\n## install new version of the package if needed on gen01\nlibrary(devtools)\ninstall_github(\"mRMRe\", username=\"bhaibeka\", ref=\"master\")\nsystem(\"chmod -R 775 /stockage/Laboratoires/HAI/Rlib\")\n\n\nlibrary(mRMRe)\n## set the number of threads\nset.thread.count(2)\n## run the network inference\ndata(cgps)\nge <- mRMR.data(data = data.frame(cgps.ge[ ,1:1000]))\n#Rprof(filename = \"Rprof.out\", append = FALSE, interval = 0.02, memory.profiling=TRUE)\nexect <- system.time(netw <- new(\"mRMRe.Network\", data = ge, target_indices = 1:10, levels = c(8, 1, 1, 1, 1), layers = 2))\nprint(exect)\n#summaryRprof(filename = \"Rprof.out\", chunksize = 5000, memory=c(\"both\"), index=2, diff=TRUE, exclude=NULL)\n\n\nprint(table(adjacencyMatrix(netw)))\n\npdf(\"temp.pdf\", width=14, height=14)\nvisualize(netw)\ndev.off()\n\n\n# Generate the basic stuff\ndata(cgps)\ndd <- mRMR.data(data=data.frame(cgps.ge))\nnetw <- new(\"mRMRe.Network\", data = dd, target_indices = c(1, 2), levels = c(1, 1, 1), layers = 1)\nfilter <- new(\"mRMRe.Filter\", data = dd, target_indices = c(1, 2), levels = c(1,1,1))\n\n# Create all 3 mim and remove NA's\nnetwork_mim <- mim(netw)\nindices <- !is.na(network_mim)\nnetwork_mim <- network_mim[indices]\nfilter_mim <- mim(filter)[indices]\ndata_mim <- mim(dd)[indices]\n\n# Compare\nquantile(network_mim)\nquantile(filter_mim)\nquantile(data_mim)\n\n# Causality\ncausality(filter) # a list of causality scores for each solution\ncausality(filter, merge=T) # a single vector of causality scores that is the min value between all solutions\ncausality(netw) # network-wide minimal causality scores\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mRMR.data()` function in the given code snippet, and how is it used?",
        "answer": "The `mRMR.data()` function is used to create a data object suitable for use with the mRMRe package. It converts the input data frame into a specialized format that can be used for feature selection and network analysis. In the code snippet, it's used twice: once with `as.data.frame(cgps.ge)` and once with `data.frame(data_cgp[, 1:10000])`, creating data objects for further analysis."
      },
      {
        "question": "Explain the purpose and parameters of the `mRMR.ensemble()` function call in the code snippet.",
        "answer": "The `mRMR.ensemble()` function is used to perform ensemble feature selection using the minimum redundancy maximum relevance (mRMR) algorithm. In this code, it's called with the following parameters:\n- 'mRMRe.Filter': specifies the type of filter to use\n- data: the input data object created by mRMR.data()\n- target_indices = c(1): indicates that the first column is the target variable\n- feature_count = 200: selects the top 200 features\n- solution_count = 160: generates 160 different solutions\nThe function returns a filter object containing the selected features and their scores."
      },
      {
        "question": "What is the purpose of the `system.time()` function in the code, and what information does it provide?",
        "answer": "The `system.time()` function is used to measure the execution time of the code enclosed within its parentheses. In this snippet, it's used twice:\n1. To measure the time taken by the `mRMR.ensemble()` function\n2. To measure the time taken by the `mim()` function\nIt provides information about the real time, user CPU time, and system CPU time taken by the enclosed expression. This is useful for performance analysis and optimization of computationally intensive operations in the mRMRe package."
      }
    ],
    "completion_tasks": [
      {
        "partial": "library(mRMRe)\nset.seed(0)\n\nx <- rnorm(100, 0)\ndd <- data.frame(\n        \"cont1\" = x,\n        \"cont2\" = x + rnorm(100, 0.1),\n\t\t\"cont3\" = x + rnorm(100, 0.1),\n\t\t\"cont4\" = x + rnorm(100, 0.1),\n\t\t\"cont5\" = x + rnorm(100, 0.1),\n\t\t\"cont6\" = x + rnorm(100, 0.01))\n\t\t\ndata <- mRMR.data(data = dd)\nfilter <- mRMR.classic(\"mRMRe.Filter\", data = data, target_indices = 3:5, feature_count = 2)\n# Complete the code to print the scores and solutions of the filter",
        "complete": "library(mRMRe)\nset.seed(0)\n\nx <- rnorm(100, 0)\ndd <- data.frame(\n        \"cont1\" = x,\n        \"cont2\" = x + rnorm(100, 0.1),\n\t\t\"cont3\" = x + rnorm(100, 0.1),\n\t\t\"cont4\" = x + rnorm(100, 0.1),\n\t\t\"cont5\" = x + rnorm(100, 0.1),\n\t\t\"cont6\" = x + rnorm(100, 0.01))\n\t\t\ndata <- mRMR.data(data = dd)\nfilter <- mRMR.classic(\"mRMRe.Filter\", data = data, target_indices = 3:5, feature_count = 2)\nprint(scores(filter))\nprint(solutions(filter))"
      },
      {
        "partial": "library(mRMRe)\nset.seed(0)\ndd <- data.frame(\n        \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont1\" = runif(100),\n        \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n        \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont2\" = runif(100),\n        \"cont3\" = runif(100),\n        \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cat2\"=factor(sample(1:5, 100, replace = TRUE), ordered = TRUE))\n\ndata <- mRMR.data(data = dd)\nnetwork <- new(\"mRMRe.Network\", data = data, target_indices = c(1, 2), levels = c(2, 1), layers = 1)\n# Complete the code to visualize the network and print its adjacency matrix",
        "complete": "library(mRMRe)\nset.seed(0)\ndd <- data.frame(\n        \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont1\" = runif(100),\n        \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n        \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont2\" = runif(100),\n        \"cont3\" = runif(100),\n        \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cat2\"=factor(sample(1:5, 100, replace = TRUE), ordered = TRUE))\n\ndata <- mRMR.data(data = dd)\nnetwork <- new(\"mRMRe.Network\", data = data, target_indices = c(1, 2), levels = c(2, 1), layers = 1)\nvisualize(network)\nprint(adjacencyMatrix(network))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/Filter.cpp",
    "language": "cpp",
    "content": "#include \"Filter.h\"\n#include <iostream>\n\nFilter::Filter(int const* const pChildrenCountPerLevel, unsigned int const levelCount,\n        Matrix* const pFeatureInformationMatrix, unsigned int const targetFeatureIndex, \n        unsigned int const fixedFeatureCount) :\n        mpChildrenCountPerLevel(pChildrenCountPerLevel), mLevelCount(levelCount), mpFeatureInformationMatrix(\n                pFeatureInformationMatrix), mpStartingIndexPerLevel(\n                new unsigned int[mLevelCount + 2]), mFixedFeatureCount(fixedFeatureCount)\n{\n    unsigned int cumulative_element_count = 1;\n    unsigned int children_per_level = 1;\n\n    mpStartingIndexPerLevel[0] = 0;\n\n    for (unsigned int level = 0; level < mLevelCount; ++level)\n    {\n        mpStartingIndexPerLevel[level + 1] = cumulative_element_count;\n        children_per_level *= mpChildrenCountPerLevel[level];\n        cumulative_element_count += children_per_level;\n    }\n\n    mpStartingIndexPerLevel[mLevelCount + 1] = cumulative_element_count;\n    mTreeElementCount = cumulative_element_count;\n    mpIndexTree = new unsigned int[cumulative_element_count];\n    mpScoreTree = new double [cumulative_element_count];\n\n    for (unsigned int i = 0; i < mTreeElementCount; ++i)\n    {\n        mpIndexTree[i] = targetFeatureIndex;\n        mpScoreTree[i] = 0;\n    }\n}\n\nFilter::~Filter()\n{\n    delete[] mpStartingIndexPerLevel;\n    delete[] mpIndexTree;\n    delete[] mpScoreTree;\n}\n\nvoid const\nFilter::build()\n{\n    for (unsigned int level = 0; level < mLevelCount; ++level)\n    {\n        unsigned int const parent_count = mpStartingIndexPerLevel[level + 1]\n                - mpStartingIndexPerLevel[level];\n\n\n#ifdef _OPENMP\n#pragma omp parallel for schedule(dynamic)\n#endif \n        for (unsigned int parent = 0; parent < parent_count; ++parent)\n            placeElements(\n                    mpStartingIndexPerLevel[level + 1] + (parent * mpChildrenCountPerLevel[level]),\n                    mpChildrenCountPerLevel[level], level + 1);\n    }\n}\n\n/* inline */unsigned int const\nFilter::getParentAbsoluteIndex(unsigned int const absoluteIndex, unsigned int const level) const\n{\n    return (absoluteIndex - mpStartingIndexPerLevel[level]) / mpChildrenCountPerLevel[level - 1]\n            + mpStartingIndexPerLevel[level - 1];\n}\n\nvoid const\nFilter::getSolutions(int* const solutions) const\n{\n    unsigned int counter = 0;\n\n    for (unsigned int end_element_absolute_index = mTreeElementCount - 1;\n            end_element_absolute_index >= mpStartingIndexPerLevel[mLevelCount];\n            --end_element_absolute_index)\n    {\n        unsigned int element_absolute_index = end_element_absolute_index;\n\n        for (unsigned int level = mLevelCount; level > 0; --level)\n        {\n            solutions[counter++] = mpIndexTree[element_absolute_index];\n            element_absolute_index = getParentAbsoluteIndex(element_absolute_index, level);\n        }\n    }\n}\n\nvoid const\nFilter::getScores(double* const scores) const\n{\n    unsigned int counter = 0;\n\n    for (unsigned int end_element_absolute_index = mTreeElementCount - 1;\n            end_element_absolute_index >= mpStartingIndexPerLevel[mLevelCount];\n            --end_element_absolute_index)\n    {\n        unsigned int element_absolute_index = end_element_absolute_index;\n\n        for (unsigned int level = mLevelCount; level > 0; --level)\n        {\n            scores[counter++] = mpScoreTree[element_absolute_index];\n            element_absolute_index = getParentAbsoluteIndex(element_absolute_index, level);\n        }\n    }\n}\n\nbool const\nFilter::hasAncestorByFeatureIndex(unsigned int const absoluteIndex, unsigned int const featureIndex,\n        unsigned int level) const\n{\n    // This function only considers the ancestry of the putative absolute/featureIndex\n\n    unsigned int parent_absolute_index = absoluteIndex;\n\n    for (unsigned int i = level; i > 0; --i)\n    {\n        parent_absolute_index = getParentAbsoluteIndex(parent_absolute_index, i);\n\n        if (mpIndexTree[parent_absolute_index] == featureIndex)\n            return true;\n    }\n\n    return false;\n}\n\nbool const\nFilter::isRedundantPath(unsigned int const absoluteIndex, unsigned int const featureIndex,\n        unsigned int const level) const\n{\n    for (unsigned int i = mpStartingIndexPerLevel[level]; i < mpStartingIndexPerLevel[level + 1];\n            ++i)\n    {\n        if (mpIndexTree[i] == mpIndexTree[0])\n            continue;\n\n        unsigned int candidate_absolute_index = absoluteIndex;\n        unsigned int candidate_feature_index = featureIndex;\n\n        bool solution_is_redundant = true;\n\n        for (unsigned int j = level; j > 0; --j)\n        {\n            unsigned int parent_absolute_index = i;\n\n            bool feature_is_redundant = false;\n\n            for (unsigned int k = level; k > 0; --k)\n            {\n                if (mpIndexTree[parent_absolute_index] == candidate_feature_index)\n                {\n                    feature_is_redundant = true;\n                    break;\n                }\n\n                parent_absolute_index = getParentAbsoluteIndex(parent_absolute_index, k);\n            }\n\n            if (!feature_is_redundant)\n            {\n                solution_is_redundant = false;\n                break;\n            }\n\n            candidate_absolute_index = getParentAbsoluteIndex(candidate_absolute_index, j);\n            candidate_feature_index = mpIndexTree[candidate_absolute_index];\n        }\n\n        if (solution_is_redundant)\n            return true;\n    }\n\n    return false;\n}\n\nvoid const\nFilter::placeElements(unsigned int const startingIndex, unsigned int childrenCount,\n        unsigned int const level)\n{   \n    // This function calculates the solutions and scores\n    unsigned int counter = 0;\n    unsigned int const feature_count = mpFeatureInformationMatrix->getRowCount();\n    unsigned int* const p_candidate_feature_indices = new unsigned int[feature_count];\n    unsigned int* const p_order = new unsigned int[feature_count];\n    unsigned int* const p_adaptor = new unsigned int[feature_count];\n    double* const p_candidate_scores = new double[feature_count];\n\n    /*  The reason why the selection does not start from the 0, it is because the package request (temporarily) the input \n    *   dataframe has the fixed selected features in the first several columns\n    */ \n\n    for (unsigned int i = mFixedFeatureCount; i < feature_count; ++i)\n    {   \n        \n        if (hasAncestorByFeatureIndex(startingIndex, i, level))\n            continue;\n        \n        double ancestry_score = 0.;\n        \n        for (int j = 0; j < mFixedFeatureCount; ++j) \n        {\n            double ancestry_score_ij = Math::computeMi(\n                    mpFeatureInformationMatrix->at(i, j));\n            double ancestry_score_ji = Math::computeMi(\n                    mpFeatureInformationMatrix->at(j, i));\n            \n            ancestry_score += std::max(ancestry_score_ij, ancestry_score_ji);\n        }\n\n        \n        if (level > 1)\n        {\n            unsigned int ancestor_absolute_index = startingIndex;\n            \n            // The below for loop is used to compute the redundancy (loops from the top to bottom)\n\n            for (unsigned int j = level; j > 0; --j)\n            {\n                ancestor_absolute_index = getParentAbsoluteIndex(ancestor_absolute_index, j);\n\n                double ancestry_score_ij = Math::computeMi(\n                        mpFeatureInformationMatrix->at(i, mpIndexTree[ancestor_absolute_index]));\n                double ancestry_score_ji = Math::computeMi(\n                        mpFeatureInformationMatrix->at(mpIndexTree[ancestor_absolute_index], i));\n\n                ancestry_score += std::max(ancestry_score_ij, ancestry_score_ji);\n                \n            }\n        }\n\n        double const score = Math::computeMi(mpFeatureInformationMatrix->at(i, mpIndexTree[0]))\n                - (ancestry_score / (level + mFixedFeatureCount));\n\n        if (score == score)\n        {\n            p_order[counter] = counter;\n            p_adaptor[counter] = counter;\n            p_candidate_feature_indices[counter] = i;\n            p_candidate_scores[counter] = score;\n\n            ++counter;\n        }\n    }\n\n    std::sort(p_order, p_order + counter, Math::IndirectComparator(p_candidate_scores, p_adaptor));\n\n#pragma omp critical(filter_element_placement)\n    {\n        unsigned int children_counter = 0;\n        unsigned int i = counter - 1;\n\n        // i < counter depends on the fact that i-- causes an overflow on the unsigned int\n        while (i < counter && children_counter < childrenCount)\n        {\n            unsigned int const index = p_candidate_feature_indices[p_order[i--]];\n\n            if (!isRedundantPath(startingIndex + children_counter, index, level))\n            {\n                mpIndexTree[startingIndex + children_counter++] = index;\n                mpScoreTree[startingIndex + children_counter-1] = p_candidate_scores[p_order[i+1]];\n            }\n        }\n    }\n\n    delete[] p_order;\n    delete[] p_adaptor;\n    delete[] p_candidate_feature_indices;\n    delete[] p_candidate_scores;\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `Filter` class constructor, and how does it initialize the `mpStartingIndexPerLevel` array?",
        "answer": "The `Filter` class constructor initializes various member variables and allocates memory for data structures. It calculates the `mpStartingIndexPerLevel` array, which stores the starting indices for each level in the tree structure. The array is initialized by iterating through the levels, calculating cumulative element counts, and storing the starting index for each level. This array is used for efficient navigation and indexing within the tree structure."
      },
      {
        "question": "Explain the purpose and functionality of the `build()` method in the `Filter` class.",
        "answer": "The `build()` method constructs the filter's tree structure. It iterates through each level of the tree, calling the `placeElements()` method for each parent node to determine and place its child elements. The method uses OpenMP parallelization (`#pragma omp parallel for`) to improve performance on multi-core systems. The `placeElements()` function is responsible for calculating scores, selecting features, and populating the `mpIndexTree` and `mpScoreTree` arrays based on the filter's criteria."
      },
      {
        "question": "How does the `placeElements()` method handle feature selection and score calculation, and what measures does it take to avoid redundancy?",
        "answer": "The `placeElements()` method selects features and calculates scores for child nodes. It considers fixed features, avoids selecting features already present in ancestors, and calculates a score based on mutual information and ancestry. To avoid redundancy, it uses the `hasAncestorByFeatureIndex()` method to check if a feature is already present in the ancestry. It also calculates an ancestry score to penalize features that are similar to those already selected. The `isRedundantPath()` method is called to ensure that the selected features don't create redundant paths in the tree structure. Finally, it sorts the candidate features by score and selects the top-scoring non-redundant features for placement in the tree."
      }
    ],
    "completion_tasks": [
      {
        "partial": "void const\nFilter::getSolutions(int* const solutions) const\n{\n    unsigned int counter = 0;\n\n    for (unsigned int end_element_absolute_index = mTreeElementCount - 1;\n            end_element_absolute_index >= mpStartingIndexPerLevel[mLevelCount];\n            --end_element_absolute_index)\n    {\n        unsigned int element_absolute_index = end_element_absolute_index;\n\n        for (unsigned int level = mLevelCount; level > 0; --level)\n        {\n            // TODO: Fill in the missing code here\n        }\n    }\n}",
        "complete": "void const\nFilter::getSolutions(int* const solutions) const\n{\n    unsigned int counter = 0;\n\n    for (unsigned int end_element_absolute_index = mTreeElementCount - 1;\n            end_element_absolute_index >= mpStartingIndexPerLevel[mLevelCount];\n            --end_element_absolute_index)\n    {\n        unsigned int element_absolute_index = end_element_absolute_index;\n\n        for (unsigned int level = mLevelCount; level > 0; --level)\n        {\n            solutions[counter++] = mpIndexTree[element_absolute_index];\n            element_absolute_index = getParentAbsoluteIndex(element_absolute_index, level);\n        }\n    }\n}"
      },
      {
        "partial": "bool const\nFilter::hasAncestorByFeatureIndex(unsigned int const absoluteIndex, unsigned int const featureIndex,\n        unsigned int level) const\n{\n    unsigned int parent_absolute_index = absoluteIndex;\n\n    for (unsigned int i = level; i > 0; --i)\n    {\n        // TODO: Fill in the missing code here\n    }\n\n    return false;\n}",
        "complete": "bool const\nFilter::hasAncestorByFeatureIndex(unsigned int const absoluteIndex, unsigned int const featureIndex,\n        unsigned int level) const\n{\n    unsigned int parent_absolute_index = absoluteIndex;\n\n    for (unsigned int i = level; i > 0; --i)\n    {\n        parent_absolute_index = getParentAbsoluteIndex(parent_absolute_index, i);\n\n        if (mpIndexTree[parent_absolute_index] == featureIndex)\n            return true;\n    }\n\n    return false;\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/radSensitivitySig.R",
    "language": "R",
    "content": "#' Creates a signature representing the association between gene expression (or\n#' other molecular profile) and radiation dose response, for use in radiation sensitivity\n#' analysis.\n#'\n#' Given a RadioSet of the sensitivity experiment type, and a list of radiation types,\n#' the function will compute a signature for the effect of gene expression on the\n#' molecular profile of a cell. The function returns the estimated coefficient,\n#' the t-stat, the p-value and the false discovery rate associated with that\n#' coefficient, in a 3 dimensional array, with genes in the first direction,\n#' drugs in the second, and the selected return values in the third.\n#'\n#' @examples\n#' data(clevelandSmall)\n#' rad.sensitivity <- radSensitivitySig(clevelandSmall, mDataType=\"rna\",\n#'              nthread=1, features = fNames(clevelandSmall, \"rna\")[1],\n#'              radiation.types=treatmentNames(clevelandSmall))\n#' print(rad.sensitivity)\n#'\n#' @param rSet A \\code{RadioSet} of the perturbation experiment type\n#' @param mDataType \\code{character} which one of the molecular data types to use\n#'   in the analysis, out of dna, rna, rnaseq, snp, cnv\n#' @param radiation.types \\code{character} a vector of radiation.types for which to compute the\n#'   signatures. Should match the names used in the PharmacoSet.\n#' @param features \\code{character} a vector of features for which to compute the\n#'   signatures. Should match the names used in correspondant molecular data in PharmacoSet.\n#' @param nthread \\code{numeric} if multiple cores are available, how many cores\n#'   should the computation be parallelized over?\n#' @param returnValues \\code{character} Which of estimate, t-stat, p-value and fdr\n#'   should the function return for each gene?\n#' @param sensitivity.measure \\code{character} which measure of the radiation\n#'   sensitivity should the function use for its computations? Use the\n#'   sensitivityMeasures function to find out what measures are available for each PSet.\n#' @param molecular.summary.stat What summary statistic should be used to\n#'   summarize duplicates for cell line molecular profile measurements?\n#' @param sensitivity.summary.stat What summary statistic should be used to\n#'   summarize duplicates for cell line sensitivity measurements?\n#' @param sensitivity.cutoff Allows to provide upper and lower bounds to\n#'   sensitivity measures in the cases where the values exceed physical values\n#'   due to numerical or other errors.\n#' @param standardize \\code{character} One of \"SD\", \"rescale\", or \"none\", for the form of standardization of\n#'   the data to use. If \"SD\", the the data is scaled so that SD = 1. If rescale, then the data is scaled so that the 95%\n#'   interquantile range lies in [0,1]. If none no rescaling is done.\n#' @param verbose \\code{boolean} 'TRUE' if the warnings and other infomrative message shoud be displayed\n#' @param ... additional arguments not currently fully supported by the function\n#'\n#' @return \\code{list} a 3D array with genes in the first dimension, radiation.types in the\n#'   second, and return values in the third.\n#'\n#' @export\n#' @importFrom parallel detectCores splitIndices\nradSensitivitySig <- function(rSet,\n mDataType,\n radiation.types,\n features,\n sensitivity.measure = \"AUC_recomputed\",\n molecular.summary.stat = c(\"mean\", \"median\", \"first\", \"last\", \"or\", \"and\"),\n sensitivity.summary.stat = c(\"mean\", \"median\", \"first\", \"last\"),\n returnValues = c(\"estimate\", \"pvalue\", \"fdr\"),\n sensitivity.cutoff=NA,\n standardize = c(\"SD\", \"rescale\", \"none\"),\n nthread = 1,\n verbose=TRUE, ...) {\n\n  ### This function needs to: Get a table of AUC values per cell line / drug\n  ### Be able to recompute those values on the fly from raw data if needed to change concentration\n  ### Be able to choose different summary methods on fly if needed (need to add annotation to table to tell what summary\n  #   method previously used)\n  ### Be able to extract genomic data\n  ### Run rankGeneDrugSens in parallel at the drug level\n  ### Return matrix as we had before\n\n  molecular.summary.stat <- match.arg(molecular.summary.stat)\n  sensitivity.summary.stat <- match.arg(sensitivity.summary.stat)\n  standardize <- match.arg(standardize)\n\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  dots <- list(...)\n  ndots <- length(dots)\n\n  if (!all(sensitivity.measure %in% colnames(sensitivityProfiles(rSet)))) {\n    stop (sprintf(\"Invalid sensitivity measure for %s, choose among: %s\",\n                  annotation(rSet)$name, paste(colnames(sensitivityProfiles(rSet)),\n                                              collapse=\", \")))\n  }\n\n  if (!(mDataType %in% names(molecularProfilesSlot(rSet)))) {\n    stop (sprintf(\"Invalid mDataType for %s, choose among: %s\",\n                  annotation(rSet)$name, paste(names(molecularProfilesSlot(rSet)),\n                                              collapse=\", \")))\n  }\n  switch(S4Vectors::metadata(molecularProfilesSlot(rSet)[[mDataType]])$annotation,\n    \"mutation\" = {\n      if (!is.element(molecular.summary.stat, c(\"or\", \"and\"))) {\n        stop(\"Molecular summary statistic for mutation must be either 'or' or 'and'\")\n      }\n    },\n    \"fusion\" = {\n      if (!is.element(molecular.summary.stat, c(\"or\", \"and\"))) {\n        stop(\"Molecular summary statistic for fusion must be either 'or' or 'and'\")\n      }\n    },\n    \"rna\" = {\n      if (!is.element(molecular.summary.stat, c(\"mean\", \"median\", \"first\", \"last\"))) {\n        stop(\"Molecular summary statistic for rna must be either 'mean', 'median', 'first' or 'last'\")\n      }\n    },\n    \"cnv\" = {\n      if (!is.element(molecular.summary.stat, c(\"mean\", \"median\", \"first\", \"last\"))) {\n        stop (\"Molecular summary statistic for cnv must be either 'mean', 'median', 'first' or 'last'\")\n      }\n    },\n    \"rnaseq\" = {\n      if (!is.element(molecular.summary.stat, c(\"mean\", \"median\", \"first\", \"last\"))) {\n        stop (\"Molecular summary statistic for rna must be either 'mean', 'median', 'first' or 'last'\")\n      }},\n      stop (sprintf(\"No summary statistic for %s has been implemented yet\", S4Vectors::metadata(molecularProfilesSlot(rSet)[[mDataType]])$annotation))\n      )\n\n  if (!is.element(sensitivity.summary.stat, c(\"mean\", \"median\", \"first\", \"last\"))) {\n    stop (\"Sensitivity summary statistic for sensitivity must be either 'mean', 'median', 'first' or 'last'\")\n  }\n\n  if (missing(radiation.types)){\n    radiation.types <- treatmentNames(rSet)\n  }\n\n  availcore <- parallel::detectCores()\n  if ( nthread > availcore) {\n    nthread <- availcore\n  }\n\n  if (missing(features)) {\n    features <- rownames(featureInfo(rSet, mDataType))\n  } else {\n    fix <- is.element(features, rownames(featureInfo(rSet, mDataType)))\n    if (verbose && !all(fix)) {\n      warning (sprintf(\"%i/%i features can be found\", sum(fix), length(features)))\n    }\n    features <- features[fix]\n  }\n\n  if(is.null(dots[[\"sProfiles\"]])){\n    drugpheno.all <- lapply(sensitivity.measure, function(sensitivity.measure) {\n\n      return(t(summarizeSensitivityProfiles(rSet,\n        sensitivity.measure = sensitivity.measure,\n        summary.stat = sensitivity.summary.stat,\n        verbose = verbose)))\n\n    })} else {\n      sProfiles <- dots[[\"sProfiles\"]]\n      drugpheno.all <- list(t(sProfiles))\n    }\n\n    dix <- is.element(radiation.types, do.call(colnames, drugpheno.all))\n    if (verbose && !all(dix)) {\n      warning (sprintf(\"Only %i/%i radiation types can be found\", sum(dix), length(radiation.types)))\n    }\n    if (!any(dix)) {\n      stop(\"None of the chosen radiation types were found in the dataset\")\n    }\n    radiation.types <- radiation.types[dix]\n\n    molecularProfilesSlot(rSet)[[mDataType]] <- summarizeMolecularProfiles(object=rSet,\n      mDataType = mDataType,\n      summary.stat = molecular.summary.stat,\n      verbose = verbose)[features, ]\n\n    if(!is.null(dots[[\"mProfiles\"]])) {\n      mProfiles <- dots[[\"mProfiles\"]]\n      SummarizedExperiment::assay(molecularProfilesSlot(rSet)[[mDataType]]) <- mProfiles[features, colnames(molecularProfilesSlot(rSet)[[mDataType]]), drop = FALSE]\n\n    }\n\n    drugpheno.all <- lapply(drugpheno.all, function(x) {x[phenoInfo(rSet, mDataType)[ ,\"sampleid\"], , drop = FALSE]})\n\n    type <- as.factor(sampleInfo(rSet)[phenoInfo(rSet, mDataType)[ ,\"sampleid\"], \"tissueid\"])\n    batch <- phenoInfo(rSet, mDataType)[, \"batchid\"]\n    batch[!is.na(batch) & batch == \"NA\"] <- NA\n    batch <- as.factor(batch)\n    names(batch) <- phenoInfo(rSet, mDataType)[ , \"sampleid\"]\n    batch <- batch[rownames(drugpheno.all[[1]])]\n    if (verbose) {\n      message(\"Computing radiation sensitivity signatures...\")\n    }\n\n    mcres <-  lapply(radiation.types, function(treatmentid, expr, drugpheno, type, batch, standardize, nthread) {\n     res <- NULL\n     for(i in treatmentid) {\n       ## using a linear model (x ~ concentration + cell + batch)\n       dd <- lapply(drugpheno, function(rad) rad[, i])\n       dd <- do.call(cbind, dd)\n       colnames(dd) <- seq_len(ncol(dd))\n       if(!is.na(sensitivity.cutoff)) {\n         dd <- factor(ifelse(dd > sensitivity.cutoff, 1, 0), levels=c(0, 1))\n       }\n       rr <- rankGeneRadSensitivity(data=expr, drugpheno=dd, type=type, batch=batch, single.type=FALSE, standardize=standardize, nthread=nthread, verbose=verbose)\n       res <- c(res, list(rr$all))\n     }\n     names(res) <- treatmentid\n     return(res)\n    }, expr=t(molecularProfiles(rSet, mDataType)[features, , drop=FALSE]), drugpheno=drugpheno.all, type=type, batch=batch, nthread=nthread, standardize=standardize)\n\n    res <- do.call(c, mcres)\n    res <- res[!vapply(res, is.null, logical(1))]\n    drug.sensitivity <- array(NA,\n      dim = c(nrow(featureInfo(rSet, mDataType)[features,, drop=FALSE]),\n        length(res), ncol(res[[1]])),\n      dimnames = list(rownames(featureInfo(rSet, mDataType)[features,]), names(res), colnames(res[[1]])))\n    for(j in seq_len(ncol(res[[1]]))) {\n      ttt <- unlist(lapply(res, function(x, j, k) {\n        xx <- array(NA, dim = length(k), dimnames = list(k))\n        xx[rownames(x)] <- x[ , j, drop=FALSE]\n        return (xx)\n      },\n      j = j,\n      k = rownames(featureInfo(rSet, mDataType)[features,, drop = FALSE])))\n      drug.sensitivity[rownames(featureInfo(rSet, mDataType)[features,, drop = FALSE]), names(res), j] <- ttt\n    }\n\n    drug.sensitivity <- RadioSig(drug.sensitivity, RSetName = name(rSet), Call =\"as.character(match.call())\", SigType='Sensitivity')\n\n    return(drug.sensitivity)\n  }\n",
    "qa_pairs": [
      {
        "question": "What is the main purpose of the `radSensitivitySig` function?",
        "answer": "The main purpose of the `radSensitivitySig` function is to create a signature representing the association between gene expression (or other molecular profile) and radiation dose response for use in radiation sensitivity analysis. It computes a signature for the effect of gene expression on the molecular profile of a cell, returning estimated coefficients, t-stats, p-values, and false discovery rates for genes across different radiation types."
      },
      {
        "question": "How does the function handle different types of molecular data?",
        "answer": "The function handles different types of molecular data through the `mDataType` parameter and uses appropriate summary statistics based on the data type. For example, it uses 'or' or 'and' for mutation and fusion data, while 'mean', 'median', 'first', or 'last' are used for RNA, CNV, and RNAseq data. The function checks the validity of the chosen summary statistic for each data type and throws an error if an incompatible statistic is selected."
      },
      {
        "question": "How does the function support parallel processing, and what precautions does it take?",
        "answer": "The function supports parallel processing through the `nthread` parameter, which determines how many cores should be used for computation. It uses the `parallel::detectCores()` function to check the available cores and adjusts the `nthread` value if it exceeds the available cores. The function also sets multicore options at the beginning and uses `on.exit()` to restore the original options when the function exits, ensuring that global settings are not permanently altered."
      }
    ],
    "completion_tasks": null,
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/Matrix.cpp",
    "language": "cpp",
    "content": "#include \"Matrix.h\"\n\nMatrix::Matrix(unsigned int const rowCount, unsigned int const columnCount) :\n        mpData(new double[rowCount * columnCount]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(\n                true)\n{\n\n}\n\n/* explicit */\nMatrix::Matrix(unsigned int const size, unsigned int const rowCount, unsigned int const columnCount) :\n        mpData(new double[size]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(\n                true)\n{\n\n}\n\n/* explicit */\nMatrix::Matrix(double* const pData, unsigned int const rowCount, unsigned int const columnCount) :\n        mpData(pData), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(false)\n{\n\n}\n\n/* virtual */\nMatrix::~Matrix()\n{\n    if (mHasAllocation)\n        delete[] mpData;\n}\n\n/* virtual */double&\nMatrix::at(unsigned int const i, unsigned int const j)\n{\n    return mpData[(j * mRowCount) + i];\n}\n\n/* virtual */double const&\nMatrix::at(unsigned int const i, unsigned int const j) const\n{\n    return mpData[(j * mRowCount) + i];\n}\n\nunsigned int const\nMatrix::getColumnCount() const\n{\n    return mColumnCount;\n}\n\nunsigned int const\nMatrix::getRowCount() const\n{\n    return mRowCount;\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'mHasAllocation' member variable in the Matrix class, and how is it used?",
        "answer": "The 'mHasAllocation' member variable is a boolean flag that indicates whether the Matrix object owns the memory it's using. It's set to true when the Matrix allocates its own memory (in the first two constructors) and false when it's given a pointer to existing data (in the third constructor). This flag is used in the destructor to determine whether the object should delete the memory it's using. If mHasAllocation is true, the destructor calls delete[] on mpData; if it's false, it doesn't, preventing the deletion of memory that might be owned by another part of the program."
      },
      {
        "question": "How does the Matrix class handle element access, and why might the implementation be problematic for certain use cases?",
        "answer": "The Matrix class handles element access through the 'at' method, which takes row (i) and column (j) indices. The element is accessed using the formula mpData[(j * mRowCount) + i]. This implementation assumes column-major order, where elements in the same column are stored contiguously in memory. While this works, it might be problematic for certain use cases because: 1) It's not the most common convention (row-major order is more typical in C++), which could lead to confusion. 2) It may result in poor cache performance when iterating over the matrix in row-major order, which is a common operation. 3) The method doesn't include bounds checking, which could lead to undefined behavior if invalid indices are provided."
      },
      {
        "question": "What is the purpose of declaring some of the Matrix class methods as 'virtual', and what implications does this have for the class design?",
        "answer": "The 'virtual' keyword is used for the destructor and the 'at' methods in the Matrix class. This indicates that these methods can be overridden in derived classes. The implications of this design choice are: 1) It allows for polymorphic behavior, meaning derived classes can provide their own implementations of these methods. 2) It enables proper cleanup of derived class resources when deleting a Matrix pointer to a derived class object. 3) It suggests that the Matrix class is designed to be a base class in a hierarchy, potentially supporting different types of matrices or matrix operations in derived classes. 4) It introduces a small performance overhead due to the use of virtual function tables. 5) It requires that users of this class be aware of the potential for dynamic dispatch when calling these methods."
      }
    ],
    "completion_tasks": [
      {
        "partial": "class Matrix {\nprivate:\n    double* mpData;\n    unsigned int mRowCount;\n    unsigned int mColumnCount;\n    bool mHasAllocation;\n\npublic:\n    Matrix(unsigned int rowCount, unsigned int columnCount);\n    Matrix(unsigned int size, unsigned int rowCount, unsigned int columnCount);\n    Matrix(double* pData, unsigned int rowCount, unsigned int columnCount);\n    virtual ~Matrix();\n\n    virtual double& at(unsigned int i, unsigned int j);\n    virtual double const& at(unsigned int i, unsigned int j) const;\n\n    unsigned int getColumnCount() const;\n    unsigned int getRowCount() const;\n};",
        "complete": "class Matrix {\nprivate:\n    double* mpData;\n    unsigned int mRowCount;\n    unsigned int mColumnCount;\n    bool mHasAllocation;\n\npublic:\n    Matrix(unsigned int rowCount, unsigned int columnCount)\n        : mpData(new double[rowCount * columnCount]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true) {}\n\n    Matrix(unsigned int size, unsigned int rowCount, unsigned int columnCount)\n        : mpData(new double[size]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true) {}\n\n    Matrix(double* pData, unsigned int rowCount, unsigned int columnCount)\n        : mpData(pData), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(false) {}\n\n    virtual ~Matrix() {\n        if (mHasAllocation)\n            delete[] mpData;\n    }\n\n    virtual double& at(unsigned int i, unsigned int j) {\n        return mpData[(j * mRowCount) + i];\n    }\n\n    virtual double const& at(unsigned int i, unsigned int j) const {\n        return mpData[(j * mRowCount) + i];\n    }\n\n    unsigned int getColumnCount() const {\n        return mColumnCount;\n    }\n\n    unsigned int getRowCount() const {\n        return mRowCount;\n    }\n};"
      },
      {
        "partial": "#include \"Matrix.h\"\n\nMatrix::Matrix(unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(new double[rowCount * columnCount]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true)\n{\n}\n\nMatrix::Matrix(unsigned int const size, unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(new double[size]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true)\n{\n}\n\nMatrix::Matrix(double* const pData, unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(pData), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(false)\n{\n}\n\nMatrix::~Matrix()\n{\n    // Implement destructor\n}\n\ndouble& Matrix::at(unsigned int const i, unsigned int const j)\n{\n    // Implement at() method\n}\n\ndouble const& Matrix::at(unsigned int const i, unsigned int const j) const\n{\n    // Implement const at() method\n}\n\nunsigned int const Matrix::getColumnCount() const\n{\n    // Implement getColumnCount()\n}\n\nunsigned int const Matrix::getRowCount() const\n{\n    // Implement getRowCount()\n}",
        "complete": "#include \"Matrix.h\"\n\nMatrix::Matrix(unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(new double[rowCount * columnCount]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true)\n{\n}\n\nMatrix::Matrix(unsigned int const size, unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(new double[size]), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(true)\n{\n}\n\nMatrix::Matrix(double* const pData, unsigned int const rowCount, unsigned int const columnCount)\n    : mpData(pData), mRowCount(rowCount), mColumnCount(columnCount), mHasAllocation(false)\n{\n}\n\nMatrix::~Matrix()\n{\n    if (mHasAllocation)\n        delete[] mpData;\n}\n\ndouble& Matrix::at(unsigned int const i, unsigned int const j)\n{\n    return mpData[(j * mRowCount) + i];\n}\n\ndouble const& Matrix::at(unsigned int const i, unsigned int const j) const\n{\n    return mpData[(j * mRowCount) + i];\n}\n\nunsigned int const Matrix::getColumnCount() const\n{\n    return mColumnCount;\n}\n\nunsigned int const Matrix::getRowCount() const\n{\n    return mRowCount;\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/CoreSet-utils.R",
    "language": "R",
    "content": "#' @include CoreSet-class.R CoreSet-accessors.R\n#' @importFrom BiocGenerics match %in%\nNULL\n\n.local_class <- 'CoreSet'\n.local_data <- 'clevelandSmall_cSet'\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n\n# ===================================\n# Utility Method Documentation Object\n# -----------------------------------\n\n\n#' @noRd\n.docs_CoreSet_utils <- function(...) .parseToRoxygen(\n    \"\n    @title Utility methods for a `{class_}` object.\n\n    @description\n    Documentation for utility methods for a `{class_}` object, such as\n    set operations like subset and intersect. See @details for information\n    on different types of methods and their implementations.\n\n    @param x A `{class_}` object.\n    @param samples `character()` vector of sample names. Must be valid rownames\n    from `sampleInfo(x)`.\n    @param treatments `character()` vector of treatment names. Must be valid\n    rownames from `treatmentInfo(x)`. This method does not work with\n    `CoreSet` objects yet.\n    @param features `character()` vector of feature names. Must be valid feature\n    names for a given `mDataType`\n    @param mDataTypes `character()` One or more molecular data types to\n        to subset features by. Must be valid rownames for the selected\n        SummarizedExperiment mDataTypes.\n\n    @return See details.\n    \",\n    ...\n)\n\n\n#' @name CoreSet-utils\n#' @eval .docs_CoreSet_utils(class_=.local_class)\n#' @eval .parseToRoxygen(\"@examples data({data_})\", data_=.local_data)\nNULL\n\n\n# ======================================\n# Subset Methods\n# --------------------------------------\n\n\n## ===================\n## ---- subsetBySample\n## -------------------\n\n\n#' @export\nsetGeneric('subsetBySample', function(x, samples, ...)\n    standardGeneric('subsetBySample'))\n\n#' @noRd\n.docs_CoreSet_subsetBySample <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    ## subset methods\n    __subsetBySample__: Subset a `{class_}` object by sample identifier.\n    - value: a `{class_}` object containing only `samples`.\n\n    @examples\n\n    ## subset methods\n\n    ### subsetBySample\n    samples <- sampleInfo({data_})$sampleid[seq_len(10)]\n    {data_}_sub <- subsetBySample({data_}, samples)\n\n    @md\n    @aliases subsetBySample subsetBySample,CoreSet-method\n    @exportMethod subsetBySample\n    \",\n    ...\n)\n\n#' @rdname CoreSet-utils\n#' @eval .docs_CoreSet_subsetBySample(class_=.local_class, data_=.local_data)\nsetMethod('subsetBySample', signature('CoreSet'), function(x, samples) {\n\n    funContext <- .S4MethodContext('subsetBySample', 'CoreSet')\n\n    sampleNames <- rownames(sampleInfo(x))\n    if (!all(samples %in% sampleNames)) {\n        .warning(funContext, 'Samples missing from ', class(x)[1], ': ',\n            setdiff(samples, sampleNames), '! Please ensure all specified\n            samples are valid rownames of sampleInfo(x). Proceeding with\n            the valid samples only.')\n        samples <- union(samples, sampleNames)\n    }\n\n    # -- molecularProfiles slot\n    molecSlot <- molecularProfilesSlot(x)\n    molecularProfilesSlot(x) <-\n        .subsetMolecularProfilesBySample(molecSlot, samples)\n\n    # -- sensitivity slot\n    sensSlot <- treatmentResponse(x)\n    treatmentResponse(x) <- .subsetSensitivityBySample(sensSlot, samples)\n\n    # -- perturbatiion slot\n    ##TODO:: do we still need this?\n    \n    # -- curation slot\n    sampleCuration <- curation(x)$sample\n    curation(x)$sample <- sampleCuration[rownames(sampleCuration) %in% samples, ]\n\n    # -- sample slot\n    sampleInf <- sampleInfo(x)\n    sampleInfo(x) <- sampleInf[rownames(sampleInf) %in% samples, ]\n\n    # -- check object is still valid and return\n    tryCatch(checkCsetStructure(x), error = function(e) {})\n\n    return(x)\n})\n\n.subsetMolecularProfilesBySample <- function(slotData, samples) {\n    funContext <- .funContext(':::.subsetMolecularProfilesBySample')\n    if (is(slotData, 'MultiAssayExperiment')) {\n        hasSamples <- colData(slotData)$sampleid %in% samples\n        if (!all(hasSamples)) .warning(funContext, 'Some specified samples are\n            not present in `molecularProfilesSlot(x)`')\n        molecProfs <- slotData[, hasSamples]\n    } else {\n        SEcolData <- lapply(slotData, colData)\n        SEsamples <- lapply(SEcolData, FUN=`[[`, i='sampleid')\n        hasSEsamples <- lapply(SEsamples, FUN=`%in%`, samples)\n        molecProfs <- mapply(`[`, x=slotData, j=hasSEsamples)\n    }\n    return(molecProfs)\n}\n\n.subsetSensitivityBySample <- function(slotData, samples) {\n    funContext <- .funContext(':::.subsetSensitivityBySample')\n    if (is(slotData, 'LongTable')) {\n        slotData <- slotData[, samples]\n    } else {\n        keepSamples <- slotData$info$sampleid %in% samples\n        slotData$profiles <- slotData$profiles[keepSamples, ]\n        slotData$raw <- slotData$raw[keepSamples, , ]\n        slotData$n <- slotData$n[rownames(slotData$n) %in% samples, ]\n        slotData$info <- slotData$info[keepSamples, ]\n    }\n    return(slotData)\n}\n\n## ======================\n## ---- subsetByTreatment\n## ----------------------\n\n#' @export\nsetGeneric('subsetByTreatment', function(x, treatments, ...)\n    standardGeneric('subsetByTreatment'))\n\n#' @noRd\n.docs_CoreSet_subsetByTreatment <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    ## subset methods\n    __subsetByTreatment__: Subset a `{class_}` object by treatment identifier.\n    - value: a `{class_}` object containing only `treatments`.\n\n    @examples\n\n    ## subset methods\n\n    ### subsetByTreatment\n    #treatments <- {treatment_}Info({data_})${treatment_}id[seq_len(10)]\n    #{data_}_sub <- subsetByTreatment({data_}, treatments)\n\n    @md\n    @aliases subsetByTreatment subsetByTreatment,{class_}-method\n    @exportMethod subsetByTreatment\n    \",\n    ...\n)\n\n#' @rdname CoreSet-utils\n#' @eval CoreGx:::.docs_CoreSet_subsetByTreatment(class_=.local_class,\n#' data_=.local_data, treatment_='treatment')\nsetMethod('subsetByTreatment', signature('CoreSet'),\n        function(x, treatments) {\n    funContext <- .S4MethodContext('subsetByTreatment', 'PharmacoSet')\n    treatmentType <- switch(class(x)[1],\n        'PharmacoSet'='drug',\n        'ToxicoSet'='drug',\n        'RadioSet'='radiation',\n        'CoreSet'=return(data.frame())\n    )\n    treatmentNames <- rownames(treatmentInfo(x))\n    if (!all(treatments %in% treatmentNames)) {\n        .warning(funContext, 'Treatments missing from ', class(x)[1], ': ',\n            setdiff(treatments, treatmentNames), '! Please ensure all specified\n            treatments are valid rownames of treatmentInfo(x).\n            Proceeding with the valid treatments only.')\n        treatments <- union(treatments, treatmentNames)\n    }\n    # -- sensitivity slot\n    sensSlot <- treatmentResponse(x)\n    treatmentResponse(x) <- .subsetSensitivityByTreatment(sensSlot, treatments,\n        treatmentType=treatmentType)\n\n    # -- perturbation slot\n    ## TODO: do we still need this?\n\n    # -- curation slot\n    treatmentCuration <- curation(x)[[treatmentType]]\n    curation(x)[[treatmentType]] <- treatmentCuration[\n        rownames(treatmentCuration) %in% treatments, ]\n\n    # -- treatment slot\n    treatmentInf <- treatmentInfo(x)\n    treatmentInfo(x) <- treatmentInf[rownames(treatmentInf) %in% treatments, ]\n\n    # -- molecularProfiles\n    # deal with potential loss of samples when subsetting by treatment\n    keepSamples <- sampleNames(x)\n    molecSlot <- molecularProfilesSlot(x)\n    molecularProfilesSlot(x) <- .subsetMolecularProfilesBySample(molecSlot,\n        keepSamples)\n\n    # -- check object is still valid and return\n    tryCatch(checkCsetStructure(x), error = function(e) {})\n\n    return(x)\n})\n\n.subsetSensitivityByTreatment <- function(slotData, treatments,\n        treatmentType) {\n    funContext <- .funContext(':::.subsetSensitivityByTreatment')\n    treatmentId <- if (treatmentType == 'radiation')\n        paste0(treatmentType, '.type') else paste0(treatmentType, 'id')\n    if (is(slotData, 'LongTable')) {\n        slotData <- slotData[treatments, ]\n    } else {\n        keepTreatments <- slotData$info[[treatmentId]] %in% treatments\n        slotData$profiles <- slotData$profiles[keepTreatments, ]\n        slotData$raw <- slotData$raw[keepTreatments, , ]\n        slotData$info <- slotData$info[keepTreatments, ]\n        slotData$n <- slotData$n[, colnames(slotData$n) %in% treatments]\n    }\n    return(slotData)\n}\n\n\n## ====================\n## ---- subsetByFeature\n## --------------------\n\n\n#' @export\nsetGeneric('subsetByFeature', function(x, features, ...)\n    standardGeneric('subsetByFeature'))\n\n#' @noRd\n.docs_CoreSet_subsetByFeature <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    ## subset methods\n    __subsetByFeature__: Subset a `{class_}` object by molecular feature\n        identifier.\n    - value: a `{class_}` object containing only `features`.\n\n    @examples\n\n    ## subset methods\n\n    ### subsetByFeature\n    features <- fNames({data_}, 'rna')[seq_len(5)]\n    {data_}_sub <- subsetByFeature({data_}, features, 'rna')\n\n    @md\n    @aliases subsetByFeature subsetByFeature,{class_}-method\n    @importFrom MultiAssayExperiment MultiAssayExperiment\n    @exportMethod subsetByFeature\n    \",\n    ...\n)\n\n#' @rdname CoreSet-utils\n#' @eval .docs_CoreSet_subsetByFeature(class_=.local_class, data_=.local_data)\nsetMethod('subsetByFeature', signature(x='CoreSet'),\n        function(x, features, mDataTypes) {\n    slotData <- molecularProfilesSlot(x)\n    MAE <- if (!is(slotData, 'MultiAssayExperiment'))\n        MultiAssayExperiment(slotData) else slotData\n    if (missing(mDataTypes)) mDataTypes <- names(MAE)\n    suppressMessages({\n        suppressWarnings({\n            MAE_sub <- MAE[, , mDataTypes]\n        })\n    })\n    keepFeatures <- rownames(MAE_sub) %in% features\n    subsetMAE <- MAE[keepFeatures, drop=TRUE]\n    newSlotData <- if (is(slotData, 'MultiAssayExperiment')) subsetMAE else\n        as.list(experiments(subsetMAE))\n    molecularProfilesSlot(x) <- newSlotData\n    ## TODO:: What if this drops samples from the PSet?\n    return(x)\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.docs_CoreSet_utils` function in this code snippet?",
        "answer": "The `.docs_CoreSet_utils` function is used to generate dynamic documentation for utility methods of a `CoreSet` object. It creates a Roxygen2 documentation string that describes the utility methods, their parameters, and return values. This function is used to maintain consistent and easily updatable documentation for the `CoreSet` class."
      },
      {
        "question": "How does the `subsetBySample` method handle invalid sample names?",
        "answer": "The `subsetBySample` method checks if all provided sample names are valid by comparing them to the rownames of `sampleInfo(x)`. If any invalid sample names are found, it issues a warning message and proceeds with only the valid samples. It uses the `union` function to ensure that only existing samples are used for subsetting, effectively ignoring any invalid sample names."
      },
      {
        "question": "What is the purpose of the `.subsetMolecularProfilesBySample` function, and how does it handle different types of input data?",
        "answer": "The `.subsetMolecularProfilesBySample` function is used to subset molecular profiles data by sample. It handles two types of input data: 1) If the input is a `MultiAssayExperiment` object, it subsets the data using column names. 2) If the input is not a `MultiAssayExperiment`, it assumes the data is a list of `SummarizedExperiment` objects and subsets each element individually. This function ensures that molecular profile data is correctly subset regardless of its structure."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('subsetBySample', signature('CoreSet'), function(x, samples) {\n    funContext <- .S4MethodContext('subsetBySample', 'CoreSet')\n\n    sampleNames <- rownames(sampleInfo(x))\n    if (!all(samples %in% sampleNames)) {\n        .warning(funContext, 'Samples missing from ', class(x)[1], ': ',\n            setdiff(samples, sampleNames), '! Please ensure all specified\n            samples are valid rownames of sampleInfo(x). Proceeding with\n            the valid samples only.')\n        samples <- union(samples, sampleNames)\n    }\n\n    # -- molecularProfiles slot\n    molecSlot <- molecularProfilesSlot(x)\n    molecularProfilesSlot(x) <-\n        .subsetMolecularProfilesBySample(molecSlot, samples)\n\n    # -- sensitivity slot\n    sensSlot <- treatmentResponse(x)\n    treatmentResponse(x) <- .subsetSensitivityBySample(sensSlot, samples)\n\n    # -- curation slot\n    sampleCuration <- curation(x)$sample\n    curation(x)$sample <- sampleCuration[rownames(sampleCuration) %in% samples, ]\n\n    # -- sample slot\n    sampleInf <- sampleInfo(x)\n    sampleInfo(x) <- sampleInf[rownames(sampleInf) %in% samples, ]\n\n    # -- check object is still valid and return\n    tryCatch(checkCsetStructure(x), error = function(e) {})\n\n    return(x)\n})",
        "complete": "setMethod('subsetBySample', signature('CoreSet'), function(x, samples) {\n    funContext <- .S4MethodContext('subsetBySample', 'CoreSet')\n\n    sampleNames <- rownames(sampleInfo(x))\n    if (!all(samples %in% sampleNames)) {\n        .warning(funContext, 'Samples missing from ', class(x)[1], ': ',\n            setdiff(samples, sampleNames), '! Please ensure all specified\n            samples are valid rownames of sampleInfo(x). Proceeding with\n            the valid samples only.')\n        samples <- intersect(samples, sampleNames)\n    }\n\n    # -- molecularProfiles slot\n    molecSlot <- molecularProfilesSlot(x)\n    molecularProfilesSlot(x) <-\n        .subsetMolecularProfilesBySample(molecSlot, samples)\n\n    # -- sensitivity slot\n    sensSlot <- treatmentResponse(x)\n    treatmentResponse(x) <- .subsetSensitivityBySample(sensSlot, samples)\n\n    # -- curation slot\n    sampleCuration <- curation(x)$sample\n    curation(x)$sample <- sampleCuration[rownames(sampleCuration) %in% samples, , drop=FALSE]\n\n    # -- sample slot\n    sampleInf <- sampleInfo(x)\n    sampleInfo(x) <- sampleInf[rownames(sampleInf) %in% samples, , drop=FALSE]\n\n    # -- check object is still valid and return\n    validObject(x)\n\n    return(x)\n})"
      },
      {
        "partial": "setMethod('subsetByFeature', signature(x='CoreSet'),\n        function(x, features, mDataTypes) {\n    slotData <- molecularProfilesSlot(x)\n    MAE <- if (!is(slotData, 'MultiAssayExperiment'))\n        MultiAssayExperiment(slotData) else slotData\n    if (missing(mDataTypes)) mDataTypes <- names(MAE)\n    suppressMessages({\n        suppressWarnings({\n            MAE_sub <- MAE[, , mDataTypes]\n        })\n    })\n    keepFeatures <- rownames(MAE_sub) %in% features\n    subsetMAE <- MAE[keepFeatures, drop=TRUE]\n    newSlotData <- if (is(slotData, 'MultiAssayExperiment')) subsetMAE else\n        as.list(experiments(subsetMAE))\n    molecularProfilesSlot(x) <- newSlotData\n    return(x)\n})",
        "complete": "setMethod('subsetByFeature', signature(x='CoreSet'),\n        function(x, features, mDataTypes) {\n    slotData <- molecularProfilesSlot(x)\n    MAE <- if (!is(slotData, 'MultiAssayExperiment'))\n        MultiAssayExperiment(slotData) else slotData\n    if (missing(mDataTypes)) mDataTypes <- names(MAE)\n    MAE_sub <- MAE[, , mDataTypes, drop=FALSE]\n    keepFeatures <- rownames(MAE_sub) %in% features\n    subsetMAE <- MAE_sub[keepFeatures, , drop=FALSE]\n    newSlotData <- if (is(slotData, 'MultiAssayExperiment')) subsetMAE else\n        as.list(experiments(subsetMAE))\n    molecularProfilesSlot(x) <- newSlotData\n    validObject(x)\n    return(x)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/linearQuadratic.R",
    "language": "R",
    "content": "# Linear quadratic\n#\n# @param D A vector of drug concentrations\n# @param pars Parameters (a, b) of the linear model\n# @param SF_as_log Boolen indicating whether survival fraction is logged\n#\n# @return \\code{numeric} The survival fraction for a linear quadratic model\n.linearQuadratic <- function(D, pars, SF_as_log = TRUE) {\n  SF <- -(pars[[1]] * D + pars[[2]] * D ^ 2)\n  if (!SF_as_log) {\n    SF <- exp(SF)\n  }\n  return(SF)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.linearQuadratic` function and what are its input parameters?",
        "answer": "The `.linearQuadratic` function calculates the survival fraction for a linear quadratic model. It takes three input parameters: 'D' (a vector of drug concentrations), 'pars' (a list of parameters 'a' and 'b' for the linear model), and 'SF_as_log' (a boolean indicating whether the survival fraction should be returned as a log value, defaulting to TRUE)."
      },
      {
        "question": "How does the function calculate the survival fraction (SF) and what does the equation represent?",
        "answer": "The function calculates the survival fraction using the equation: SF = -(pars[[1]] * D + pars[[2]] * D^2). This represents a linear quadratic model where pars[[1]] is the linear coefficient (a) and pars[[2]] is the quadratic coefficient (b). The negative sign indicates that higher drug concentrations (D) lead to lower survival fractions."
      },
      {
        "question": "What is the purpose of the `SF_as_log` parameter, and how does it affect the function's output?",
        "answer": "The `SF_as_log` parameter determines whether the survival fraction is returned as a log value or as a regular probability. If `SF_as_log` is TRUE (default), the function returns the log survival fraction. If it's FALSE, the function applies exp(SF) to convert the log survival fraction to a regular probability before returning it. This allows flexibility in how the results are used or interpreted."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Linear quadratic\n#\n# @param D A vector of drug concentrations\n# @param pars Parameters (a, b) of the linear model\n# @param SF_as_log Boolen indicating whether survival fraction is logged\n#\n# @return \\code{numeric} The survival fraction for a linear quadratic model\n.linearQuadratic <- function(D, pars, SF_as_log = TRUE) {\n  SF <- -(pars[[1]] * D + pars[[2]] * D ^ 2)\n  # Complete the function\n}",
        "complete": "# Linear quadratic\n#\n# @param D A vector of drug concentrations\n# @param pars Parameters (a, b) of the linear model\n# @param SF_as_log Boolen indicating whether survival fraction is logged\n#\n# @return \\code{numeric} The survival fraction for a linear quadratic model\n.linearQuadratic <- function(D, pars, SF_as_log = TRUE) {\n  SF <- -(pars[[1]] * D + pars[[2]] * D ^ 2)\n  if (!SF_as_log) SF <- exp(SF)\n  SF\n}"
      },
      {
        "partial": "# Linear quadratic\n#\n# @param D A vector of drug concentrations\n# @param pars Parameters (a, b) of the linear model\n# @param SF_as_log Boolen indicating whether survival fraction is logged\n#\n# @return \\code{numeric} The survival fraction for a linear quadratic model\n.linearQuadratic <- function(D, pars, SF_as_log = TRUE) {\n  # Complete the function body\n}",
        "complete": "# Linear quadratic\n#\n# @param D A vector of drug concentrations\n# @param pars Parameters (a, b) of the linear model\n# @param SF_as_log Boolen indicating whether survival fraction is logged\n#\n# @return \\code{numeric} The survival fraction for a linear quadratic model\n.linearQuadratic <- function(D, pars, SF_as_log = TRUE) {\n  SF <- -(pars[[1]] * D + pars[[2]] * D ^ 2)\n  if (!SF_as_log) SF <- exp(SF)\n  SF\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/matthewCor.R",
    "language": "R",
    "content": "## Matthews correlatipon coefficient\n## TODO:: Give this function a more descriptive name\n#' Compute a Mathews Correlation Coefficient\n#'\n#' The function computes a Matthews correlation coefficient for two factors\n#' provided to the function. It assumes each factor is a factor of class labels,\n#' and the enteries are paired in order of the vectors.\n#'\n#' Please note: we recommend you call set.seed() before using this function to\n#' ensure the reproducibility of your results. Write down the seed number or\n#' save it in a script if you intend to use the results in a publication.\n#'\n#' @examples\n#' x <- factor(c(1,2,1,2,3,1))\n#' y <- factor(c(2,1,1,1,2,2))\n#' mcc(x,y)\n#'\n#' @param x,y \\code{factor} of the same length with the same number of levels\n#' @param nperm \\code{numeric} number of permutations for significance\n#' estimation. If 0, no permutation testing is done\n#' @param nthread \\code{numeric} can parallelize permutation texting using\n#'   BiocParallels bplapply\n#' @param alternative indicates the alternative hypothesis and must be one of\n#' \u2018\"two.sided\"\u2019, \u2018\"greater\"\u2019 or \u2018\"less\"\u2019.  You can specify just\n#' the initial letter.  \u2018\"greater\"\u2019 corresponds to positive\n#' association, \u2018\"less\"\u2019 to negative association.\n#' @param ... \\code{list} Additional arguments\n#'\n#' @return A list with the MCC as the $estimate, and p value as $p.value\n#' @export\nmcc <- function(x, y, nperm = 1000, nthread = 1, alternative=c(\"two.sided\", \"less\", \"greater\"), ...) {\n    # PARAMETER CHANGE WARNING\n    if (!missing(...)) {\n        if (\"setseed\" %in% names(...)) {\n            warning(\"The setseed parameter has been removed in this release to conform\n              to Bioconductor coding standards. Please call set.seed in your\n              script before running this function.\")\n        }\n    }\n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y)) || (!is.factor(x) || length(levels(x)) < 2) || (!is.factor(y) || length(levels(y)) < 2)) {\n        stop(\"x and y must be factors of the same length with at least two levels\")\n    }\n    if (length(levels(x)) != length(levels(y))) {\n\n        warning(\"The number of levels x and y was different. Taking the union of all class labels.\")\n        levels(x) <- union(levels(x), levels(y))\n        levels(y) <- union(levels(x), levels(y))\n\n    }\n    res <- list(estimate = NA, p.value = NA)\n    ## compute MCC\n    res[[\"estimate\"]] <- .mcc(ct = table(x, y))\n    ## compute significance of MCC using a permutation test\n    if (nperm > 0) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy) {\n            res <- vapply(x, function(x, xx, yy) {\n                xx <- sample(xx)\n                yy <- sample(yy)\n                return(.mcc(ct = table(xx, yy)))\n            }, xx = xx, yy = yy, FUN.VALUE = numeric(1))\n            return(res)\n        }, xx = x, yy = y)\n        mcres <- unlist(mcres)\n        #res[[\"p.value\"]] <- sum(mcres > res[\"estimate\"])/sum(!is.na(mcres))\n        switch(alternative, \"two.sided\" = {\n            if(res[[\"estimate\"]] > 0) {\n                res[[\"p.value\"]] <- 2*sum(res[[\"estimate\"]] <=  mcres )/sum(!is.na(mcres))\n            } else {\n                res[[\"p.value\"]] <- 2*sum(res[[\"estimate\"]] >=  mcres )/sum(!is.na(mcres))\n            }\n        }, \"less\" = {\n            res[[\"p.value\"]] <- sum(res[[\"estimate\"]] >=  mcres )/sum(!is.na(mcres)) \n        }, \"greater\" = {\n            res[[\"p.value\"]] <- sum(res[[\"estimate\"]] <=  mcres )/sum(!is.na(mcres))\n        })\n        if (res[\"p.value\"] == 0) {\n            res[\"p.value\"] <- 1/(nperm + 1)\n        }\n    }\n    return(res)\n}\n\n## Helper functions\n\n\n## Just a lot of math, multiclass MCC\n## https://en.wikipedia.org/wiki/Matthews_correlation_coefficient#Multiclass_case\n.mcc <-\n  function(ct, nbcat=nrow(ct)) {\n    if(nrow(ct) != ncol(ct)) { stop(\"the confusion table should be square!\") }\n\n    ## The following code checks if there would be a division by 0 error in the computation on the Matthew's\n    ## correlation coefficient. In practice, this occurs when there are multiple categories but all predictions end up\n    ## in only one category - in this case, the denominator is 0. This is dealt with by adding a psuedocount to each.\n    ## This is chosen because the mcc of a matrix of 1s is 0, and such should not affect the value in expectation.\n    ## Note this is not necessary when alll entries lie on the diagonal.\n    if( !(sum(ct)==sum(diag(ct))) && ## Check if all entries are on the diagonal. If they are, no adjustment necessary.\n        ((sum(rowSums(ct) == 0) == (nbcat-1)) || ## Otherwise, check if there is entries only in one column or only in one row.\n        (sum(colSums(ct) == 0) == (nbcat-1)))) {\n        ct <- ct + matrix(1, ncol=nbcat, nrow=nbcat)\n      } ### add element to categories if nbcat-1 predictive categories do not contain elements. Not in case where all are correct!\n\n    if (sum(ct, na.rm = TRUE) <= 0) {\n        return(NA)\n    }\n\n    myx <- matrix(TRUE, nrow = nrow(ct), ncol = ncol(ct))\n    diag(myx) <- FALSE\n    if (sum(ct[myx]) == 0) {\n        return(1)\n    }\n    myperf <- 0\n    for (k in seq_len(nbcat)) {\n        for (m in seq_len(nbcat)) {\n            for (l in seq_len(nbcat)) {\n                myperf <- myperf + ((ct[k, k] * ct[m, l]) - (ct[l, k] * ct[k, m]))\n            }\n        }\n    }\n    aa <- 0\n    for (k in seq_len(nbcat)) {\n        cc <- 0\n        for (l in seq_len(nbcat)) {\n            cc <- cc + ct[l, k]\n        }\n        dd <- 0\n        for (f in seq_len(nbcat)) {\n            for (g in seq_len(nbcat)) {\n                if (f != k) {\n                  dd <- dd + ct[g, f]\n                }\n            }\n        }\n        aa <- aa + (cc * dd)\n    }\n    bb <- 0\n    for (k in seq_len(nbcat)) {\n        cc <- 0\n        for (l in seq_len(nbcat)) {\n            cc <- cc + ct[k, l]\n        }\n        dd <- 0\n        for (f in seq_len(nbcat)) {\n            for (g in seq_len(nbcat)) {\n                if (f != k) {\n                  dd <- dd + ct[f, g]\n                }\n            }\n        }\n        bb <- bb + (cc * dd)\n    }\n\n    myperf <- myperf/(sqrt(aa) * sqrt(bb))\n    return(myperf)\n}\n\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mcc` function and what does it return?",
        "answer": "The `mcc` function computes the Matthews Correlation Coefficient (MCC) for two factors. It takes two factors `x` and `y` as input, along with optional parameters for permutation testing. The function returns a list containing two elements: $estimate (the MCC value) and $p.value (the significance of the MCC if permutation testing is performed)."
      },
      {
        "question": "How does the function handle factors with different numbers of levels?",
        "answer": "If the input factors `x` and `y` have different numbers of levels, the function issues a warning and takes the union of all class labels. It then assigns this union of levels to both `x` and `y`, effectively expanding their level sets to include all unique levels from both factors."
      },
      {
        "question": "Explain the purpose of the `.mcc` helper function and how it handles potential division by zero errors.",
        "answer": "The `.mcc` helper function calculates the actual Matthews Correlation Coefficient for a confusion table. To handle potential division by zero errors, it checks if all predictions fall into a single category. If so, it adds a pseudocount of 1 to each cell in the confusion table. This adjustment prevents division by zero while maintaining the expected MCC value of 0 for a matrix of 1s."
      }
    ],
    "completion_tasks": [
      {
        "partial": "mcc <- function(x, y, nperm = 1000, nthread = 1, alternative=c(\"two.sided\", \"less\", \"greater\"), ...) {\n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y)) || (!is.factor(x) || length(levels(x)) < 2) || (!is.factor(y) || length(levels(y)) < 2)) {\n        stop(\"x and y must be factors of the same length with at least two levels\")\n    }\n    if (length(levels(x)) != length(levels(y))) {\n        warning(\"The number of levels x and y was different. Taking the union of all class labels.\")\n        levels(x) <- union(levels(x), levels(y))\n        levels(y) <- union(levels(x), levels(y))\n    }\n    res <- list(estimate = NA, p.value = NA)\n    res[\"estimate\"] <- .mcc(ct = table(x, y))\n    if (nperm > 0) {\n        # TODO: Implement permutation test\n    }\n    return(res)\n}",
        "complete": "mcc <- function(x, y, nperm = 1000, nthread = 1, alternative=c(\"two.sided\", \"less\", \"greater\"), ...) {\n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y)) || (!is.factor(x) || length(levels(x)) < 2) || (!is.factor(y) || length(levels(y)) < 2)) {\n        stop(\"x and y must be factors of the same length with at least two levels\")\n    }\n    if (length(levels(x)) != length(levels(y))) {\n        warning(\"The number of levels x and y was different. Taking the union of all class labels.\")\n        levels(x) <- union(levels(x), levels(y))\n        levels(y) <- union(levels(x), levels(y))\n    }\n    res <- list(estimate = NA, p.value = NA)\n    res[\"estimate\"] <- .mcc(ct = table(x, y))\n    if (nperm > 0) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy) {\n            vapply(x, function(x, xx, yy) {\n                .mcc(ct = table(sample(xx), sample(yy)))\n            }, xx = xx, yy = yy, FUN.VALUE = numeric(1))\n        }, xx = x, yy = y)\n        mcres <- unlist(mcres)\n        res[\"p.value\"] <- switch(alternative,\n            \"two.sided\" = 2 * min(sum(res[\"estimate\"] <= mcres), sum(res[\"estimate\"] >= mcres)) / sum(!is.na(mcres)),\n            \"less\" = sum(res[\"estimate\"] >= mcres) / sum(!is.na(mcres)),\n            \"greater\" = sum(res[\"estimate\"] <= mcres) / sum(!is.na(mcres))\n        )\n        if (res[\"p.value\"] == 0) res[\"p.value\"] <- 1 / (nperm + 1)\n    }\n    return(res)\n}"
      },
      {
        "partial": ".mcc <- function(ct, nbcat=nrow(ct)) {\n    if(nrow(ct) != ncol(ct)) { stop(\"the confusion table should be square!\") }\n    if(sum(ct)==sum(diag(ct)) || \n       !((sum(rowSums(ct) == 0) == (nbcat-1)) || (sum(colSums(ct) == 0) == (nbcat-1)))) {\n        # No adjustment necessary\n    } else {\n        ct <- ct + matrix(1, ncol=nbcat, nrow=nbcat)\n    }\n    if (sum(ct, na.rm = TRUE) <= 0) return(NA)\n    myx <- matrix(TRUE, nrow = nrow(ct), ncol = ncol(ct))\n    diag(myx) <- FALSE\n    if (sum(ct[myx]) == 0) return(1)\n    # TODO: Implement MCC calculation\n}",
        "complete": ".mcc <- function(ct, nbcat=nrow(ct)) {\n    if(nrow(ct) != ncol(ct)) { stop(\"the confusion table should be square!\") }\n    if(sum(ct)==sum(diag(ct)) || \n       !((sum(rowSums(ct) == 0) == (nbcat-1)) || (sum(colSums(ct) == 0) == (nbcat-1)))) {\n        # No adjustment necessary\n    } else {\n        ct <- ct + matrix(1, ncol=nbcat, nrow=nbcat)\n    }\n    if (sum(ct, na.rm = TRUE) <= 0) return(NA)\n    myx <- matrix(TRUE, nrow = nrow(ct), ncol = ncol(ct))\n    diag(myx) <- FALSE\n    if (sum(ct[myx]) == 0) return(1)\n    myperf <- sum(sapply(seq_len(nbcat), function(k) {\n        sum(sapply(seq_len(nbcat), function(m) {\n            sum(sapply(seq_len(nbcat), function(l) {\n                (ct[k, k] * ct[m, l]) - (ct[l, k] * ct[k, m])\n            }))\n        }))\n    }))\n    aa <- sum(sapply(seq_len(nbcat), function(k) {\n        cc <- sum(ct[, k])\n        dd <- sum(ct[, -k])\n        cc * dd\n    }))\n    bb <- sum(sapply(seq_len(nbcat), function(k) {\n        cc <- sum(ct[k, ])\n        dd <- sum(ct[-k, ])\n        cc * dd\n    }))\n    myperf / (sqrt(aa) * sqrt(bb))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-guessMapping.R",
    "language": "R",
    "content": "#' Generic for Guessing the Mapping Between Some Raw Data and an S4 Object\n#'\n#' @param object An `S4` object containing so raw data to guess data to\n#'   object slot mappings for.\n#' @param ... Allow new arguments to be defined for this generic.\n#'\n#' @return A `list` with mapping guesses as items.\n#'\n#' @examples\n#' \"Generics shouldn't need examples!\"\n#'\n#' @md\n#' @export\nsetGeneric('guessMapping', function(object, ...) standardGeneric('guessMapping'))\n\n#' Guess which columns in raw experiment data map to which dimensions.\n#'\n#' Checks for columns which are uniquely identified by a group of identifiers.\n#' This should be used to help identify the columns required to uniquely\n#' identify the rows, columns, assays and metadata of a `DataMapper` class\n#' object.\n#'\n#' @details\n#' Any unmapped columns will be added to the end of the returned `list` in an\n#' item called unmapped.\n#'\n#' The function automatically guesses metadata by checking if any columns have\n#' only a single value. This is returned as an additional item in the list.\n#'\n#' @param object A `LongTableDataMapper` object.\n#' @param groups A `list` containing one or more vector of column names\n#'   to group-by. The function uses these to determine 1:1 mappings between\n#'   the combination of columns in each vector and unique values in the raw\n#'   data columns.\n#' @param subset A `logical` vector indicating whether to to subset out mapped\n#'   columns after each grouping. Must be a single `TRUE` or `FALSE` or have\n#'   the same length as groups, indicating whether to subset out mapped columns\n#'   after each grouping. This will prevent mapping a column to two different\n#'   groups.\n#' @param data A `logical` vector indicating whether you would like the data\n#'   for mapped columns to be returned instead of their column names. Defaults\n#'   to `FALSE` for easy use assigning mapped columns to a `DataMapper` object.\n#'\n#' @return A `list`, where each item is named for the associated `groups` item\n#' the guess is for. The character vector in each item are columns which are\n#' uniquely identified by the identifiers from that group.\n#'\n#' @examples\n#' guessMapping(exampleDataMapper, groups=list(rows='treatmentid', cols='sampleid'),\n#' subset=FALSE)\n#'\n#' @md\n#' @export\nsetMethod('guessMapping', signature(object='LongTableDataMapper'),\n        function(object, groups, subset, data=FALSE) {\n    funContext <- '[CoreGx::guessMapping,LongTableDataMapper-method]\\n\\t'\n\n    # Extract the raw data\n    mapData <- copy(rawdata(object))\n    if (!is.data.table(mapData)) setDT(mapData)\n\n    # Error handle for subset parameter\n    if (!(length(subset) == length(groups) || length(subset) == 1))\n        stop(.errorMsg(funContext, ' The subset parameter must be\n            either length 1 or length equal to the groups parameter!'))\n\n    if (length(subset) == 1) subset <- rep(subset, length(groups))\n\n    # Get the id columns to prevent subsetting them out\n    idCols <- unique(unlist(groups))\n\n    # Map unique columns in the data to the metadata slot\n    metadataColumns <- names(which(vapply(mapData, FUN=.length_unique,\n        numeric(1)) == 1))\n    metadataColumns <- setdiff(metadataColumns, idCols)\n    metadata <- mapData[, .SD, .SDcols=metadataColumns]\n    DT <- mapData[, .SD, .SDcols=!metadataColumns]\n\n    # Check the mappings for each group in groups\n    for (i in seq_along(groups)) {\n        message(funContext, paste0('Mapping for group ', names(groups)[i],\n            ': ', paste0(groups[[i]], collapse=', ')))\n        mappedCols <- checkColumnCardinality(DT, groups[[i]])\n        mappedCols <- setdiff(mappedCols, idCols)\n        assign(names(groups)[i], DT[, .SD, .SDcols=mappedCols])\n        if (subset[i]) DT <- DT[, .SD, .SDcols=!mappedCols]\n    }\n\n    # Merge the results\n    groups <- c(list(metadata=NA), groups)\n    mappings <- mget(names(groups))\n    unmapped <- setdiff(colnames(mapData),\n        unique(c(unlist(groups), unlist(lapply(mappings, colnames)))))\n    if (!data) mappings <- lapply(mappings, colnames)\n    mappings <- Map(f=list, groups, mappings)\n    mappings <- lapply(mappings, FUN=setNames,\n        nm=c('id_columns', 'mapped_columns'))\n\n    mappings[['unmapped']] <- unmapped\n\n    return(mappings)\n})\n\n#' Search a data.frame for 1:`cardinality` relationships between a group\n#'   of columns (your identifiers) and all other columns.\n#'\n#' @param df A `data.frame` to search for 1:`cardinality` mappings with\n#'   the columns in `group`.\n#' @param group A `character` vector of one or more column names to\n#'   check the cardinality of other columns against.\n#' @param cardinality The cardinality of to search for (i.e., 1:`cardinality`)\n#'   relationships with the combination of columns in group. Defaults to 1\n#'   (i.e., 1:1 mappings).\n#' @param ... Fall through arguments to data.table::`[`. For developer use.\n#'   One use case is setting verbose=TRUE to diagnose slow data.table\n#'   operations.\n#'\n#' @return A `character` vector with the names of the columns with\n#'    cardinality of 1:`cardinality` with the columns listed in `group`.\n#'\n#' @examples\n#' df <- rawdata(exampleDataMapper)\n#' checkColumnCardinality(df, group='treatmentid')\n#'\n#' @aliases cardinality\n#'\n#' @md\n#' @importFrom data.table setindexv\n#' @importFrom MatrixGenerics colAlls\n#' @export\ncheckColumnCardinality <- function(df, group, cardinality=1, ...) {\n\n    funContext <- '\\n[CoreGx::checkColumnCardinality]\\n\\t'\n\n    # Copy to prevent accidental modify by references\n    df <- copy(df)\n    if (!is.data.table(df)) setDT(df)\n\n    # Intercept slow data.table group by when nrow == .NGRP\n    setkeyv(df, cols=group)\n    nrowEqualsNGroup <- df[, .N, by=group, ...][, max(N), ...] == 1\n    if (nrowEqualsNGroup) {\n        if (cardinality != 1) stop(.errorMsg(funContext, 'The group argument\n            uniquely identifies each row, so the cardinality is 1:1!'))\n        columnsHaveCardinality <- setdiff(colnames(df), group)\n    } else {\n        dimDT <- df[, lapply(.SD, FUN=uniqueN), by=group, ...]\n        columnsHaveCardinality <- colnames(dimDT)[colAlls(dimDT == cardinality)]\n    }\n\n    return(columnsHaveCardinality)\n}\n#' @export\ncardinality <- checkColumnCardinality",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `guessMapping` generic function and its method for `LongTableDataMapper` objects?",
        "answer": "The `guessMapping` generic function and its method for `LongTableDataMapper` objects are designed to guess the mapping between raw data columns and dimensions of an S4 object. It helps identify columns required to uniquely identify rows, columns, assays, and metadata of a `DataMapper` class object. The method takes groups of column names, checks for unique identifiers, and returns a list of mapped columns for each group, along with metadata and unmapped columns."
      },
      {
        "question": "How does the `checkColumnCardinality` function work, and what is its primary use case?",
        "answer": "The `checkColumnCardinality` function searches a data.frame for 1:cardinality relationships between a group of columns (identifiers) and all other columns. It takes a data.frame, a group of column names, and a cardinality value (default 1). The function returns a character vector with names of columns that have the specified cardinality relationship with the group columns. Its primary use case is to find columns that are uniquely identified by a set of identifier columns, which is crucial for the `guessMapping` function to determine column mappings."
      },
      {
        "question": "What are the key steps in the `guessMapping` method for `LongTableDataMapper` objects?",
        "answer": "The key steps in the `guessMapping` method for `LongTableDataMapper` objects are: 1) Extract and copy the raw data. 2) Handle the subset parameter. 3) Identify metadata columns (columns with only one unique value). 4) Iterate through each group in the 'groups' parameter, using `checkColumnCardinality` to find mapped columns. 5) Optionally subset out mapped columns after each group. 6) Merge the results into a list, including metadata, mapped columns for each group, and unmapped columns. 7) Return the final list of mappings, with options to return column names or actual data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('guessMapping', signature(object='LongTableDataMapper'),\n        function(object, groups, subset, data=FALSE) {\n    funContext <- '[CoreGx::guessMapping,LongTableDataMapper-method]\\n\\t'\n\n    # Extract the raw data\n    mapData <- copy(rawdata(object))\n    if (!is.data.table(mapData)) setDT(mapData)\n\n    # Error handle for subset parameter\n    if (!(length(subset) == length(groups) || length(subset) == 1))\n        stop(.errorMsg(funContext, ' The subset parameter must be\n            either length 1 or length equal to the groups parameter!'))\n\n    if (length(subset) == 1) subset <- rep(subset, length(groups))\n\n    # Get the id columns to prevent subsetting them out\n    idCols <- unique(unlist(groups))\n\n    # Map unique columns in the data to the metadata slot\n    metadataColumns <- names(which(vapply(mapData, FUN=.length_unique,\n        numeric(1)) == 1))\n    metadataColumns <- setdiff(metadataColumns, idCols)\n    metadata <- mapData[, .SD, .SDcols=metadataColumns]\n    DT <- mapData[, .SD, .SDcols=!metadataColumns]\n\n    # TODO: Implement the rest of the function\n\n    return(mappings)\n})",
        "complete": "setMethod('guessMapping', signature(object='LongTableDataMapper'),\n        function(object, groups, subset, data=FALSE) {\n    funContext <- '[CoreGx::guessMapping,LongTableDataMapper-method]\\n\\t'\n\n    mapData <- copy(rawdata(object))\n    if (!is.data.table(mapData)) setDT(mapData)\n\n    if (!(length(subset) == length(groups) || length(subset) == 1))\n        stop(.errorMsg(funContext, ' The subset parameter must be\n            either length 1 or length equal to the groups parameter!'))\n\n    if (length(subset) == 1) subset <- rep(subset, length(groups))\n\n    idCols <- unique(unlist(groups))\n\n    metadataColumns <- names(which(vapply(mapData, FUN=.length_unique,\n        numeric(1)) == 1))\n    metadataColumns <- setdiff(metadataColumns, idCols)\n    metadata <- mapData[, .SD, .SDcols=metadataColumns]\n    DT <- mapData[, .SD, .SDcols=!metadataColumns]\n\n    for (i in seq_along(groups)) {\n        message(funContext, paste0('Mapping for group ', names(groups)[i],\n            ': ', paste0(groups[[i]], collapse=', ')))\n        mappedCols <- checkColumnCardinality(DT, groups[[i]])\n        mappedCols <- setdiff(mappedCols, idCols)\n        assign(names(groups)[i], DT[, .SD, .SDcols=mappedCols])\n        if (subset[i]) DT <- DT[, .SD, .SDcols=!mappedCols]\n    }\n\n    groups <- c(list(metadata=NA), groups)\n    mappings <- mget(names(groups))\n    unmapped <- setdiff(colnames(mapData),\n        unique(c(unlist(groups), unlist(lapply(mappings, colnames)))))\n    if (!data) mappings <- lapply(mappings, colnames)\n    mappings <- Map(f=list, groups, mappings)\n    mappings <- lapply(mappings, FUN=setNames,\n        nm=c('id_columns', 'mapped_columns'))\n\n    mappings[['unmapped']] <- unmapped\n\n    return(mappings)\n})"
      },
      {
        "partial": "checkColumnCardinality <- function(df, group, cardinality=1, ...) {\n    funContext <- '\\n[CoreGx::checkColumnCardinality]\\n\\t'\n\n    df <- copy(df)\n    if (!is.data.table(df)) setDT(df)\n\n    setkeyv(df, cols=group)\n    nrowEqualsNGroup <- df[, .N, by=group, ...][, max(N), ...] == 1\n    if (nrowEqualsNGroup) {\n        if (cardinality != 1) stop(.errorMsg(funContext, 'The group argument\n            uniquely identifies each row, so the cardinality is 1:1!'))\n        columnsHaveCardinality <- setdiff(colnames(df), group)\n    } else {\n        # TODO: Implement the else condition\n    }\n\n    return(columnsHaveCardinality)\n}",
        "complete": "checkColumnCardinality <- function(df, group, cardinality=1, ...) {\n    funContext <- '\\n[CoreGx::checkColumnCardinality]\\n\\t'\n\n    df <- copy(df)\n    if (!is.data.table(df)) setDT(df)\n\n    setkeyv(df, cols=group)\n    nrowEqualsNGroup <- df[, .N, by=group, ...][, max(N), ...] == 1\n    if (nrowEqualsNGroup) {\n        if (cardinality != 1) stop(.errorMsg(funContext, 'The group argument\n            uniquely identifies each row, so the cardinality is 1:1!'))\n        columnsHaveCardinality <- setdiff(colnames(df), group)\n    } else {\n        dimDT <- df[, lapply(.SD, FUN=uniqueN), by=group, ...]\n        columnsHaveCardinality <- colnames(dimDT)[colAlls(dimDT == cardinality)]\n    }\n\n    return(columnsHaveCardinality)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/updateObject-methods.R",
    "language": "R",
    "content": "#' @include RadioSet-accessors.R\nNULL\n\n#' Update the RadioSet class after changes in it struture or API\n#'\n#' @param object A `RadioSet` object to update the class structure for.\n#'\n#' @return `RadioSet` with update class structure.\n#'\n#' @md\n#' @importMethodsFrom CoreGx updateObject\n#' @export\nsetMethod(\"updateObject\", signature(\"RadioSet\"), function(object) {\n    cSet <- callNextMethod(object)\n    rSet <- as(cSet, \"RadioSet\")\n    # treatment slot\n    colnames(treatmentInfo(rSet)) <- gsub(\"X.radiation.|treatmentid|radiation\",\n        \"treatmentid\", colnames(treatmentInfo(rSet)))\n    # sensitivity slot\n    colnames(sensitivityInfo(rSet)) <- gsub(\"treatmentid\", \"treatmentid\",\n        colnames(sensitivityInfo(rSet)))\n    # curation slot\n    names(curation(rSet)) <- gsub(\"radiation\", \"treatment\", names(curation(rSet)))\n    if (\"radiation\" %in% names(curation(rSet))) {\n        colnames(curation(rSet)$radiation) <- gsub(\"treatmentid|radiation\",\n            \"treatment\", colnames(curation(rSet)$radiation))\n    }\n    # molecularProfiles slot\n    for (i in seq_along(molecularProfilesSlot(rSet))) {\n        colnames(colData(molecularProfilesSlot(rSet)[[i]])) <-\n            gsub(\"treatmentid|radiation\", \"treatmentid\",\n                colnames(colData(molecularProfilesSlot(rSet)[[i]]))\n            )\n    }\n    validObject(rSet)\n    return(rSet)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `updateObject` method for the `RadioSet` class?",
        "answer": "The `updateObject` method is designed to update the `RadioSet` class structure after changes in its structure or API. It performs several tasks:\n1. Calls the superclass method using `callNextMethod`\n2. Converts the result back to a `RadioSet` object\n3. Updates column names in various slots (treatmentInfo, sensitivityInfo, curation, molecularProfiles) to ensure consistency\n4. Validates the updated object\n5. Returns the updated `RadioSet` object"
      },
      {
        "question": "How does the method handle the 'treatment' terminology in different slots of the `RadioSet` object?",
        "answer": "The method standardizes the terminology related to 'treatment' across different slots:\n1. In the treatmentInfo slot, it replaces 'X.radiation.', 'treatmentid', and 'radiation' with 'treatmentid'\n2. In the sensitivityInfo slot, it ensures 'treatmentid' is used\n3. In the curation slot, it replaces 'radiation' with 'treatment' in the names\n4. If a 'radiation' element exists in the curation slot, it renames its columns from 'treatmentid' or 'radiation' to 'treatment'\n5. In the molecularProfiles slot, it replaces 'treatmentid' or 'radiation' with 'treatmentid' in column names\nThis standardization ensures consistency across the object's structure."
      },
      {
        "question": "What are the key steps in the `updateObject` method to ensure the updated `RadioSet` object is valid and properly structured?",
        "answer": "The key steps to ensure the updated `RadioSet` object is valid and properly structured are:\n1. Calling the superclass method with `callNextMethod(object)` to perform any necessary updates from the parent class\n2. Converting the result back to a `RadioSet` object using `as(cSet, \"RadioSet\")`\n3. Updating column names and slot names to ensure consistency in terminology\n4. Iterating through the molecularProfiles slot to update column names in each profile\n5. Calling `validObject(rSet)` to verify that the updated object meets all validity requirements\n6. Returning the validated and updated `RadioSet` object\nThese steps ensure that the object maintains its structure and validity after the update process."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"updateObject\", signature(\"RadioSet\"), function(object) {\n    cSet <- callNextMethod(object)\n    rSet <- as(cSet, \"RadioSet\")\n    # Update treatment slot\n    colnames(treatmentInfo(rSet)) <- gsub(\"X.radiation.|treatmentid|radiation\",\n        \"treatmentid\", colnames(treatmentInfo(rSet)))\n    # Update sensitivity slot\n    colnames(sensitivityInfo(rSet)) <- gsub(\"treatmentid\", \"treatmentid\",\n        colnames(sensitivityInfo(rSet)))\n    # Update curation slot\n    names(curation(rSet)) <- gsub(\"radiation\", \"treatment\", names(curation(rSet)))\n    if (\"radiation\" %in% names(curation(rSet))) {\n        colnames(curation(rSet)$radiation) <- gsub(\"treatmentid|radiation\",\n            \"treatment\", colnames(curation(rSet)$radiation))\n    }\n    # Update molecularProfiles slot\n    # TODO: Complete the code to update the molecularProfiles slot\n    \n    validObject(rSet)\n    return(rSet)\n})",
        "complete": "setMethod(\"updateObject\", signature(\"RadioSet\"), function(object) {\n    cSet <- callNextMethod(object)\n    rSet <- as(cSet, \"RadioSet\")\n    # Update treatment slot\n    colnames(treatmentInfo(rSet)) <- gsub(\"X.radiation.|treatmentid|radiation\",\n        \"treatmentid\", colnames(treatmentInfo(rSet)))\n    # Update sensitivity slot\n    colnames(sensitivityInfo(rSet)) <- gsub(\"treatmentid\", \"treatmentid\",\n        colnames(sensitivityInfo(rSet)))\n    # Update curation slot\n    names(curation(rSet)) <- gsub(\"radiation\", \"treatment\", names(curation(rSet)))\n    if (\"radiation\" %in% names(curation(rSet))) {\n        colnames(curation(rSet)$radiation) <- gsub(\"treatmentid|radiation\",\n            \"treatment\", colnames(curation(rSet)$radiation))\n    }\n    # Update molecularProfiles slot\n    for (i in seq_along(molecularProfilesSlot(rSet))) {\n        colnames(colData(molecularProfilesSlot(rSet)[[i]])) <-\n            gsub(\"treatmentid|radiation\", \"treatmentid\",\n                colnames(colData(molecularProfilesSlot(rSet)[[i]]))\n            )\n    }\n    validObject(rSet)\n    return(rSet)\n})"
      },
      {
        "partial": "#' Update the RadioSet class after changes in it struture or API\n#'\n#' @param object A `RadioSet` object to update the class structure for.\n#'\n#' @return `RadioSet` with update class structure.\n#'\n#' @md\n#' @importMethodsFrom CoreGx updateObject\n#' @export\nsetMethod(\"updateObject\", signature(\"RadioSet\"), function(object) {\n    # TODO: Implement the updateObject method for RadioSet\n    # Hint: Use callNextMethod, update various slots, and ensure the object is valid\n})",
        "complete": "#' Update the RadioSet class after changes in it struture or API\n#'\n#' @param object A `RadioSet` object to update the class structure for.\n#'\n#' @return `RadioSet` with update class structure.\n#'\n#' @md\n#' @importMethodsFrom CoreGx updateObject\n#' @export\nsetMethod(\"updateObject\", signature(\"RadioSet\"), function(object) {\n    cSet <- callNextMethod(object)\n    rSet <- as(cSet, \"RadioSet\")\n    colnames(treatmentInfo(rSet)) <- gsub(\"X.radiation.|treatmentid|radiation\", \"treatmentid\", colnames(treatmentInfo(rSet)))\n    colnames(sensitivityInfo(rSet)) <- gsub(\"treatmentid\", \"treatmentid\", colnames(sensitivityInfo(rSet)))\n    names(curation(rSet)) <- gsub(\"radiation\", \"treatment\", names(curation(rSet)))\n    if (\"radiation\" %in% names(curation(rSet))) {\n        colnames(curation(rSet)$radiation) <- gsub(\"treatmentid|radiation\", \"treatment\", colnames(curation(rSet)$radiation))\n    }\n    for (i in seq_along(molecularProfilesSlot(rSet))) {\n        colnames(colData(molecularProfilesSlot(rSet)[[i]])) <- gsub(\"treatmentid|radiation\", \"treatmentid\", colnames(colData(molecularProfilesSlot(rSet)[[i]])))\n    }\n    validObject(rSet)\n    return(rSet)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/Math.cpp",
    "language": "cpp",
    "content": "#include \"Math.h\"\n\nMath::IndirectComparator::IndirectComparator(double const* const pSamples,\n        unsigned int const* const pSampleIndices) :\n        mpSamples(pSamples), mpSampleIndices(pSampleIndices)\n{\n\n}\n\nbool const\nMath::IndirectComparator::operator()(unsigned int const i, unsigned int const j) const\n{\n    return mpSamples[mpSampleIndices[i]] < mpSamples[mpSampleIndices[j]];\n}\n\n/* static */void const\nMath::computeCausality(double* const pCausalityArray, Matrix const* const pMiMatrix,\n        int const* const pSolutions, unsigned int const solutionCount,\n        unsigned int const featureCountPerSolution, unsigned int const featureCount,\n        unsigned int const targetFeatureIndex)\n{\n    for (unsigned int s = 0; s < solutionCount; ++s)\n    {\n        for (unsigned int i = 0; i < featureCountPerSolution - 1; ++i)\n        {\n            for (unsigned int j = i + 1; j < featureCountPerSolution; ++j)\n            {\n                int const a = pSolutions[(featureCountPerSolution * s) + i];\n                int const b = pSolutions[(featureCountPerSolution * s) + j];\n\n                double const cor_ij =\n                        (std::fabs(pMiMatrix->at(a, b)) > std::fabs(pMiMatrix->at(b, a))) ?\n                                pMiMatrix->at(a, b) : pMiMatrix->at(b, a);\n\n                double const cor_ik = pMiMatrix->at(a, targetFeatureIndex);\n                double const cor_jk = pMiMatrix->at(b, targetFeatureIndex);\n\n                double const coefficient = Math::computeCoInformationLattice(cor_ij, cor_ik,\n                        cor_jk);\n\n                if (pCausalityArray[a] != pCausalityArray[a] || pCausalityArray[a] > coefficient)\n                    pCausalityArray[a] = coefficient;\n\n                if (pCausalityArray[b] != pCausalityArray[b] || pCausalityArray[b] > coefficient)\n                    pCausalityArray[b] = coefficient;\n            }\n        }\n    }\n}\n\n/* static */double const\nMath::computeCoInformationLattice(double const cor_ij, double const cor_ik, double const cor_jk)\n{\n    double const cor_ij_sq = cor_ij * cor_ij;\n    double const cor_jk_sq = cor_jk * cor_jk;\n    double const cor_ik_sq = cor_ik * cor_ik;\n\n    return -.5\n            * std::log(\n                    ((1 - cor_ij_sq) * (1 - cor_ik_sq) * (1 - cor_jk_sq))\n                            / (1 + 2 * cor_ij * cor_ik * cor_jk - cor_ij_sq - cor_ik_sq - cor_jk_sq));\n}\n\n/* static */double const\nMath::computeConcordanceIndex(double const* const pDiscreteSamples,\n        double const* const pContinuousSamples, double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        bool const outX, double* const pConcordantWeights, double* const pDiscordantWeights,\n        double* const pUninformativeWeights, double* const pRelevantWeights)\n{\n    double sum_concordant_weight = 0.;\n    double sum_relevant_weight = 0.;\n\n    for (unsigned int stratum = 0; stratum < sampleStratumCount; ++stratum)\n    {\n        for (unsigned int a = 0; a < pSampleCountPerStratum[stratum]; ++a)\n        {\n            unsigned int const i = pSampleIndicesPerStratum[stratum][a];\n\n            double concordant_weight = 0.;\n            double discordant_weight = 0.;\n            double uninformative_weight = 0.;\n            double relevant_weight = 0.; \n\n            if (pDiscreteSamples[i] != pDiscreteSamples[i]\n                    || pContinuousSamples[i] != pContinuousSamples[i])\n                continue;\n\n            for (unsigned int b = 0; b < pSampleCountPerStratum[stratum]; ++b)\n            {\n                unsigned int const j = pSampleIndicesPerStratum[stratum][b];\n\n                if (pDiscreteSamples[j] != pDiscreteSamples[j]\n                        || pContinuousSamples[j] != pContinuousSamples[j])\n                    continue;\n\n                double pair_weight = pSampleWeights[i] * pSampleWeights[j];\n\n                if (pDiscreteSamples[i] > pDiscreteSamples[j])\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pContinuousSamples[i] > pContinuousSamples[j])\n                        concordant_weight += pair_weight;\n                    else if (pContinuousSamples[i] < pContinuousSamples[j])\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n                else if (pDiscreteSamples[i] < pDiscreteSamples[j])\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pContinuousSamples[i] < pContinuousSamples[j])\n                        concordant_weight += pair_weight;\n                    else if (pContinuousSamples[i] > pContinuousSamples[j])\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n            }\n\n            sum_concordant_weight += concordant_weight;\n            sum_relevant_weight += relevant_weight;\n\n            if (pConcordantWeights != 0) // Implicity, the other similar vectors\n            {                            // should also match this condition.\n                pConcordantWeights[i] = concordant_weight;\n                pDiscordantWeights[i] = discordant_weight;\n                pUninformativeWeights[i] = uninformative_weight;\n                pRelevantWeights[i] = relevant_weight;\n            }\n        }\n    }\n\n    return sum_concordant_weight / sum_relevant_weight;\n}\n\n/*static*/double const\nMath::computeConcordanceIndex(double const* const pDiscreteSamples,\n        double const* const pContinuousSamples, double const* const pTimeSamples,\n        double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        bool const outX, double* const pConcordantWeights, double* const pDiscordantWeights,\n        double* const pUninformativeWeights, double* const pRelevantWeights)\n{\n    double sum_concordant_weight = 0.;\n    double sum_relevant_weight = 0.;\n\n    for (unsigned int stratum = 0; stratum < sampleStratumCount; ++stratum)\n    {\n        for (unsigned int a = 0; a < pSampleCountPerStratum[stratum]; ++a)\n        {\n            unsigned int const i = pSampleIndicesPerStratum[stratum][a];\n\n            double concordant_weight = 0.;\n            double discordant_weight = 0.;\n            double uninformative_weight = 0.;\n            double relevant_weight = 0.; \n\n            if (pDiscreteSamples[i] != pDiscreteSamples[i] || pTimeSamples[i] != pTimeSamples[i]\n                    || pContinuousSamples[i] != pContinuousSamples[i])\n                continue;\n\n            for (unsigned int b = 0; b < pSampleCountPerStratum[stratum]; ++b)\n            {\n                unsigned int const j = pSampleIndicesPerStratum[stratum][b];\n\n                if (pDiscreteSamples[j] != pDiscreteSamples[j] || pTimeSamples[j] != pTimeSamples[j]\n                        || pContinuousSamples[j] != pContinuousSamples[j])\n                    continue;\n\n                double pair_weight = pSampleWeights[i] * pSampleWeights[j];\n\n                if (pTimeSamples[i] < pTimeSamples[j] && pDiscreteSamples[i] == 1)\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pContinuousSamples[i] > pContinuousSamples[j])\n                        concordant_weight += pair_weight;\n                    else if (pContinuousSamples[i] < pContinuousSamples[j])\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n                else if (pTimeSamples[i] > pTimeSamples[j] && pDiscreteSamples[j] == 1)\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pContinuousSamples[i] < pContinuousSamples[j])\n                        concordant_weight += pair_weight;\n                    else if (pContinuousSamples[i] > pContinuousSamples[j])\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n            }\n\n            sum_concordant_weight += concordant_weight;\n            sum_relevant_weight += relevant_weight;\n\n            if (pConcordantWeights != 0) // Implicity, the other similar vectors\n            {                            // should also match this condition.\n                pConcordantWeights[i] = concordant_weight;\n                pDiscordantWeights[i] = discordant_weight;\n                pUninformativeWeights[i] = uninformative_weight;\n                pRelevantWeights[i] = relevant_weight;\n            }\n        }\n    }\n\n    return sum_concordant_weight / sum_relevant_weight;\n}\n\n/*static*/double const\nMath::computeConcordanceIndex(double const* const pDiscreteSamplesX,\n        double const* const pDiscreteSamplesY, double const* const pTimeSamplesX,\n        double const* const pTimeSamplesY, double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        bool const outX, double* const pConcordantWeights, double* const pDiscordantWeights,\n        double* const pUninformativeWeights, double* const pRelevantWeights)\n{\n    double sum_concordant_weight = 0.;\n    double sum_relevant_weight = 0.;\n\n    for (unsigned int stratum = 0; stratum < sampleStratumCount; ++stratum)\n    {\n        for (unsigned int a = 0; a < pSampleCountPerStratum[stratum]; ++a)\n        {\n            unsigned int const i = pSampleIndicesPerStratum[stratum][a];\n\n            double concordant_weight = 0.;\n            double discordant_weight = 0.;\n            double uninformative_weight = 0.;\n            double relevant_weight = 0.; \n\n            if (pDiscreteSamplesX[i] != pDiscreteSamplesX[i]\n                    || pDiscreteSamplesY[i] != pDiscreteSamplesY[i]\n                    || pTimeSamplesX[i] != pTimeSamplesX[i] || pTimeSamplesY[i] != pTimeSamplesY[i])\n                continue;\n\n            for (unsigned int b = 0; b < pSampleCountPerStratum[stratum]; ++b)\n            {\n                unsigned int const j = pSampleIndicesPerStratum[stratum][b];\n\n                if (pDiscreteSamplesX[j] != pDiscreteSamplesX[j]\n                        || pDiscreteSamplesY[j] != pDiscreteSamplesY[j]\n                        || pTimeSamplesX[j] != pTimeSamplesX[j]\n                        || pTimeSamplesY[j] != pTimeSamplesY[j])\n                    continue;\n\n                double pair_weight = pSampleWeights[i] * pSampleWeights[j];\n\n                if (pTimeSamplesX[i] < pTimeSamplesX[j] && pDiscreteSamplesX[i] == 1)\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pTimeSamplesY[i] > pTimeSamplesY[j] && pDiscreteSamplesY[j] == 1)\n                        concordant_weight += pair_weight;\n                    else if (pTimeSamplesY[i] < pTimeSamplesY[j] && pDiscreteSamplesY[j] == 1)\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n                else if (pTimeSamplesX[i] > pTimeSamplesX[j] && pDiscreteSamplesX[j] == 1)\n                {\n                    relevant_weight += pair_weight;\n\n                    if (pTimeSamplesY[i] > pTimeSamplesY[j] && pDiscreteSamplesY[j] == 1)\n                        concordant_weight += pair_weight;\n                    else if (pTimeSamplesY[i] < pTimeSamplesY[j] && pDiscreteSamplesY[j] == 1)\n                        discordant_weight += pair_weight;\n                    else if (outX)\n                        uninformative_weight += pair_weight;\n                    else\n                        discordant_weight += pair_weight;\n                }\n            }\n\n           sum_concordant_weight += concordant_weight;\n            sum_relevant_weight += relevant_weight;\n\n            if (pConcordantWeights != 0) // Implicity, the other similar vectors\n            {                            // should also match this condition.\n                pConcordantWeights[i] = concordant_weight;\n                pDiscordantWeights[i] = discordant_weight;\n                pUninformativeWeights[i] = uninformative_weight;\n                pRelevantWeights[i] = relevant_weight;\n            }\n        }\n    }\n\n    return sum_concordant_weight / sum_relevant_weight;\n}\n\n/* static */double const\nMath::computeCramersV(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        unsigned int const bootstrapCount)\n{\n    bool const useBootstrap = bootstrapCount > 3 && sampleStratumCount > 0;\n    double* p_error_per_stratum = 0;\n\n    if (useBootstrap)\n    {\n        p_error_per_stratum = new double[sampleStratumCount];\n        unsigned int seed = std::time(NULL);\n        Matrix bootstraps(bootstrapCount, sampleStratumCount);\n\n#ifdef _OPENMP\n#pragma omp parallel for schedule(dynamic) firstprivate(seed)\n#endif\n        for (unsigned int i = 0; i < bootstrapCount; ++i)\n        {\n            for (unsigned int j = 0; j < sampleStratumCount; ++j)\n            {\n                unsigned int const sample_count = pSampleCountPerStratum[j];\n                unsigned int* const p_samples = new unsigned int[sample_count];\n\n                for (unsigned int k = 0; k < sample_count; ++k)\n                    p_samples[k] = pSampleIndicesPerStratum[j][Math::computeRandomNumber(&seed)\n                            % sample_count];\n\n                double const correlation = computeCramersV(pSamplesX, pSamplesY, pSampleWeights,\n                        p_samples, sample_count);\n                bootstraps.at(i, j) = correlation;\n\n                delete[] p_samples;\n            }\n        }\n\n        for (unsigned int i = 0; i < sampleStratumCount; ++i)\n            p_error_per_stratum[i] = 1.\n                    / Math::computeVariance(&(bootstraps.at(0, i)), bootstrapCount);\n    }\n\n    double r = 0.;\n    double total_weight = 0.;\n\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        double weight = 0.;\n        double const correlation = computeCramersV(pSamplesX, pSamplesY, pSampleWeights,\n                pSampleIndicesPerStratum[i], pSampleCountPerStratum[i], &weight);\n\n        if (useBootstrap)\n            weight = p_error_per_stratum[i];\n\n        r += weight * correlation;\n        total_weight += weight;\n    }\n\n    r /= total_weight;\n\n    delete[] p_error_per_stratum;\n\n    return r;\n}\n\n/* static */double const\nMath::computeCramersV(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    unsigned int x_class_count = 0;\n    unsigned int y_class_count = 0;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const index = pSampleIndices[i];\n\n        if (x_class_count <= pSamplesX[index])\n            x_class_count = pSamplesX[index] + 1;\n        if (y_class_count <= pSamplesY[index])\n            y_class_count = pSamplesY[index] + 1;\n    }\n\n    Matrix contingency_table(x_class_count + 1, y_class_count + 1);\n\n    for (unsigned int i = 0; i <= x_class_count; ++i)\n        for (unsigned int j = 0; j <= y_class_count; ++j)\n            contingency_table.at(i, j) = 0;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const index = pSampleIndices[i];\n\n        if (pSamplesX[index] != pSamplesX[index] || pSamplesY[index] != pSamplesY[index])\n            continue;\n\n        double const sample_weight = pSampleWeights[index];\n        contingency_table.at(pSamplesX[index], pSamplesY[index]) += sample_weight;\n        contingency_table.at(x_class_count, pSamplesY[index]) += sample_weight;\n        contingency_table.at(pSamplesX[index], y_class_count) += sample_weight;\n        contingency_table.at(x_class_count, y_class_count) += sample_weight;\n    }\n\n    double chi_square = 0.;\n\n    for (unsigned int i = 0; i < x_class_count; ++i)\n        for (unsigned int j = 0; j < y_class_count; ++j)\n        {\n            double expected_value = contingency_table.at(i, y_class_count)\n                    * contingency_table.at(x_class_count, j)\n                    / contingency_table.at(x_class_count, y_class_count);\n\n            chi_square += std::pow((contingency_table.at(i, j) - expected_value), 2)\n                    / expected_value;\n        }\n\n    unsigned int const min_classes =\n            (x_class_count < y_class_count) ? x_class_count : y_class_count;\n\n    *pTotalWeight = contingency_table.at(x_class_count, y_class_count);\n\n    double const v = std::sqrt(chi_square / ((*pTotalWeight) * (min_classes - 1)));\n\n    return v;\n}\n\n/* static */double const\nMath::computeFrequency(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        unsigned int const bootstrapCount)\n{\n    bool const useBootstrap = bootstrapCount > 3 && sampleStratumCount > 0;\n    double* p_error_per_stratum = 0;\n\n    if (useBootstrap)\n    {\n        p_error_per_stratum = new double[sampleStratumCount];\n        unsigned int seed = std::time(NULL);\n        Matrix bootstraps(bootstrapCount, sampleStratumCount);\n\n#ifdef _OPENMP\n#pragma omp parallel for schedule(dynamic) firstprivate(seed)\n#endif\n        for (unsigned int i = 0; i < bootstrapCount; ++i)\n        {\n            for (unsigned int j = 0; j < sampleStratumCount; ++j)\n            {\n                unsigned int const sample_count = pSampleCountPerStratum[j];\n                unsigned int* const p_samples = new unsigned int[sample_count];\n\n                for (unsigned int k = 0; k < sample_count; ++k)\n                    p_samples[k] = pSampleIndicesPerStratum[j][Math::computeRandomNumber(&seed)\n                            % sample_count];\n\n                double const correlation = computeFrequency(pSamplesX, pSamplesY, pSampleWeights,\n                        p_samples, sample_count);\n                bootstraps.at(i, j) = correlation;\n\n                delete[] p_samples;\n            }\n        }\n\n        for (unsigned int i = 0; i < sampleStratumCount; ++i)\n            p_error_per_stratum[i] = 1.\n                    / Math::computeVariance(&(bootstraps.at(0, i)), bootstrapCount);\n    }\n\n    double r = 0.;\n    double total_weight = 0.;\n\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        double weight = 0.;\n        double const correlation = computeFrequency(pSamplesX, pSamplesY, pSampleWeights,\n                pSampleIndicesPerStratum[i], pSampleCountPerStratum[i], &weight);\n\n        if (useBootstrap)\n            weight = p_error_per_stratum[i];\n\n        r += weight * correlation;\n        total_weight += weight;\n    }\n\n    r /= total_weight;\n\n    delete[] p_error_per_stratum;\n\n    return r;\n}\n\n/* static */double const\nMath::computeFrequency(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    double sum = 0.;\n    double total_weight = 0.;\n    double r = 0.;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const sample_index = pSampleIndices[i];\n        double const sample_weight = pSampleWeights[sample_index];\n\n        if (pSamplesX[sample_index] == pSamplesX[sample_index]\n                && pSamplesY[sample_index] == pSamplesY[sample_index])\n        {\n            total_weight += sample_weight;\n\n            if (pSamplesX[sample_index] > pSamplesY[sample_index])\n                sum += sample_weight;\n        }\n    }\n\n    if (pTotalWeight != 0)\n        *pTotalWeight = total_weight;\n    \n    r = sum / total_weight;\n    \n    return r;\n}\n\n/* static */double const\nMath::computeFisherTransformation(double const r)\n{\n    return 0.5 * std::log((1 + r) / (1 - r));\n}\n\n/* static */double const\nMath::computeFisherTransformationReverse(double const z)\n{\n    double const exp = std::exp(2 * z);\n    return (exp - 1) / (exp + 1);\n}\n\n/* static */double const\nMath::computeMi(double const r)\n{\n    return -0.5 * std::log(1 - (r * r));\n}\n\n/* static */double const\nMath::computePearsonCorrelation(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        unsigned int const bootstrapCount)\n{\n    bool const useBootstrap = bootstrapCount > 3 && sampleStratumCount > 0;\n    double* p_error_per_stratum = 0;\n\n    if (useBootstrap)\n    {\n        p_error_per_stratum = new double[sampleStratumCount];\n        unsigned int seed = std::time(NULL);\n        Matrix bootstraps(bootstrapCount, sampleStratumCount);\n\n#ifdef _OPENMP\n#pragma omp parallel for schedule(dynamic) firstprivate(seed)\n#endif\n        for (unsigned int i = 0; i < bootstrapCount; ++i)\n        {\n            for (unsigned int j = 0; j < sampleStratumCount; ++j)\n            {\n                unsigned int const sample_count = pSampleCountPerStratum[j];\n                unsigned int* const p_samples = new unsigned int[sample_count];\n\n                for (unsigned int k = 0; k < sample_count; ++k)\n                    p_samples[k] = pSampleIndicesPerStratum[j][Math::computeRandomNumber(&seed)\n                            % sample_count];\n\n                double const correlation = computeCramersV(pSamplesX, pSamplesY, pSampleWeights,\n                        p_samples, sample_count);\n                bootstraps.at(i, j) = correlation;\n\n                delete[] p_samples;\n            }\n        }\n\n        for (unsigned int i = 0; i < sampleStratumCount; ++i)\n            p_error_per_stratum[i] = 1.\n                    / Math::computeVariance(&(bootstraps.at(0, i)), bootstrapCount);\n    }\n\n    double r = 0.;\n    double total_weight = 0.;\n\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        double weight = 0.;\n        double const correlation = computePearsonCorrelation(pSamplesX, pSamplesY, pSampleWeights,\n                pSampleIndicesPerStratum[i], pSampleCountPerStratum[i], &weight);\n\n        if (useBootstrap)\n            weight = p_error_per_stratum[i];\n\n        r += weight * correlation;\n        total_weight += weight;\n    }\n\n    r /= total_weight;\n\n    delete[] p_error_per_stratum;\n\n    return r;\n}\n\n/* static */double const\nMath::computePearsonCorrelation(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    double sum_of_x = 0.;\n    double sum_of_x_x = 0.;\n    double sum_of_y = 0.;\n    double sum_of_y_y = 0.;\n    double sum_of_x_y = 0.;\n    double sum_of_weights = 0.;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        double const my_x = pSamplesX[pSampleIndices[i]];\n        double const my_y = pSamplesY[pSampleIndices[i]];\n\n        if (my_x == my_x && my_y == my_y)\n        {\n            double const my_weight = pSampleWeights[pSampleIndices[i]];\n            sum_of_x += my_x * my_weight;\n            sum_of_x_x += my_x * my_x * my_weight;\n            sum_of_y += my_y * my_weight;\n            sum_of_y_y += my_y * my_y * my_weight;\n            sum_of_x_y += my_x * my_y * my_weight;\n            sum_of_weights += my_weight;\n        }\n    }\n\n    double const r = (sum_of_x_y - ((sum_of_x * sum_of_y) / sum_of_weights))\n            / std::sqrt(\n                    (sum_of_x_x - ((sum_of_x * sum_of_x) / sum_of_weights))\n                            * (sum_of_y_y - ((sum_of_y * sum_of_y) / sum_of_weights)));\n\n    *pTotalWeight = sum_of_weights;\n\n    return r;\n}\n\n/* static */int const\nMath::computeRandomNumber(unsigned int* const seed)\n{\n    unsigned int next = *seed;\n    int result;\n\n    next *= 1103515245;\n    next += 12345;\n    result = static_cast<unsigned int>(next / 65536) % 2048;\n\n    next *= 1103515245;\n    next += 12345;\n    result <<= 10;\n    result ^= static_cast<unsigned int>(next / 65536) % 1024;\n\n    next *= 1103515245;\n    next += 12345;\n    result <<= 10;\n    result ^= static_cast<unsigned int>(next / 65536) % 1024;\n\n    *seed = next;\n    return result;\n}\n\n/* static */double const\nMath::computeSomersD(double const c)\n{\n    return (c - 0.5) * 2;\n}\n\n/* static */double const\nMath::computeSpearmanCorrelation(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount,\n        unsigned int const bootstrapCount, unsigned int const sampleCount)\n{\n    double* const p_ordered_samples_x = new double[sampleCount];\n    double* const p_ordered_samples_y = new double[sampleCount];\n\n    Math::placeOrders(&pSamplesX[0], p_ordered_samples_x, pSampleIndicesPerStratum,\n            pSampleCountPerStratum, sampleStratumCount);\n    Math::placeOrders(&pSamplesY[0], p_ordered_samples_y, pSampleIndicesPerStratum,\n            pSampleCountPerStratum, sampleStratumCount);\n\n    double* const p_ranked_samples_x = new double[sampleCount];\n    double* const p_ranked_samples_y = new double[sampleCount];\n\n    Math::placeRanksFromOrders(&pSamplesX[0], &pSamplesY[0], p_ordered_samples_x,\n            p_ordered_samples_y, p_ranked_samples_x, p_ranked_samples_y, pSampleIndicesPerStratum,\n            pSampleCountPerStratum, sampleStratumCount);\n\n    delete[] p_ordered_samples_x;\n    delete[] p_ordered_samples_y;\n\n    double const r = Math::computePearsonCorrelation(p_ranked_samples_x, p_ranked_samples_y,\n            &pSampleWeights[0], pSampleIndicesPerStratum, pSampleCountPerStratum,\n            sampleStratumCount, bootstrapCount);\n\n    delete[] p_ranked_samples_x;\n    delete[] p_ranked_samples_y;\n\n    return r;\n}\n\n/* static */double const\nMath::computeVariance(double const* const pSamples, unsigned int const sampleCount)\n{\n    if (sampleCount == 0)\n        return 0.;\n\n    double sum_for_mean = pSamples[0];\n    double sum_for_error = 0.;\n\n    for (unsigned int i = 1; i < sampleCount; ++i)\n    {\n        double const my_sum = pSamples[i] - sum_for_mean;\n        double const my_mean = ((i - 1) * my_sum) / i;\n        sum_for_mean += my_mean;\n        sum_for_error += my_mean * my_sum;\n    }\n\n    return sum_for_error / (sampleCount - 1);\n}\n\n/* static */void const\nMath::placeOrders(double const* const pSamples, double* const pOrders,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount)\n{\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        unsigned int const* const p_sample_indices = pSampleIndicesPerStratum[i];\n        unsigned int const sample_count = pSampleCountPerStratum[i];\n        unsigned int* const p_order = new unsigned int[sample_count];\n\n        unsigned int offset = 0;\n        for (unsigned int j = 0; j < sample_count; ++j)\n        {\n            if (pSamples[p_sample_indices[j]] == pSamples[p_sample_indices[j]])\n                p_order[j - offset] = j;\n            else\n                p_order[sample_count - 1 - offset++] = j;\n        }\n\n        std::sort(p_order, p_order + sample_count - offset,\n                Math::IndirectComparator(pSamples, p_sample_indices));\n\n        for (unsigned int j = 0; j < sample_count; ++j)\n            pOrders[p_sample_indices[j]] = p_order[j];\n\n        delete[] p_order;\n    }\n}\n\n/* static */void const\nMath::placeRanksFromOrders(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pOrdersX, double const* const pOrdersY, double* const pRanksX,\n        double* const pRanksY, unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount)\n{\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        unsigned int const* const p_sample_indices = pSampleIndicesPerStratum[i];\n        unsigned int const stratum_sample_count = pSampleCountPerStratum[i];\n\n        unsigned int offset_x = 0;\n        unsigned int offset_y = 0;\n\n        for (unsigned int j = 0; j < stratum_sample_count; ++j)\n        {\n            unsigned int const order_x =\n                    p_sample_indices[static_cast<unsigned int>(pOrdersX[p_sample_indices[j]])];\n            unsigned int const order_y =\n                    p_sample_indices[static_cast<unsigned int>(pOrdersY[p_sample_indices[j]])];\n\n            bool const NA_x = pSamplesX[order_x] != pSamplesX[order_x]\n                    || pSamplesY[order_x] != pSamplesY[order_x];\n            bool const NA_y = pSamplesY[order_y] != pSamplesY[order_y]\n                    || pSamplesX[order_y] != pSamplesX[order_y];\n\n            if (NA_x)\n                pRanksX[order_x] = std::numeric_limits<double>::quiet_NaN();\n            else\n                pRanksX[order_x] = offset_x++;\n\n            if (NA_y)\n                pRanksY[order_y] = std::numeric_limits<double>::quiet_NaN();\n            else\n                pRanksY[order_y] = offset_y++;\n        }\n    }\n}\n\n/* static */void const\nMath::placeRanksFromSamples(double const* const pSamples, double* const pRanks,\n        unsigned int const* const * const pSampleIndicesPerStratum,\n        unsigned int const* const pSampleCountPerStratum, unsigned int const sampleStratumCount)\n{\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        unsigned int const* const p_sample_indices = pSampleIndicesPerStratum[i];\n        unsigned int const sample_count = pSampleCountPerStratum[i];\n        unsigned int* const p_order = new unsigned int[sample_count];\n\n        unsigned int offset = 0;\n        for (unsigned int j = 0; j < sample_count; ++j)\n        {\n            unsigned int const my_index = p_sample_indices[j];\n\n            if (pSamples[my_index] == pSamples[my_index])\n                p_order[j - offset] = j;\n            else\n                ++offset;\n        }\n\n        std::sort(p_order, p_order + sample_count - offset,\n                Math::IndirectComparator(pSamples, p_sample_indices));\n\n        for (unsigned int j = 0; j < sample_count; ++j)\n            pRanks[j] = std::numeric_limits<double>::quiet_NaN();\n\n        for (unsigned int j = 0; j < sample_count - offset; ++j)\n            pRanks[p_sample_indices[p_order[j]]] = j;\n\n        delete[] p_order;\n    }\n}\n\n/* static */void const\nMath::placeStratificationData(int const* const pSampleStrata, double const* const pSampleWeights,\n        unsigned int** const pSampleIndicesPerStratum, unsigned int* const pSampleCountPerStratum,\n        unsigned int const sampleStratumCount, unsigned int const sampleCount)\n{\n    unsigned int* const p_iterator_per_stratum = new unsigned int[sampleStratumCount];\n\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n    {\n        p_iterator_per_stratum[i] = 0;\n        pSampleCountPerStratum[i] = 0;\n    }\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n        ++pSampleCountPerStratum[pSampleStrata[i]];\n\n    for (unsigned int i = 0; i < sampleStratumCount; ++i)\n        pSampleIndicesPerStratum[i] = new unsigned int[pSampleCountPerStratum[i]];\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const p_sample_stratum = pSampleStrata[i];\n        pSampleIndicesPerStratum[p_sample_stratum][p_iterator_per_stratum[p_sample_stratum]++] = i;\n    }\n\n    delete[] p_iterator_per_stratum;\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `IndirectComparator` class in the `Math` namespace?",
        "answer": "The `IndirectComparator` class is used for indirect comparison of samples. It takes two pointers as constructor arguments: one to an array of samples and another to an array of sample indices. The class overloads the `operator()` to compare two indices based on their corresponding sample values. This allows for sorting or comparing elements indirectly, which is useful in various mathematical operations like ranking or ordering samples."
      },
      {
        "question": "Explain the functionality of the `computeConcordanceIndex` function that takes discrete and continuous samples as input.",
        "answer": "This `computeConcordanceIndex` function calculates the concordance index for paired samples. It iterates through sample pairs, comparing their discrete and continuous values. It accumulates weights for concordant, discordant, and uninformative pairs based on specific conditions. The function handles stratified data and can optionally compute weights for individual samples. The concordance index is calculated as the ratio of the sum of concordant weights to the sum of relevant weights, providing a measure of the agreement between the discrete and continuous samples."
      },
      {
        "question": "How does the `computeCramersV` function work, and what does it measure?",
        "answer": "The `computeCramersV` function calculates Cramer's V, a measure of association between two nominal variables. It first determines the number of classes for each variable, then constructs a contingency table. It computes the chi-square statistic from the observed and expected frequencies in the table. Finally, it calculates Cramer's V using the formula: V = sqrt(chi_square / (N * (min_classes - 1))), where N is the total sample weight. Cramer's V ranges from 0 to 1, with higher values indicating stronger association between the variables."
      }
    ],
    "completion_tasks": [
      {
        "partial": "/* static */double const\nMath::computeCramersV(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    unsigned int x_class_count = 0;\n    unsigned int y_class_count = 0;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const index = pSampleIndices[i];\n\n        if (x_class_count <= pSamplesX[index])\n            x_class_count = pSamplesX[index] + 1;\n        if (y_class_count <= pSamplesY[index])\n            y_class_count = pSamplesY[index] + 1;\n    }\n\n    Matrix contingency_table(x_class_count + 1, y_class_count + 1);\n\n    // TODO: Complete the function\n}",
        "complete": "/* static */double const\nMath::computeCramersV(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    unsigned int x_class_count = 0;\n    unsigned int y_class_count = 0;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const index = pSampleIndices[i];\n\n        if (x_class_count <= pSamplesX[index])\n            x_class_count = pSamplesX[index] + 1;\n        if (y_class_count <= pSamplesY[index])\n            y_class_count = pSamplesY[index] + 1;\n    }\n\n    Matrix contingency_table(x_class_count + 1, y_class_count + 1);\n\n    for (unsigned int i = 0; i <= x_class_count; ++i)\n        for (unsigned int j = 0; j <= y_class_count; ++j)\n            contingency_table.at(i, j) = 0;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        unsigned int const index = pSampleIndices[i];\n\n        if (pSamplesX[index] != pSamplesX[index] || pSamplesY[index] != pSamplesY[index])\n            continue;\n\n        double const sample_weight = pSampleWeights[index];\n        contingency_table.at(pSamplesX[index], pSamplesY[index]) += sample_weight;\n        contingency_table.at(x_class_count, pSamplesY[index]) += sample_weight;\n        contingency_table.at(pSamplesX[index], y_class_count) += sample_weight;\n        contingency_table.at(x_class_count, y_class_count) += sample_weight;\n    }\n\n    double chi_square = 0.;\n\n    for (unsigned int i = 0; i < x_class_count; ++i)\n        for (unsigned int j = 0; j < y_class_count; ++j)\n        {\n            double expected_value = contingency_table.at(i, y_class_count)\n                    * contingency_table.at(x_class_count, j)\n                    / contingency_table.at(x_class_count, y_class_count);\n\n            chi_square += std::pow((contingency_table.at(i, j) - expected_value), 2)\n                    / expected_value;\n        }\n\n    unsigned int const min_classes =\n            (x_class_count < y_class_count) ? x_class_count : y_class_count;\n\n    *pTotalWeight = contingency_table.at(x_class_count, y_class_count);\n\n    double const v = std::sqrt(chi_square / ((*pTotalWeight) * (min_classes - 1)));\n\n    return v;\n}"
      },
      {
        "partial": "/* static */double const\nMath::computePearsonCorrelation(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    double sum_of_x = 0.;\n    double sum_of_x_x = 0.;\n    double sum_of_y = 0.;\n    double sum_of_y_y = 0.;\n    double sum_of_x_y = 0.;\n    double sum_of_weights = 0.;\n\n    // TODO: Complete the function\n}",
        "complete": "/* static */double const\nMath::computePearsonCorrelation(double const* const pSamplesX, double const* const pSamplesY,\n        double const* const pSampleWeights, unsigned int const* const pSampleIndices,\n        unsigned int const sampleCount, double* const pTotalWeight)\n{\n    double sum_of_x = 0.;\n    double sum_of_x_x = 0.;\n    double sum_of_y = 0.;\n    double sum_of_y_y = 0.;\n    double sum_of_x_y = 0.;\n    double sum_of_weights = 0.;\n\n    for (unsigned int i = 0; i < sampleCount; ++i)\n    {\n        double const my_x = pSamplesX[pSampleIndices[i]];\n        double const my_y = pSamplesY[pSampleIndices[i]];\n\n        if (my_x == my_x && my_y == my_y)\n        {\n            double const my_weight = pSampleWeights[pSampleIndices[i]];\n            sum_of_x += my_x * my_weight;\n            sum_of_x_x += my_x * my_x * my_weight;\n            sum_of_y += my_y * my_weight;\n            sum_of_y_y += my_y * my_y * my_weight;\n            sum_of_x_y += my_x * my_y * my_weight;\n            sum_of_weights += my_weight;\n        }\n    }\n\n    double const r = (sum_of_x_y - ((sum_of_x * sum_of_y) / sum_of_weights))\n            / std::sqrt(\n                    (sum_of_x_x - ((sum_of_x * sum_of_x) / sum_of_weights))\n                            * (sum_of_y_y - ((sum_of_y * sum_of_y) / sum_of_weights)));\n\n    *pTotalWeight = sum_of_weights;\n\n    return r;\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/optimizeCoreGx.R",
    "language": "R",
    "content": "#' @importFrom data.table setDTthreads as.data.table\n#' @importFrom bench press mark\n#' @importFrom parallel detectCores\n\n\n#' @title A helper method to find the best multithreading configuration for your\n#'   computer\n#'\n#' @param sample_data `TreatmentResponseExperiment`\n#' @param set `logical(1)` Should the function modify your R environment\n#'   with the predicted optimal settings? This changes the global state of your\n#'   R session!\n#' @param report `logical(1)` Should a `data.frame` of results be returned\n#'   by number of threads and operation be returned? Defaults to `!set`.\n#'\n#' @return\n#' If `set=TRUE`, modifies `data.table` threads via `setDTthreads()`, otherwise\n#' displays a message indicating the optimal number of threads.\n#' If `report=TRUE`, also returns a `data.frame` of the benchmark results.\n#'\n#' @examples\n#' \\donttest{\n#'   data(merckLongTable)\n#'   optimizeCoreGx(merckLongTable)\n#' }\n#'\n#' @md\n#' @export\noptimizeCoreGx <- function(sample_data, set=FALSE, report=!set) {\n    ncores <- max(1, parallel::detectCores() - 2)\n    nthread_range <- if (ncores == 1) 1 else c(1, seq(2, ncores, 2))\n    old_threads <- data.table::getDTthreads()\n    message(\"Benchmarking assay(sample_data, withDimnames=TRUE)...\")\n    assay_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ assay(sample_data, 1, withDimnames=TRUE); NA })\n    })\n    message(\"Benchmarking assays(sample_data)...\")\n    assays_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ assays(sample_data); NA })\n    })\n    message(\"Benchmarking reindex(sample_data)...\")\n    reindex_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ reindex(sample_data); NA })\n    })\n    report_table <- as.data.table(\n        rbind(assay_report, assays_report, reindex_report)\n    )[,\n        .(expression=as.character(expression), nthread,\n            min_sec=as.numeric(min), median_sec=as.numeric(median),\n            total_sec=as.numeric(total_time),\n            mem_alloc_mb=as.numeric(mem_alloc) / 1e6, `itr/sec`,  `gc/sec`)\n    ]\n    best_results <- report_table[,\n        .SD[which.min(median_sec), .(time=median_sec, nthread=nthread)],\n        by=expression\n    ]\n    optimal_cores <- best_results[,\n        as.integer(as.data.table(table(nthread))[which.max(N), nthread])\n    ]\n    message(\"Optimal cores for your machine are: \", optimal_cores)\n    if (set) {\n        message(\"Setting optimal cores\")\n        data.table::setDTthreads(optimal_cores)\n    } else {\n        data.table::setDTthreads(old_threads)\n    }\n    if (report) return(as.data.frame(report_table)) else return(invisible(NULL))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `optimizeCoreGx` function and what are its main parameters?",
        "answer": "The `optimizeCoreGx` function is designed to find the best multithreading configuration for a user's computer when working with `TreatmentResponseExperiment` data. It has three main parameters: `sample_data` (a `TreatmentResponseExperiment` object), `set` (a logical value indicating whether to modify the R environment with optimal settings), and `report` (a logical value determining if a data frame of benchmark results should be returned)."
      },
      {
        "question": "How does the function determine the optimal number of cores to use?",
        "answer": "The function determines the optimal number of cores by benchmarking three operations (`assay`, `assays`, and `reindex`) with different numbers of threads. It uses the `bench::press` function to run these benchmarks across a range of thread counts. The optimal core count is then determined by finding the thread count that yields the lowest median execution time across all three operations."
      },
      {
        "question": "What does the function return, and how does it handle the `set` and `report` parameters?",
        "answer": "The function's return value depends on the `set` and `report` parameters. If `set=TRUE`, it modifies the `data.table` threads using `setDTthreads()` and displays a message with the optimal core count. If `report=TRUE`, it returns a data frame containing the benchmark results. If both are FALSE, it only displays the optimal core count message and returns `invisible(NULL)`. The function also ensures that the original thread settings are restored if `set=FALSE`."
      }
    ],
    "completion_tasks": [
      {
        "partial": "optimizeCoreGx <- function(sample_data, set=FALSE, report=!set) {\n    ncores <- max(1, parallel::detectCores() - 2)\n    nthread_range <- if (ncores == 1) 1 else c(1, seq(2, ncores, 2))\n    old_threads <- data.table::getDTthreads()\n    message(\"Benchmarking assay(sample_data, withDimnames=TRUE)...\")\n    assay_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ assay(sample_data, 1, withDimnames=TRUE); NA })\n    })\n    # Add code to benchmark assays and reindex operations\n    # Calculate report_table and best_results\n    # Determine optimal_cores\n    # Set or restore threads based on 'set' parameter\n    # Return report if requested\n}",
        "complete": "optimizeCoreGx <- function(sample_data, set=FALSE, report=!set) {\n    ncores <- max(1, parallel::detectCores() - 2)\n    nthread_range <- if (ncores == 1) 1 else c(1, seq(2, ncores, 2))\n    old_threads <- data.table::getDTthreads()\n    message(\"Benchmarking assay(sample_data, withDimnames=TRUE)...\")\n    assay_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ assay(sample_data, 1, withDimnames=TRUE); NA })\n    })\n    message(\"Benchmarking assays(sample_data)...\")\n    assays_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ assays(sample_data); NA })\n    })\n    message(\"Benchmarking reindex(sample_data)...\")\n    reindex_report <- bench::press(nthread=nthread_range, {\n        data.table::setDTthreads(nthread)\n        gc()\n        bench::mark({ reindex(sample_data); NA })\n    })\n    report_table <- as.data.table(rbind(assay_report, assays_report, reindex_report))[, .(expression=as.character(expression), nthread, min_sec=as.numeric(min), median_sec=as.numeric(median), total_sec=as.numeric(total_time), mem_alloc_mb=as.numeric(mem_alloc) / 1e6, `itr/sec`, `gc/sec`)]\n    best_results <- report_table[, .SD[which.min(median_sec), .(time=median_sec, nthread=nthread)], by=expression]\n    optimal_cores <- best_results[, as.integer(as.data.table(table(nthread))[which.max(N), nthread])]\n    message(\"Optimal cores for your machine are: \", optimal_cores)\n    if (set) {\n        message(\"Setting optimal cores\")\n        data.table::setDTthreads(optimal_cores)\n    } else {\n        data.table::setDTthreads(old_threads)\n    }\n    if (report) return(as.data.frame(report_table)) else return(invisible(NULL))\n}"
      },
      {
        "partial": "optimizeCoreGx <- function(sample_data, set=FALSE, report=!set) {\n    ncores <- max(1, parallel::detectCores() - 2)\n    nthread_range <- if (ncores == 1) 1 else c(1, seq(2, ncores, 2))\n    old_threads <- data.table::getDTthreads()\n    # Benchmark assay, assays, and reindex operations\n    # Calculate report_table\n    best_results <- report_table[,\n        .SD[which.min(median_sec), .(time=median_sec, nthread=nthread)],\n        by=expression\n    ]\n    optimal_cores <- best_results[,\n        as.integer(as.data.table(table(nthread))[which.max(N), nthread])\n    ]\n    message(\"Optimal cores for your machine are: \", optimal_cores)\n    # Set or restore threads based on 'set' parameter\n    # Return report if requested\n}",
        "complete": "optimizeCoreGx <- function(sample_data, set=FALSE, report=!set) {\n    ncores <- max(1, parallel::detectCores() - 2)\n    nthread_range <- if (ncores == 1) 1 else c(1, seq(2, ncores, 2))\n    old_threads <- data.table::getDTthreads()\n    benchmark_op <- function(op_name, op) {\n        message(paste(\"Benchmarking\", op_name, \"...\"))\n        bench::press(nthread=nthread_range, {\n            data.table::setDTthreads(nthread)\n            gc()\n            bench::mark({ op; NA })\n        })\n    }\n    reports <- list(\n        assay = benchmark_op(\"assay(sample_data, withDimnames=TRUE)\", assay(sample_data, 1, withDimnames=TRUE)),\n        assays = benchmark_op(\"assays(sample_data)\", assays(sample_data)),\n        reindex = benchmark_op(\"reindex(sample_data)\", reindex(sample_data))\n    )\n    report_table <- as.data.table(do.call(rbind, reports))[, .(expression=as.character(expression), nthread, min_sec=as.numeric(min), median_sec=as.numeric(median), total_sec=as.numeric(total_time), mem_alloc_mb=as.numeric(mem_alloc) / 1e6, `itr/sec`, `gc/sec`)]\n    best_results <- report_table[, .SD[which.min(median_sec), .(time=median_sec, nthread=nthread)], by=expression]\n    optimal_cores <- best_results[, as.integer(as.data.table(table(nthread))[which.max(N), nthread])]\n    message(\"Optimal cores for your machine are: \", optimal_cores)\n    if (set) {\n        message(\"Setting optimal cores\")\n        data.table::setDTthreads(optimal_cores)\n    } else {\n        data.table::setDTthreads(old_threads)\n    }\n    if (report) return(as.data.frame(report_table)) else return(invisible(NULL))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/R/mRMRe.Data.R",
    "language": "R",
    "content": "## Definition\n\nsetClass(\"mRMRe.Data\", representation(sample_names = \"character\", feature_names = \"character\", feature_types = \"numeric\", data = \"matrix\", strata = \"numeric\", weights = \"numeric\", priors = \"matrix\"))\n\n## Wrapper\n\n`mRMR.data` <- function(...)\n{\n    return(new(\"mRMRe.Data\", ...))\n}\n\n## initialize\n\nsetMethod(\"initialize\", signature(\"mRMRe.Data\"), function(.Object, data, strata, weights, priors)\n{\n    ## Data Processing\n    \n    if (!is.data.frame(data))\n        stop(\"data must be of type data frame\")\n        \n    if(ncol(data) > (sqrt((2^31) - 1)))\n        stop(\"Too many features, the number of features should be <= 46340!\")\n    \n    feature_types <- sapply(data, function(feature) paste(class(feature), collapse = \"_\"))\n    \n    if (any(!is.element(feature_types, c(\"numeric\", \"ordered_factor\", \"Surv\"))))\n        stop(\"data columns must be either of numeric, ordered factor or Surv type\")\n\n    .Object@sample_names <- rownames(data)\n    .Object@feature_names <- colnames(data)\n    .Object@feature_types <- unlist(lapply(feature_types, switch, \"Surv\" = c(2, 3), \"ordered_factor\" = 1, 0))\n    names(.Object@feature_types) <- NULL\n    # Optimize the case when all features are continuous\n    if(sum(.Object@feature_types) == 0)\n\t.Object@data <- as.matrix(data) \n    else\n        .Object@data <- do.call(cbind, lapply(seq(feature_types), function(i) switch(feature_types[[i]],\n                                \"Surv\" = cbind(event = data[, i][, \"status\"], time = data[, i][, \"time\"]),\n                                \"ordered_factor\" = as.numeric(as.integer(data[, i]) - 1),\n                                as.numeric(data[, i]))))\n    \n    \n    rownames(.Object@data) <- rownames(data)\n    colnames(.Object@data)[!.Object@feature_types %in% c(2, 3)] <- colnames(data)[feature_types != \"Surv\"]\n    colnames(.Object@data)[.Object@feature_types %in% c(2, 3)] <- paste(rep(colnames(data)[feature_types == \"Surv\"],\n                    each = 2), rep(c(\"event\", \"time\"), sum(feature_types == \"Surv\")), sep = \"_\")\n    \n    ## Sample Stratum Processing\n    \n    if (missing(strata)) \n        .Object@strata <- rep.int(0, nrow(data))\n    else\n        sampleStrata(.Object) <- strata\n    \n    ## Sample Weight Processing\n    \n    if (missing(weights)) \n        .Object@weights <- rep(1, nrow(data))\n    else\n        sampleWeights(.Object) <- weights\n\n    ## Prior Feature Matrix Processing\n    \n    if (!missing(priors) && !is.null(priors))\n        priors(.Object) <- priors\n    \n    return(.Object)\n})\n\n## show\n\nsetMethod(\"show\", signature(\"mRMRe.Data\"), function(object)\n{\n    str(object)\n})\n\n## featureData\n\nsetMethod(\"featureData\", signature(\"mRMRe.Data\"), function(object)\n{\n    data <- lapply(seq(object@feature_types), function(i) switch(as.character(object@feature_types[[i]]),\n                        \"3\" = Surv(time = object@data[, i], event = object@data[, i - 1]),\n                        \"2\" = NULL,\n                        \"1\" = object@data[, i] + 1,\n                        \"0\" = object@data[, i],\n                        NULL))\n    data <- data.frame(data[!sapply(data, is.null)])\n    colnames(data) <- object@feature_names\n    \n    return(data)\n})\n\n## subsetData\n\nsetMethod(\"subsetData\", signature(\"mRMRe.Data\"), function(object, row_indices, column_indices)\n{\n    if(missing(row_indices) && missing(column_indices))\n        return(object)\n        \n    if(missing(row_indices))\n        row_indices <- 1:sampleCount(object)\n    if(missing(column_indices))\n        column_indices <- 1:featureCount(object)\n    \n    data <- featureData(object)[row_indices, column_indices, drop=FALSE]\n    strata <- factor(sampleStrata(object)[row_indices])\n    weights <- sampleWeights(object)[row_indices]\n    priors <- priors(object)\n    if(length(priors) > 0)\n        priors <- priors[column_indices, column_indices, drop=FALSE]\n    else\n        priors <- NULL\n    \n    return(new(\"mRMRe.Data\", data = data, strata = strata, weights = weights, priors = priors))\n})\n\n## sampleCount\n\nsetMethod(\"sampleCount\", signature(\"mRMRe.Data\"), function(object)\n{\n    return(nrow(object@data))\n})\n\n## sampleNames\n\nsetMethod(\"sampleNames\", signature(\"mRMRe.Data\"), function(object)\n{\n    return(object@sample_names)\n})\n\n## featureCount\n\nsetMethod(\"featureCount\", signature(\"mRMRe.Data\"), function(object)\n{\n    return(length(object@feature_names))\n})\n\n## featureNames\n\nsetMethod(\"featureNames\", signature(\"mRMRe.Data\"), function(object)\n{\n    return(object@feature_names)\n})\n\n## sampleStrata\n\nsetMethod(\"sampleStrata\", signature(\"mRMRe.Data\"), function(object)\n{\n    strata <- object@strata\n    names(strata) <- rownames(object@data)\n    \n    return(strata)\n})\n\n## sampleStrata<-\n\nsetReplaceMethod(\"sampleStrata\", signature(\"mRMRe.Data\"), function(object, value)\n{\n    if (length(value) != nrow(object@data))\n        stop(\"data and strata must contain the same number of samples\")\n    else if (!is.factor(value))\n        stop(\"strata must be provided as factors\")\n    else if (sum(is.na(value)) > 0)\n        stop(\"cannot have missing values in strata\")\n    else\n        object@strata <- as.integer(value) - 1\n    \n    return(object)\n})\n\n## sampleWeights\n\nsetMethod(\"sampleWeights\", signature(\"mRMRe.Data\"), function(object)\n{\n    weights <- object@weights\n    names(weights) <- rownames(object@data)\n    \n    return(weights)\n})\n\n## sampleWeights<-\n\nsetReplaceMethod(\"sampleWeights\", signature(\"mRMRe.Data\"), function(object, value)\n{\n    if (length(value) != nrow(object@data))\n        stop(\"data and weight must contain the same number of samples\")\n    else if (sum(is.na(value)) > 0)\n        stop(\"cannot have missing values in weights\")\n    else\n        object@weights <- as.numeric(value)\n    \n    return(object)\n})\n\n## priors\n\nsetMethod(\"priors\", signature(\"mRMRe.Data\"), function(object)\n{\n    if (length(object@priors) == 0)\n        return(object@priors)\n    else\n        return(.compressFeatureMatrix(object, object@priors))\n})\n\n## priors<-\n\nsetReplaceMethod(\"priors\", signature(\"mRMRe.Data\"), function(object, value)\n{\n    if (ncol(value) != ncol(object@data) || nrow(value) != ncol(object@data))\n        stop(\"priors matrix must be a symmetric matrix containing as many features as data\")\n    else\n        object@priors <- .expandFeatureMatrix(object, value)\n    \n    return(object)\n})\n\n## mim\n\nsetMethod(\"mim\", signature(\"mRMRe.Data\"),\n        function(object, prior_weight = 0, continuous_estimator = c(\"pearson\", \"spearman\", \"kendall\", \"frequency\"), outX = TRUE, bootstrap_count = 0)\n{\n    continuous_estimator <- match.arg(continuous_estimator)\n    if (length(object@priors) != 0)\n    {\n        if (missing(prior_weight))\n            stop(\"prior weight must be provided if there are priors\")\n        else if  (prior_weight < 0 || prior_weight > 1)\n            stop(\"prior weight must be a value ranging from 0 to 1\")\n    }\n    else\n        prior_weight <- 0\n    \n    mi_matrix <- as.numeric(matrix(NA, ncol = ncol(object@data), nrow = ncol(object@data)))\n    \n    .Call(.C_export_mim, as.numeric(object@data), as.numeric(object@priors),\n            as.numeric(prior_weight), as.integer(object@strata), as.numeric(object@weights),\n            as.integer(object@feature_types), as.integer(nrow(object@data)), as.integer(ncol(object@data)),\n            as.integer(length(unique(object@strata))),\n            as.integer(.map.continuous.estimator(continuous_estimator)),\n            as.integer(outX), as.integer(bootstrap_count), mi_matrix)\n    \n    mi_matrix <- matrix(mi_matrix, ncol = ncol(object@data), nrow = ncol(object@data))\n    \n    mi_matrix <- .compressFeatureMatrix(object, mi_matrix)\n\n    # mi_matrix[i, j] contains the biased correlation between\n    # features i and j (i -> j directionality)\n    \n    return(mi_matrix)\n})\n\n## expandFeatureMatrix\n\nsetMethod(\".expandFeatureMatrix\", signature(\"mRMRe.Data\"), function(object, matrix)\n{\n    adaptor <- which(object@feature_types != 3)\n    matrix <- do.call(cbind, lapply(seq(adaptor), function(i)\n    {\n        column <- do.call(rbind, lapply(seq(adaptor), function(j)\n        {\n            item <- matrix[j, i]\n            \n            if (object@feature_types[[adaptor[[j]]]] == 2)\n                return(rbind(item, item, deparse.level = 0))\n            else\n                return(item)\n        }))\n        \n        if (object@feature_types[[adaptor[[i]]]] == 2)\n            return(cbind(column, column, deparse.level = 0))\n        else\n            return(column)\n    }))\n\n    return(matrix)\n})\n\n## compressFeatureMatrix\n\nsetMethod(\".compressFeatureMatrix\", signature(\"mRMRe.Data\"), function(object, matrix)\n{\n    adaptor <- which(object@feature_types != 3)\n    matrix <- matrix[adaptor, adaptor]\n    colnames(matrix) <- object@feature_names\n    rownames(matrix) <- object@feature_names\n    \n    return(matrix)\n})\n\n## expandFeatureIndices\n\nsetMethod(\".expandFeatureIndices\", signature(\"mRMRe.Data\"), function(object, indices)\n{\n    adaptor <- which(object@feature_types == 3)\n    if (length(adaptor) > 0 && any(indices >= adaptor))\n        indices <- sapply(indices, function(i) i + sum(sapply(1:length(adaptor), function(j) i >= (adaptor[[j]] - j + 1))))\n\n    return(as.integer(indices))\n})\n\n## compressFeatureIndices\n\nsetMethod(\".compressFeatureIndices\", signature(\"mRMRe.Data\"), function(object, indices)\n{\n    adaptor <- which(object@feature_types == 3)\n    \n    if (length(adaptor) > 0)\n        indices <- sapply(indices, function(i) i - sum(i >= adaptor))\n    \n    return(as.integer(indices))\n})\n\n\nsetMethod(\"scores\", signature(\"mRMRe.Data\"), function(object, solutions)\n{\n    mi_matrix <- mim(object)\n    targets <- names(solutions)\n    scores <- lapply(targets, function(target) {\n      apply(solutions[[target]], 2, function(solution) {\n\t \t \t \t sapply(1:length(solution), function(i) {\n\t \t \t \t \t \t \tfeature_i <- solution[i] \n\t\t\tif(i == 1)\n\t\t\t\treturn(mi_matrix[as.numeric(target), feature_i])\n\n\t\t\t ancestry_score <- mean(sapply((i-1):1, function(j) mi_matrix[feature_i, solution[j]]))\n\t \t \t \t \t \t \t return(mi_matrix[as.numeric(target), feature_i] - ancestry_score)\n\t \t \t \t \t })\n\t \t \t \t \n\t \t \t })\n\t })\n\t names(scores) <- targets\n\t return(scores)\n})\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mRMRe.Data` class and its initialization method?",
        "answer": "The `mRMRe.Data` class is designed to store and manage data for feature selection. Its initialization method processes input data, validates it, and sets up various attributes such as sample names, feature names, feature types, and data matrix. It also handles optional inputs like strata, weights, and priors."
      },
      {
        "question": "How does the `mim` method handle different types of features and what is its primary output?",
        "answer": "The `mim` method calculates mutual information between features. It handles different feature types (numeric, ordered factor, and survival) by using the `feature_types` attribute. The method also considers sample strata and weights. Its primary output is a mutual information matrix, where each element [i, j] represents the biased correlation between features i and j."
      },
      {
        "question": "What is the purpose of the `expandFeatureMatrix` and `compressFeatureMatrix` methods in the `mRMRe.Data` class?",
        "answer": "These methods handle the conversion between the internal representation of the feature matrix and its user-facing form. `expandFeatureMatrix` expands the matrix to include separate columns for survival data (event and time), while `compressFeatureMatrix` does the opposite, combining survival data columns into a single feature. This allows for efficient internal processing while providing a more intuitive interface for the user."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"scores\", signature(\"mRMRe.Data\"), function(object, solutions)\n{\n    mi_matrix <- mim(object)\n    targets <- names(solutions)\n    scores <- lapply(targets, function(target) {\n      apply(solutions[[target]], 2, function(solution) {\n         sapply(1:length(solution), function(i) {\n              feature_i <- solution[i] \n            if(i == 1)\n                return(mi_matrix[as.numeric(target), feature_i])\n\n            # Complete the code here\n         })\n      })\n    })\n    names(scores) <- targets\n    return(scores)\n})",
        "complete": "setMethod(\"scores\", signature(\"mRMRe.Data\"), function(object, solutions)\n{\n    mi_matrix <- mim(object)\n    targets <- names(solutions)\n    scores <- lapply(targets, function(target) {\n      apply(solutions[[target]], 2, function(solution) {\n         sapply(1:length(solution), function(i) {\n              feature_i <- solution[i] \n            if(i == 1)\n                return(mi_matrix[as.numeric(target), feature_i])\n\n            ancestry_score <- mean(sapply((i-1):1, function(j) mi_matrix[feature_i, solution[j]]))\n            return(mi_matrix[as.numeric(target), feature_i] - ancestry_score)\n         })\n      })\n    })\n    names(scores) <- targets\n    return(scores)\n})"
      },
      {
        "partial": "setMethod(\".expandFeatureMatrix\", signature(\"mRMRe.Data\"), function(object, matrix)\n{\n    adaptor <- which(object@feature_types != 3)\n    matrix <- do.call(cbind, lapply(seq(adaptor), function(i)\n    {\n        column <- do.call(rbind, lapply(seq(adaptor), function(j)\n        {\n            item <- matrix[j, i]\n            \n            # Complete the code here\n        }))\n        \n        # Complete the code here\n    }))\n\n    return(matrix)\n})",
        "complete": "setMethod(\".expandFeatureMatrix\", signature(\"mRMRe.Data\"), function(object, matrix)\n{\n    adaptor <- which(object@feature_types != 3)\n    matrix <- do.call(cbind, lapply(seq(adaptor), function(i)\n    {\n        column <- do.call(rbind, lapply(seq(adaptor), function(j)\n        {\n            item <- matrix[j, i]\n            \n            if (object@feature_types[[adaptor[[j]]]] == 2)\n                return(rbind(item, item, deparse.level = 0))\n            else\n                return(item)\n        }))\n        \n        if (object@feature_types[[adaptor[[i]]]] == 2)\n            return(cbind(column, column, deparse.level = 0))\n        else\n            return(column)\n    }))\n\n    return(matrix)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/adaptiveMatthewCor.R",
    "language": "R",
    "content": "## adaptive Matthews correlation coefficient for binary classification\n#' Calculate an Adaptive Matthews Correlation Coefficient\n#' \n#' This function calculates an Adaptive Matthews Correlation Coefficient (AMCC) \n#' for two vectors of values of the same length. It assumes the entries in the \n#' two vectors are paired. The Adaptive Matthews Correlation Coefficient for two\n#' vectors of values is defined as the Maximum Matthews Coefficient over all \n#' possible binary splits of the ranks of the two vectors. In this way, it \n#' calculates the best possible agreement of a binary classifier on the two \n#' vectors of data. If the AMCC is low, then it is impossible to find any binary \n#' classification of the two vectors with a high degree of concordance.   \n#' \n#' @examples \n#' x <- c(1,2,3,4,5,6,7)\n#' y <- c(1,3,5,4,2,7,6)\n#' amcc(x,y, min.cat=2)\n#' \n#' @param x,y Two paired vectors of values. Could be replicates of observations \n#'   for the same experiments for example.  \n#' @param step.prct Instead of testing all possible splits of the data, it is \n#'   possible to test steps of a percentage size of the total number of ranks in \n#'   x/y. If this variable is 0, function defaults to testing all possible \n#'   splits.\n#' @param min.cat The minimum number of members per category. Classifications \n#'   with less members fitting into both categories will not be considered. \n#' @param nperm The number of perumatation to use for estimating significance. \n#'   If 0, then no p-value is calculated. \n#' @param nthread Number of threads to parallize over. Both the AMCC calculation \n#'   and the permutation testing is done in parallel. \n#' @param ... Additional arguments\n#' \n#' @return Returns a list with two elements. $amcc contains the highest 'mcc' \n#'   value over all the splits, the p value, as well as the rank at which the \n#'   split was done.\n#'\n#' @importFrom BiocParallel bplapply\n#' @importFrom stats quantile\n#'\n#' @export\n## FIXME:: We need a more descriptive name for this function\namcc <- function(x, y, step.prct = 0, min.cat = 3, nperm = 1000, nthread = 1, ...) {\n    # PARAMETER CHANGE WARNING\n    if (!missing(...)) {\n        if (\"setseed\" %in% names(...)) {\n            warning(\"The setseed parameter has been removed in this release to conform\n              to Bioconductor coding standards. Please call set.seed in your\n              script before running this function.\")\n        }\n    }\n    \n    if (!min.cat > 1) {\n        \n        stop(\"Min.cat should be at least 2\")\n        \n    }\n    ccix <- complete.cases(x, y)\n    if (sum(ccix) >= (2 * min.cat)) {\n        x2 <- rank(-x[ccix], ties.method = \"first\")\n        y2 <- rank(-y[ccix], ties.method = \"first\")\n        ## compute mcc for each rank\n        iix <- seq_len(min(max(x2), max(y2)) - 1)\n        if (step.prct > 0) {\n            iix <- round(quantile(iix, probs = seq(0, 1, by = step.prct)))\n        }\n        splitix <- parallel::splitIndices(nx = length(iix), ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- bplapply(splitix, function(x, iix, x2, y2) {\n            res <- t(vapply(iix[x], function(x, x2, y2) {\n                x3 <- factor(ifelse(x2 <= x, \"1\", \"0\"))\n                y3 <- factor(ifelse(y2 <= x, \"1\", \"0\"))\n                res <- mcc(x = x3, y = y3, nperm = 0, nthread = 1)\n                return(res)\n            }, x2 = x2, y2 = y2, FUN.VALUE = list(1, 1)))\n            ## TODO:: Why is return value a list of doubles when the class of res is matrix in debug ?\n            return(res)\n        }, iix = iix, x2 = x2, y2 = y2)\n        mm <- do.call(rbind, mcres)\n        mode(mm) <- \"numeric\"\n        ## remove extreme indices\n        rmix <- c(seq_len(min.cat - 1), (nrow(mm) - min.cat + 2):nrow(mm))\n        mccix <- max(which(mm[-rmix, \"estimate\", drop = FALSE] == max(mm[-rmix, \"estimate\", drop = FALSE], na.rm = TRUE))) + (min.cat - 1)\n        ## compute significance only for the AMCC\n        x3 <- factor(ifelse(x2 <= mccix, \"1\", \"0\"))\n        y3 <- factor(ifelse(y2 <= mccix, \"1\", \"0\"))\n        if (nperm > 0) {\n            mm[mccix, \"p.value\"] <- mcc(x = x3, y = y3, nperm = nperm, nthread = nthread)[[\"p.value\"]]\n            ## bonferronni correction mm[mccix, 'p'] <- mm[mccix, 'p'] * length(x3)\n        }\n        if (!is.na(mm[mccix, \"p.value\"]) && mm[mccix, \"p.value\"] > 1) {\n            mm[mccix, \"p.value\"] <- 1\n        }\n        res <- c(mcc = mm[mccix, ], n1 = mccix, n2 = nrow(mm) - mccix, n = nrow(mm))\n    } else {\n        res <- c(mcc = NA, p = NA, n1 = 0, n2 = 0, n = sum(ccix))\n        mm <- NA\n    }\n    names(res) <- c(\"mcc\", \"p\", \"n1\", \"n2\", \"n\")\n    return(list(amcc = res, mcc = mm))\n}\n\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `amcc` function and what does AMCC stand for?",
        "answer": "The `amcc` function calculates an Adaptive Matthews Correlation Coefficient (AMCC) for two vectors of values. AMCC is defined as the Maximum Matthews Coefficient over all possible binary splits of the ranks of the two input vectors. It aims to find the best possible agreement of a binary classifier on the two vectors of data, which is useful for assessing the potential for binary classification between two sets of observations."
      },
      {
        "question": "How does the function handle parallel processing, and what parameters control this behavior?",
        "answer": "The function uses parallel processing for both the AMCC calculation and permutation testing. It utilizes the `bplapply` function from the BiocParallel package to parallelize computations. The `nthread` parameter controls the number of threads to use for parallelization. The function splits the work into chunks using `parallel::splitIndices` and processes these chunks in parallel."
      },
      {
        "question": "What is the significance of the `min.cat` parameter, and how does it affect the AMCC calculation?",
        "answer": "The `min.cat` parameter specifies the minimum number of members per category in the binary classification. It ensures that classifications with fewer members in both categories are not considered. This parameter affects the AMCC calculation by removing extreme indices from consideration. Specifically, it removes `min.cat - 1` indices from both the beginning and end of the sorted results before finding the maximum MCC value. This helps to avoid overfitting to very small subsets of the data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "amcc <- function(x, y, step.prct = 0, min.cat = 3, nperm = 1000, nthread = 1, ...) {\n    if (!min.cat > 1) {\n        stop(\"Min.cat should be at least 2\")\n    }\n    ccix <- complete.cases(x, y)\n    if (sum(ccix) >= (2 * min.cat)) {\n        x2 <- rank(-x[ccix], ties.method = \"first\")\n        y2 <- rank(-y[ccix], ties.method = \"first\")\n        iix <- seq_len(min(max(x2), max(y2)) - 1)\n        if (step.prct > 0) {\n            iix <- round(quantile(iix, probs = seq(0, 1, by = step.prct)))\n        }\n        splitix <- parallel::splitIndices(nx = length(iix), ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        # Complete the function from here\n    }\n}",
        "complete": "amcc <- function(x, y, step.prct = 0, min.cat = 3, nperm = 1000, nthread = 1, ...) {\n    if (!min.cat > 1) {\n        stop(\"Min.cat should be at least 2\")\n    }\n    ccix <- complete.cases(x, y)\n    if (sum(ccix) >= (2 * min.cat)) {\n        x2 <- rank(-x[ccix], ties.method = \"first\")\n        y2 <- rank(-y[ccix], ties.method = \"first\")\n        iix <- seq_len(min(max(x2), max(y2)) - 1)\n        if (step.prct > 0) {\n            iix <- round(quantile(iix, probs = seq(0, 1, by = step.prct)))\n        }\n        splitix <- parallel::splitIndices(nx = length(iix), ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- bplapply(splitix, function(x, iix, x2, y2) {\n            res <- t(vapply(iix[x], function(x, x2, y2) {\n                x3 <- factor(ifelse(x2 <= x, \"1\", \"0\"))\n                y3 <- factor(ifelse(y2 <= x, \"1\", \"0\"))\n                mcc(x = x3, y = y3, nperm = 0, nthread = 1)\n            }, x2 = x2, y2 = y2, FUN.VALUE = list(1, 1)))\n            return(res)\n        }, iix = iix, x2 = x2, y2 = y2)\n        mm <- do.call(rbind, mcres)\n        mode(mm) <- \"numeric\"\n        rmix <- c(seq_len(min.cat - 1), (nrow(mm) - min.cat + 2):nrow(mm))\n        mccix <- max(which(mm[-rmix, \"estimate\", drop = FALSE] == max(mm[-rmix, \"estimate\", drop = FALSE], na.rm = TRUE))) + (min.cat - 1)\n        x3 <- factor(ifelse(x2 <= mccix, \"1\", \"0\"))\n        y3 <- factor(ifelse(y2 <= mccix, \"1\", \"0\"))\n        if (nperm > 0) {\n            mm[mccix, \"p.value\"] <- mcc(x = x3, y = y3, nperm = nperm, nthread = nthread)[[\"p.value\"]]\n        }\n        if (!is.na(mm[mccix, \"p.value\"]) && mm[mccix, \"p.value\"] > 1) {\n            mm[mccix, \"p.value\"] <- 1\n        }\n        res <- c(mcc = mm[mccix, ], n1 = mccix, n2 = nrow(mm) - mccix, n = nrow(mm))\n    } else {\n        res <- c(mcc = NA, p = NA, n1 = 0, n2 = 0, n = sum(ccix))\n        mm <- NA\n    }\n    names(res) <- c(\"mcc\", \"p\", \"n1\", \"n2\", \"n\")\n    return(list(amcc = res, mcc = mm))\n}"
      },
      {
        "partial": "amcc <- function(x, y, step.prct = 0, min.cat = 3, nperm = 1000, nthread = 1, ...) {\n    if (!min.cat > 1) {\n        stop(\"Min.cat should be at least 2\")\n    }\n    ccix <- complete.cases(x, y)\n    if (sum(ccix) >= (2 * min.cat)) {\n        x2 <- rank(-x[ccix], ties.method = \"first\")\n        y2 <- rank(-y[ccix], ties.method = \"first\")\n        iix <- seq_len(min(max(x2), max(y2)) - 1)\n        if (step.prct > 0) {\n            iix <- round(quantile(iix, probs = seq(0, 1, by = step.prct)))\n        }\n        splitix <- parallel::splitIndices(nx = length(iix), ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- bplapply(splitix, function(x, iix, x2, y2) {\n            # Complete the function from here\n        }, iix = iix, x2 = x2, y2 = y2)\n    }\n}",
        "complete": "amcc <- function(x, y, step.prct = 0, min.cat = 3, nperm = 1000, nthread = 1, ...) {\n    if (!min.cat > 1) {\n        stop(\"Min.cat should be at least 2\")\n    }\n    ccix <- complete.cases(x, y)\n    if (sum(ccix) >= (2 * min.cat)) {\n        x2 <- rank(-x[ccix], ties.method = \"first\")\n        y2 <- rank(-y[ccix], ties.method = \"first\")\n        iix <- seq_len(min(max(x2), max(y2)) - 1)\n        if (step.prct > 0) {\n            iix <- round(quantile(iix, probs = seq(0, 1, by = step.prct)))\n        }\n        splitix <- parallel::splitIndices(nx = length(iix), ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- bplapply(splitix, function(x, iix, x2, y2) {\n            res <- t(vapply(iix[x], function(x, x2, y2) {\n                x3 <- factor(ifelse(x2 <= x, \"1\", \"0\"))\n                y3 <- factor(ifelse(y2 <= x, \"1\", \"0\"))\n                mcc(x = x3, y = y3, nperm = 0, nthread = 1)\n            }, x2 = x2, y2 = y2, FUN.VALUE = list(1, 1)))\n            return(res)\n        }, iix = iix, x2 = x2, y2 = y2)\n        mm <- do.call(rbind, mcres)\n        mode(mm) <- \"numeric\"\n        rmix <- c(seq_len(min.cat - 1), (nrow(mm) - min.cat + 2):nrow(mm))\n        mccix <- max(which(mm[-rmix, \"estimate\", drop = FALSE] == max(mm[-rmix, \"estimate\", drop = FALSE], na.rm = TRUE))) + (min.cat - 1)\n        x3 <- factor(ifelse(x2 <= mccix, \"1\", \"0\"))\n        y3 <- factor(ifelse(y2 <= mccix, \"1\", \"0\"))\n        if (nperm > 0) {\n            mm[mccix, \"p.value\"] <- mcc(x = x3, y = y3, nperm = nperm, nthread = nthread)[[\"p.value\"]]\n        }\n        if (!is.na(mm[mccix, \"p.value\"]) && mm[mccix, \"p.value\"] > 1) {\n            mm[mccix, \"p.value\"] <- 1\n        }\n        res <- c(mcc = mm[mccix, ], n1 = mccix, n2 = nrow(mm) - mccix, n = nrow(mm))\n    } else {\n        res <- c(mcc = NA, p = NA, n1 = 0, n2 = 0, n = sum(ccix))\n        mm <- NA\n    }\n    names(res) <- c(\"mcc\", \"p\", \"n1\", \"n2\", \"n\")\n    return(list(amcc = res, mcc = mm))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/LongTable-accessors.R",
    "language": "R",
    "content": "# Navigating this file:\n# - Slot section names start with ----\n# - Method section names start with ==\n#\n# As a result, you can use Ctrl + f to find the slot or method you are looking\n# for quickly, assuming you know its name.\n#\n# For example Ctrl + f '== molecularProfiles' would take you the molecularProfiles\n# method, while Ctrl + f '---- molecularProfiles' would take you to the slot\n# section.\n\n#' @include LongTable-class.R allGenerics.R\nNULL\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n.local_class_4 <- 'LongTable'\n.local_data_4 <- 'merckLongTable'\n\n\n# =======================================\n# Accessor Method Documentation Object\n# ---------------------------------------\n\n\n#' @noRd\n.docs_LongTable_accessors <- function(...) .parseToRoxygen(\n    \"\n    @title Accessing and modifying information in a `{class_}`\n\n    @description\n    Documentation for the various setters and getters which allow manipulation\n    of data in the slots of a `{class_}` object.\n\n    @return Accessors: See details.\n    @return Setters: An updated `{class_}` object, returned invisibly.\n    \",\n    ...\n)\n\n#' @name LongTable-accessors\n#' @eval .docs_LongTable_accessors(class_=.local_class_4)\n#' @eval .parseToRoxygen(\"@examples data({data_})\", data_=.local_data_4)\nNULL\n\n\n# ======================================\n# Accessor Methods\n# --------------------------------------\n\n\n## ==================\n## ---- .intern Slot\n## ------------------\n\n\n##\n## == getIntern\n\n\n#' Get the symbol(s) x from the object@.intern slot of a LongTable\n#'\n#' This is used as an alternative to R attributes for storing structural\n#' metadata of an S4 objects.\n#'\n#' @examples\n#' getIntern(merckLongTable, 'rowIDs')\n#' getIntern(merckLongTable, c('colIDs', 'colMeta'))\n#'\n#' @describeIn LongTable Access structural metadata present within a\n#'   LongTable object. This is mostly for developmer use.\n#'\n#' @param object `LongTable`\n#' @param x `character` One or more symbol name strings to retrieve from\n#'     the object@.intern environment.\n#'\n#' @return `immutable` value of x if length(x) == 1 else named list of values\n#'     for all symbols in x.\n#'\n#' @include LongTable-class.R\n#' @export\nsetMethod('getIntern', signature(object='LongTable', x='character'),\n        function(object, x) {\n    return(if (length(x) == 1) object@.intern[[x]] else object@.intern[x])\n})\n#' @describeIn LongTable Access all structural metadata present within a\n#'   LongTable object. This is primarily for developmer use.\n#'\n#' @param object `LongTable`\n#' @param x `missing` This argument is excluded from from the function call.\n#'\n#' @return An `immutable` list.\n#'\n#' @examples\n#' getIntern(merckLongTable)\n#'\n#' @aliases getIntern,LongTable,missing-method\n#' @export\nsetMethod('getIntern', signature(object='LongTable', x='missing'),\n    function(object, x) object@.intern\n)\n\n#' Set the .intern slot of a LongTable\n#'\n#' @param object `LongTable`\n#' @param value An `immutable_list` object, being a class union between `list`\n#'   and `immutable` S3 classes.\n#'\n#' @return Updates the object and returns invisibly.\n#'\n#' @keywords internal\nsetReplaceMethod(\"getIntern\", signature(object=\"LongTable\",\n    value=\"immutable_list\"), function(object, value) {\n        object@.intern <- value\n        return(object)\n})\n\n## ==================\n## ---- rowData Slot\n## ------------------\n\n#' Retrieve the row metadata table from a LongTable object\n#'\n#' @examples\n#' rowData(merckLongTable)\n#'\n#' @describeIn LongTable Get the row level annotations for a `LongTable` object.\n#'\n#' @param x A `LongTable` object to retrieve the row metadata from.\n#' @param key `logical` Should the rowKey column also be returned? Defaults\n#'     to FALSE.\n#' @param use.names `logical` This parameter is just here to stop matching\n#'     the positional argument to use.names from the rowData generic. It\n#'     doesn't do anything at this time and can be ignored.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A `data.table` containing rowID, row identifiers, and row metadata.\n#'\n#' @importFrom data.table data.table copy\n#' @export\nsetMethod('rowData', signature(x='LongTable'),\n        function(x, key=FALSE, use.names=FALSE, ...) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@rowData)\n    } else {\n        return(if (key) copy(x@rowData[, -'.rownames']) else\n            copy(x@rowData[, -c('.rownames', 'rowKey')]))\n    }\n})\n\n#' Helper method to share functionality between rowData and colData replace methods\n#'\n#' @param x `LongTable` or inheriting class to update dimData for.\n#' @param dim `character(1)` One of \"row\" or \"col\" indicating with dimension\n#'   to updated metadata for.\n#' @param value #' @param value A `data.table` or `data.frame` to update the\n#'   `rowData` or `colData` of `x` with.\n#'\n#' @return An updated version of `value` which meets all the requirements for\n#'   assignment to a `LongTable` or inheriting class.\n#'\n#' @noRd\n#' @keywords internal\n.update_dimData <- function(x, dim, value) {\n\n    titleDim <- paste0(toupper(substr(dim, 1, 1)), substr(dim, 2, nchar(dim)))\n    dimIDs <- get(paste0(dim, \"IDs\"))\n    dimKey <- paste(dim, \"Key\")\n    dimData <- paste0(dim, \"Data\")\n\n    # type check input\n    if (is(value, 'data.frame')) setDT(value)\n    if (!is(value, 'data.table'))\n        stop(.errorMsg('\\n[CoreGx::', dim, 'Data<-] Please pass a data.frame or ',\n            'data.table to update the ', dim, 'Data slot. We recommend modifying the',\n            ' object returned by ', dim, 'Data(x) then reassigning it with ',\n            dim, 'Data(x)',\n            ' <- new', titleDim, 'Data'),\n            call.=FALSE\n        )\n\n    # remove key column\n    if (dimKey %in% colnames(value)) {\n        value[, (dimKey) := NULL]\n        .message('\\n[CoreGx::', dim, ,'Data<-] Dropping ', dim, 'Key from replacement',\n            ' value, this function will deal with mapping the ', dim, 'Key',\n            ' automatically.')\n    }\n\n    # assemble information to select proper update method\n    dimIDCols <- dimIDs(x)\n    sharedDimIDCols <- intersect(dimIDCols, colnames(value))\n\n    # error if all the row/colID columns are not present in the new row/colData\n    equalDimIDs <- dimIDCols %in% sharedDimIDCols\n    if (!all(equalDimIDs)) warning(.warnMsg('\\n[CoreGx::', dim,\n        'Data<-] The ID columns ', dimIDCols[!equalDimIDs],\n        ' are not present in value. The function ',\n        'will attempt to join with existing ', dim, 'IDs, but this may fail!',\n        collapse=', '), call.=FALSE)\n\n    dimIDs_ <- dimIDs(x, data=TRUE, key=TRUE)\n\n    ## TODO:: Throw error if user tries to modify ID columns\n\n    duplicatedIDcols <- value[, .N, by=c(sharedDimIDCols)][, N > 1]\n    if (any(duplicatedIDcols))\n        warning(.warnMsg(\"\\n[CoreGx::\", dim, \"Data<-,\", class(x)[1], \"-method] The \",\n            \"ID columns are duplicated for rows \",\n            .collapse(which(duplicatedIDcols)),\n            \"! These rows will be dropped before assignment.\"),\n        call.=FALSE)\n\n    dimData <- dimIDs_[unique(value), on=.NATURAL, allow.cartesian=FALSE]\n    dimData[, (dimKey) := .I]\n    dimData <- dimData[!duplicated(get(dimKey)), ]\n    setkeyv(dimData, dimKey)\n    dimData[, .rownames := Reduce(.paste_colon, mget(dimIDCols))]\n\n    ## TODO:: Add some sanity checks before returing\n\n    return(dimData)\n}\n\n\n#' Updates the `rowData` slot as long as the ID columns are not changed.\n#'\n#' @examples\n#' rowData(merckLongTable) <- rowData(merckLongTable)\n#'\n#' @describeIn LongTable Update the row annotations for a `LongTable` object.\n#'   Currently requires that all columns in rowIDs(longTable) be present in\n#'   value.\n#'\n#' @param x A `LongTable` object to modify.\n#' @param value A `data.table` or `data.frame` to update the `rowData` of\n#'   `x` with.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A copy of the `LongTable` object with the `rowData`\n#'   slot updated.\n#'\n#' @md\n#' @importFrom crayon cyan magenta\n#' @importFrom SummarizedExperiment `rowData<-`\n#' @importFrom data.table setDT\n#' @export\nsetReplaceMethod('rowData', signature(x='LongTable'), function(x, ..., value) {\n\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        x@rowData <- value\n        return(invisible(x))\n    }\n\n    x@rowData <- .update_dimData(x=x, dim=\"row\", value=value)\n    return(invisible(x))\n})\n\n\n## ==================\n## ---- colData Slot\n## ------------------\n\n\n#' Retrieve the column metadata table from a LongTable object\n#'\n#' @examples\n#' colData(merckLongTable)\n#'\n#' # Get the keys as well, mostly for internal use\n#' colData(merckLongTable, key=TRUE)\n#'\n#' @describeIn LongTable Get the column level annotations for a LongTable\n#'   object.\n#'\n#' @param x A `LongTable` to retrieve column metadata from.\n#' @param key `logical` Should the colKey column also be returned? Defaults to\n#'     FALSE.\n#' @param ... For developer use only! Pass raw=TRUE to return the slot for\n#'   modification by reference.\n#'\n#' @return A `data.table` containing row identifiers and metadata.\n#'\n#' @import data.table\n#' @export\nsetMethod('colData', signature(x='LongTable'),\n        function(x, key=FALSE, dimnames=FALSE, ...) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@colData)\n    }\n    return(if (key) copy(x@colData[, -'.colnames']) else\n        copy(x@colData[, -c('.colnames', 'colKey')]))\n})\n\n#' Updates the `colData` slot as long as the ID columns are not changed.\n#'\n#' @examples\n#' colData(merckLongTable) <- colData(merckLongTable)\n#'\n#' @describeIn LongTable Update the colData of a LongTable object. Currently\n#'   requires that all of the colIDs(longTable) be in the value object.\n#'\n#' @param x A `LongTable` object to modify.\n#' @param value A `data.table` or `data.frame` to update with. Must have\n#'   all of the colIDs currently in the `LongTable` object in order to ensure\n#'   assay key mappings are consistent.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A copy of the `LongTable` object with the `colData`\n#'   slot updated.\n#'\n#' @importFrom crayon cyan magenta\n#' @importFrom SummarizedExperiment colData<-\n#' @importFrom data.table data.table setDT\n#' @export\nsetReplaceMethod('colData', signature(x='LongTable'),\n        function(x, ..., value) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        x@colData <- value\n        return(invisible(x))\n    }\n    x@colData <- .update_dimData(x=x, dim=\"col\", value=value)\n    return(invisible(x))\n})\n\n## ==================\n## ---- assaySlot\n## ------------------\n\n\n##\n## == assays\n\n\n#' Return a list of `data.table` objects with the assay measurements from a\n#'  `LongTable` object.\n#'\n#' @examples\n#' assays(merckLongTable)\n#'\n#' @describeIn LongTable Get a list containing all the assays in a `LongTable`.\n#'\n#' @param x `LongTable` What to extract the assay data from.\n#' @param withDimnames `logical` Should the returned assays be joined to\n#'   the row and column identifiers (i.e., the pseudo-dimnames of the object).\n#' @param metadata `logical` Should row and column metadata also be joined\n#'   to the returned assays. This is useful for modifying assays before\n#'   reconstructing a new LongTable.\n#' @param key `logical` Should the key columns also be returned? Defaults\n#'   to !`withDimnames`.\n#' @param ... For developer use only! Pass raw=TRUE to return the slot for\n#'   modification by reference.\n#'\n#' @return A `list` of `data.table` objects, one per assay in the object.\n#'\n#' @importMethodsFrom SummarizedExperiment assays\n#' @import data.table\n#' @export\nsetMethod('assays', signature(x='LongTable'), function(x, withDimnames=TRUE,\n        metadata=withDimnames, key=!withDimnames, ...) {\n    # secret arguments for internal use\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@assays)\n    }\n\n    # input validation\n    if (!withDimnames && metadata)\n        warning(.warnMsg('[CoreGx::assays] Cannot use metadata=TRUE when',\n            ' withDimnames=FALSE. Ignoring the metadata argument.'),\n            call.=FALSE)\n\n    # optionally join with rowData and colData\n    assayIndex <- assayIndex(x)\n    if (metadata) {\n        rData <- rowData(x, key=TRUE)\n        cData <- colData(x, key=TRUE)\n    } else {\n        rData <- rowIDs(x, data=TRUE, key=TRUE)\n        cData <- colIDs(x, data=TRUE, key=TRUE)\n    }\n    if (withDimnames) {\n        setkeyv(assayIndex, \"rowKey\")\n        assayIndex <- rData[assayIndex, , on=\"rowKey\"]\n        setkeyv(assayIndex, \"colKey\")\n        assayIndex <- cData[assayIndex, , on=\"colKey\"]\n    }\n\n    # honor row and column ordering guarantees from CoreGx design documentation\n    aList <- copy(x@assays)\n    aNames <- names(aList)\n    # prepend with . to match assay index naming convention\n    names(aList) <- paste0(\".\", aNames)\n    corder <- c(\n        if (withDimnames) idCols(x),\n        if (key) c(\"rowKey\", \"colKey\"),\n        if (withDimnames && metadata) c(sort(rowMeta(x)), sort(colMeta(x)))\n    )\n    for (i in seq_along(aList)) {\n        setkeyv(assayIndex, names(aList)[i])\n        aList[[i]] <- assayIndex[aList[[i]], ]\n        deleteCols <- setdiff(names(aList), names(aList)[i])\n        if (length(deleteCols) > 0) {\n            aList[[i]][, (deleteCols) := NULL]\n        }\n        if (withDimnames || key) aList[[i]][, (names(aList)[i]) := NULL]\n        if (!key) {\n            aList[[i]][, c(\"rowKey\", \"colKey\") := NULL]\n        }\n        if (withDimnames) setkeyv(aList[[i]], idCols(x))\n        else if (key) setkeyv(aList[[i]], c(\"rowKey\", \"colKey\"))\n        else setkeyv(aList[[i]], names(aList)[[i]])\n        if (!is.null(corder)) setcolorder(aList[[i]], corder) else\n            setcolorder(aList[[i]])\n    }\n    # reset names to non dot version\n    names(aList) <- aNames\n    return(aList)\n})\n\n\n#' Setter method for the assays slot in a LongTable object\n#'\n#' @examples\n#' assays(merckLongTable) <- assays(merckLongTable, withDimnames=TRUE)\n#'\n#' @describeIn LongTable Update the assays in a LongTable object. The rowIDs\n#'   and colIDs must be present in all assays to allow successfully remapping\n#'   the keys. We recommend modifying the list returned by\n#'   assays(longTable, withDimnames=TRUE) and the reassigning to the\n#'   `LongTable`.\n#'\n#' @param x A `LongTable` to modify the assays in.\n#' @param value A `list` of `data.frame` or `data.table` objects, all of which\n#'   contain the row and column identifiers and metadata.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A copy of the `LongTable` with the assays modified.\n#'\n#' @importMethodsFrom SummarizedExperiment assays<-\n#' @import data.table\n#' @export\nsetReplaceMethod('assays', signature(x='LongTable', value='list'),\n        function(x, ..., value) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        x@assays <- value\n    } else {\n        assay_names <- names(value)\n        for (name in assay_names) {\n            x[[name]] <- value[[name]]\n        }\n    }\n    return(x)\n})\n\n\n##\n## == assay\n\n\n#' Get an assay from a LongTable object\n#'\n#' @describeIn LongTable Retrieve an assay `data.table` object from the\n#'   `assays` slot of a `LongTable` object.\n#'\n#' @examples\n#' # Default annotations, just the key columns\n#' assay(merckLongTable, 'sensitivity')\n#' assay(merckLongTable, 1)\n#'\n#' # With identifiers joined\n#' assay(merckLongTable, 'sensitivity', withDimnames=TRUE)\n#'\n#' # With identifiers and metadata\n#' assay(merckLongTable, 'profiles', withDimnames=TRUE, metadata=TRUE)\n#'\n#' @param x `LongTable` The `LongTable` object to get the assay from.\n#' @param i `integer` or `character` vector containing the index or name\n#'   of the assay, respectively.\n#' @param withDimnames `logical(1)` Should the dimension names be returned\n#'   joined to the assay. This retrieves both the row and column identifiers\n#'   and returns them joined to the assay. For\n#' @param summarize `logical(1)` If the assays is a summary where some of\n#'   `idCols(x)` are not in `assayKeys(x, i)`, then those missing columns\n#'   are dropped. Defaults to `FALSE`. When `metadata` is `TRUE`, only\n#'   metadata columns with 1:1 cardinality with the assay keys for `i`.\n#' @param metadata `logical(1)` Should all of the metadata also be joined to\n#'   the assay. This is useful when modifying assays as the resulting list\n#'   has all the information needed to recreated the LongTable object. Defaults\n#'   to `withDimnames`.\n#' @param key `logical` Should the key columns also be returned? Defaults to\n#'   !withDimnames. This is incompatible with `summarize=TRUE`, which will\n#'   drop the key columns regardless of the value of this argument.\n#' @param ... For developer use only! Pass raw=TRUE to return the slot for\n#'   modification by reference.\n#'\n#' @importMethodsFrom SummarizedExperiment assay\n#' @importFrom crayon magenta cyan\n#' @import data.table\n#' @export\nsetMethod('assay', signature(x='LongTable'), function(x, i, withDimnames=TRUE,\n        summarize=withDimnames, metadata=!summarize,\n        key=!(summarize || withDimnames), ...) {\n    # secret arguments for internal use\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@assays[[i]])\n    }\n\n    ## TODO:: Update input validation to use checkmate where possible\n    # validate input\n    if (length(i) > 1)\n        .error('\\n[CoreGx::assay] Please specifying a single string ',\n            'assay name or integer index. See assayNames(x) for available ',\n            'assays.')\n\n    keepAssay <- if (is.character(i)) which(assayNames(x) == i) else i\n    assayName <- assayNames(x)[keepAssay]\n    .assayName <- paste0(\".\", assayName)\n    if (length(keepAssay) < 1)\n        stop(.errorMsg('\\n[CoreGx::assay] There is no assay ', i,\n            ' in this LongTable. Use assayNames(longTable) for a list',\n            'of valid assay names.'),\n            call.=FALSE)\n\n    if (!withDimnames && metadata)\n        warning(.warnMsg('\\n[CoreGx::assay] Cannot use metadata=TRUE when',\n            ' withDimnames=FALSE. Ignoring the metadata argument.'),\n            call.=FALSE)\n\n    if (summarize && key)\n        warning(.warnMsg('\\n[CoreGx::assay] Cannot use key=TRUE when',\n            ' summarize=TRUE. Ignoring the key argument.'),\n            call.=FALSE)\n\n    # extract the specified assay\n    assayData <- copy(x@assays[[keepAssay]])\n\n    # extract the assay index\n    assayIndex <- na.omit(unique(assayIndex(x)[,\n        c(\"rowKey\", \"colKey\", .assayName),\n        with=FALSE\n    ]))\n\n    # handle summarized assays\n    aKeys <- assayKeys(x, assayName)\n    # only compute summaries for assays that are actually summarized\n    summarize <- summarize && !all(idCols(x) %in% aKeys)\n    if (summarize) {\n        assayIndex <- assayIndex[, first(.SD), by=.assayName]\n    }\n\n    setkeyv(assayIndex, .assayName)\n    assayData <- assayData[assayIndex, on=.assayName]\n    # # optinally join with row and column metadata\n    setkeyv(assayData, \"rowKey\")\n    if (withDimnames && !metadata) {\n        assayData <- rowIDs(x, data=TRUE, key=TRUE)[assayData, ]\n        setkeyv(assayData, \"colKey\")\n        assayData <- colIDs(x, data=TRUE, key=TRUE)[assayData, ]\n    } else if (withDimnames && metadata) {\n        assayData <- rowData(x, key=TRUE)[assayData, ]\n        setkeyv(assayData, \"colKey\")\n        assayData <- colData(x, key=TRUE)[assayData, ]\n    }\n    # honour row and column ordering guarantees\n    ## See: https://github.com/bhklab/CoreGx/wiki/CoreGx-Design-Documentation\n    if (withDimnames || key) {\n        assayData[, (.assayName) := NULL]\n        if (withDimnames) setkeyv(assayData, idCols(x)) else\n            setkeyv(assayData, c(\"rowKey\", \"colKey\"))\n    } else {\n        setkeyv(assayData, .assayName)\n    }\n    if (!key) assayData[, c(\"rowKey\", \"colKey\") := NULL]\n    corder <- c(\n        if (withDimnames) idCols(x),\n        if (key) c(\"rowKey\", \"colKey\"),\n        if (withDimnames && metadata) c(sort(rowMeta(x)), sort(colMeta(x)))\n    )\n    if (!is.null(corder)) setcolorder(assayData, corder) else setcolorder(assayData)\n\n    # Drop columns with wrong cardinality from summary assays\n    if (summarize) {\n        summaryCols <- assayCols(x, assayName)\n        if (metadata) {\n            rCols <- colnames(rowData(x))\n            cCols <- colnames(colData(x))\n            rBy <- intersect(rCols, aKeys)\n            cBy <- intersect(cCols, aKeys)\n            rKeep <- rCols[\n                rowData(x)[, lapply(.SD, uniqueN), by=c(rBy)][, lapply(.SD, max)] == 1\n            ]\n            cKeep <- cCols[\n                colData(x)[, lapply(.SD, uniqueN), by=c(cBy)][, lapply(.SD, max)] == 1\n            ]\n            summaryCols <- c(summaryCols, rKeep, cKeep)\n        }\n        # use of %in% should maintain column ordering gaurantees\n        assayData <- assayData[, colnames(assayData) %in% summaryCols, with=FALSE]\n        setkeyv(assayData, aKeys)\n    }\n\n    ## Add [] to ensure assay always prints, even after modify by reference\n    ## See: https://stackoverflow.com/questions/33195362/data-table-is-not-displayed-on-first-call-after-being-modified-in-a-function\n    return(assayData[])\n})\n\n\n#' Add or replace an assay in a LongTable by name or index\n#'\n#' @description Add or replace an assay in a LongTable by name. Currently\n#'    this function only works when the assay has all columns in row and column\n#'    data tables (i.e., when assays is retured withDimnames=TRUE).\n#'\n#' @examples\n#' assay(merckLongTable, 'sensitivity') <-\n#'      assay(merckLongTable, 'sensitivity', withDimnames=TRUE)\n#' assay(merckLongTable, 'sensitivity') <- merckLongTable$sensitivity\n#'\n#' @param x A `LongTable` to update.\n#' @param i `integer` or `character` vector containing the index or name\n#'   of the assay to update.\n#' @param value\n#' A `data.frame` or `data.table` to update the assay data\n#'   with. This must at minumum contain the row and column data identifier\n#'   columns to allow correctly mapping the assay keys. We recommend modifying\n#'   the results returned by assay(longTable, 'assayName', withDimnames=TRUE).\n#'   For convenience, both the `[[` and `$` LongTable accessors return an assay\n#'   with the dimnames.\n#'\n#' @return `LongTable` With updated assays slot.\n#'\n#' @describeIn LongTable\n#'\n#' @md\n#' @importMethodsFrom SummarizedExperiment assay<-\n#' @importFrom data.table data.table fsetdiff setcolorder set setDT\n#' @export\nsetReplaceMethod('assay', signature(x='LongTable'), function(x, i, value) {\n    stopifnot(is.character(i) || is.numeric(i))\n\n    funContext <- CoreGx:::.S4MethodContext('assay', class(x))\n    if (length(i) > 1) .error(funContext, ' Only a single assay ',\n        'name can be assiged with assay(x, i) <- value.')\n\n    # -- determine if the assay already exists\n    if (is.numeric(i)) i <- assayNames(x)[i]\n    .i <- paste0(\".\", i)\n    assayExists <- i %in% assayNames(x)\n\n    if (is.null(value)) {\n        keepAssays <- setdiff(assayNames(x), i)\n        return(x[, , keepAssays])\n    }\n\n    if (!is.data.frame(value)) .error(funContext, ' Only a data.frame or',\n        ' data.table can be assiged to the assay slot!')\n    value <- copy(value)  # prevent modify by reference\n    if (!is.data.table(value)) setDT(value)\n\n    # -- extract strucutral metadata from .intern slot\n    mutable_intern <- mutable(getIntern(x))\n    aIndex <- mutable_intern$assayIndex\n    aKeys <- mutable_intern$assayKeys\n\n    # -- determine the id columns if the assay doesn't already exits\n    if (!any(assayExists)) {\n        assayKey <- intersect(idCols(x), colnames(value))\n    } else {\n        if (sum(assayExists) > 1)\n            .error(funContext, \"Only one assay can be modified at a time.\",\n                \" Please set i to be a character(1) vector.\")\n        assayKey <- aKeys[[i]]\n    }\n    # -- add assayKey column to the value\n    setkeyv(value, assayKey)\n    value[, (.i) := .I]\n\n    # -- join assay with existing metadata\n    rKeys <- intersect(rowIDs(x), assayKey)\n    cKeys <- intersect(colIDs(x), assayKey)\n    rIndex <- rowIDs(x, data=TRUE, key=TRUE)[, .SD, .SDcols=c(\"rowKey\", rKeys)]\n    setkeyv(rIndex, rKeys)\n    cIndex <- colIDs(x, data=TRUE, key=TRUE)[, .SD, .SDcols=c(\"colKey\", cKeys)]\n    setkeyv(cIndex, cKeys)\n\n    # -- add an index to the assay\n    setkeyv(rIndex, \"rowKey\")\n    setkeyv(cIndex, \"colKey\")\n    setkeyv(aIndex, \"rowKey\")\n    annotatedIndex <- merge.data.table(aIndex, rIndex, all=TRUE)\n    setkeyv(annotatedIndex, \"colKey\")\n    annotatedIndex <- merge.data.table(annotatedIndex, cIndex, all=TRUE)\n\n    # -- update assayIndex with the new assay\n    setkeyv(annotatedIndex, assayKey)\n    if (.i %in% colnames(annotatedIndex)) annotatedIndex[, (.i) := NULL]\n    # FIXME:: This is really slow with by=.EACHI when the cardinality is high\n    annotatedIndex[value, (.i) := get(.i), on=assayKey, by=.EACHI]\n    annotatedIndex[, (assayKey) := NULL]\n    setkeyv(annotatedIndex, unique(c(paste0(\".\", assayNames(x)), .i)))\n\n    # -- detect and warn users if they have modified id columns\n    # rowIDs\n    presentRowIDs <- intersect(rowIDs(x), colnames(value))  # allow summary over some keys\n    if (!(length(presentRowIDs) > 0)) stop(.errorMsg(\"No rowIDs(x) present in\",\n        \"value! Cannot summarize over an entire dimension.\"), call.=FALSE)\n    ## set check.attributes=FALSE to allow unequal table keys\n    equalRowIDs <- .table_is_subset(\n        unique(value[, presentRowIDs, with=FALSE])[order(mget(presentRowIDs))],\n        unique(rowIDs(x, data=TRUE)[order(mget(presentRowIDs)), presentRowIDs,\n            with=FALSE])\n    )\n    if (!isTRUE(equalRowIDs))\n        stop(.errorMsg(\"One or more rowIDs(x) columns have been modified.\",\n                \" Identifier columns cannot be modified via assay assignment!\"),\n            call.=FALSE\n        )\n    # colIDs\n    presentColIDs <- intersect(colIDs(x), colnames(value))  # allow summary over some keys\n    if (!(length(presentColIDs) > 0)) stop(.errorMsg(\"No colIDs(x) present in\",\n        \"value! Cannot summarize over an entire dimension.\"), call.=FALSE)\n    equalColIDs <- .table_is_subset(\n        unique(value[, presentColIDs, with=FALSE])[order(mget(presentColIDs))],\n        unique(colIDs(x, data=TRUE)[order(mget(presentColIDs)), presentColIDs,\n            with=FALSE])\n    )\n    if (!isTRUE(equalColIDs))\n        stop(.errorMsg(\"One or more colIDs(x) column have been modified.\",\n                \" Identifier columns cannot be modified via assay assignment!\"),\n            call.=FALSE\n        )\n\n    # -- remove metadata columns for the assay\n    throwAwayCols <- c(idCols(x), rowMeta(x), colMeta(x))\n    keepCols <- setdiff(colnames(value), throwAwayCols)\n    assayValue <- unique(value[, keepCols, with=FALSE])\n    setkeyv(assayValue, .i)\n\n    # -- update the object\n    setcolorder(annotatedIndex, c(\"rowKey\", \"colKey\"))\n    mutable_intern$assayIndex <- annotatedIndex\n    mutable_intern$assayKeys[[i]] <- assayKey\n    x@.intern <- immutable(mutable_intern)\n    x@assays[[i]] <- assayValue\n\n    return(x)\n})\n\n##\n## == assayNames\n\n\n#' Retrieve the assay names from a `LongTable` object.\n#'\n#' @examples\n#' assayNames(merckLongTable)\n#' names(merckLongTable)\n#'\n#' @describeIn LongTable Return the names of the assays contained in a\n#'   `LongTable`\n#'\n#' @param x A `LongTable` object to retrieve the assay names from.\n#'\n#' @return `character` Names of the assays contained in the `LongTable`.\n#'\n#' @importMethodsFrom SummarizedExperiment assayNames\n#' @aliases names,LongTable-method names\n#' @export\nsetMethod('assayNames', signature(x='LongTable'), function(x) {\n    return(names(x@assays))\n})\n#' @export\nsetMethod(\"names\", signature(x=\"LongTable\"), function(x) {\n    return(assayNames(x))\n})\n\n\n## ==================\n## ---- metadata Slot\n## ------------------\n\n\n#' Getter method for the metadata slot of a `LongTable` object\n#'\n#' @param x The `LongTable` object from which to retrieve the metadata list.\n#'\n#' @return `list` The contents of the `metadata` slot of the `LongTable`\n#'   object.\n#'\n#' @importMethodsFrom S4Vectors metadata\n#' @export\nsetMethod('metadata', signature(x='LongTable'), function(x) {\n    return(x@metadata)\n})\n\n\n#' Setter method for the metadata slot of a `LongTable` object\n#'\n#' @param x `LongTable` The LongTable to update\n#' @param value `list` A list of new metadata associated with a `LongTable`\n#'   object.\n#'\n#' @return `LongTable` A copy of the `LongTable` object with the `value` in\n#'   the metadata slot.\n#'\n#' @importMethodsFrom S4Vectors metadata<-\n#' @importFrom crayon cyan magenta\n#' @export\nsetReplaceMethod('metadata', signature(x='LongTable'), function(x, value) {\n    if (!is(value, 'list'))\n        stop(magenta$bold('The `metadata` slot must be a list!'))\n    x@metadata <- value\n    return(x)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.local_class_4` and `.local_data_4` variables at the beginning of the code?",
        "answer": "These variables are used for dynamic documentation. `.local_class_4` is set to 'LongTable' and `.local_data_4` is set to 'merckLongTable'. They are likely used to generate documentation for the LongTable class and provide examples using the merckLongTable dataset."
      },
      {
        "question": "How does the `getIntern` method work for the LongTable class?",
        "answer": "The `getIntern` method retrieves structural metadata from the `.intern` slot of a LongTable object. It has two versions: one that takes a character vector of symbol names to retrieve specific metadata, and another that returns all metadata when no specific symbols are provided. The method returns either a single value or a named list of values, depending on the input."
      },
      {
        "question": "What is the purpose of the `.update_dimData` function in the context of the LongTable class?",
        "answer": "The `.update_dimData` function is a helper method used by both `rowData<-` and `colData<-` methods. It updates the row or column metadata of a LongTable object. It handles tasks such as removing key columns, joining with existing IDs, checking for duplicates, and ensuring the updated data meets the requirements for assignment to a LongTable or inheriting class."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Navigating this file:\n# - Slot section names start with ----\n# - Method section names start with ==\n#\n# As a result, you can use Ctrl + f to find the slot or method you are looking\n# for quickly, assuming you know its name.\n#\n# For example Ctrl + f '== molecularProfiles' would take you the molecularProfiles\n# method, while Ctrl + f '---- molecularProfiles' would take you to the slot\n# section.\n\n#' @include LongTable-class.R allGenerics.R\nNULL\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n.local_class_4 <- 'LongTable'\n.local_data_4 <- 'merckLongTable'\n\n\n# =======================================\n# Accessor Method Documentation Object\n# ---------------------------------------\n\n\n#' @noRd\n.docs_LongTable_accessors <- function(...) .parseToRoxygen(\n    \"\n    @title Accessing and modifying information in a `{class_}`\n\n    @description\n    Documentation for the various setters and getters which allow manipulation\n    of data in the slots of a `{class_}` object.\n\n    @return Accessors: See details.\n    @return Setters: An updated `{class_}` object, returned invisibly.\n    \",\n    ...\n)\n\n#' @name LongTable-accessors\n#' @eval .docs_LongTable_accessors(class_=.local_class_4)\n#' @eval .parseToRoxygen(\"@examples data({data_})\", data_=.local_data_4)\nNULL\n\n\n# ======================================\n# Accessor Methods\n# --------------------------------------\n\n\n## ==================\n## ---- .intern Slot\n## ------------------\n\n\n##\n## == getIntern\n\n\n#' Get the symbol(s) x from the object@.intern slot of a LongTable\n#'\n#' This is used as an alternative to R attributes for storing structural\n#' metadata of an S4 objects.\n#'\n#' @examples\n#' getIntern(merckLongTable, 'rowIDs')\n#' getIntern(merckLongTable, c('colIDs', 'colMeta'))\n#'\n#' @describeIn LongTable Access structural metadata present within a\n#'   LongTable object. This is mostly for developmer use.\n#'\n#' @param object `LongTable`\n#' @param x `character` One or more symbol name strings to retrieve from\n#'     the object@.intern environment.\n#'\n#' @return `immutable` value of x if length(x) == 1 else named list of values\n#'     for all symbols in x.\n#'\n#' @include LongTable-class.R\n#' @export\nsetMethod('getIntern', signature(object='LongTable', x='character'),\n        function(object, x) {\n    return(if (length(x) == 1) object@.intern[[x]] else object@.intern[x])\n})\n#' @describeIn LongTable Access all structural metadata present within a\n#'   LongTable object. This is primarily for developmer use.\n#'\n#' @param object `LongTable`\n#' @param x `missing` This argument is excluded from from the function call.\n#'\n#' @return An `immutable` list.\n#'\n#' @examples\n#' getIntern(merckLongTable)\n#'\n#' @aliases getIntern,LongTable,missing-method\n#' @export\nsetMethod('getIntern', signature(object='LongTable', x='missing'),\n    function(object, x) object@.intern\n)\n\n#' Set the .intern slot of a LongTable\n#'\n#' @param object `LongTable`\n#' @param value An `immutable_list` object, being a class union between `list`\n#'   and `immutable` S3 classes.\n#'\n#' @return Updates the object and returns invisibly.\n#'\n#' @keywords internal\nsetReplaceMethod(\"getIntern\", signature(object=\"LongTable\",\n    value=\"immutable_list\"), function(object, value) {\n        object@.intern <- value\n        return(object)\n})\n\n## ==================\n## ---- rowData Slot\n## ------------------\n\n#' Retrieve the row metadata table from a LongTable object\n#'\n#' @examples\n#' rowData(merckLongTable)\n#'\n#' @describeIn LongTable Get the row level annotations for a `LongTable` object.\n#'\n#' @param x A `LongTable` object to retrieve the row metadata from.\n#' @param key `logical` Should the rowKey column also be returned? Defaults\n#'     to FALSE.\n#' @param use.names `logical` This parameter is just here to stop matching\n#'     the positional argument to use.names from the rowData generic. It\n#'     doesn't do anything at this time and can be ignored.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A `data.table` containing rowID, row identifiers, and row metadata.\n#'\n#' @importFrom data.table data.table copy\n#' @export\nsetMethod('rowData', signature(x='LongTable'),\n        function(x, key=FALSE, use.names=FALSE, ...) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@rowData)\n    } else {\n        return(if (key) copy(x@rowData[, -'.rownames']) else\n            copy(x@rowData[, -c('.rownames', 'rowKey')]))\n    }\n})\n\n#' Helper method to share functionality between rowData and colData replace methods\n#'\n#' @param x `LongTable` or inheriting class to update dimData for.\n#' @param dim `character(1)` One of \"row\" or \"col\" indicating with dimension\n#'   to updated metadata for.\n#' @param value #' @param value A `data.table` or `data.frame` to update the\n#'   `rowData` or `colData` of `x` with.\n#'\n#' @return An updated version of `value` which meets all the requirements for\n#'   assignment to a `LongTable` or inheriting class.\n#'\n#' @noRd\n#' @keywords internal\n.update_dimData <- function(x, dim, value) {\n\n    titleDim <- paste0(toupper(substr(dim, 1, 1)), substr(dim, 2, nchar(dim)))\n    dimIDs <- get(paste0(dim, \"IDs\"))\n    dimKey <- paste(dim, \"Key\")\n    dimData <- paste0(dim, \"Data\")\n\n    # type check input\n    if (is(value, 'data.frame')) setDT(value)\n    if (!is(value, 'data.table'))\n        stop(.errorMsg('\\n[CoreGx::', dim, 'Data<-] Please pass a data.frame or ',\n            'data.table to update the ', dim, 'Data slot. We recommend modifying the',\n            ' object returned by ', dim, 'Data(x) then reassigning it with ',\n            dim, 'Data(x)',\n            ' <- new', titleDim, 'Data'),\n            call.=FALSE\n        )\n\n    # remove key column\n    if (dimKey %in% colnames(value)) {\n        value[, (dimKey) := NULL]\n        .message('\\n[CoreGx::', dim, ,'Data<-] Dropping ', dim, 'Key from replacement',\n            ' value, this function will deal with mapping the ', dim, 'Key',\n            ' automatically.')\n    }\n\n    # assemble information to select proper update method\n    dimIDCols <- dimIDs(x)\n    sharedDimIDCols <- intersect(dimIDCols, colnames(value))\n\n    # error if all the row/colID columns are not present in the new row/colData\n    equalDimIDs <- dimIDCols %in% sharedDimIDCols\n    if (!all(equalDimIDs)) warning(.warnMsg('\\n[CoreGx::', dim,\n        'Data<-] The ID columns ', dimIDCols[!equalDimIDs],\n        ' are not present in value. The function ',\n        'will attempt to join with existing ', dim, 'IDs, but this may fail!',\n        collapse=', '), call.=FALSE)\n\n    dimIDs_ <- dimIDs(x, data=TRUE, key=TRUE)\n\n    ## TODO:: Throw error if user tries to modify ID columns\n\n    duplicatedIDcols <- value[, .N, by=c(sharedDimIDCols)][, N > 1]\n    if (any(duplicatedIDcols))\n        warning(.warnMsg(\"\\n[CoreGx::\", dim, \"Data<-,\", class(x)[1], \"-method] The \",\n            \"ID columns are duplicated for rows \",\n            .collapse(which(duplicatedIDcols)),\n            \"! These rows will be dropped before assignment.\"),\n        call.=FALSE)\n\n    dimData <- dimIDs_[unique(value), on=.NATURAL, allow.cartesian=FALSE]\n    dimData[, (dimKey) := .I]\n    dimData <- dimData[!duplicated(get(dimKey)), ]\n    setkeyv(dimData, dimKey)\n    dimData[, .rownames := Reduce(.paste_colon, mget(dimIDCols))]\n\n    ## TODO:: Add some sanity checks before returing\n\n    return(dimData)\n}\n\n\n#' Updates the `rowData` slot as long as the ID columns are not changed.\n#'\n#' @examples\n#' rowData(merckLongTable) <- rowData(merckLongTable)\n#'\n#' @describeIn LongTable Update the row annotations for a `LongTable` object.\n#'   Currently requires that all columns in rowIDs(longTable) be present in\n#'   value.\n#'\n#' @param x A `LongTable` object to modify.\n#' @param value A `data.table` or `data.frame` to update the `rowData` of\n#'   `x` with.\n#' @param ... For developer use only! Pass raw=TRUE to modify the slot\n#'   directly. This will corrupt your data if you don't know what you are\n#'   doing!\n#'\n#' @return A copy of the `LongTable` object with the `rowData`\n#'   slot updated.\n#'\n#' @md\n#' @importFrom crayon cyan magenta\n#' @importFrom SummarizedExperiment `rowData<-`\n#' @importFrom data.table setDT\n#' @export\nsetReplaceMethod('rowData', signature(x='LongTable'), function(x, ..., value) {\n\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        x@rowData <- value\n        return(invisible(x))\n    }\n\n    x@rowData <- .update_dimData(x=x, dim=\"row\", value=value)\n    return(invisible(x))\n})\n\n\n## ==================\n## ---- colData Slot\n## ------------------\n\n\n#' Retrieve the column metadata table from a LongTable object\n#'\n#' @examples\n#' colData(merckLongTable)\n#'\n#' # Get the keys as well, mostly for internal use\n#' colData(merckLongTable, key=TRUE)\n#'\n#' @describeIn LongTable Get the column level annotations for a LongTable\n#'   object.\n#'\n#' @param x A `LongTable` to retrieve column metadata from.\n#' @param key `logical` Should the colKey column also be returned? Defaults to\n#'     FALSE.\n#' @param ... For developer use only! Pass raw=TRUE to return the slot for\n#'   modification by reference.\n#'\n#' @return A `data.table` containing row identifiers and metadata.\n#'\n#' @import data.table\n#' @export\nsetMethod('colData', signature(x='LongTable'),\n        function(x, key=FALSE, dimnames=FALSE, ...) {\n    if (any(...names() == \"raw\") && isTRUE(...elt(which(...names() == \"raw\")))) {\n        return(x@colData)\n    }\n    return(if (key) copy(x@colData[, -'.colnames']) else\n        copy(x@colData[, -c('.colnames', 'colKey')]))\n})\n\n#' Updates the `colData` slot as long as the ID columns are not changed.\n#'\n#' @examples\n#' colData(mer"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/zzz.R",
    "language": "R",
    "content": "# Package Start-up Functions\n\n.onAttach <- function(libname, pkgname) {\n\n    if (interactive() && is.null(options('bhklab.startup_'))) {\n        oldOpts <- options()\n        options(warn=-1)\n        on.exit(options(oldOpts))\n\n        packageStartupMessage(\n        \"\nRadioGx package brought to you by:\n\n\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557 \\u2588\\u2588\\u2557  \\u2588\\u2588\\u2557\\u2588\\u2588\\u2557  \\u2588\\u2588\\u2557\\u2588\\u2588\\u2557      \\u2588\\u2588\\u2588\\u2588\\u2588\\u2557 \\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\n\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2551  \\u2588\\u2588\\u2551\\u2588\\u2588\\u2551 \\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2551     \\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\n\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2551\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d \\u2588\\u2588\\u2551     \\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2551\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\n\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2551\\u2588\\u2588\\u2554\\u2550\\u2588\\u2588\\u2557 \\u2588\\u2588\\u2551     \\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2551\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\n\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2551  \\u2588\\u2588\\u2551\\u2588\\u2588\\u2551  \\u2588\\u2588\\u2557\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2588\\u2588\\u2551  \\u2588\\u2588\\u2551\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\n\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d \\u255a\\u2550\\u255d  \\u255a\\u2550\\u255d\\u255a\\u2550\\u255d  \\u255a\\u2550\\u255d\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\\u255a\\u2550\\u255d  \\u255a\\u2550\\u255d\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\n\nFor more of our work visit bhklab.ca!\n        \"\n        )\n        # Prevent repeated messages when loading multiple lab packages\n        options(bhklab.startup_=FALSE)\n    }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.onAttach` function in this code snippet?",
        "answer": "The `.onAttach` function is a special R function that is automatically called when a package is loaded. In this case, it's used to display a startup message with ASCII art when the RadioGx package is loaded interactively. It also sets an option to prevent the message from being displayed multiple times if other related packages are loaded."
      },
      {
        "question": "How does the code ensure that the startup message is only displayed once, even if multiple related packages are loaded?",
        "answer": "The code uses the `options()` function to set and check a custom option called 'bhklab.startup_'. Before displaying the message, it checks if this option is NULL. After displaying the message, it sets the option to FALSE. This prevents the message from being shown again if another package uses the same mechanism."
      },
      {
        "question": "What is the purpose of the `on.exit(options(oldOpts))` line in the code?",
        "answer": "The `on.exit(options(oldOpts))` line ensures that the original R options are restored when the function exits, even if an error occurs. This is a good practice to maintain the user's environment. In this case, it's specifically used to restore the warning level (`options(warn=-1)`) that was temporarily changed to suppress warnings during the function execution."
      }
    ],
    "completion_tasks": [
      {
        "partial": ".onAttach <- function(libname, pkgname) {\n    if (interactive() && is.null(options('bhklab.startup_'))) {\n        oldOpts <- options()\n        options(warn=-1)\n        on.exit(options(oldOpts))\n\n        packageStartupMessage(\n        \"RadioGx package brought to you by:\\n\\nBHK Lab\\n\\nFor more of our work visit bhklab.ca!\"\n        )\n        # Complete the function\n    }\n}",
        "complete": ".onAttach <- function(libname, pkgname) {\n    if (interactive() && is.null(options('bhklab.startup_'))) {\n        oldOpts <- options()\n        options(warn=-1)\n        on.exit(options(oldOpts))\n\n        packageStartupMessage(\n        \"RadioGx package brought to you by:\\n\\nBHK Lab\\n\\nFor more of our work visit bhklab.ca!\"\n        )\n        options(bhklab.startup_=FALSE)\n    }\n}"
      },
      {
        "partial": ".onAttach <- function(libname, pkgname) {\n    if (interactive() && is.null(options('bhklab.startup_'))) {\n        # Set up options and display message\n    }\n}",
        "complete": ".onAttach <- function(libname, pkgname) {\n    if (interactive() && is.null(options('bhklab.startup_'))) {\n        oldOpts <- options()\n        options(warn=-1)\n        on.exit(options(oldOpts))\n        packageStartupMessage(\"RadioGx package brought to you by:\\n\\nBHK Lab\\n\\nFor more of our work visit bhklab.ca!\")\n        options(bhklab.startup_=FALSE)\n    }\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-metaConstruct.R",
    "language": "R",
    "content": "#' Generic for preprocessing complex data before being used in the constructor\n#'   of an `S4` container object.\n#'\n#' This method is intended to abstract away complex constructor arguments\n#'   and data preprocessing steps needed to transform raw data, such as that\n#'   produced in a treatment-response or next-gen sequencing experiment, and\n#'   automate building of the appropriate `S4` container object. This is\n#'   is intended to allow mapping between different experimental designs,\n#'   in the form of an `S4` configuration object, and various S4 class\n#'   containers in the Bioconductor community and beyond.\n#'\n#' @param mapper An `S4` object abstracting arguments to an `S4` class\n#'   constructor into a well documented `Mapper` object.\n#' @param ... Allow new arguments to be defined for this generic.\n#'\n#' @return An `S4` object for which the class corresponds to the type of\n#'   the build configuration object passed to this method.\n#'\n#' @md\n#' @export\nsetGeneric('metaConstruct', function(mapper, ...) standardGeneric('metaConstruct'))\n\n#' @rdname metaConstruct\n#' @title metaConstruct\n#'\n#' @param mapper An `LongTableDataMapper` object abstracting arguments to an\n#'  the `LongTable` constructor.\n#'\n#' @return A `LongTable` object, as specified in the mapper.\n#'\n#' @examples\n#' data(exampleDataMapper)\n#' rowDataMap(exampleDataMapper) <- list(c('treatmentid'), c())\n#' colDataMap(exampleDataMapper) <- list(c('sampleid'), c())\n#' assayMap(exampleDataMapper) <- list(sensitivity=list(c(\"treatmentid\", \"sampleid\"), c('viability')))\n#' metadataMap(exampleDataMapper) <- list(experiment_metadata=c('metadata'))\n#' longTable <- metaConstruct(exampleDataMapper)\n#' longTable\n#'\n#' @md\n#' @importFrom data.table key\n#' @export\nsetMethod('metaConstruct', signature(mapper='LongTableDataMapper'),\n        function(mapper) {\n    .metaConstruct(mapper)\n})\n\n#' @rdname metaConstruct\n#' @title metaConstruct\n#'\n#' @param mapper An `TREDataMapper` object abstracting arguments to an\n#'  the `TreatmentResponseExperiment` constructor.\n#'\n#' @return A `TreatmentResponseExperiment` object, as specified in the mapper.\n#'\n#' @examples\n#' data(exampleDataMapper)\n#' exampleDataMapper <- as(exampleDataMapper, \"TREDataMapper\")\n#' rowDataMap(exampleDataMapper) <- list(c('treatmentid'), c())\n#' colDataMap(exampleDataMapper) <- list(c('sampleid'), c())\n#' assayMap(exampleDataMapper) <- list(sensitivity=list(c(\"treatmentid\", \"sampleid\"), c('viability')))\n#' metadataMap(exampleDataMapper) <- list(experiment_metadata=c('metadata'))\n#' tre <- metaConstruct(exampleDataMapper)\n#' tre\n#'\n#' @md\n#' @importFrom data.table key\n#' @export\nsetMethod('metaConstruct', signature(mapper='TREDataMapper'),\n        function(mapper) {\n    .metaConstruct(mapper, constructor=CoreGx::TreatmentResponseExperiment)\n})\n\n#' @keywords internal\n#' @noRd\n.metaConstruct <- function(mapper, constructor=CoreGx::LongTable) {\n    funContext <- paste0('[', .S4MethodContext('metaConstruct', class(mapper)[1]))\n\n    # subset the rawdata slot to build out each component of LongTable\n    rowDataDT <- rowData(mapper)\n    rowIDs <- rowDataMap(mapper)[[1]]\n    rid_names <- names(rowIDs)\n    has_rid_names <- !is.null(rid_names) & rid_names != \"\"\n    rowIDs[has_rid_names] <- rid_names[has_rid_names]\n    colDataDT <- colData(mapper)\n    colIDs <- colDataMap(mapper)[[1]]\n    cid_names <- names(colIDs)\n    has_cid_names <- !is.null(cid_names) & cid_names != \"\"\n    colIDs[has_cid_names] <- cid_names[has_cid_names]\n    assayDtL <- assays(mapper)\n    assayIDs <- lapply(assayMap(mapper), `[[`, i=1)\n    for (i in seq_along(assayIDs)) {\n        aid_names <- names(assayIDs[[i]])\n        notEmptyNames <- !is.null(aid_names) & aid_names != \"\"\n        assayIDs[[i]][notEmptyNames] <- aid_names[notEmptyNames]\n    }\n\n    # subset the metadata columns out of raw data and add any additional metadata\n    metadataL <- lapply(metadataMap(mapper),\n        function(j, x) as.list(unique(x[, j, with=FALSE])), x=rawdata(mapper))\n    metadataL <- c(metadataL, metadata(mapper))\n\n    ## FIXME:: Handle TREDataMapper class after updating constructor\n    object <- constructor(\n        rowData=rowDataDT, rowIDs=rowIDs,\n        colData=colDataDT, colIDs=colIDs,\n        assays=assayDtL, assayIDs=assayIDs,\n        metadata=metadataL)\n\n    return(object)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `metaConstruct` generic function in this code snippet?",
        "answer": "The `metaConstruct` generic function is designed to preprocess complex data before it's used in the constructor of an `S4` container object. It abstracts away complex constructor arguments and data preprocessing steps needed to transform raw data from experiments like treatment-response or next-gen sequencing. This function automates the building of appropriate `S4` container objects, allowing mapping between different experimental designs and various S4 class containers in the Bioconductor community."
      },
      {
        "question": "How does the `.metaConstruct` internal function handle the creation of rowIDs and colIDs?",
        "answer": "The `.metaConstruct` function creates rowIDs and colIDs by extracting them from the mapper object. It uses `rowDataMap(mapper)[[1]]` for rowIDs and `colDataMap(mapper)[[1]]` for colIDs. The function also handles naming of these IDs. If names are provided and are not empty, it assigns these names to the corresponding IDs. This is done using the logic: `rowIDs[has_rid_names] <- rid_names[has_rid_names]` for rowIDs, and similarly for colIDs."
      },
      {
        "question": "What is the difference between the `metaConstruct` method for `LongTableDataMapper` and `TREDataMapper`?",
        "answer": "The main difference lies in the constructor used in the `.metaConstruct` function call. For `LongTableDataMapper`, the default constructor `CoreGx::LongTable` is used. For `TREDataMapper`, the constructor is explicitly set to `CoreGx::TreatmentResponseExperiment`. This allows the `metaConstruct` generic to create different types of S4 objects based on the class of the mapper object passed to it, while using the same underlying `.metaConstruct` function for the actual object construction."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setGeneric('metaConstruct', function(mapper, ...) standardGeneric('metaConstruct'))\n\nsetMethod('metaConstruct', signature(mapper='LongTableDataMapper'),\n        function(mapper) {\n    # TODO: Implement the method\n})\n\nsetMethod('metaConstruct', signature(mapper='TREDataMapper'),\n        function(mapper) {\n    # TODO: Implement the method\n})",
        "complete": "setGeneric('metaConstruct', function(mapper, ...) standardGeneric('metaConstruct'))\n\nsetMethod('metaConstruct', signature(mapper='LongTableDataMapper'),\n        function(mapper) {\n    .metaConstruct(mapper)\n})\n\nsetMethod('metaConstruct', signature(mapper='TREDataMapper'),\n        function(mapper) {\n    .metaConstruct(mapper, constructor=CoreGx::TreatmentResponseExperiment)\n})"
      },
      {
        "partial": ".metaConstruct <- function(mapper, constructor=CoreGx::LongTable) {\n    # TODO: Implement the function body\n    # Hint: Extract data from mapper and create the object using the constructor\n}",
        "complete": ".metaConstruct <- function(mapper, constructor=CoreGx::LongTable) {\n    rowDataDT <- rowData(mapper)\n    rowIDs <- rowDataMap(mapper)[[1]]\n    rid_names <- names(rowIDs)\n    has_rid_names <- !is.null(rid_names) & rid_names != \"\"\n    rowIDs[has_rid_names] <- rid_names[has_rid_names]\n    colDataDT <- colData(mapper)\n    colIDs <- colDataMap(mapper)[[1]]\n    cid_names <- names(colIDs)\n    has_cid_names <- !is.null(cid_names) & cid_names != \"\"\n    colIDs[has_cid_names] <- cid_names[has_cid_names]\n    assayDtL <- assays(mapper)\n    assayIDs <- lapply(assayMap(mapper), `[[`, i=1)\n    for (i in seq_along(assayIDs)) {\n        aid_names <- names(assayIDs[[i]])\n        notEmptyNames <- !is.null(aid_names) & aid_names != \"\"\n        assayIDs[[i]][notEmptyNames] <- aid_names[notEmptyNames]\n    }\n    metadataL <- lapply(metadataMap(mapper),\n        function(j, x) as.list(unique(x[, j, with=FALSE])), x=rawdata(mapper))\n    metadataL <- c(metadataL, metadata(mapper))\n    object <- constructor(\n        rowData=rowDataDT, rowIDs=rowIDs,\n        colData=colDataDT, colIDs=colIDs,\n        assays=assayDtL, assayIDs=assayIDs,\n        metadata=metadataL)\n    return(object)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/endoaggregate-methods.R",
    "language": "R",
    "content": "#' @include allGenerics.R\n#' @include aggregate-methods.R\nNULL\n\n#' Functional API for endomorphic aggregation over a `LongTable` or\n#' inheriting class\n#'\n#' @description\n#' Compute a group-by operation over a `LongTable` object or its inhering\n#' classes.\n#'\n#' @param x `LongTable` or inheriting class to compute aggregation on.\n#' @param assay `character(1)` The assay to aggregate over.\n#' @param target `character(1)` The assay to assign the results to. Defaults\n#' to `assay`.\n#' @param subset `call` An R call to evaluate before perfoming an aggregate.\n#' This allows you to aggregate over a subset of columns in an assay but have\n#' it be assigned to the parent object. Default is TRUE, which includes all\n#' rows. Passed through as the `i` argument in `[.data.table`.\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return Object with the same class as `x`, with the aggregation results\n#' assigned to `target`, using `strategy` if `target` is an existing assay in\n#' `x`.\n#'\n#' @seealso `data.table::[.data.table`, `BiocParallel::bplapply`\n#'\n#' @export\nsetMethod(\"endoaggregate\", signature(x=\"LongTable\"),\n        function(x, ..., assay, target=assay, by, subset=TRUE, nthread=1,\n        progress=TRUE, BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[[assay]][eval(i), ]\n    res <- aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n        moreArgs=moreArgs\n    )\n    if (target %in% assayNames(x)) {\n        res <- merge.data.table(x[[assay]], res, by=by)\n    }\n    x[[target]] <- res\n    x\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `endoaggregate` method in this code snippet?",
        "answer": "The `endoaggregate` method is designed to perform a group-by operation over a `LongTable` object or its inheriting classes. It computes an aggregation on a specified assay, potentially applies a subset operation, and assigns the results to a target assay within the same object. This method allows for endomorphic aggregation, meaning the input and output have the same class."
      },
      {
        "question": "How does the `subset` parameter work in the `endoaggregate` method?",
        "answer": "The `subset` parameter allows for filtering the data before aggregation. It's defined as a `call` object, which is evaluated before performing the aggregate operation. This parameter is passed as the `i` argument to `[.data.table`, enabling users to aggregate over a subset of columns in an assay while assigning the result to the parent object. By default, it's set to `TRUE`, which includes all rows in the aggregation."
      },
      {
        "question": "What happens if the `target` assay already exists in the input object `x`?",
        "answer": "If the `target` assay already exists in the input object `x`, the code merges the aggregation results with the existing assay data. This is done using the `merge.data.table` function, which combines the existing assay data (`x[[assay]]`) with the aggregation results (`res`) based on the `by` columns. This ensures that the existing data in the target assay is preserved and updated with the new aggregation results."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"endoaggregate\", signature(x=\"LongTable\"),\n        function(x, ..., assay, target=assay, by, subset=TRUE, nthread=1,\n        progress=TRUE, BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[[assay]][eval(i), ]\n    res <- aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n        moreArgs=moreArgs\n    )\n    # Complete the code to handle the case when target is in assayNames(x)\n    # and return the modified x object\n})",
        "complete": "setMethod(\"endoaggregate\", signature(x=\"LongTable\"),\n        function(x, ..., assay, target=assay, by, subset=TRUE, nthread=1,\n        progress=TRUE, BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[[assay]][eval(i), ]\n    res <- aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n        moreArgs=moreArgs\n    )\n    if (target %in% assayNames(x)) {\n        res <- merge.data.table(x[[assay]], res, by=by)\n    }\n    x[[target]] <- res\n    x\n})"
      },
      {
        "partial": "#' Functional API for endomorphic aggregation over a `LongTable` or\n#' inheriting class\n#'\n#' @param x `LongTable` or inheriting class to compute aggregation on.\n#' @param assay `character(1)` The assay to aggregate over.\n#' @param target `character(1)` The assay to assign the results to. Defaults\n#' to `assay`.\n#' @param subset `call` An R call to evaluate before perfoming an aggregate.\n#' This allows you to aggregate over a subset of columns in an assay but have\n#' it be assigned to the parent object. Default is TRUE, which includes all\n#' rows. Passed through as the `i` argument in `[.data.table`.\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return Object with the same class as `x`, with the aggregation results\n#' assigned to `target`, using `strategy` if `target` is an existing assay in\n#' `x`.\n#'\n#' @seealso `data.table::[.data.table`, `BiocParallel::bplapply`\n#'\n#' @export\n# Complete the function signature and body",
        "complete": "#' Functional API for endomorphic aggregation over a `LongTable` or\n#' inheriting class\n#'\n#' @param x `LongTable` or inheriting class to compute aggregation on.\n#' @param assay `character(1)` The assay to aggregate over.\n#' @param target `character(1)` The assay to assign the results to. Defaults\n#' to `assay`.\n#' @param subset `call` An R call to evaluate before perfoming an aggregate.\n#' This allows you to aggregate over a subset of columns in an assay but have\n#' it be assigned to the parent object. Default is TRUE, which includes all\n#' rows. Passed through as the `i` argument in `[.data.table`.\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return Object with the same class as `x`, with the aggregation results\n#' assigned to `target`, using `strategy` if `target` is an existing assay in\n#' `x`.\n#'\n#' @seealso `data.table::[.data.table`, `BiocParallel::bplapply`\n#'\n#' @export\nsetMethod(\"endoaggregate\", signature(x=\"LongTable\"),\n        function(x, ..., assay, target=assay, by, subset=TRUE, nthread=1,\n        progress=TRUE, BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[[assay]][eval(i), ]\n    res <- aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n        moreArgs=moreArgs\n    )\n    if (target %in% assayNames(x)) {\n        res <- merge.data.table(x[[assay]], res, by=by)\n    }\n    x[[target]] <- res\n    x\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-drugSensitivitySig.R",
    "language": "R",
    "content": "#' Compute the correlation between a molecular feature and treatment response\n#'\n#' @param object An object inheriting form the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A 3D array of genes x drugs x metric\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"drugSensitivitySig\", function(object, ...)\n    standardGeneric(\"drugSensitivitySig\"))",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `drugSensitivitySig` function based on the given code snippet?",
        "answer": "The `drugSensitivitySig` function is designed to compute the correlation between a molecular feature and treatment response. It is defined as a generic function using `setGeneric`, which allows for method dispatch based on the class of the input object."
      },
      {
        "question": "What is the significance of the `@export` and `@keywords internal` annotations in the code?",
        "answer": "The `@export` annotation indicates that this function should be made available to users of the package, while `@keywords internal` suggests that it is primarily intended for internal use within the package. This combination might seem contradictory, but it could mean that the function is exported for advanced users or other packages to use, while not being part of the main public API."
      },
      {
        "question": "What does the `...` argument in the function definition represent, and why might it be useful?",
        "answer": "The `...` (ellipsis) argument in the function definition allows for the passing of additional arguments to the function. This is useful for creating a flexible interface that can accommodate future extensions or method-specific parameters without changing the generic function signature. It's particularly valuable in generic functions where different methods might require different parameters."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' Compute the correlation between a molecular feature and treatment response\n#'\n#' @param object An object inheriting form the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A 3D array of genes x drugs x metric\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"drugSensitivitySig\", function(object, ...)\n    # Complete the function body here\n)",
        "complete": "#' Compute the correlation between a molecular feature and treatment response\n#'\n#' @param object An object inheriting form the `CoreGx::CoreSet` class\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return A 3D array of genes x drugs x metric\n#'\n#' @export\n#' @keywords internal\nsetGeneric(\"drugSensitivitySig\", function(object, ...)\n    standardGeneric(\"drugSensitivitySig\"))"
      },
      {
        "partial": "# Create a generic function for drug sensitivity signature\n# Complete the function definition\nsetGeneric(\"drugSensitivitySig\", ...)",
        "complete": "# Create a generic function for drug sensitivity signature\nsetGeneric(\"drugSensitivitySig\", function(object, ...)\n    standardGeneric(\"drugSensitivitySig\"))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/connectivityScore.R",
    "language": "R",
    "content": "#' Function computing connectivity scores between two signatures\n#' \n#' A function for finding the connectivity between two signatures, using either\n#' the GSEA method based on the KS statistic, or the gwc method based on a \n#' weighted spearman statistic. The GSEA analysis is implemented in the piano package. \n#' \n#' @references \n#'    F. Pozzi, T. Di Matteo, T. Aste, 'Exponential smoothing weighted\n#'    correlations', The European Physical Journal B, Vol. 85, No 6, 2012. DOI:\n#'    10.1140/epjb/e2012-20697-x\n#' @references\n#'    Varemo, L., Nielsen, J. and Nookaew, I. (2013) Enriching the gene set\n#'    analysis of genome-wide data by incorporating directionality of gene\n#'    expression and combining statistical hypotheses and methods. Nucleic\n#'    Acids Research. 41 (8), 4378-4391. doi: 10.1093/nar/gkt111\n#'    \n#' @examples\n#' xValue <- c(1,5,23,4,8,9,2,19,11,12,13)\n#' xSig <- c(0.01, 0.001, .97, 0.01,0.01,0.28,0.7,0.01,0.01,0.01,0.01)\n#' yValue <- c(1,5,10,4,8,19,22,19,11,12,13)\n#' ySig <- c(0.01, 0.001, .97,0.01, 0.01,0.78,0.9,0.01,0.01,0.01,0.01)\n#' xx <- cbind(xValue, xSig)\n#' yy <- cbind(yValue, ySig)\n#' rownames(xx) <- rownames(yy) <- c('1','2','3','4','5','6','7','8','9','10','11')\n#' data.cor <- connectivityScore(xx,yy,method='gwc', gwc.method='spearman', nperm=300)\n#' \n#' @param x A \\code{matrix} with the first gene signature. In the case of GSEA the vector of\n#'   values per gene for GSEA in which we are looking for an enrichment. In the \n#'   case of gwc, this should be a matrix, with the per gene responses in the \n#'   first column, and the significance values in the second.\n#' @param y A \\code{matrix} with the second signature. In the case of GSEA, this is the\n#'   vector of up and down regulated genes we are looking for in our signature,\n#'   with the direction being determined from the sign. In the case of gwc, this\n#'   should be a matrix of identical size to x, once again with the per gene\n#'   responses in the first column, and their significance in the second.\n#' @param method \\code{character} string identifying which method to use, out of 'fgsea' and 'gwc'\n#' @param nperm \\code{numeric}, how many permutations should be done to determine\n#'   significance through permutation testing? The minimum is 100, default is\n#'   1e4.\n#' @param nthread \\code{numeric}, how many cores to run parallel processing on.\n#' @param gwc.method \\code{character}, should gwc use a weighted spearman or pearson\n#'   statistic?\n#' @param ... Additional arguments passed down to gsea and gwc functions\n#' \n#' @return \\code{numeric} a numeric vector with the score and the p-value associated\n#'   with it\n#' \n#' @export\n#' \n#' @importFrom piano runGSA loadGSC\n#' @importFrom stats complete.cases\n## TODO:: Implement 'gsea' method for this function\nconnectivityScore <- function(x, y, method = c(\"fgsea\", \"gwc\"), nperm = 10000, nthread = 1, gwc.method = c(\"spearman\", \"pearson\"), ...) {\n    \n    if (method == \"gsea\") {\n        stop(\"The gsea method is implemented using fgsea, please change your\n             method argument to 'fgsea'. Consult ?connectivityScore for\n             more information\")\n    }\n    \n    method <- match.arg(method)\n    gwc.method <- match.arg(gwc.method)\n    if (!is.matrix(x)) {\n        x <- as.matrix(x)\n    }\n    if (!is.matrix(y)) {\n        y <- as.matrix(y)\n    }\n    if ((ncol(x) != 2 || ncol(y) != 2) && method == \"gwc\") {\n        stop(\"x and y should have 2 columns: effect size and corresponding p-values\")\n    }\n    if (method == \"fgsea\" && nrow(y) >= nrow(x)) {\n        warning(\"GSEA method: query gene set (y) larger than signature (x)\")\n    }\n    \n    if (is.null(rownames(x)) || is.null(rownames(y)) || !length(intersect(rownames(x), rownames(y)))) {\n        stop(\"Row names of x and y are either missing or have no intersection\")\n    }\n    if (nperm < 100) {\n        stop(\"The minimum number of permutations for permutation testing is 100\")\n    }\n    switch(method, fgsea = {\n        ## remove missing values\n        y <- y[!is.na(y[, 1]), , drop = FALSE]\n        x <- x[!is.na(x[, 1]), , drop = FALSE]\n        ## create gene set\n        gset <- cbind(gene = rownames(y), set = ifelse(as.numeric(y[, 1]) >= 0, \"UP\", \"DOWN\"))\n        gset <- piano::loadGSC(gset)\n        \n        ## run enrichment analysis\n        ##FIXME:: Update runGSA to use fgseaMultilevel to stop warnings\n        suppressWarnings({ \n            nes <- piano::runGSA(geneLevelStats = x[, 1], geneSetStat = \"fgsea\", \n                                 gsc = gset, nPerm = nperm + (nperm%%nthread), \n                                 ncpus = nthread, \n            verbose = FALSE, adjMethod = \"none\", ...) \n        })\n        \n        ## merge p-values for negative and positive enrichment scores\n        nes$pDistinctDir <- nes$pDistinctDirUp\n        nes$pDistinctDir[is.na(nes$pDistinctDirUp), 1] <- nes$pDistinctDirDn[is.na(nes$pDistinctDirUp), 1]\n        nes.up <- c(nes$statDistinctDir[which(names(nes$gsc) == \"UP\"), 1], nes$pDistinctDir[which(names(nes$gsc) == \"UP\"), 1])\n        nes.down <- c(nes$statDistinctDir[which(names(nes$gsc) == \"DOWN\"), 1], nes$pDistinctDir[which(names(nes$gsc) == \"DOWN\"), 1])\n        ## combine UP and DOWN\n        if (length(nes.up) == 0) {\n            score = c(es = -nes.down[1], p = nes.down[2])\n        } else if (length(nes.down) == 0) {\n            score = c(es = nes.up[1], p = nes.up[2])\n        } else if (all(complete.cases(cbind(nes.up, nes.down))) && sign(nes.up[1]) != sign(nes.down[1])) {\n            score <- c(es = (nes.up[1] - nes.down[1])/2, p = .combineTest(p = c(nes.up[2], nes.down[2]), method = \"fisher\", na.rm = TRUE))\n        } else {\n            score <- c(score = 0, p = 1)\n        }\n    }, gwc = {\n        ## intersection between x and y\n        ii <- intersect(rownames(x), rownames(y))\n        if (length(ii) < 10) {\n            stop(\"Less than 10 probes/genes in common between x and y\")\n        }\n        score <- gwc(x1 = x[ii, 1], p1 = x[ii, 2], x2 = y[ii, 1], p2 = y[ii, 2], method.cor = gwc.method, nperm = nperm, ...)\n        names(score) <- c(\"score\", \"p\")\n    })\n    return(score)\n}\n\n#' @importFrom stats pchisq qnorm pnorm pt\n.combineTest <- function(p, weight, method = c(\"fisher\", \"z.transform\", \"logit\"), hetero = FALSE, na.rm = FALSE) {\n    if (hetero) {\n        stop(\"function to deal with heterogeneity is not implemented yet!\")\n    }\n    method <- match.arg(method)\n    na.ix <- is.na(p)\n    if (any(na.ix) && !na.rm) {\n        stop(\"missing values are present!\")\n    }\n    if (all(na.ix)) \n        {\n            return(NA)\n        }  ## all p-values are missing\n    p <- p[!na.ix]\n    k <- length(p)\n    if (k == 1) {\n        return(p)\n    }\n    if (missing(weight)) {\n        weight <- rep(1, k)\n    }\n    switch(method, fisher = {\n        cp <- pchisq(-2 * sum(log(p)), df = 2 * k, lower.tail = FALSE)\n    }, z.transform = {\n        z <- qnorm(p, lower.tail = FALSE)\n        cp <- pnorm(sum(weight * z)/sqrt(sum(weight^2)), lower.tail = FALSE)\n    }, logit = {\n        tt <- (-sum(log(p/(1 - p))))/sqrt(k * pi^2 * (5 * k + 2)/(3 * (5 * k + 4)))\n        cp <- pt(tt, df = 5 * k + 4, lower.tail = FALSE)\n    })\n    return(cp)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `connectivityScore` function and what are its main methods?",
        "answer": "The `connectivityScore` function computes connectivity scores between two gene signatures. It has two main methods: 'fgsea' (Fast Gene Set Enrichment Analysis) and 'gwc' (Gene-Wise Correlation). The 'fgsea' method is based on the GSEA approach using the KS statistic, while the 'gwc' method uses a weighted Spearman or Pearson correlation statistic."
      },
      {
        "question": "How does the function handle missing values and what is the minimum number of permutations allowed?",
        "answer": "The function removes missing values from the input matrices x and y before processing. For the 'fgsea' method, it explicitly removes NA values from both x and y. The function also checks if there are at least 10 common probes/genes between x and y for the 'gwc' method. The minimum number of permutations allowed is 100, as specified in the error check: `if (nperm < 100) { stop(\"The minimum number of permutations for permutation testing is 100\") }`."
      },
      {
        "question": "What is the purpose of the `.combineTest` helper function and what methods does it support for combining p-values?",
        "answer": "The `.combineTest` helper function is used to combine multiple p-values into a single p-value. It supports three methods for combining p-values: 'fisher' (Fisher's method), 'z.transform' (Z-transform method), and 'logit' (Logit method). The function is used in the 'fgsea' method of the `connectivityScore` function to combine p-values for negative and positive enrichment scores when necessary."
      }
    ],
    "completion_tasks": [
      {
        "partial": "connectivityScore <- function(x, y, method = c(\"fgsea\", \"gwc\"), nperm = 10000, nthread = 1, gwc.method = c(\"spearman\", \"pearson\"), ...) {\n    method <- match.arg(method)\n    gwc.method <- match.arg(gwc.method)\n    if (!is.matrix(x)) x <- as.matrix(x)\n    if (!is.matrix(y)) y <- as.matrix(y)\n    if ((ncol(x) != 2 || ncol(y) != 2) && method == \"gwc\") {\n        stop(\"x and y should have 2 columns: effect size and corresponding p-values\")\n    }\n    if (method == \"fgsea\" && nrow(y) >= nrow(x)) {\n        warning(\"GSEA method: query gene set (y) larger than signature (x)\")\n    }\n    if (is.null(rownames(x)) || is.null(rownames(y)) || !length(intersect(rownames(x), rownames(y)))) {\n        stop(\"Row names of x and y are either missing or have no intersection\")\n    }\n    if (nperm < 100) stop(\"The minimum number of permutations for permutation testing is 100\")\n    \n    # Complete the function implementation here\n}",
        "complete": "connectivityScore <- function(x, y, method = c(\"fgsea\", \"gwc\"), nperm = 10000, nthread = 1, gwc.method = c(\"spearman\", \"pearson\"), ...) {\n    method <- match.arg(method)\n    gwc.method <- match.arg(gwc.method)\n    if (!is.matrix(x)) x <- as.matrix(x)\n    if (!is.matrix(y)) y <- as.matrix(y)\n    if ((ncol(x) != 2 || ncol(y) != 2) && method == \"gwc\") {\n        stop(\"x and y should have 2 columns: effect size and corresponding p-values\")\n    }\n    if (method == \"fgsea\" && nrow(y) >= nrow(x)) {\n        warning(\"GSEA method: query gene set (y) larger than signature (x)\")\n    }\n    if (is.null(rownames(x)) || is.null(rownames(y)) || !length(intersect(rownames(x), rownames(y)))) {\n        stop(\"Row names of x and y are either missing or have no intersection\")\n    }\n    if (nperm < 100) stop(\"The minimum number of permutations for permutation testing is 100\")\n    \n    switch(method,\n        fgsea = {\n            y <- y[!is.na(y[, 1]), , drop = FALSE]\n            x <- x[!is.na(x[, 1]), , drop = FALSE]\n            gset <- cbind(gene = rownames(y), set = ifelse(as.numeric(y[, 1]) >= 0, \"UP\", \"DOWN\"))\n            gset <- piano::loadGSC(gset)\n            suppressWarnings({\n                nes <- piano::runGSA(geneLevelStats = x[, 1], geneSetStat = \"fgsea\", \n                                    gsc = gset, nPerm = nperm + (nperm%%nthread), \n                                    ncpus = nthread, verbose = FALSE, adjMethod = \"none\", ...)\n            })\n            nes$pDistinctDir <- nes$pDistinctDirUp\n            nes$pDistinctDir[is.na(nes$pDistinctDirUp), 1] <- nes$pDistinctDirDn[is.na(nes$pDistinctDirUp), 1]\n            nes.up <- c(nes$statDistinctDir[which(names(nes$gsc) == \"UP\"), 1], nes$pDistinctDir[which(names(nes$gsc) == \"UP\"), 1])\n            nes.down <- c(nes$statDistinctDir[which(names(nes$gsc) == \"DOWN\"), 1], nes$pDistinctDir[which(names(nes$gsc) == \"DOWN\"), 1])\n            if (length(nes.up) == 0) {\n                score = c(es = -nes.down[1], p = nes.down[2])\n            } else if (length(nes.down) == 0) {\n                score = c(es = nes.up[1], p = nes.up[2])\n            } else if (all(complete.cases(cbind(nes.up, nes.down))) && sign(nes.up[1]) != sign(nes.down[1])) {\n                score <- c(es = (nes.up[1] - nes.down[1])/2, p = .combineTest(p = c(nes.up[2], nes.down[2]), method = \"fisher\", na.rm = TRUE))\n            } else {\n                score <- c(score = 0, p = 1)\n            }\n        },\n        gwc = {\n            ii <- intersect(rownames(x), rownames(y))\n            if (length(ii) < 10) stop(\"Less than 10 probes/genes in common between x and y\")\n            score <- gwc(x1 = x[ii, 1], p1 = x[ii, 2], x2 = y[ii, 1], p2 = y[ii, 2], method.cor = gwc.method, nperm = nperm, ...)\n            names(score) <- c(\"score\", \"p\")\n        }\n    )\n    return(score)\n}"
      },
      {
        "partial": ".combineTest <- function(p, weight, method = c(\"fisher\", \"z.transform\", \"logit\"), hetero = FALSE, na.rm = FALSE) {\n    if (hetero) stop(\"function to deal with heterogeneity is not implemented yet!\")\n    method <- match.arg(method)\n    na.ix <- is.na(p)\n    if (any(na.ix) && !na.rm) stop(\"missing values are present!\")\n    if (all(na.ix)) return(NA)\n    p <- p[!na.ix]\n    k <- length(p)\n    if (k == 1) return(p)\n    if (missing(weight)) weight <- rep(1, k)\n    \n    # Complete the function implementation here\n}",
        "complete": ".combineTest <- function(p, weight, method = c(\"fisher\", \"z.transform\", \"logit\"), hetero = FALSE, na.rm = FALSE) {\n    if (hetero) stop(\"function to deal with heterogeneity is not implemented yet!\")\n    method <- match.arg(method)\n    na.ix <- is.na(p)\n    if (any(na.ix) && !na.rm) stop(\"missing values are present!\")\n    if (all(na.ix)) return(NA)\n    p <- p[!na.ix]\n    k <- length(p)\n    if (k == 1) return(p)\n    if (missing(weight)) weight <- rep(1, k)\n    \n    switch(method,\n        fisher = {\n            cp <- pchisq(-2 * sum(log(p)), df = 2 * k, lower.tail = FALSE)\n        },\n        z.transform = {\n            z <- qnorm(p, lower.tail = FALSE)\n            cp <- pnorm(sum(weight * z)/sqrt(sum(weight^2)), lower.tail = FALSE)\n        },\n        logit = {\n            tt <- (-sum(log(p/(1 - p))))/sqrt(k * pi^2 * (5 * k + 2)/(3 * (5 * k + 4)))\n            cp <- pt(tt, df = 5 * k + 4, lower.tail = FALSE)\n        }\n    )\n    return(cp)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/datasets.R",
    "language": "R",
    "content": "#' Cleaveland_mut RadioSet subsetted\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the exampe\n#' usage in the roxygen2 documentation for CoreGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name clevelandSmall\n#' @usage data(clevelandSmall)\n#' @keywords datasets\n#' @format RadioSet object\n#'\nNULL\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'NULL' at the end of this R code snippet?",
        "answer": "The 'NULL' at the end of the code snippet is used to create a placeholder for the dataset documentation. In R, when documenting datasets using roxygen2, it's common to use 'NULL' to indicate that no actual R object is being created. This allows the documentation to be processed without defining the dataset in the same file."
      },
      {
        "question": "What class of object is 'clevelandSmall' based on the documentation provided?",
        "answer": "Based on the documentation, 'clevelandSmall' is a RadioSet object. This is indicated by the '@format RadioSet object' line in the roxygen2 documentation."
      },
      {
        "question": "What roxygen2 tag is used to specify how the dataset should be loaded, and what is the correct usage for the 'clevelandSmall' dataset?",
        "answer": "The roxygen2 tag used to specify how the dataset should be loaded is '@usage'. For the 'clevelandSmall' dataset, the correct usage as specified in the documentation is 'data(clevelandSmall)'."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' Cleaveland_mut RadioSet subsetted\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the exampe\n#' usage in the roxygen2 documentation for CoreGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name clevelandSmall\n#' @usage data(clevelandSmall)\n#' @keywords datasets\n#' @format RadioSet object\n#'\n# Complete the code below\n",
        "complete": "#' Cleaveland_mut RadioSet subsetted\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the exampe\n#' usage in the roxygen2 documentation for CoreGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name clevelandSmall\n#' @usage data(clevelandSmall)\n#' @keywords datasets\n#' @format RadioSet object\n#'\nNULL"
      },
      {
        "partial": "#' @name clevelandSmall\n#' @usage data(clevelandSmall)\n#' @keywords datasets\n#' @format RadioSet object\n#'\n# Complete the roxygen2 documentation\n",
        "complete": "#' Cleaveland_mut RadioSet subsetted\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the exampe\n#' usage in the roxygen2 documentation for CoreGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name clevelandSmall\n#' @usage data(clevelandSmall)\n#' @keywords datasets\n#' @format RadioSet object\n#'\nNULL"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/doseResponseCurve.R",
    "language": "R",
    "content": "#' Plot drug response curve of a given drug and a given cell for a list of\n#'   rSets (objects of the RadioSet class).\n#'\n#' Given a list of RadioSets, the function will plot the drug_response curve,\n#'   for a given drug/cell pair. The y axis of the plot is the viability\n#'   percentage and x axis is the log transformed Ds. If more than one rSet is\n#'   provided, a light gray area would show the common concentration range\n#'   between rSets. User can ask for type of sensitivity measurment to be shown\n#'   in the plot legend. The user can also provide a list of their own Ds and\n#'   viability values, as in the examples below, and it will be treated as\n#'   experiments equivalent to values coming from a pset. The names of the\n#'   concentration list determine the legend labels.\n#'\n#' @examples\n#' doseResponseCurve(Ds=list(\"Experiment 1\" = c(0, 2, 4, 6)),\n#'   SFs=list(\"Experiment 1\" = c(1,.6,.4,.2)), plot.type=\"Both\")\n#'\n#' @param rad.type `character(1)` The type(s) of radiation dosage to be\n#'   plotted. If the plot is desirable for more than one radioset, A unique drug\n#'   id should be provided.\n#' @param cellline `character(1)` A cell line name for which the radiation response\n#'   curve should be plotted. If the plot is desirable for more than one\n#'   radioset, a unique cell id should be provided.\n#' @param rSets `list` a list of RadioSet objects, for which the function\n#'   should plot the curves.\n#' @param Ds,SFs `list` A list of Doses and SFs to plot, the function assumes\n#'   that Ds[[i]] is plotted against SFs[[i]]. The names of the D list are used\n#'   to create the legend labels\n#' @param legends.label `numeric` A vector of sensitivity measurment types which\n#'   could be any combination of  ic50_published, auc_published, auc_recomputed\n#'   and auc_recomputed_star. A legend will be displayed on the top right of the\n#'   plot which each line of the legend is the values of requested sensitivity\n#'   measerments for one of the requested rSets. If this parameter is missed no\n#'   legend would be provided for the plot.\n#' @param ylim `numeric` A vector of two numerical values to be used as ylim of\n#'   the plot. If this parameter would be missed c(0,100) would be used as the\n#'   ylim of the plot.\n#' @param xlim `numeric` A vector of two numerical values to be used as xlim of\n#'   the plot. If this parameter would be missed the minimum and maximum\n#'   concentrations between all the rSets would be used as plot xlim.\n#' @param mycol `numeric` A vector with the same lenght of the rSets parameter\n#'   which will determine the color of the curve for the pharmaco sets. If this\n#'   parameter is missed default colors from Rcolorbrewer package will be used\n#'   as curves color.\n#' @param plot.type `character` Plot type which can be the actual one (\"Actual\")\n#'   or the one fitted by logl logistic regression (\"Fitted\") or both of them\n#'   (\"Both\"). If this parameter is missed by default actual curve is plotted.\n#' @param summarize.replicates `character` If this parameter is set to true\n#'   replicates are summarized and replicates are plotted individually otherwise\n#' @param title `character` The title of the graph. If no title is provided,\n#'   then it defaults to Drug':'Cell Line'.\n#' @param lwd `numeric` The line width to plot with\n#' @param cex `numeric` The cex parameter passed to plot\n#' @param cex.main `numeric` The cex.main parameter passed to plot, controls the\n#'   size of the titles\n#' @param legend.loc And argument passable to xy.coords for the position to\n#'   place the legend.\n#' @param trunc `logical(1)` Should the viability values be truncated to lie in\n#'   [0-100] before doing the fitting\n#' @param verbose `logical(1)` Should warning messages about the data passed in be\n#'   printed?\n#'\n#' @return Plots to the active graphics device and returns and invisible NULL.\n#'\n#' @import RColorBrewer\n#' @importFrom graphics plot rect axis points lines legend\n#' @importFrom grDevices rgb\n#' @importFrom magicaxis magaxis\n#' @importFrom matrixStats colMedians colMeans2\n#'\n#' @export\ndoseResponseCurve <-\nfunction(rad.type = \"radiation\",\n         cellline,\n         rSets=list(),\n         Ds=list(),\n         SFs=list(),\n         trunc=TRUE,\n         legends.label = c(\"alpha\", \"beta\",\"rsquared\"),\n         ylim=c(0,100),\n         xlim, mycol,\n         title,\n         plot.type=c(\"Fitted\",\"Actual\", \"Both\"),\n         summarize.replicates=TRUE,\n         lwd = 1,\n         cex = 0.7,\n         cex.main = 0.9,\n         legend.loc = \"topright\",\n         verbose=TRUE)\n{\n  if(!missing(rSets)){\n    if (!is(rSets, \"list\")) {\n      if (!is(rSets, \"RadioSet\")) {\n        temp <- name(rSets)\n        rSets <- list(rSets)\n        names(rSets) <- temp\n      } else {\n        stop(\"Type of rSets parameter should be either a rSet or a list of rSets.\")\n      }\n    }\n  }\n  if(!all(legends.label %in% c(\"alpha\", \"beta\",\"rsquared\"))){\n    stop(paste(\"Only\", paste(c(\"'alpha'\", \"'beta'\",\"'rsquared'\"), collapse = \", \"), \"implemented for legend labels.\", split = \" \"))\n  }\n  ##FIXME::\n  if(!missing(rSets) && (missing(cellline))){\n    stop(\"If you pass in a rSet then drug and cellline must be set\") }\n\n    if(!missing(Ds)){\n      if(missing(SFs)){\n\n        stop(\"Please pass in the Survival Fractions to Plot with the Doses.\")\n\n      }\n      if (!is(Ds, \"list\")) {\n        if (mode(Ds) == \"numeric\") {\n          if(mode(SFs) != \"numeric\"){\n            stop(\"Passed in 1 vector of Doses but the Survival Fractions are not numeric!\")\n          }\n          Ds <- list(Ds)\n          SFs <- list(SFs)\n          names(Ds) <- \"Exp1\"\n          names(SFs) <- \"Exp1\"\n        } else {\n          stop(\"Mode of Doses parameter should be either numeric or a list of numeric vectors\")\n        }\n      } else{\n        if(length(SFs)!= length(Ds)){\n          stop(\"The number of D and SF vectors passed in differs\")\n        }\n        if(is.null(names(Ds))){\n          names(Ds) <- paste(\"Exp\", seq_along(Ds))\n        }\n        for(i in seq_along(Ds)){\n\n          if (mode(Ds[[i]]) == \"numeric\") {\n            if(mode(SFs[[i]])!=\"numeric\"){\n              stop(sprintf(\"Ds[[%d]] are numeric but the SFs[[%d]] are not numeric!\",i,i))\n            }\n          } else {\n            stop(sprintf(\"Mode of Ds[[%d]] parameter should be numeric\",i))\n          }\n        }\n\n      }\n    }\n\n    common.range.star <- FALSE\n\n    if (missing(plot.type)) {\n      plot.type <- \"Actual\"\n    }\n\n    doses <- list(); responses <- list(); legend.values <- list(); j <- 0; rSetNames <- list()\n    if(!missing(rSets)){\n      for(i in seq_along(rSets)) {\n        exp_i <- which(sensitivityInfo(rSets[[i]])[ ,\"sampleid\"] == cellline & sensitivityInfo(rSets[[i]])[ ,\"treatmentid\"] == rad.type)\n        if(length(exp_i) > 0) {\n          if (summarize.replicates) {\n            rSetNames[[i]] <- name(rSets[[i]])\n            if (length(exp_i) == 1) {\n              drug.responses <- as.data.frame(cbind(\"Dose\"=as.numeric(as.vector(sensitivityRaw(rSets[[i]])[exp_i, , \"Dose\"])),\n                \"Viability\" = as.numeric(as.vector(sensitivityRaw(rSets[[i]])[exp_i, , \"Viability\"])), stringsAsFactors=FALSE))\n              drug.responses <- drug.responses[complete.cases(drug.responses), ]\n            }else{\n              drug.responses <- as.data.frame(cbind(\"Dose\"=colMedians(sensitivityRaw(rSets[[i]])[exp_i, , \"Dose\"], na.rm=TRUE),\n                \"Viability\"=colMedians(sensitivityRaw(rSets[[i]])[exp_i, , \"Viability\"], na.rm=TRUE)))\n              drug.responses <- drug.responses[complete.cases(drug.responses), ]\n            }\n            doses[[i]] <- drug.responses$Dose\n            responses[[i]] <- drug.responses$Viability\n            names(doses[[i]]) <- names(responses[[i]]) <- seq_along(doses[[i]])\n            if (!missing(legends.label)) {\n              if(length(legends.label)>0) {\n                linQuad_params <- linearQuadraticModel(D = doses[[i]], SF = responses[[i]])\n                if(any(grepl(\"alpha\", x=legends.label))){\n                  legend.values[[i]] <- paste(legend.values[i][[1]],sprintf(\"%s = %s\", \"alpha\", round(linQuad_params[1], digits=2)), sep=\", \")\n                }\n                if(any(grepl(\"beta\", x=legends.label))){\n                  legend.values[[i]] <- paste(legend.values[i][[1]],sprintf(\"%s = %s\", \"beta\", round(linQuad_params[2], digits=2)), sep=\", \")\n                }\n                if(any(grepl(\"rsquared\", x=legends.label))){\n                  legend.values[[i]] <- paste(legend.values[i][[1]],sprintf(\"%s = %s\", \"R^2\", round(CoreGx::.examineGOF(linQuad_params)[1], digits=2)), sep=\", \")\n                }\n              } else {\n                legend.values[[i]] <- \"\"\n              }\n            }\n          } else {\n            for (exp in exp_i) {\n              j <- j + 1\n              rSetNames[[j]] <- name(rSets[[i]])\n\n              drug.responses <- as.data.frame(cbind(\"Dose\"=as.numeric(as.vector(sensitivityRaw(rSets[[i]])[exp, , \"Dose\"])),\n                \"Viability\"=as.numeric(as.vector(sensitivityRaw(rSets[[i]])[exp, , \"Viability\"])), stringsAsFactors=FALSE))\n              drug.responses <- drug.responses[complete.cases(drug.responses), ]\n              doses[[j]] <- drug.responses$Dose\n              responses[[j]] <- drug.responses$Viability\n              names(doses[[j]]) <- names(responses[[j]]) <- seq_along(doses[[j]])\n              if (!missing(legends.label)) {\n                if(length(legends.label)>0){\n                  linQuad_params <- linearQuadraticModel(D = doses2[[i]], SF = responses2[[i]])\n                  if(any(grepl(\"alpha\", x=legends.label))){\n                    legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"alpha\", round(linQuad_params[1], digits=2)), sep=\", \")\n                  }\n                  if(any(grepl(\"beta\", x=legends.label))){\n                    legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"beta\", round(linQuad_params[2], digits=2)), sep=\", \")\n                  }\n                  if(any(grepl(\"rsquared\", x=legends.label))){\n                    legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"R^2\", round(CoreGx::.examineGOF(linQuad_params)[1], digits=2)), sep=\", \")\n                  }\n                }\n              } else {\n                tt <- unlist(strsplit(rownames(sensitivityInfo(rSets[[i]]))[exp], split=\"_\"))\n                if (tt[1] == \"treatmentid\") {\n                  legend.values[[j]] <- tt[2]\n                }else{\n                  legend.values[[j]] <- rownames(sensitivityInfo(rSets[[i]]))[exp]\n                }\n              }\n            }\n          }\n        } else {\n          warning(\"The cell line and drug combo were not tested together. Aborting function.\")\n          return()\n        }\n      }\n    }\n    if(!missing(Ds)){\n      doses2 <- list(); responses2 <- list(); legend.values2 <- list(); j <- 0; rSetNames2 <- list();\n      for (i in seq_along(Ds)){\n        doses2[[i]] <- Ds[[i]]\n        responses2[[i]] <- SFs[[i]]\n        if(length(legends.label)>0){\n          linQuad_params <- linearQuadraticModel(D = doses2[[i]], SF = responses2[[i]])\n          if(any(grepl(\"alpha\", x=legends.label))){\n            legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"alpha\", round(linQuad_params[1], digits=2)), sep=\", \")\n          }\n          if(any(grepl(\"beta\", x=legends.label))){\n            legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"beta\", round(linQuad_params[2], digits=2)), sep=\", \")\n          }\n          if(any(grepl(\"rsquared\", x=legends.label))){\n            legend.values2[[i]] <- paste(legend.values2[i][[1]],sprintf(\"%s = %s\", \"R^2\", round(CoreGx::.examineGOF(linQuad_params)[1], digits=2)), sep=\", \")\n          }\n        } else{ legend.values2[[i]] <- \"\"}\n\n        rSetNames2[[i]] <- names(Ds)[[i]]\n      }\n      doses <- c(doses, doses2)\n      responses <- c(responses, responses2)\n      legend.values <- c(legend.values, legend.values2)\n      rSetNames <- c(rSetNames, rSetNames2)\n    }\n\n    if (missing(mycol)) {\n      mycol <- RColorBrewer::brewer.pal(n=7, name=\"Set1\")\n    }\n\n    dose.range <- c(10^100 , 0)\n    viability.range <- c(1 , 1)\n    for(i in seq_along(doses)) {\n      dose.range <- c(0, max(dose.range[2], max(doses[[i]], na.rm=TRUE), na.rm=TRUE))\n      viability.range <- c(min(viability.range[1], min(responses[[i]], na.rm=TRUE), na.rm=TRUE), 1)\n    }\n    x1 <- 10 ^ 10; x2 <- 0\n\n    if (!missing(xlim)) {\n      dose.range <- xlim\n    }\n    if (!missing(ylim)) {\n      viability.range <- ylim\n    }\n    if(missing(title)){\n      if (length(rSets)){\n        title <- sprintf(\"Radiation Response Curve for: %s\", cellline)\n      } else {\n        title <- \"Radiation Response Curve\"\n      }\n    }\n    plot(NA, xlab=\"Dose (Gy)\", ylab=\"Survival Fraction\", axes =FALSE, main=title, log=\"y\", ylim=viability.range, xlim=dose.range, cex=cex, cex.main=cex.main)\n    magicaxis::magaxis(side=seq_len(2), frame.plot=TRUE, tcl=-.3, majorn=c(5,5), minorn=c(5,3), label=c(TRUE,FALSE))\n    if(max(viability.range)/min(viability.range)<50){\n      ticks <- magicaxis::maglab(viability.range, exptext = TRUE)\n    } else {\n      ticks <- magicaxis::maglab(viability.range, exptext = TRUE, log=TRUE)\n    }\n    ticks$exp <- unlist(lapply(ticks$exp, function(x)\n      return(as.expression(bquote(10^ .(round(log10(eval(x)), 2)))))))\n    axis(2, at=ticks$labat,labels=ticks$exp)\n    legends <- NULL\n    legends.col <- NULL\n\n    for (i in seq_along(doses)) {\n      points(doses[[i]],responses[[i]],pch=20,col = mycol[i], cex=cex)\n\n      switch(plot.type , \"Actual\"={\n        lines(doses[[i]], responses[[i]], lty=1, lwd=lwd, col=mycol[i])\n      }, \"Fitted\"= {\n        linQuad_params <- linearQuadraticModel(D = doses[[i]], SF = responses[[i]])\n        x_vals <- CoreGx::.getSupportVec(c(0,doses[[i]]))\n        lines(x_vals, (.linearQuadratic(x_vals, pars=linQuad_params, SF_as_log=FALSE)),lty=1, lwd=lwd, col=mycol[i])\n      },\"Both\"={\n        linQuad_params <- linearQuadraticModel(D = doses[[i]], SF = responses[[i]])\n        x_vals <- CoreGx::.getSupportVec(c(0,doses[[i]]))\n        lines(x_vals, (.linearQuadratic(x_vals, pars=linQuad_params, SF_as_log=FALSE)),lty=1, lwd=lwd, col=mycol[i])\n      })\n      if (length(legend.values)){\n              legends<- c(legends, sprintf(\"%s%s\", rSetNames[[i]], legend.values[[i]]))\n      } else {\n                      legends<- c(legends, sprintf(\"%s\", rSetNames[[i]]))\n      }\n      legends.col <-  c(legends.col, mycol[i])\n    }\n\n    legend(legend.loc, legend=legends, col=legends.col, bty=\"n\", cex=cex, pch=c(15,15))\n    return(invisible(NULL))\n  }\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `doseResponseCurve` function and what are its main input parameters?",
        "answer": "The `doseResponseCurve` function is designed to plot drug response curves for given drug-cell line pairs across multiple RadioSet objects. Its main input parameters include `rad.type` (radiation type), `cellline` (cell line name), `rSets` (list of RadioSet objects), `Ds` and `SFs` (optional lists of doses and survival fractions), and various plotting options such as `legends.label`, `ylim`, `xlim`, and `plot.type`."
      },
      {
        "question": "How does the function handle replicates in the input data, and what option controls this behavior?",
        "answer": "The function can handle replicates in two ways, controlled by the `summarize.replicates` parameter. If set to TRUE (default), it summarizes replicates by taking the median of doses and viabilities. If FALSE, it plots each replicate individually. This is implemented in the code block that checks `if (summarize.replicates)` and processes the data accordingly."
      },
      {
        "question": "What types of plots can be generated by this function, and how are they specified?",
        "answer": "The function can generate three types of plots, specified by the `plot.type` parameter: 'Actual' (plots the actual data points and lines), 'Fitted' (plots a fitted curve using the linear quadratic model), or 'Both' (plots both actual and fitted curves). The plotting logic is implemented in a switch statement that handles each case separately, using the `linearQuadraticModel` function for fitting when required."
      }
    ],
    "completion_tasks": [
      {
        "partial": "doseResponseCurve <- function(rad.type = \"radiation\", cellline, rSets=list(), Ds=list(), SFs=list(), trunc=TRUE, legends.label = c(\"alpha\", \"beta\",\"rsquared\"), ylim=c(0,100), xlim, mycol, title, plot.type=c(\"Fitted\",\"Actual\", \"Both\"), summarize.replicates=TRUE, lwd = 1, cex = 0.7, cex.main = 0.9, legend.loc = \"topright\", verbose=TRUE) {\n  # Function implementation\n  # ...\n}",
        "complete": "doseResponseCurve <- function(rad.type = \"radiation\", cellline, rSets=list(), Ds=list(), SFs=list(), trunc=TRUE, legends.label = c(\"alpha\", \"beta\",\"rsquared\"), ylim=c(0,100), xlim, mycol, title, plot.type=c(\"Fitted\",\"Actual\", \"Both\"), summarize.replicates=TRUE, lwd = 1, cex = 0.7, cex.main = 0.9, legend.loc = \"topright\", verbose=TRUE) {\n  if(!missing(rSets)){\n    if (!is(rSets, \"list\")) {\n      if (!is(rSets, \"RadioSet\")) {\n        temp <- name(rSets)\n        rSets <- list(rSets)\n        names(rSets) <- temp\n      } else {\n        stop(\"Type of rSets parameter should be either a rSet or a list of rSets.\")\n      }\n    }\n  }\n  if(!all(legends.label %in% c(\"alpha\", \"beta\",\"rsquared\"))){\n    stop(paste(\"Only\", paste(c(\"'alpha'\", \"'beta'\",\"'rsquared'\"), collapse = \", \"), \"implemented for legend labels.\", split = \" \"))\n  }\n  if(!missing(rSets) && (missing(cellline))){\n    stop(\"If you pass in a rSet then drug and cellline must be set\")\n  }\n  if(!missing(Ds)){\n    if(missing(SFs)){\n      stop(\"Please pass in the Survival Fractions to Plot with the Doses.\")\n    }\n    if (!is(Ds, \"list\")) {\n      if (mode(Ds) == \"numeric\") {\n        if(mode(SFs) != \"numeric\"){\n          stop(\"Passed in 1 vector of Doses but the Survival Fractions are not numeric!\")\n        }\n        Ds <- list(Ds)\n        SFs <- list(SFs)\n        names(Ds) <- \"Exp1\"\n        names(SFs) <- \"Exp1\"\n      } else {\n        stop(\"Mode of Doses parameter should be either numeric or a list of numeric vectors\")\n      }\n    } else{\n      if(length(SFs)!= length(Ds)){\n        stop(\"The number of D and SF vectors passed in differs\")\n      }\n      if(is.null(names(Ds))){\n        names(Ds) <- paste(\"Exp\", seq_along(Ds))\n      }\n      for(i in seq_along(Ds)){\n        if (mode(Ds[[i]]) == \"numeric\") {\n          if(mode(SFs[[i]])!=\"numeric\"){\n            stop(sprintf(\"Ds[[%d]] are numeric but the SFs[[%d]] are not numeric!\",i,i))\n          }\n        } else {\n          stop(sprintf(\"Mode of Ds[[%d]] parameter should be numeric\",i))\n        }\n      }\n    }\n  }\n  # Rest of the function implementation\n  # ...\n}"
      },
      {
        "partial": "linearQuadraticModel <- function(D, SF) {\n  # Function implementation\n  # ...\n}",
        "complete": "linearQuadraticModel <- function(D, SF) {\n  if (length(D) != length(SF)) {\n    stop(\"Length of D and SF must be equal\")\n  }\n  if (any(SF <= 0)) {\n    warning(\"Some SF values are <= 0. These will be removed for fitting.\")\n    valid <- SF > 0\n    D <- D[valid]\n    SF <- SF[valid]\n  }\n  logSF <- log(SF)\n  model <- lm(logSF ~ D + I(D^2))\n  coef <- coef(model)\n  alpha <- -coef[2]\n  beta <- -coef[3]\n  return(c(alpha = alpha, beta = beta))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/TREDataMapper-class.R",
    "language": "R",
    "content": "#' @include DataMapper-class.R\n#' @include LongTableDataMapper-class.R\n#' @include TreatmentResponseExperiment-class.R\n#' @include LongTableDataMapper-accessors.R\nNULL\n\n#' A Class for Mapping Between Raw Data and an `TreatmentResponseExperiment`\n#'   Object\n#'\n#' @slot rawdata See Slots section.\n#' @slot rowDataMap See Slots section.\n#' @slot colDataMap See Slots section.\n#' @slot assayMap See Slots section.\n#' @slot metadataMap See Slots section.\n#'\n#' @inheritSection LongTableDataMapper-class Slots\n#'\n#' @md\n#' @aliases TREDataMapper-class\n.TREDataMapper <- setClass(\"TREDataMapper\", contains=c(\"LongTableDataMapper\"))\n\n#' Constructor for the `TREDataMapper` class, which maps from one or\n#'   more raw experimental data files to the slots of a `LongTable` object.\n#'\n#' @details\n#' The `guessMapping` method can be used to test hypotheses about the\n#' cardinality of one or more sets of identifier columns. This is helpful\n#' to determine the id columns for `rowDataMap` and `colDataMap`, as well\n#' as identify columns mapping to `assays` or `metadata`.\n#'\n#' To attach metadata not associated with `rawdata`, please use the `metadata`\n#' assignment method on your `TREDataMapper`. This metadata will be\n#' merge with any metadata from `metadataMap` and added to the `LongTable`\n#' which this object ultimately constructs.\n#'\n#' @param rawdata A `data.frame` of raw data from a treatment response\n#' experiment. This will be coerced to a `data.table` internally. We recommend\n#' using joins to aggregate your raw data if it is not present in a single file.\n#' @param rowDataMap A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each row,\n#' the second is additional columns which map to rows, but are not required to\n#' uniquely identify them. Rows should be treatments.\n#' @param colDataMap A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each\n#' column, the second is additional columns which map to rows, but are not\n#' required to uniquely identify them. Columns should be samples.\n#' @param assayMap A list-like where each item is a `list` with two `character`\n#' vectors defining an assay, the first containing the identifier columns in\n#' `rawdata` needed to uniquely identify each row an assay, and the second the\n#' `rawdata` columns to be mapped to that assay. The names of `assayMap`\n#' will be the names of the assays in the `TreatmentResponseExperiment` that\n#' is created when calling `metaConstruct` on this `DataMapper` object. If the\n#' character vectors have names, the value columns will be renamed accordingly.\n#' @param metadataMap A list-like where each item is a `character` vector of\n#' `rawdata` column names to assign to the `@metadata` of the `LongTable`,\n#' where the name of that assay is the name of the list item. If names are\n#' omitted, assays will be numbered by their index in the list.\n#'\n#' @return A `TREDataMapper` object, with columns mapped to it's slots according\n#' to the various maps in the `LongTableDataMapper` object.\n#'\n#' @seealso [`guessMapping`]\n#'\n#' @md\n#' @importFrom data.table setDT\n#' @export\nTREDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, \"LongTableDataMapper\")) {\n        lt_dm <- rawdata\n    } else {\n        lt_dm <- LongTableDataMapper(rawdata=rawdata, rowDataMap=rowDataMap,\n            colDataMap=colDataMap, assayMap=assayMap, metadataMap=metadataMap)\n    }\n\n    .TREDataMapper(\n        rawdata=rawdata(lt_dm),\n        rowDataMap=rowDataMap(lt_dm),\n        colDataMap=colDataMap(lt_dm),\n        assayMap=assayMap(lt_dm),\n        metadataMap=metadata(lt_dm)\n    )\n}\n\n## ===========================================\n## TREDataMapper Accessors Documentation\n## -------------------------------------------\n\n.local_class_5 <- \"TREDataMapper\"\n.local_data_5 <- \"exampleDataMapper\"\n\n#' @name TREDataMapper-accessors\n#'\n#' @eval .docs_DataMapper_accessors(class_=.local_class_5)\n#' @eval .docs_DataMapper_get_rawdata(class_=.local_class_5)\n#'\n#' @param value See details.\nNULL\n\n\n## ---------------\n## -- rawdata slot\n\n\n#' @rdname TREDataMapper-accessors\n#' @eval .docs_DataMapper_set_rawdata(class_=.local_class_5,\n#' class1_='list')\nsetReplaceMethod(\"rawdata\", signature=c(object=\"TREDataMapper\",\n        value=\"list\"), function(object, value) {\n    callNextMethod(object=object, value=value)\n})\n\n\n## --------------------\n## ---- rowDataMap slot\n\n\n##\n## -- rowDataMap\n\n#' @rdname TREDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_get_dimDataMap(dim_='row', class_=.local_class_5,\n#' data_=.local_data_5)\n#' @aliases rowDataMap\nsetMethod('rowDataMap', signature(object='TREDataMapper'), function(object) {\n    callNextMethod()\n})\n\n\n#' @rdname TREDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_set_dimDataMap(dim_='row', class_=.local_class_5,\n#' data_=.local_data_5, id_col_='treatmentid')\n#' @aliases rowDataMap<-\nsetReplaceMethod('rowDataMap', signature(object='TREDataMapper',\n        value='list_OR_List'), function(object, value) {\n    callNextMethod()\n})\n\n\n##\n## -- rowData\n\n\n#' Convenience method to subset the `rowData` out of the `rawdata` slot using\n#'   the assigned `rowDataMap` metadata.\n#'\n#' @param x `TREDataMapper` object with valid data in the `rawdata` and\n#'   `colDataMap` slots.\n#' @param key `logical(1)` Should the table be keyed according to the\n#'   `id_columns` of the `rowDataMap` slot? This will sort the table in memory.\n#'   Default is TRUE.\n#'\n#' @return `data.table` The `rowData` as specified in the `rowDataMap` slot.\n#'\n#' @export\nsetMethod(\"rowData\", signature(x=\"TREDataMapper\"), function(x, key=TRUE) {\n    callNextMethod()\n})\n\n\n## --------------------\n## ---- colDataMap slot\n\n\n##\n## -- colDataMap\n\n#' @rdname TREDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_get_dimDataMap(dim_='col', class_=.local_class_5,\n#' data_=.local_data_5)\n#' @aliases colDataMap\nsetMethod('colDataMap', signature(object='TREDataMapper'),\n        function(object) {\n    callNextMethod()\n})\n\n#' @rdname TREDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_set_dimDataMap(dim_='col', class_=.local_class_5,\n#' data_=.local_data_5, id_col_='sampleid')\n#' @aliases colDataMap<-\nsetReplaceMethod('colDataMap',\n        signature(object=\"TREDataMapper\", value=\"list_OR_List\"),\n        function(object, value) {\n    callNextMethod()\n})\n\n\n##\n## -- colData\n\n\n#' Convenience method to subset the `colData` out of the `rawdata` slot using\n#'   the assigned `colDataMap` metadata.\n#'\n#' @param x `TREDataMapper` object with valid data in the `rawdata` and\n#'   `colDataMap` slots.\n#' @param key `logical(1)` Should the table be keyed according to the\n#'   `id_columns` of the `colDataMap` slot? This will sort the table in memory.\n#'   Default is TRUE.\n#'\n#' @return `data.table` The `colData` as specified in the `colDataMap` slot.\n#'\n#' @export\nsetMethod(\"colData\", signature(x=\"TREDataMapper\"), function(x, key=TRUE) {\n    callNextMethod()\n})\n\n\n## ----------------\n## ---- assayMap slot\n\n#' @rdname TREDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_get_assayMap(class_=.local_class_5, data_=.local_data_5)\n#' @aliases assayMap\nsetMethod('assayMap', signature(object='TREDataMapper'),\n        function(object) {\n    callNextMethod()\n})\n\n\n#' @rdname TREDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_set_assayMap(class_=.local_class_5, data_=.local_data_5)\n#' @aliases assayMap<-\nsetReplaceMethod('assayMap', signature(object='TREDataMapper',\n        value='list_OR_List'), function(object, value) {\n    callNextMethod()\n})\n\n\n#' Extract the data for an assay from a `TREDataMapper`\n#'\n#' @param x `TREDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param i `character(1)` Name of an assay in the `assayMap` slot of `x`.\n#' @param withDimnames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `data.table` Data for the specified assay extracted from the\n#'   `rawdata` slot of `x`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assay\", signature(x=\"TREDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n    callNextMethod()\n})\n\n\n#' Extract the data for all assays from a `TREDataMapper`\n#'\n#' @param x `TREDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param withDimnames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `list` Data for all assays extracted from the\n#'   `rawdata` slot of `x` as a `list` of `data.tables`, where the `keys` for\n#'   each table are their `id_columns`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assays\", signature(x=\"TREDataMapper\"),\n        function(x, withDimnames=TRUE) {\n    callNextMethod()\n})\n\n# -- metadataMap\n\n#' @rdname TREDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_get_metadataMap(class_=.local_class_5, data_=.local_data_5)\n#' @aliases metadataMap\nsetMethod('metadataMap', signature(object='TREDataMapper'),\n        function(object) {\n    callNextMethod()\n})\n\n\n#' @rdname TREDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_set_metadataMap(class_=.local_class_5, data_=.local_data_5, col_='metadata')\n#' @aliases metadataMap<-\nsetReplaceMethod('metadataMap', signature(object='TREDataMapper',\n        value='list_OR_List'), function(object, value) {\n    callNextMethod()\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `TREDataMapper` class and how does it relate to the `LongTableDataMapper` class?",
        "answer": "The `TREDataMapper` class is designed for mapping between raw data and a `TreatmentResponseExperiment` object. It inherits from the `LongTableDataMapper` class, extending its functionality to specifically handle treatment response experiment data. The class provides a structured way to organize and map raw experimental data to the appropriate slots in a `LongTable` object, which can then be used to construct a `TreatmentResponseExperiment` object."
      },
      {
        "question": "How does the `TREDataMapper` constructor handle different types of input for the `rawdata` parameter?",
        "answer": "The `TREDataMapper` constructor can handle two types of input for the `rawdata` parameter: 1) If `rawdata` is a `data.frame`, it creates a new `LongTableDataMapper` object using the provided parameters. 2) If `rawdata` is already a `LongTableDataMapper` object, it uses that object directly. This flexibility allows users to either start with raw data or use a pre-existing `LongTableDataMapper` when creating a `TREDataMapper` object."
      },
      {
        "question": "What is the purpose of the `assay` and `assays` methods in the `TREDataMapper` class, and how do they differ?",
        "answer": "The `assay` method extracts data for a single specified assay from a `TREDataMapper` object, returning it as a `data.table`. It takes an argument `i` to specify which assay to extract. The `assays` method, on the other hand, extracts data for all assays defined in the `TREDataMapper` object, returning a list of `data.tables`. Both methods use the `assayMap` slot to determine how to extract the assay data from the `rawdata` slot. The `assay` method is useful for accessing a specific assay, while `assays` provides a comprehensive view of all assays in the object."
      }
    ],
    "completion_tasks": [
      {
        "partial": "TREDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, \"LongTableDataMapper\")) {\n        lt_dm <- rawdata\n    } else {\n        lt_dm <- LongTableDataMapper(rawdata=rawdata, rowDataMap=rowDataMap,\n            colDataMap=colDataMap, assayMap=assayMap, metadataMap=metadataMap)\n    }\n\n    # Complete the function by returning a new TREDataMapper object\n    # using the .TREDataMapper constructor\n}",
        "complete": "TREDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, \"LongTableDataMapper\")) {\n        lt_dm <- rawdata\n    } else {\n        lt_dm <- LongTableDataMapper(rawdata=rawdata, rowDataMap=rowDataMap,\n            colDataMap=colDataMap, assayMap=assayMap, metadataMap=metadataMap)\n    }\n\n    .TREDataMapper(\n        rawdata=rawdata(lt_dm),\n        rowDataMap=rowDataMap(lt_dm),\n        colDataMap=colDataMap(lt_dm),\n        assayMap=assayMap(lt_dm),\n        metadataMap=metadata(lt_dm)\n    )"
      },
      {
        "partial": "setMethod(\"assay\", signature(x=\"TREDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n    # Implement the method to extract data for an assay\n    # from a TREDataMapper object\n})",
        "complete": "setMethod(\"assay\", signature(x=\"TREDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n    assertCharacter(i, len=1)\n    assertSubset(i, names(assayMap(x)))\n    am <- assayMap(x)[[i]]\n    dt <- rawdata(x)[, c(am$id_columns, am$value_columns), with=FALSE]\n    setkeyv(dt, am$id_columns)\n    dt\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-dim.R",
    "language": "R",
    "content": "# ==== LongTable\n\n#' Get the dimensions of a `LongTable` object.\n#'\n#' @examples\n#' dim(merckLongTable)\n#'\n#' @describeIn LongTable Get the number of row annotations by the number of\n#'   column annotations from a LongTable object. Please note that row x columns\n#'   does not necessarily equal the number of rows in an assay, since it is\n#'   not required for each assay to have every row or column present.\n#'\n#' @examples\n#' dim(merckLongTable)\n#'\n#' @param x A `LongTable` object to retrieve dimensions for.\n#'\n#' @return `numeric` Vector of object dimensions.\n#'\n#' @importMethodsFrom SummarizedExperiment dim\n#' @export\nsetMethod('dim', signature(x='LongTable'), function(x) {\n    return(c(nrow(rowData(x)), nrow(colData(x))))\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `dim` method for a `LongTable` object?",
        "answer": "The `dim` method for a `LongTable` object returns the dimensions of the table, specifically the number of row annotations by the number of column annotations. It's important to note that this doesn't necessarily equal the number of rows in an assay, as not every assay is required to have every row or column present."
      },
      {
        "question": "How does the `dim` method calculate the dimensions of a `LongTable` object?",
        "answer": "The `dim` method calculates the dimensions by returning a vector with two elements: the number of rows in the `rowData` and the number of rows in the `colData` of the `LongTable` object. This is achieved using the `nrow` function on both `rowData(x)` and `colData(x)`."
      },
      {
        "question": "What is the significance of the `@importMethodsFrom SummarizedExperiment dim` annotation in this code?",
        "answer": "The `@importMethodsFrom SummarizedExperiment dim` annotation indicates that the `dim` method is being imported from the `SummarizedExperiment` package. This suggests that the `LongTable` class is likely extending or building upon functionality from the `SummarizedExperiment` package, which is commonly used in bioinformatics for representing and analyzing high-throughput genomic data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('dim', signature(x='LongTable'), function(x) {\n    # Complete the function to return the dimensions of a LongTable object\n})",
        "complete": "setMethod('dim', signature(x='LongTable'), function(x) {\n    return(c(nrow(rowData(x)), nrow(colData(x))))\n})"
      },
      {
        "partial": "setMethod('dim', signature(x='LongTable'), function(x) {\n    rows <- # Get the number of row annotations\n    cols <- # Get the number of column annotations\n    return(c(rows, cols))\n})",
        "complete": "setMethod('dim', signature(x='LongTable'), function(x) {\n    rows <- nrow(rowData(x))\n    cols <- nrow(colData(x))\n    return(c(rows, cols))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/linearQuadraticInv.R",
    "language": "R",
    "content": "# Calculate Linear Quadratic Inverse\n#\n# @return Estimated survival fraction for the model fit\n#\n.linearQuadraticInv <- function(SF, pars, SF_as_log = TRUE) {\n\n  if (!SF_as_log) {\n    if (SF < 0) {\n      stop(\"Survival fraction must be nonnegative.\")\n    } else {\n      SF <- log(SF)\n    }\n  }\n\n  if (SF > 0) {\n    stop(\"Positive log survival fraction \", SF,  \"cannot be reached at any dose\n         of radiation with linear quadratic paramaters alpha, beta > 0.\")\n  } else {\n    if (pars[[2]] == 0) {\n      if (pars[[1]] == 0) {\n        if (SF == 1) {\n          return(0)\n        } else {\n          stop(paste0(\"Survival fraction \", SF, \" cannot be reached at any dose\n                      of radiation with linear-quadratic parameters alpha = \",\n                      pars[[1]], \" and beta = \", pars[[2]], \".\"))\n        }\n      } else {\n        return(-SF / pars[[1]])\n      }\n    } else {\n      return((sqrt(pars[[1]] ^ 2 - 4 * pars[[2]] * SF) - pars[[1]]) / 2 / pars[[2]])\n    }\n  }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `linearQuadraticInv` function and what are its input parameters?",
        "answer": "The `linearQuadraticInv` function calculates the estimated survival fraction for a linear quadratic model fit. It takes three input parameters: `SF` (survival fraction), `pars` (a list containing alpha and beta parameters), and `SF_as_log` (a boolean indicating whether SF is provided as a log value, defaulting to TRUE)."
      },
      {
        "question": "How does the function handle different cases of alpha and beta parameters?",
        "answer": "The function handles different cases as follows:\n1. If beta (pars[[2]]) is 0 and alpha (pars[[1]]) is 0, it returns 0 if SF is 1, otherwise it throws an error.\n2. If beta is 0 but alpha is not 0, it returns -SF / alpha.\n3. If both alpha and beta are non-zero, it uses the quadratic formula to calculate the result: (sqrt(alpha^2 - 4*beta*SF) - alpha) / (2*beta)."
      },
      {
        "question": "What error checks does the function perform on the input parameters?",
        "answer": "The function performs the following error checks:\n1. If SF is not provided as a log value (SF_as_log is FALSE), it checks if SF is negative and throws an error if so.\n2. It checks if the log survival fraction (SF) is positive and throws an error if it is, as this cannot be reached with positive alpha and beta.\n3. It checks for cases where the given survival fraction cannot be reached with the provided alpha and beta parameters and throws appropriate error messages."
      }
    ],
    "completion_tasks": [
      {
        "partial": ".linearQuadraticInv <- function(SF, pars, SF_as_log = TRUE) {\n  if (!SF_as_log) {\n    if (SF < 0) {\n      stop(\"Survival fraction must be nonnegative.\")\n    } else {\n      SF <- log(SF)\n    }\n  }\n\n  if (SF > 0) {\n    stop(\"Positive log survival fraction \", SF,  \"cannot be reached at any dose\n         of radiation with linear quadratic paramaters alpha, beta > 0.\")\n  } else {\n    if (pars[[2]] == 0) {\n      if (pars[[1]] == 0) {\n        # Complete this section\n      } else {\n        return(-SF / pars[[1]])\n      }\n    } else {\n      return((sqrt(pars[[1]] ^ 2 - 4 * pars[[2]] * SF) - pars[[1]]) / 2 / pars[[2]])\n    }\n  }\n}",
        "complete": ".linearQuadraticInv <- function(SF, pars, SF_as_log = TRUE) {\n  if (!SF_as_log) {\n    if (SF < 0) {\n      stop(\"Survival fraction must be nonnegative.\")\n    } else {\n      SF <- log(SF)\n    }\n  }\n\n  if (SF > 0) {\n    stop(\"Positive log survival fraction \", SF,  \"cannot be reached at any dose\n         of radiation with linear quadratic paramaters alpha, beta > 0.\")\n  } else {\n    if (pars[[2]] == 0) {\n      if (pars[[1]] == 0) {\n        if (SF == 0) return(0)\n        stop(paste0(\"Survival fraction \", SF, \" cannot be reached at any dose\n                    of radiation with linear-quadratic parameters alpha = \",\n                    pars[[1]], \" and beta = \", pars[[2]], \".\"))\n      } else {\n        return(-SF / pars[[1]])\n      }\n    } else {\n      return((sqrt(pars[[1]] ^ 2 - 4 * pars[[2]] * SF) - pars[[1]]) / 2 / pars[[2]])\n    }\n  }\n}"
      },
      {
        "partial": ".linearQuadraticInv <- function(SF, pars, SF_as_log = TRUE) {\n  if (!SF_as_log) {\n    if (SF < 0) stop(\"Survival fraction must be nonnegative.\")\n    SF <- log(SF)\n  }\n\n  if (SF > 0) {\n    stop(\"Positive log survival fraction \", SF,  \"cannot be reached at any dose\n         of radiation with linear quadratic paramaters alpha, beta > 0.\")\n  } else {\n    # Complete the rest of the function\n  }\n}",
        "complete": ".linearQuadraticInv <- function(SF, pars, SF_as_log = TRUE) {\n  if (!SF_as_log) {\n    if (SF < 0) stop(\"Survival fraction must be nonnegative.\")\n    SF <- log(SF)\n  }\n\n  if (SF > 0) {\n    stop(\"Positive log survival fraction \", SF,  \"cannot be reached at any dose\n         of radiation with linear quadratic paramaters alpha, beta > 0.\")\n  } else {\n    if (pars[[2]] == 0) {\n      if (pars[[1]] == 0) {\n        if (SF == 0) return(0)\n        stop(paste0(\"Survival fraction \", SF, \" cannot be reached at any dose\n                    of radiation with linear-quadratic parameters alpha = \",\n                    pars[[1]], \" and beta = \", pars[[2]], \".\"))\n      }\n      return(-SF / pars[[1]])\n    }\n    return((sqrt(pars[[1]] ^ 2 - 4 * pars[[2]] * SF) - pars[[1]]) / 2 / pars[[2]])\n  }\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/computeAUC.R",
    "language": "R",
    "content": "#' computeAUC: computes AUC\n#'\n#' @description This function computes the area under a dose-response curve of\n#'   the form survival fraction SF = exp(-alpha * D - beta * D ^ 2).\n#'\n#' @examples\n#' computeAUC(D=c(0.1, 0.5, 0.7, 0.9), pars=c(0.2, 0.1), lower = 0,\n#'  upper = 1) # Returns 0.7039296\n#'\n#' @param D vector of dosages\n#' @param SF vector of survival fractions\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#' @param lower lower bound of dose region to compute AUC over\n#' @param upper upper bound of dose region to compute AUC over\n#' @param trunc should survival fractions be truncated downward to 1 if they\n#'   exceed 1?\n#' @param SF_as_log A boolean indicating whether survival fraction is displayed\n#'   on a log axis. Defaults to FALSE\n#' @param area.type should the AUC of the raw (D, SF) points be returned, or\n#'   should the AUC of a curve fit to said points be returned instead?\n#' @param verbose how detailed should error and warning messages be?\n#'   See details.\n#'\n#' @return \\code{numeric} The area under the ROC curve\n#'\n#' @details If lower and/or upper are missing, the function assumes their values\n#'   to be the minimum and maximum D-values, respectively. For all warnings to\n#'   be silent, set trunc = FALSE. For warnings to be output, set trunc = TRUE.\n#'   For warnings to be output along with the arguments that triggered them,\n#'   set trunc = 2.\n#'\n#' @importFrom stats pnorm\n#' @importFrom caTools trapz\n#' @export\n# Added SF_as_log argument with default as false to match condition on line 93\ncomputeAUC <- function(D, SF, pars, lower, upper, trunc = TRUE,\n                       SF_as_log = FALSE,\n                       area.type = c(\"Fitted\", \"Actual\"),\n                       verbose = TRUE)\n  {\n  area.type <- match.arg(area.type)\n\n  if (!missing(SF)) {\n    CoreGx::.sanitizeInput(x = D,\n                            y = SF,\n                            x_as_log = FALSE,\n                            y_as_log = FALSE,\n                            y_as_pct = FALSE,\n                            trunc = trunc,\n                            verbose = FALSE)\n\n    DSF <- CoreGx::.reformatData(x = D,\n                                 y = SF,\n                                 x_to_log = FALSE,\n                                 y_to_log = FALSE,\n                                 y_to_frac = FALSE,\n                                 trunc = trunc)\n    D <- DSF[[\"x\"]]\n    SF <- DSF[[\"y\"]]\n  } else if (!missing(pars)) {\n    CoreGx::.sanitizeInput(pars = pars,\n                            x_as_log = FALSE,\n                            y_as_log = FALSE,\n                            y_as_pct = FALSE,\n                            trunc = trunc,\n                            verbose = FALSE)\n    Dpars <- CoreGx::.reformatData(x = D,\n                                    pars = pars,\n                                    x_to_log = FALSE,\n                                    y_to_log = FALSE,\n                                    y_to_frac = FALSE,\n                                    trunc = trunc)\n    D <- Dpars[[\"x\"]]\n    pars <- Dpars[[\"pars\"]]\n  } else {\n    stop(\"SF and pars can't both be missing.\")\n  }\n\n  if (!missing(lower) && !missing(upper)) {\n    ###TODO:: Check if this function still works correctly\n    CoreGx::.sanitizeInput(pars = pars, # Added this line to resolve error returned from CoreGx\n                           lower = lower,\n                           upper = upper,\n                           x_as_log = FALSE,\n                           y_as_log = FALSE,\n                           y_as_pct = FALSE,\n                           trunc = trunc,\n                           verbose = verbose)\n  }\n\n  if (area.type == \"Fitted\") {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D = D,\n                                          SF = SF,\n                                          trunc = trunc,\n                                          verbose = verbose))\n    }\n    if (missing(lower)) {\n      lower <- min(D)\n    }\n    if (missing(upper)) {\n      upper <- max(D)\n    }\n\n    if (SF_as_log == TRUE) { # Modified condition to correct error\n      return(pars[[1]] / 2 * (lower ^ 2 - upper ^ 2) + pars[[2]] / 3 * (lower ^ 3 - upper ^ 3))\n    } else {\n      if (pars[[2]] == 0) {\n        if (pars[[1]] == 0) {\n          return(upper - lower)\n        } else {\n          return((exp(-pars[[1]] * lower) - exp(-pars[[1]] * upper)) / pars[[1]])\n        }\n      } else {\n        x <- CoreGx::.getSupportVec(x=D, output_length = 1000)\n        y <- .linearQuadratic(D=x, pars=pars, SF_as_log=FALSE)\n        return(caTools::trapz(x, y))\n\n      }\n    }\n\n  } else if (area.type == \"Actual\") {\n    if (missing(SF)) {\n      stop(\"Please pass in SF-values.\")\n    } else {\n      return(caTools::trapz(x = D, y = SF))\n    }\n  }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `computeAUC` function and what are its main input parameters?",
        "answer": "The `computeAUC` function computes the area under a dose-response curve. Its main input parameters are:\n- `D`: vector of dosages\n- `SF`: vector of survival fractions\n- `pars`: parameters (alpha, beta) for the equation y = exp(-alpha * x - beta * x ^ 2)\n- `lower` and `upper`: bounds of the dose region to compute AUC over\n- `trunc`: whether to truncate survival fractions to 1 if they exceed 1\n- `SF_as_log`: whether survival fraction is displayed on a log axis\n- `area.type`: whether to return AUC of raw points or fitted curve\n- `verbose`: level of detail for error and warning messages"
      },
      {
        "question": "How does the function handle the case when both `SF` and `pars` are missing?",
        "answer": "If both `SF` and `pars` are missing, the function will throw an error with the message \"SF and pars can't both be missing.\" This is because the function needs either the survival fractions (`SF`) or the parameters (`pars`) to compute the AUC. The check is performed in an if-else block, where if both `SF` and `pars` are missing, it reaches the else condition and calls `stop()` with the error message."
      },
      {
        "question": "What is the difference between 'Fitted' and 'Actual' area types in the `computeAUC` function?",
        "answer": "The `area.type` parameter in `computeAUC` function determines how the AUC is calculated:\n\n1. 'Fitted': This calculates the AUC using a fitted curve. If `pars` are not provided, it fits a linear quadratic model to the data. It then uses these parameters to compute the AUC either analytically (for simple cases) or numerically (using trapezoid rule).\n\n2. 'Actual': This calculates the AUC directly from the provided data points (D and SF) using the trapezoid rule, without fitting any curve. It requires the `SF` values to be provided.\n\nThe 'Fitted' option is more suitable for smoothing out noise in the data, while 'Actual' gives the AUC of the raw data points."
      }
    ],
    "completion_tasks": [
      {
        "partial": "computeAUC <- function(D, SF, pars, lower, upper, trunc = TRUE,\n                       SF_as_log = FALSE,\n                       area.type = c(\"Fitted\", \"Actual\"),\n                       verbose = TRUE) {\n  area.type <- match.arg(area.type)\n\n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE,\n                                 y_to_log = FALSE, y_to_frac = FALSE,\n                                 trunc = trunc)\n    D <- DSF[[\"x\"]]\n    SF <- DSF[[\"y\"]]\n  } else if (!missing(pars)) {\n    Dpars <- CoreGx::.reformatData(x = D, pars = pars, x_to_log = FALSE,\n                                    y_to_log = FALSE, y_to_frac = FALSE,\n                                    trunc = trunc)\n    D <- Dpars[[\"x\"]]\n    pars <- Dpars[[\"pars\"]]\n  } else {\n    stop(\"SF and pars can't both be missing.\")\n  }\n\n  if (area.type == \"Fitted\") {\n    # Complete the code for the \"Fitted\" area type\n  } else if (area.type == \"Actual\") {\n    # Complete the code for the \"Actual\" area type\n  }\n}",
        "complete": "computeAUC <- function(D, SF, pars, lower, upper, trunc = TRUE,\n                       SF_as_log = FALSE,\n                       area.type = c(\"Fitted\", \"Actual\"),\n                       verbose = TRUE) {\n  area.type <- match.arg(area.type)\n\n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE,\n                                 y_to_log = FALSE, y_to_frac = FALSE,\n                                 trunc = trunc)\n    D <- DSF[[\"x\"]]\n    SF <- DSF[[\"y\"]]\n  } else if (!missing(pars)) {\n    Dpars <- CoreGx::.reformatData(x = D, pars = pars, x_to_log = FALSE,\n                                    y_to_log = FALSE, y_to_frac = FALSE,\n                                    trunc = trunc)\n    D <- Dpars[[\"x\"]]\n    pars <- Dpars[[\"pars\"]]\n  } else {\n    stop(\"SF and pars can't both be missing.\")\n  }\n\n  if (area.type == \"Fitted\") {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D = D, SF = SF, trunc = trunc, verbose = verbose))\n    }\n    lower <- if (missing(lower)) min(D) else lower\n    upper <- if (missing(upper)) max(D) else upper\n\n    if (SF_as_log) {\n      return(pars[[1]] / 2 * (lower^2 - upper^2) + pars[[2]] / 3 * (lower^3 - upper^3))\n    } else {\n      if (pars[[2]] == 0) {\n        if (pars[[1]] == 0) return(upper - lower)\n        return((exp(-pars[[1]] * lower) - exp(-pars[[1]] * upper)) / pars[[1]])\n      } else {\n        x <- CoreGx::.getSupportVec(x = D, output_length = 1000)\n        y <- .linearQuadratic(D = x, pars = pars, SF_as_log = FALSE)\n        return(caTools::trapz(x, y))\n      }\n    }\n  } else if (area.type == \"Actual\") {\n    if (missing(SF)) stop(\"Please pass in SF-values.\")\n    return(caTools::trapz(x = D, y = SF))\n  }\n}"
      },
      {
        "partial": "linearQuadraticModel <- function(D, SF, trunc = TRUE, verbose = TRUE) {\n  # Implement the linear quadratic model fitting\n  # Return the fitted parameters\n}",
        "complete": "linearQuadraticModel <- function(D, SF, trunc = TRUE, verbose = TRUE) {\n  if (trunc) {\n    SF[SF > 1] <- 1\n    if (verbose) warning(\"Some SF values were > 1 and have been truncated.\")\n  }\n  \n  log_SF <- log(SF)\n  model <- lm(log_SF ~ D + I(D^2))\n  \n  alpha <- -coef(model)[2]\n  beta <- -coef(model)[3]\n  \n  return(list(alpha = alpha, beta = beta))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/LongTable-utils.R",
    "language": "R",
    "content": "#' @include LongTable-class.R LongTable-accessors.R\n#' @importFrom checkmate assertClass assertDataFrame\nNULL\n\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown=TRUE, r6=FALSE)\n#### in the DESCRIPTION file!\n\n\n# ===================================\n# Utility Method Documentation Object\n# -----------------------------------\n\n\n# ======================================\n# Subset Methods\n# --------------------------------------\n\n\n##\n## == subset\n\n\n#' Subset a `LongTable` using an \"assayIndex\" data.frame\n#'\n#' @param x `LongTable`\n#' @param index `data.frame` Table with columns \"rowKey\", \"colKey\" and\n#'   \".\\<assayName\\>\", where \\<assayName\\> is the value for each `assayNames(x)`.\n#'   Warning: rownames are dropped internally in coercion to `data.table`,\n#' @param reindex `logical(1)` Should index values be reset such that they\n#'   are the smallest possible set of consecutive integers. Modifies the\n#'   \"rowKey\", \"colKey\", and all assayKey columns. Initial benchmarks indicate\n#'   `reindex=FALSE` saves ~20% of both execution time and memory allocation. The\n#'   cost of reindexing decreases the smaller your subet gets.\n#'\n#' @return `LongTable` subset according to the provided index.\n#'\n#' @noRd\n.subsetByIndex <- function(x, index, reindex=FALSE) {\n\n    # -- validate input\n    assertClass(x, \"LongTable\")\n    assertDataFrame(index)\n    if (!is.data.table(index)) setDT(index)\n    x <- copy(x)\n\n    # -- subset slots\n    rData <- rowData(x, raw=TRUE)[sort(unique(index$rowKey)), ]\n    cData <- colData(x, raw=TRUE)[sort(unique(sort(index$colKey))), ]\n    assays <- assays(x, withDimnames=FALSE)\n    metaKeys <- c(\"rowKey\", \"colKey\")\n    setkeyv(index, metaKeys)\n    for (i in seq_along(assays)) {\n        setkeyv(assays[[i]], metaKeys)\n        aname <- paste0(\".\", names(assays)[i])\n        # join based subsets use binary-search, O(log(n)) vs O(n) for vector-scan\n        # see https://rdatatable.gitlab.io/data.table/articles/datatable-keys-fast-subset.html\n        assays[[i]] <- assays[[i]][\n            index[!is.na(get(aname)), c(metaKeys, aname), with=FALSE],\n        ]\n        setkeyv(assays[[i]], aname)\n    }\n    # -- update object\n    # delete row-/colKeys by reference\n    for (a in assays) a[, (metaKeys) := NULL]\n    # ensure uniqueness for summary assays, fixes #149\n    assays <- lapply(assays, FUN=unique)\n    # raw=TRUE allows direct modification of slots\n    setkeyv(rData, \"rowKey\")\n    rowData(x, raw=TRUE) <- rData\n    setkeyv(cData, \"colKey\")\n    colData(x, raw=TRUE) <- cData\n    assays(x, raw=TRUE) <- assays\n    mutableIntern <- mutable(getIntern(x))\n    setkeyv(index, paste0(\".\", names(assays)))\n    mutableIntern$assayIndex <- index\n    x@.intern <- immutable(mutableIntern)\n\n    # -- optionally reindex the table\n    if (reindex) {\n        x <- reindex(x)\n    }\n    return(x)\n}\n\n#' Subset method for a LongTable object.\n#'\n#' Allows use of the colData and rowData `data.table` objects to query based on\n#'  rowID and colID, which is then used to subset all assay `data.table`s stored\n#'  in the `assays` slot.\n#' This function is endomorphic, it always returns a LongTable object.\n#'\n#' @examples\n#' # Character\n#' subset(merckLongTable, 'ABT-888', 'CAOV3')\n#' # Numeric\n#' subset(merckLongTable, 1, c(1, 2))\n#' # Logical\n#' subset(merckLongTable, , colData(merckLongTable)$sampleid == 'A2058')\n#' # Call\n#' subset(merckLongTable, drug1id == 'Dasatinib' & drug2id != '5-FU',\n#'     sampleid == 'A2058')\n#'\n#' @param x `LongTable` The object to subset.\n#' @param i `character`, `numeric`, `logical` or `call`\n#'  Character: pass in a character vector of rownames for the `LongTable` object\n#'    or a valid regex query which will be evaluated against the rownames.\n#'  Numeric or Logical: vector of indices or a logical vector to subset\n#'    the rows of a `LongTable`.\n#'  Call: Accepts valid query statements to the `data.table` i parameter,\n#'    this can be used to make complex queries using the `data.table` API\n#'    for the `rowData` data.table.\n#' @param j `character`, `numeric`, `logical` or `call`\n#'  Character: pass in a character vector of colnames for the `LongTable` object\n#'    or a valid regex query which will be evaluated against the colnames.\n#'  Numeric or Logical: vector of indices or a logical vector to subset\n#'    the columns of a `LongTable`.\n#'  Call: Accepts valid query statements to the `data.table` i parameter,\n#'    this can be used to make complex queries using the `data.table` API\n#'    for the `colData` data.table.\n#' @param assays `character`, `numeric` or `logical` Optional list of assay\n#'   names to subset. Can be used to subset the assays list further,\n#'   returning only the selected items in the new LongTable.\n#' @param reindex `logical(1)` Should index values be reset such that they\n#'   are the smallest possible set of consecutive integers. Modifies the\n#'   \"rowKey\", \"colKey\", and all assayKey columns. Initial benchmarks indicate\n#'   `reindex=FALSE` saves ~20% of both execution time and memory allocation. The\n#'   cost of reindexing decreases the smaller your subset gets.\n#'\n#' @return `LongTable` A new `LongTable` object subset based on the specified\n#'      parameters.\n#'\n#' @importMethodsFrom BiocGenerics subset\n#' @importFrom crayon magenta cyan\n#' @importFrom MatrixGenerics rowAnys\n#' @import data.table\n#' @export\nsetMethod('subset', signature('LongTable'),\n        function(x, i, j, assays=assayNames(x),\n            reindex=TRUE) {\n\n    # prevent modify by reference\n    x <- copy(x)\n\n    # local helper functions\n    .rowData <- function(...) rowData(..., key=TRUE)\n    .colData <- function(...) colData(..., key=TRUE)\n    .tryCatchNoWarn <- function(...) suppressWarnings(tryCatch(...))\n    .strSplitLength <- function(...) length(unlist(strsplit(...)))\n\n    # subset rowData\n    ## FIXME:: Can I parameterize this into a helper that works for both row\n    ## and column data?\n    if (!missing(i)) {\n        ## TODO:: Clean up this if-else block\n        if (.tryCatchNoWarn(is.call(i), error=function(e) FALSE)) {\n            rowDataSubset <- .rowData(x)[eval(i), ]\n        } else if (.tryCatchNoWarn(is.character(i), error=function(e) FALSE)) {\n            ## TODO:: Implement diagnosis for failed regex queries\n            idCols <- rowIDs(x, key=TRUE)\n            if (max(unlist(lapply(i, .strSplitLength, split=':'))) > length(idCols))\n                stop(cyan$bold('Attempting to select more rowID columns than\n                    there are in the LongTable.\\n\\tPlease use query of the form ',\n                    paste0(idCols, collapse=':')))\n            imatch <- rownames(x) %in% i\n            if (!any(imatch))\n                imatch <- grepl(.preprocessRegexQuery(i), rownames(x),\n                    ignore.case=TRUE)\n            imatch <- str2lang(.variableToCodeString(imatch))\n            rowDataSubset <- .rowData(x)[eval(imatch), ]\n        } else {\n            isub <- substitute(i)\n            rowDataSubset <- .tryCatchNoWarn(.rowData(x)[i, ],\n                error=function(e) .rowData(x)[eval(isub), ])\n        }\n    } else {\n        rowDataSubset <- .rowData(x)\n    }\n\n    # subset colData\n    if (!missing(j)) {\n        ## TODO:: Clean up this if-else block\n        if (.tryCatchNoWarn(is.call(j), error=function(e) FALSE, silent=TRUE)) {\n            colDataSubset <- .colData(x)[eval(j), ]\n        } else if (.tryCatchNoWarn(is.character(j), error=function(e) FALSE, silent=TRUE)) {\n            ## TODO:: Implement diagnosis for failed regex queries\n            idCols <- colIDs(x, key=TRUE)\n            if (max(unlist(lapply(j, .strSplitLength, split=':'))) > length(idCols))\n                stop(cyan$bold('Attempting to select more ID columns than there\n                    are in the LongTable.\\n\\tPlease use query of the form ',\n                    paste0(idCols, collapse=':')))\n            jmatch <- colnames(x) %in% j\n            if (!any(jmatch))\n                jmatch <- grepl(.preprocessRegexQuery(j), colnames(x),\n                    ignore.case=TRUE)\n            jmatch <- str2lang(.variableToCodeString(jmatch))\n            colDataSubset <- .colData(x)[eval(jmatch), ]\n        } else {\n            jsub <- substitute(j)\n            colDataSubset <- .tryCatchNoWarn(.colData(x)[j, ],\n                error=function(e) .colData(x)[eval(jsub), ])\n        }\n    } else {\n        colDataSubset <- .colData(x)\n    }\n\n    # Subset assays to only keys in remaining in rowData/colData\n    rows <- rowDataSubset$rowKey\n    cols <- colDataSubset$colKey\n\n    # -- find matching assays\n    validAssays <- assays %in% assayNames(x)\n    if (any(!validAssays))\n        warning(.warnMsg(assays[!validAssays],\n            \" are not valid assay names, ignoring...\"), call.=FALSE)\n    keepAssays <- assayNames(x) %in% assays\n\n    # -- subset index, then use index to subset x\n    assayKeys <- paste0(\".\", assayNames(x)[keepAssays])\n    idx <- mutable(getIntern(x, \"assayIndex\"))[\n        rowKey %in% rows & colKey %in% cols,\n        .SD,\n        .SDcols=c(\"rowKey\", \"colKey\", assayKeys)\n    ]\n    # -- drop rowKeys or colKeys which no longer have any assay observation\n    #   after the initial subset, fixes #148\n    validKeys <- idx[\n        which(rowAnys(!is.na(idx[, assayKeys, with=FALSE]))),\n        .(rowKey, colKey)\n    ]\n    idx <- idx[\n        rowKey %in% unique(validKeys$rowKey) &\n            colKey %in% unique(validKeys$colKey),\n    ]\n    assays(x, raw=TRUE)[!keepAssays] <- NULL  # delete assays being dropped\n\n    return(.subsetByIndex(x, idx, reindex=reindex))\n})\n\n\n\n#' Convenience function for converting R code to a call\n#'\n#' This is used to pass through unevaluated R expressions into subset and\n#'   `[`, where they will be evaluated in the correct context.\n#'\n#' @examples\n#' .(sample_line1 == 'A2058')\n#'\n#' @param ... `pairlist` One or more R expressions to convert to calls.\n#'\n#' @return `call` An R call object containing the quoted expression.\n#'\n#' @export\n. <- function(...) substitute(...)\n\n# ---- subset LongTable helpers\n\n#' Collapse vector of regex queries with | and replace * with .*\n#'\n#' @param queryString `character` Raw regex queries.\n#'\n#' @return `character` Formatted regex query.\n#'\n#' @keywords internal\n#' @noRd\n.preprocessRegexQuery <- function(queryString) {\n    # Support vectors of regex queries\n    query <- paste0(unique(queryString), collapse='|')\n    # Swap all * with .*\n    query <- gsub('\\\\.\\\\*', '*', query)\n    return(gsub('\\\\*', '.*', query))\n}\n\n\n#' @keywords internal\n#' @noRd\n.validateRegexQuery <- function(regex, names) {\n    ## TODO:: return TRUE if reqex query is valid, otherwise return error message\n}\n\n#' Convert an R object in a variable into a string of the code necessary to\n#'   create that object\n#'\n#' @param variable `symbol` A symbol containing an R variable\n#'\n#' @return `character(1)` A string representation of the code necessary to\n#'   reconstruct the variable.\n#'\n#' @keywords internal\n#' @noRd\n.variableToCodeString <- function(variable) {\n    codeString <- paste0(capture.output(dput(variable)), collapse='')\n    codeString <- gsub('\\\"', \"'\", codeString)\n    return(codeString)\n}\n\n#' Filter a data.table object based on the rowID and colID columns\n#'\n#' @param DT `data.table` Object with the columns rowID and colID, preferably\n#'  as the key columns.\n#' @param indexList `list` Two integer vectors, one indicating the rowIDs and\n#'  one indicating the colIDs to filter the `data.table` on.\n#'\n#' @return `data.table` A copy of `DT` subset on the row and column IDs specified\n#'  in `indexList`.\n#'\n#' @import data.table\n#' @keywords internal\n#' @noRd\n.filterLongDataTable <- function(DT, indexList) {\n\n    # validate input\n    if (length(indexList) > 2)\n        stop(\"This object is 2D, please only pass in two ID vectors, one for\n             rows and one for columns!\")\n\n    if (!all(vapply(unlist(indexList), is.numeric, FUN.VALUE=logical(1))))\n        stop('Please ensure indexList only contains integer vectors!')\n\n    # extract indices\n    rowIndices <- indexList[[1]]\n    colIndices <- indexList[[2]]\n\n    # return filtered data.table\n    return(copy(DT[rowKey %in% rowIndices & colKey %in% colIndices, ]))\n}\n\n##\n## == [ method\n\n\n#' [ LongTable Method\n#'\n#' Single bracket subsetting for a LongTable object. See subset for more details.\n#'\n#' This function is endomorphic, it always returns a LongTable object.\n#'\n#' @examples\n#' # Character\n#' merckLongTable['ABT-888', 'CAOV3']\n#' # Numeric\n#' merckLongTable[1, c(1, 2)]\n#' # Logical\n#' merckLongTable[, colData(merckLongTable)$sampleid == 'A2058']\n#' # Call\n#' merckLongTable[\n#'      .(drug1id == 'Dasatinib' & drug2id != '5-FU'),\n#'      .(sampleid == 'A2058'),\n#'  ]\n#'\n#' @param x `LongTable` The object to subset.\n#' @param i `character`, `numeric`, `logical` or `call`\n#'  Character: pass in a character vector of drug names, which will subset the\n#'    object on all row id columns matching the vector. This parameter also\n#'    supports valid R regex query strings which will match on the colnames\n#'    of `x`. For convenience, * is converted to .* automatically. Colon\n#'    can be to denote a specific part of the colnames string to query.\n#'  Numeric or Logical: these select based on the rowKey from the `rowData`\n#'    method for the `LongTable`.\n#'  Call: Accepts valid query statements to the `data.table` i parameter as\n#'    a call object. We have provided the function .() to conveniently\n#'    convert raw R statements into a call for use in this function.\n#' @param j `character`, `numeric`, `logical` or `call`\n#'  Character: pass in a character vector of drug names, which will subset the\n#'      object on all drug id columns matching the vector. This parameter also\n#'      supports regex queries. Colon can be to denote a specific part of the\n#'      colnames string to query.\n#'  Numeric or Logical: these select based on the rowID from the `rowData`\n#'      method for the `LongTable`.\n#'  Call: Accepts valid query statements to the `data.table` i parameter as\n#'      a call object. We have provided the function .() to conveniently\n#'      convert raw R statements into a call for use in this function.\n#' @param assays `character` Names of assays which should be kept in the\n#'   `LongTable` after subsetting.\n#' @param ... Included to ensure drop can only be set by name.\n#' @param drop `logical` Included for compatibility with the '[' primitive,\n#'   it defaults to FALSE and changing it does nothing.\n#'\n#' @return A `LongTable` containing only the data specified in the function\n#'   parameters.\n#'\n#' @export\nsetMethod('[', signature('LongTable'),\n        function(x, i, j, assays=assayNames(x), ..., drop=FALSE) {\n    subset(x, i, j, assays=assays, ...)\n})\n\n\n##\n## == [[ method'\n\n\n#' [[ Method for LongTable Class\n#'\n#' Select an assay from within a LongTable object.\n#'\n#' @describeIn LongTable Get an assay from a LongTable object. This method\n#'   returns the row and column annotations by default to make assignment\n#'   and aggregate operations easiers.\n#'\n#' @examples\n#' merckLongTable[['sensitivity']]\n#'\n#' @param x `LongTable` object to retrieve assays from\n#' @param i `character(1)` name or `integer` index of the desired assay.\n#'\n#' @importFrom crayon cyan magenta\n#' @import data.table\n#' @export\nsetMethod('[[', signature('LongTable'), function(x, i) {\n    assay(x, i)\n})\n\n\n#' `[[<-` Method for LongTable Class\n#'\n#' Just a wrapper around assay<- for convenience. See\n#' `?'assay<-,LongTable,character-method'.`\n#'\n#' @param x A `LongTable` to update.\n#' @param i The name of the assay to update, must be in `assayNames(object)`.\n#' @param value A `data.frame`\n#'\n#' @examples\n#' merckLongTable[['sensitivity']] <- merckLongTable[['sensitivity']]\n#'\n#' @return A `LongTable` object with the assay `i` updated using `value`.\n#'\n#' @export\nsetReplaceMethod('[[', signature(x='LongTable'), function(x, i, value) {\n    assay(x, i) <- value\n    x\n})\n\n\n##\n## == $ method\n\n\n#' Select an assay from a LongTable object\n#'\n#' @examples\n#' merckLongTable$sensitivity\n#'\n#' @param x A `LongTable` object to retrieve an assay from\n#' @param name `character` The name of the assay to get.\n#'\n#' @return `data.frame` The assay object.\n#'\n#' @export\nsetMethod('$', signature('LongTable'), function(x, name) {\n    # error handling is done inside `[[`\n    x[[name]]\n})\n\n#' Update an assay from a LongTable object\n#'\n#' @examples\n#' merckLongTable$sensitivity <- merckLongTable$sensitivity\n#'\n#' @param x A `LongTable` to update an assay for.\n#' @param name `character(1)` The name of the assay to update\n#' @param value A `data.frame` or `data.table` to update the assay with.\n#'\n#' @return Updates the assay `name` in `x` with `value`, returning an invisible\n#' NULL.\n#'\n#' @export\nsetReplaceMethod('$', signature('LongTable'), function(x, name, value) {\n    # error handling done inside `assay<-`\n    x[[name]] <- value\n    x\n})\n\n\n# ======================================\n# Reindex Methods\n# --------------------------------------\n\n##\n## == reindex\n\n#' Redo indexing for a LongTable object to remove any gaps in integer indexes\n#'\n#' After subsetting a LongTable, it is possible that values of rowKey or colKey\n#'   could no longer be present in the object. As a result there the indexes\n#'   will no longer be contiguous integers. This method will calcualte a new\n#'   set of rowKey and colKey values such that integer indexes are the smallest\n#'   set of contiguous integers possible for the data.\n#'\n#' @param object The `LongTable` object to recalcualte indexes (rowKey and\n#'     colKey values) for.\n#'\n#' @return A copy of the `LongTable` with all keys as the smallest set of\n#'     contiguous integers possible given the current data.\n#'\n#' @export\nsetMethod('reindex', signature(object='LongTable'), function(object) {\n\n    # -- extract the requisite data\n    mutableIntern <- mutable(getIntern(object))\n    index <- mutableIntern$assayIndex\n    rData <- copy(rowData(object, raw=TRUE))\n    cData <- copy(colData(object, raw=TRUE))\n    aList <- copy(assays(object, raw=TRUE))\n\n    # -- sort metadata tables by their id columns and update the index\n    # Add row key to rData\n    rData[, .rowKey := .I, by=c(rowIDs(object))]\n\n    # Add column key to cData\n    cData[, .colKey := .I, by=c(colIDs(object))]\n\n    # -- update rowKey and colKey in the assayIndex, if they have changed\n    if (rData[, any(rowKey != .rowKey)]) {\n        index[rData, rowKey := .rowKey, on=\"rowKey\"]\n        rData[, rowKey := .rowKey]\n        setkeyv(rData, \"rowKey\")\n    }\n    if (cData[, any(colKey != .colKey)]) {\n        index[cData, colKey := .colKey, on=\"colKey\"]\n        cData[, colKey := .colKey]\n        setkeyv(cData, \"colKey\")\n    }\n    rData[, .rowKey := NULL]\n    cData[, .colKey := NULL]\n\n    # -- add new indices for assayKeys to index\n    setkeyv(index, c(\"rowKey\", \"colKey\"))\n    assays_ <- setdiff(colnames(index), c(\"rowKey\", \"colKey\"))\n    lapply(assays_, function(nm){\n        # drop the first \".\" from nm\n        name <- gsub(\"^\\\\.\", \"\", nm)\n\n        # if there are any more \".\" in the name, then raise an erro\n        if (grepl(\"\\\\.\", name))\n            stop(\"Assay names cannot contain '.' characters!\")\n\n    })\n\n    assayEqualKeys <- setNames(vector(\"logical\", length(assays_)), assays_)\n    # This loop iterates over each element in the 'assays_' vector.\n    # For each element, it performs the following operations:\n    # 1. It checks if the element is not missing in the current data.table.\n    # 2. If the element is not missing, it creates a new column with the name\n    #    \".<element>\" and assigns a unique group identifier (.GRP) to each row\n    #    that has a non-missing value for that element. The grouping is done by\n    #    the element itself.\n    # 3. It updates the 'assayEqualKeys' list with a logical value indicating\n    #    whether all the values in the newly created column are equal to the\n    #    corresponding values in the original column.\n    #    This is done to ensure that summary assays, with repeated keys, have\n    #    consistent values across all rows.\n    #\n    # The data.table syntax used in this code is as follows:\n    # - The 'get' function is used to retrieve the value of a variable by name.\n    # - The 'is.na' function is used to check if a value is missing.\n    # - The ':=' operator is used to create or update columns by reference.\n    # - The '.GRP' variable represents a unique group identifier.\n    # - The 'by' parameter is used to specify the grouping variable(s).\n    #\n    # Note: The line width of the code has been limited to 80 characters for better readability.\n    for (nm in assays_) {\n        ## Added by to maintain cardinality of the each assayKey\n        ## Required to fix #147 and ensure summary assays, with repeated keys\n        index[!is.na(get(nm)), paste0(\".\", nm) := .GRP, by=c(nm)]\n        assayEqualKeys[nm] <- index[!is.na(get(nm)), all(get(paste0(\".\", nm)) == get(nm))]\n    }\n\n    # -- check equality and update assayKeys in assays if they have changed\n    for (.nm in names(which(!assayEqualKeys))) {\n        nm <- gsub(\"\\\\.\", \"\", .nm)\n        setkeyv(index, .nm)\n        aList[[nm]][index, (.nm) := get(paste0(\".\", .nm))]\n        setkeyv(aList[[nm]], .nm)\n        index[, (.nm) := get(paste0(\".\", .nm))]\n    }\n    index[, paste0(\".\", assays_) := NULL]\n    setkeyv(index, paste0(\".\", assayNames(object)))\n\n    # -- update the object with the reindexed tables and return\n    rowData(object, raw=TRUE) <- rData\n    colData(object, raw=TRUE) <- cData\n    assays(object, raw=TRUE) <- aList\n    mutableIntern$assayIndex <- index\n    object@.intern <- immutable(mutableIntern)\n    return(object)\n})\n\n\n#' @keywords internal\n#' @noRd\n.extractIDData <- function(assayDataList, idCols, keyName) {\n    idDT <- data.table()\n    for (assay in assayDataList) {\n        idDT <- unique(rbindlist(list(idDT, assay[, ..idCols])))\n    }\n    rm(assayDataList)\n    idDT[, eval(substitute(keyName := seq_len(.N)))]\n    setkeyv(idDT, keyName)\n    return(idDT)\n}\n\n\n#' @keywords interal\n#' @noRd\n.joinDropOn <- function(DT1, DT2, on) {\n    DT1[DT2, on=on][, -get('on')]\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.subsetByIndex` function in this code?",
        "answer": "The `.subsetByIndex` function is used to subset a `LongTable` object using an 'assayIndex' data.frame. It takes the `LongTable` object, an index data.frame, and a reindex flag as inputs. The function subsets the rowData, colData, and assays of the `LongTable` based on the provided index, and optionally reindexes the resulting subset."
      },
      {
        "question": "How does the `subset` method handle different types of input for the `i` and `j` parameters?",
        "answer": "The `subset` method for `LongTable` objects handles different types of input for `i` and `j` parameters as follows:\n1. For character input, it matches against rownames/colnames or evaluates regex queries.\n2. For numeric or logical input, it uses them as indices or logical vectors for subsetting.\n3. For call objects, it evaluates them as queries against the rowData/colData data.tables.\nThis flexibility allows for various ways of subsetting the `LongTable` object."
      },
      {
        "question": "What is the purpose of the `reindex` method for `LongTable` objects?",
        "answer": "The `reindex` method for `LongTable` objects is used to recalculate the indexing (rowKey and colKey values) after subsetting. It ensures that the integer indexes are the smallest set of contiguous integers possible for the current data. This is useful because subsetting can create gaps in the index values, and reindexing helps maintain efficient and consistent indexing across the `LongTable` object."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Subset a `LongTable` using an \"assayIndex\" data.frame\n.subsetByIndex <- function(x, index, reindex=FALSE) {\n    # -- validate input\n    assertClass(x, \"LongTable\")\n    assertDataFrame(index)\n    if (!is.data.table(index)) setDT(index)\n    x <- copy(x)\n\n    # -- subset slots\n    rData <- rowData(x, raw=TRUE)[sort(unique(index$rowKey)), ]\n    cData <- colData(x, raw=TRUE)[sort(unique(sort(index$colKey))), ]\n    assays <- assays(x, withDimnames=FALSE)\n    metaKeys <- c(\"rowKey\", \"colKey\")\n    setkeyv(index, metaKeys)\n    for (i in seq_along(assays)) {\n        setkeyv(assays[[i]], metaKeys)\n        aname <- paste0(\".\", names(assays)[i])\n        assays[[i]] <- assays[[i]][\n            index[!is.na(get(aname)), c(metaKeys, aname), with=FALSE],\n        ]\n        setkeyv(assays[[i]], aname)\n    }\n\n    # -- update object\n    for (a in assays) a[, (metaKeys) := NULL]\n    assays <- lapply(assays, FUN=unique)\n    setkeyv(rData, \"rowKey\")\n    rowData(x, raw=TRUE) <- rData\n    setkeyv(cData, \"colKey\")\n    colData(x, raw=TRUE) <- cData\n    assays(x, raw=TRUE) <- assays\n    mutableIntern <- mutable(getIntern(x))\n    setkeyv(index, paste0(\".\", names(assays)))\n    mutableIntern$assayIndex <- index\n    x@.intern <- immutable(mutableIntern)\n\n    # -- optionally reindex the table\n    if (reindex) {\n        x <- reindex(x)\n    }\n    return(x)\n}",
        "complete": "# Subset a `LongTable` using an \"assayIndex\" data.frame\n.subsetByIndex <- function(x, index, reindex=FALSE) {\n    assertClass(x, \"LongTable\")\n    assertDataFrame(index)\n    if (!is.data.table(index)) setDT(index)\n    x <- copy(x)\n\n    rData <- rowData(x, raw=TRUE)[sort(unique(index$rowKey)), ]\n    cData <- colData(x, raw=TRUE)[sort(unique(sort(index$colKey))), ]\n    assays <- assays(x, withDimnames=FALSE)\n    metaKeys <- c(\"rowKey\", \"colKey\")\n    setkeyv(index, metaKeys)\n    for (i in seq_along(assays)) {\n        setkeyv(assays[[i]], metaKeys)\n        aname <- paste0(\".\", names(assays)[i])\n        assays[[i]] <- assays[[i]][\n            index[!is.na(get(aname)), c(metaKeys, aname), with=FALSE],\n        ]\n        setkeyv(assays[[i]], aname)\n    }\n\n    for (a in assays) a[, (metaKeys) := NULL]\n    assays <- lapply(assays, FUN=unique)\n    setkeyv(rData, \"rowKey\")\n    rowData(x, raw=TRUE) <- rData\n    setkeyv(cData, \"colKey\")\n    colData(x, raw=TRUE) <- cData\n    assays(x, raw=TRUE) <- assays\n    mutableIntern <- mutable(getIntern(x))\n    setkeyv(index, paste0(\".\", names(assays)))\n    mutableIntern$assayIndex <- index\n    x@.intern <- immutable(mutableIntern)\n\n    if (reindex) x <- reindex(x)\n    return(x)\n}"
      },
      {
        "partial": "# Subset method for a LongTable object\nsetMethod('subset', signature('LongTable'),\n    function(x, i, j, assays=assayNames(x), reindex=TRUE) {\n        x <- copy(x)\n\n        .rowData <- function(...) rowData(..., key=TRUE)\n        .colData <- function(...) colData(..., key=TRUE)\n        .tryCatchNoWarn <- function(...) suppressWarnings(tryCatch(...))\n        .strSplitLength <- function(...) length(unlist(strsplit(...)))\n\n        # subset rowData\n        if (!missing(i)) {\n            if (.tryCatchNoWarn(is.call(i), error=function(e) FALSE)) {\n                rowDataSubset <- .rowData(x)[eval(i), ]\n            } else if (.tryCatchNoWarn(is.character(i), error=function(e) FALSE)) {\n                idCols <- rowIDs(x, key=TRUE)\n                if (max(unlist(lapply(i, .strSplitLength, split=':'))) > length(idCols))\n                    stop(cyan$bold('Attempting to select more rowID columns than there are in the LongTable.\\n\\tPlease use query of the form ', paste0(idCols, collapse=':')))\n                imatch <- rownames(x) %in% i\n                if (!any(imatch))\n                    imatch <- grepl(.preprocessRegexQuery(i), rownames(x), ignore.case=TRUE)\n                imatch <- str2lang(.variableToCodeString(imatch))\n                rowDataSubset <- .rowData(x)[eval(imatch), ]\n            } else {\n                isub <- substitute(i)\n                rowDataSubset <- .tryCatchNoWarn(.rowData(x)[i, ],\n                    error=function(e) .rowData(x)[eval(isub), ])\n            }\n        } else {\n            rowDataSubset <- .rowData(x)\n        }\n\n        # subset colData\n        if (!missing(j)) {\n            if (.tryCatchNoWarn(is.call(j), error=function(e) FALSE, silent=TRUE)) {\n                colDataSubset <- .colData(x)[eval(j), ]\n            } else if (.tryCatchNoWarn(is.character(j), error=function(e) FALSE, silent=TRUE)) {\n                idCols <- colIDs(x, key=TRUE)\n                if (max(unlist(lapply(j, .strSplitLength, split=':'))) > length(idCols))\n                    stop(cyan$bold('Attempting to select more ID columns than there are in the LongTable.\\n\\tPlease use query of the form ', paste0(idCols, collapse=':')))\n                jmatch <- colnames(x) %in% j\n                if (!any(jmatch))\n                    jmatch <- grepl(.preprocessRegexQuery(j), colnames(x), ignore.case=TRUE)\n                jmatch <- str2lang(.variableToCodeString(jmatch))\n                colDataSubset <- .colData(x)[eval(jmatch), ]\n            } else {\n                jsub <- substitute(j)\n                colDataSubset <- .tryCatchNoWarn(.colData(x)[j, ],\n                    error=function(e) .colData(x)[eval(jsub), ])\n            }\n        } else {\n            colDataSubset <- .colData(x)\n        }\n\n        # Subset assays to only keys in remaining in rowData/colData\n        rows <- rowDataSubset$rowKey\n        cols <- colDataSubset$colKey\n\n        # -- find matching assays\n        validAssays <- assays %in% assayNames(x)\n        if (any(!validAssays))\n            warning(.warnMsg(assays[!validAssays],\n                \" are not valid assay names, ignoring...\"), call.=FALSE)\n        keepAssays <- assayNames(x) %in% assays\n\n        # -- subset index, then use index to subset x\n        assayKeys <- paste0(\".\", assayNames(x)[keepAssays])\n        idx <- mutable(getIntern(x, \"assayIndex\"))[\n            rowKey %in% rows & colKey %in% cols,\n            .SD,\n            .SDcols=c(\"rowKey\", \"colKey\", assayKeys)\n        ]\n        # -- drop rowKeys or colKeys which no longer have any assay observation\n        #   after the initial subset, fixes #148\n        validKeys <- idx[\n            which(rowAnys(!is.na(idx[, assayKeys, with=FALSE]))),\n            .(rowKey, colKey)\n        ]\n        idx <- idx[\n            rowKey %in% unique(validKeys$rowKey) &\n                colKey %in% unique(validKeys$colKey),\n        ]\n        assays(x, raw=TRUE)[!keepAssays] <- NULL  # delete assays being dropped\n\n        return(.subsetByIndex(x, idx, reindex=reindex))\n    }\n)",
        "complete": "# Subset method for a LongTable object\nsetMethod('subset', signature('LongTable'),\n    function(x, i, j, assays=assayNames(x), reindex=TRUE) {\n        x <- copy(x)\n\n        .rowData <- function(...) rowData(..., key=TRUE)\n        .colData <- function(...) colData(..., key=TRUE)\n        .tryCatchNoWarn <- function(...) suppressWarnings(tryCatch(...))\n        .strSplitLength <- function(...) length(unlist(strsplit(...)))\n\n        if (!missing(i)) {\n            if (.tryCatchNoWarn(is.call(i), error=function(e) FALSE)) {\n                rowDataSubset <- .rowData(x)[eval(i), ]\n            } else if (.tryCatchNoWarn(is.character(i), error=function(e) FALSE)) {\n                idCols <- rowIDs(x, key=TRUE)\n                if (max(unlist(lapply(i, .strSplitLength, split=':'))) > length(idCols))\n                    stop(cyan$bold('Attempting to select more rowID columns than there are in the LongTable.\\n\\tPlease use query of the form ', paste0(idCols, collapse=':')))\n                imatch <- rownames(x) %in% i\n                if (!any(imatch))\n                    imatch <- grepl(.preprocessRegexQuery(i), rownames(x), ignore.case=TRUE)\n                imatch <- str2lang(.variableToCodeString(imatch))\n                rowDataSubset <- .rowData(x)[eval(imatch), ]\n            } else {\n                isub <- substitute(i)\n                rowDataSubset <- .tryCatchNoWarn(.rowData(x)[i, ],\n                    error=function(e) .rowData(x)[eval(isub), ])\n            }\n        } else {\n            rowDataSubset <- .rowData(x)\n        }\n\n        if (!missing(j)) {\n            if (.tryCatchNoWarn(is.call(j), error=function(e) FALSE, silent=TRUE)) {\n                colDataSubset <- .colData(x)[eval(j), ]\n            } else if (.tryCatchNoWarn(is.character(j), error=function(e) FALSE, silent=TRUE)) {\n                idCols <- colIDs(x, key=TRUE)\n                if (max(unlist(lapply(j, .strSplitLength, split=':'))) > length(idCols))\n                    stop(cyan$bold('Attempting to select more ID columns than there are in the LongTable.\\n\\tPlease use query of the form ', paste0(idCols, collapse=':')))\n                jmatch <- colnames(x) %in% j\n                if (!any(jmatch))\n                    jmatch <- grepl(.preprocessRegexQuery(j), colnames(x), ignore.case=TRUE)\n                jmatch <- str2lang(.variableToCodeString(jmatch))\n                colDataSubset <- .colData(x)[eval(jmatch), ]\n            } else {\n                jsub <- substitute(j)\n                colDataSubset <- .tryCatchNoWarn(.colData(x)[j, ],\n                    error=function(e) .colData(x)[eval(jsub), ])\n            }\n        } else {\n            colDataSubset <- .colData(x)\n        }\n\n        rows <- rowDataSubset$rowKey\n        cols <- colDataSubset$colKey\n\n        validAssays <- assays %in% assayNames(x)\n        if (any(!validAssays))\n            warning(.warnMsg(assays[!validAssays],\n                \" are not valid assay names, ignoring...\"), call.=FALSE)\n        keepAssays <- assayNames(x) %in% assays\n\n        assayKeys <- paste0(\".\", assayNames(x)[keepAssays])\n        idx <- mutable(getIntern(x, \"assayIndex\"))[\n            rowKey %in% rows & colKey %in% cols,\n            .SD,\n            .SDcols=c(\"rowKey\", \"colKey\", assayKeys)\n        "
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/CoreSet-accessors.R",
    "language": "R",
    "content": "# Navigating this file:\n# - Slot section names start with ----\n# - Method section names start with ==\n#\n# As a result, you can use Ctrl + f to find the slot or method you are looking\n# for quickly, assuming you know its name.\n#\n# For example Ctrl + f '== molecularProfiles' would take you the molecularProfiles\n# method, while Ctrl + f '---- molecularProfiles' would take you to the slot\n# section.\n\n#' @include CoreSet-class.R allGenerics.R LongTable-class.R\nNULL\n\n.local_class <- 'CoreSet'\n.local_data <- 'clevelandSmall_cSet'\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n\n# =======================================\n# Accessor Method Documentation Object\n# ---------------------------------------\n\n#' @noRd\n.docs_CoreSet_accessors <- function(...) .parseToRoxygen(\n    \"\n    @title Accessing and modifying information in a `{class_}`\n\n    @description\n    Documentation for the various setters and getters which allow manipulation\n    of data in the slots of a `{class_}` object.\n\n    @param object A `{class_}` object.\n    @param value See details.\n    @param mDataType `character(1)` The name of a molecular datatype to access\n    from the `molecularProfiles` of a `{class_}` object.\n    @param assay `character(1)` A valid assay name in the `SummarizedExperiment`\n    of `@molecularProfiles` of a {class_} object for data type `mDataType`.\n    @param dimension See details.\n    @param ... See details.\n\n    @return Accessors: See details.\n    @return Setters: An updated `{class_}` object, returned invisibly.\n    \",\n    ...\n)\n\n#' @name CoreSet-accessors\n#' @eval .docs_CoreSet_accessors(class_='CoreSet')\n#' @eval .parseToRoxygen(\"@examples data({data_})\", data_=.local_data)\nNULL\n\n\n# ======================================\n# Accessor Methods\n# --------------------------------------\n\n\n## ====================\n## ---- annotation slot\n## --------------------\n\n\n##\n## == annotation\n\n\n#' @noRd\n.docs_CoreSet_get_annotation <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    ## @annotation\n\n    __annotation__: A `list` of {class_} annotations with items: 'name',\n    the name of the object; 'dateCreated', date the object was created; 'sessionInfo',\n    the `sessionInfo()` when the object was created; 'call', the R constructor call;\n    and 'version', the object version.\n\n    @examples\n\n    ## @annotation\n\n    annotation({data_})\n\n    @md\n    @importMethodsFrom BiocGenerics annotation\n    @aliases annotation\n    @exportMethod annotation\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_annotation(class_=.local_class, data_=.local_data)\nsetMethod('annotation', signature(\"CoreSet\"), function(object) {\n    object@annotation\n})\n\n\n#' @noRd\n.docs_CoreSet_set_annotation <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __annotation<-__: Setter method for the annotation slot. Arguments:\n    - value: a `list` of annotations to update the {class_} with.\n\n    @examples\n    annotation({data_}) <- annotation({data_})\n\n    @md\n    @importMethodsFrom BiocGenerics annotation<-\n    @aliases annotation<-\n    @exportMethod annotation<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_annotation(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"annotation\", signature(\"CoreSet\", \"list\"),\n    function(object, value)\n{\n    object@annotation <- value\n    object\n})\n\n\n##\n## == dateCreated\n\n\n#' @export\nsetGeneric(\"dateCreated\", function(object, ...) standardGeneric(\"dateCreated\"))\n\n.docs_CoreSet_get_dateCreated <- function(...) .parseToRoxygen(\n    \"\n    @details\n    ## @dateCreated\n    __dateCreated__: `character(1)` The date the `{class_}` object was\n    created, as returned by the `date()` function.\n    @examples\n    dateCreated({data_})\n\n    @md\n    @aliases dateCreated,{class_}-method dateCreated\n    @exportMethod dateCreated\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_dateCreated(class_=.local_class, data_=.local_data)\nsetMethod('dateCreated', signature(\"CoreSet\"), function(object) {\n    object@annotation$dateCreated\n})\n\n\n#' @export\nsetGeneric(\"dateCreated<-\", function(object, ..., value)\n    standardGeneric(\"dateCreated<-\"))\n\n.docs_CoreSet_set_dateCreated <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __dateCreated<-__: Update the 'dateCreated' item in the `annotation` slot of\n    a `{class_}` object. Arguments:\n    - value: A `character(1)` vector, as returned by the `date()` function.\n    @examples\n    ## dateCreated\n    dateCreated({data_}) <- date()\n\n    @md\n    @aliases dateCreated<-,{class_}-method dateCreated<-\n    @exportMethod dateCreated<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_dateCreated(class_=.local_class, data_=.local_data)\nsetReplaceMethod('dateCreated', signature(object=\"CoreSet\", value=\"character\"),\n    function(object, value)\n{\n    ## TODO:: Error handling - do we ever want to allow a datetime object?\n    funContext <- .funContext('dateCreated')\n    if (length(value) > 1) .error(funContext, 'dateCreated must by a character\n        vector of length 1, as returned by the `date()` function.')\n    object@annotation$dateCreated <- value\n    return(object)\n})\n\n\n##\n## == name\n\n\n#' @export\nsetGeneric(\"name\", function(object, ...) standardGeneric(\"name\"))\n\n.docs_CoreSet_get_name <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __name__: `character(1)` The name of the `{class_}`, retreived from\n    the `@annotation` slot.\n\n    @examples\n    name({data_})\n\n    @md\n    @aliases name,{class_}-method name\n    @exportMethod name\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_name(class_=.local_class, data_=.local_data)\nsetMethod('name', signature(\"CoreSet\"), function(object) {\n    return(object@annotation$name)\n})\n\n#' @export\nsetGeneric(\"name<-\", function(object, ..., value) standardGeneric(\"name<-\"))\n\n#' @noRd\n.docs_CoreSet_set_name <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __name<-__: Update the `@annotation$name` value in a `{class_}`  object.\n    - value: `character(1)` The name of the `{class_}` object.\n\n    @examples\n    name({data_}) <- 'new_name'\n\n    @md\n    @aliases name<-,{class_},character-method name<-\n    @exportMethod name<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_name(class_=.local_class, data_=.local_data)\nsetReplaceMethod('name', signature(\"CoreSet\"), function(object, value) {\n    object@annotation$name <- value\n    return(object)\n})\n\n\n## ==============\n## ---- sample slot\n\n\n##\n## == sampleInfo\n\n\n#' @export\nsetGeneric(\"sampleInfo\", function(object, ...) standardGeneric(\"sampleInfo\"))\n\n#' @noRd\n.docs_CoreSet_get_sampleInfo <- function(...) .parseToRoxygen(\n    \"\n    ## @sample\n    @details\n    __{sample_}Info__: `data.frame` Metadata for all sample in a `{class_}` object.\n\n    @md\n    @aliases\n    sampleInfo,{class_}-method sampleInfo\n    {sample_}Info,{class_}-method\n    {sample_}Info\n    @exportMethod sampleInfo\n    \",\n    ...\n)\n\n\n.local_sample <- \"cell\"\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sampleInfo(class_=.local_class, sample_=.local_sample)\nsetMethod(\"sampleInfo\", \"CoreSet\", function(object) {\n    object@sample\n})\n#' @export\ncellInfo <- function(...) sampleInfo(...)\n\n#' @export\nsetGeneric(\"sampleInfo<-\", function(object, value) standardGeneric(\"sampleInfo<-\"))\n\n#' @noRd\n.docs_CoreSet_set_sampleInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sampleInfo<-__: assign updated sample annotations to the `{class_}`\n    object.\n    Arguments:\n    - value: a `data.frame` object.\n    @examples\n    sampleInfo({data_}) <- sampleInfo({data_})\n\n    @md\n    @aliases\n    sampleInfo<-,{class_},data.frame-method\n    sampleInfo<-\n    {sample_}Info<-,{class_},data.frame-method\n    {sample_}Info<-\n    @exportMethod sampleInfo<-\n    \",\n    ...\n)\n\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sampleInfo(class_=.local_class, data_=.local_data,\n#'  sample_=.local_sample)\nsetReplaceMethod(\"sampleInfo\", signature(object=\"CoreSet\", value=\"data.frame\"),\n        function(object, value) {\n    funContext <- .funContext('::sampleInfo')\n    if (is.null(rownames(value)))\n    .error(funContext, \"Please provide the sampleid as rownames for the sample\n        annotations\")\n    object@sample <- value\n    object\n})\n#' @export\n`cellInfo<-` <- function(object, value) `sampleInfo<-`(object, value=value)\n\n\n##\n## == sampleNames\n\n## TODO: Implement an actual @sample slot instead of using @sample  and aliases\n\n\n\n#' @noRd\n.docs_CoreSet_get_sampleNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sampleNames__: `character` Retrieve the rownames of the `data.frame` in\n    the `sample` slot from a {class_} object.\n    @examples\n    sampleNames({data_})\n\n    @md\n    @aliases\n    sampleName,{class_}-method\n    sampleNames\n    {sample_}Name,{class_}-method\n    {sample_}Names\n    @exportMethod sampleNames\n    \",\n    ...\n)\n\n#' @importMethodsFrom Biobase sampleNames\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sampleNames(class_=.local_class, data_=.local_data,\n#' sample_=.local_sample)\nsetMethod(\"sampleNames\", signature(\"CoreSet\"), function(object) {\n    rownames(sampleInfo(object))\n})\n#' @export\ncellNames <- function(object) sampleNames(object)\n\n\n#' @noRd\n.docs_CoreSet_set_sampleNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sampleNames<-__: assign new rownames to the sampleInfo `data.frame` for\n    a {class_} object.\n    Arguments:\n    - value: `character` vector of rownames for the `sampleInfo(object)` `data.frame`.\n    @examples\n    sampleNames({data_}) <- sampleNames({data_})\n\n    @md\n    @aliases\n    sampleNames<-,{class_},list-method\n    sampleNames<-\n    {sample_}Names<-,{class_},list-method\n    {sample_}Names<-\n    @exportMethod sampleNames<-\n    \",\n    ...\n)\n\n\n#' @importMethodsFrom Biobase sampleNames<-\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sampleNames(class_=.local_class, data_=.local_data,\n#' sample_=.local_sample)\nsetReplaceMethod(\"sampleNames\", signature(object=\"CoreSet\", value=\"character\"),\n        function(object, value) {\n    ## TODO: does updateSampleId also update slots other than sample?\n    object <- updateSampleId(object, value)\n    return(object)\n})\n#' @export\n`cellNames<-` <- function(object, value) `sampleNames<-`(object, value=value)\n\n\n## -------------------\n## ---- treatment slot\n\n## TODO: Implement an actual @treatment slot to replace @treatment and @radiation\n\n#\n# == treatmentInfo\n\n#' @export\nsetGeneric('treatmentInfo', function(object, ...)\n    standardGeneric('treatmentInfo'))\n\n#' @noRd\n.docs_CoreSet_get_treatmentInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __treatmentInfo__: `data.frame` Metadata for all treatments in a `{class_}`\n    object. Arguments:\n    - object: `{class_}` An object to retrieve treatment metadata from.\n\n    @examples\n    treatmentInfo({data_})\n\n    @md\n    @aliases treatmentInfo,{class_}-method treatmentInfo\n    @exportMethod treatmentInfo\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_treatmentInfo(class_=.local_class, data_=.local_data)\nsetMethod('treatmentInfo', signature('CoreSet'), function(object) {\n    treatmentType <- switch(class(object)[1],\n        'PharmacoSet'='treatment',\n        'ToxicoSet'='treatment',\n        'RadioSet'='radiation',\n        'CoreSet'='treatment'\n    )\n    package <- gsub('Set', 'Gx', class(object)[1])\n    if (\"treatment\" %in% slotNames(object)) return(object@treatment)\n    treatmentInfo <- get(paste0(treatmentType, 'Info'),\n        envir=asNamespace(package))\n    treatmentInfo(object)\n})\n\n#' @export\nsetGeneric('treatmentInfo<-', function(object, ..., value)\n    standardGeneric('treatmentInfo<-'))\n\n#' @noRd\n.docs_CoreSet_set_treatmentInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __treatmentInfo<-__: `{class_}` object with updated treatment metadata.\n    object. Arguments:\n    - object: `{class_}` An object to set treatment metadata for.\n    - value: `data.frame` A new table of treatment metadata for `object`.\n\n    @examples\n    treatmentInfo({data_}) <- treatmentInfo({data_})\n\n    @md\n    @aliases treatmentInfo<-,{class_},data.frame-method treatmentInfo<-\n    @exportMethod treatmentInfo<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_treatmentInfo(class_=.local_class, data_=.local_data)\nsetReplaceMethod('treatmentInfo', signature(object='CoreSet',\n        value='data.frame'), function(object, value) {\n    object@treatment <- value\n    return(invisible(object))\n})\n\n##\n## == treatmentNames\n\n\n#' @export\nsetGeneric('treatmentNames', function(object, ...)\n    standardGeneric('treatmentNames'))\n\n#' @noRd\n.docs_CoreSet_get_treatmentNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __treatmentNames__: `character` Names for all treatments in a `{class_}`\n    object. Arguments:\n    - object: `{class_}` An object to retrieve treatment names from.\n\n    @examples\n    treatmentNames({data_})\n\n    @md\n    @aliases treatmentNames,{class_}-method treatmentNames\n    @exportMethod treatmentNames\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_treatmentNames(class_=.local_class, data_=.local_data)\nsetMethod('treatmentNames', signature(object='CoreSet'), function(object) {\n    rownames(treatmentInfo(object))\n})\n\n\n#' @export\nsetGeneric('treatmentNames<-', function(object, ..., value)\n    standardGeneric('treatmentNames<-'))\n\n#' @noRd\n.docs_CoreSet_set_treatmentNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __treatmentNames<-__: `{class_}` Object with updates treatment names.\n    object. Arguments:\n    - object: `{class_}` An object to set treatment names from.\n    - value: `character` A character vector of updated treatment names.\n\n    @examples\n    treatmentNames({data_}) <- treatmentNames({data_})\n\n    @md\n    @aliases treatmentNames<-,{class_},character-method treatmentNames<-\n    @exportMethod treatmentNames<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_treatmentNames(class_=.local_class, data_=.local_data)\nsetReplaceMethod('treatmentNames',\n        signature(object='CoreSet', value='character'),\n        function(object, value) {\n    object <- updateTreatmentId(object, new.ids=value)\n    return(invisible(object))\n})\n\n## ------------------\n## ---- curation slot\n\n\n##\n## == curation\n\n\n#' @export\nsetGeneric(\"curation\", function(object, ...) standardGeneric(\"curation\"))\n\n#' @noRd\n.docs_CoreSet_get_curation <- function(...) .parseToRoxygen(\n    \"\n    @details\n    ## @curation\n    __curation__: A `list` of curated mappings between identifiers in the\n    {class_} object and the original data publication. {details_}\n    @examples\n    ## curation\n    curation({data_})\n\n    @md\n    @aliases curation,{class_}-method curation\n    @exportMethod curation\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_curation(class_=.local_class, data_=.local_data,\n#' details_=\"Contains two `data.frame`s, 'sample' with sample ids and\n#' 'tissue' with tissue ids.\")\nsetMethod('curation', signature(object=\"CoreSet\"), function(object) {\n    object@curation\n})\n\n#' @export\nsetGeneric(\"curation<-\", function(object, ..., value)\n    sstandardGeneric(\"curation<-\"))\n\n#' @noRd\n.docs_CoreSet_set_curation <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __curation<-__: Update the `curation` slot of a {class_} object. Arugments:\n    - value: A `list` of `data.frame`s, one for each type of curated\n    identifier. {details_}\n    @examples\n    curation({data_}) <- curation({data_})\n\n    @md\n    @aliases curation<-,{class_},list-method curation<-\n    @exportMethod curation<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_curation(class_=.local_class, data_=.local_data,\n#' details_=\"For a `CoreSet` object the slot should contain tissue and\n#' sample id `data.frame`s.\")\nsetReplaceMethod(\"curation\", signature(object=\"CoreSet\", value=\"list\"),\n    function(object, value)\n{\n    object@curation <- value\n    object\n})\n\n\n\n## ----------------------\n## ---- datasetType slot\n\n\n#\n# == datasetType\n\n\n#' @export\nsetGeneric(\"datasetType\", function(object, ...) standardGeneric(\"datasetType\"))\n\n#' @noRd\n.docs_CoreSet_get_datasetType <- function(...) .parseToRoxygen(\n    \"\n    @details\n    ## datasetType slot\n    __datasetType__: `character(1)` The type treatment response in the\n    `sensitivity` slot. Valid values are 'sensitivity', 'perturbation' or 'both'.\n    @examples\n    datasetType({data_})\n\n    @md\n    @aliases datasetType,{class_}-method datasetType\n    @exportMethod datasetType\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_datasetType(class_=.local_class, data_=.local_data)\nsetMethod(\"datasetType\", signature(\"CoreSet\"), function(object) {\n    object@datasetType\n})\n\n\n#' @export\nsetGeneric(\"datasetType<-\",  function(object, value)\n    standardGeneric(\"datasetType<-\"))\n\n#' @noRd\n.docs_CoreSet_set_datasetType <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __datasetType<-__: Update the datasetType slot of a {class_} object.\n    Arguments:\n    - value: A `character(1)` vector with one of 'sensitivity', 'perturbation'\n    or 'both'\n    @examples\n    datasetType({data_}) <- 'both'\n\n    @md\n    @aliases datasetType<-,{class_},character-method datasetType<-\n    @export\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_datasetType(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"datasetType\", signature(object=\"CoreSet\", value='character'),\n    function(object, value)\n{\n    funContext <- .funContext('::datasetType,CoreSet,character-method')\n    if (length(value) > 1) .error(funContext,\n        'datasetType must be a character vector of length 1.')\n    if (!is.element(value, c('sensitivity', 'perturbation', 'both')))\n        .error(funContext, 'datasetType must be one of \"sensitivity\",\n            \"perturbation\" or \"both\".')\n    object@datasetType <- value\n    object\n})\n\n\n\n## ---------------------------\n## ---- molecularProfiles slot\n\n\n##\n## == molecularProfiles\n\n\n#' @export\nsetGeneric(\"molecularProfiles\", function(object, mDataType, assay, ...)\n    standardGeneric(\"molecularProfiles\"))\n\n#' @noRd\n.docs_CoreSet_get_molecularProfiles <- function(...) .parseToRoxygen(\n    \"\n    @details\n    ## @molecularProfiles\n    __molecularProfiles__: `matrix()` Retrieve an assay in a\n    `SummarizedExperiment` from the `molecularProfiles` slot of a `{class_}`\n    object with the specified `mDataType`. Valid `mDataType` arguments can be\n    found with `mDataNames(object)`. Exclude `mDataType` and `assay` to\n    access the entire slot. Arguments:\n    - assay: Optional `character(1)` vector specifying an assay in the\n    `SummarizedExperiment` of the `molecularProfiles` slot of the\n    `{class_}` object for the specified `mDataType`. If excluded,\n    defaults to modifying the first assay in the `SummarizedExperiment` for\n    the given `mDataType`.\n\n    @md\n    @aliases molecularProfiles,{class_}-method molecularProfiles\n    @importClassesFrom S4Vectors DataFrame List\n    @importFrom S4Vectors DataFrame\n    @importFrom SummarizedExperiment colData assay assayNames\n    @exportMethod molecularProfiles\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_molecularProfiles(class_=.local_class, data_=.local_data)\nsetMethod(molecularProfiles, \"CoreSet\", function(object, mDataType, assay) {\n    funContext <- .funContext(paste0('::molecularProlfiles,', class(object), '-method'))\n    if (missing(mDataType) && missing(assay)) return(object@molecularProfiles)\n    if (mDataType %in% names(object@molecularProfiles)) {\n        if (!missing(assay)) {\n            if (assay %in% assayNames(object@molecularProfiles[[mDataType]])) {\n                return(SummarizedExperiment::assay(object@molecularProfiles[[mDataType]], assay))\n            } else {\n                .error(funContext, (paste('Assay', assay, 'not found in the SummarizedExperiment object!')))\n            }\n        } else {\n            return(SummarizedExperiment::assay(object@molecularProfiles[[mDataType]], 1))\n        }\n    } else {\n        stop(paste0('mDataType ', mDataType, ' not found the object!'))\n    }\n})\n\n#' @export\nsetGeneric(\"molecularProfiles<-\", function(object, mDataType, assay, value)\n    standardGeneric(\"molecularProfiles<-\"))\n\n#' @noRd\n.docs_CoreSet_set_molecularProfiles <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __molecularProfiles<-__: Update an assay in a `SummarizedExperiment` from\n    the `molecularProfiles` slot of a {class_} object with the specified\n    `mDataType`. Valid `mDataType` arguments can be found with\n    `mDataNames(object)`. Omit `mDataType` and `assay` to update the slot.\n    - assay: Optional `character(1)` vector specifying an assay in the\n    `SummarizedExperiment` of the `molecularProfiles` slot of the\n    `{class_}` object for the specified `mDataType`. If excluded,\n    defaults to modifying the first assay in the `SummarizedExperiment` for\n    the given `mDataType`.\n    - value: A `matrix` of values to assign to the `assay` slot of the\n    `SummarizedExperiment` for the selected `mDataType`. The rownames and\n    column names must match the associated `SummarizedExperiment`.\n    @examples\n    # No assay specified\n    molecularProfiles({data_}, 'rna') <- molecularProfiles({data_}, 'rna')\n\n    # Specific assay\n    molecularProfiles({data_}, 'rna', 'exprs') <-\n        molecularProfiles({data_}, 'rna', 'exprs')\n\n    # Replace the whole slot\n    molecularProfiles({data_}) <- molecularProfiles({data_})\n\n    @md\n    @aliases molecularProfiles<-,{class_},character,character,matrix-method\n    molecularProfiles<-,{class_},character,missing,matrix-method\n    molecularProfiles<-,{class_},missing,missing,list-method\n    molecularProfiles<-,{class_},missing,missing,MutliAssayExperiment-method\n    molecularProfiles<-\n    @importFrom SummarizedExperiment assay\n    @exportMethod molecularProfiles<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_molecularProfiles(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"molecularProfiles\", signature(object=\"CoreSet\",\n    mDataType =\"character\", assay=\"character\", value=\"matrix\"),\n    function(object, mDataType, assay, value)\n{\n    if (mDataType %in% names(object@molecularProfiles)) {\n        assay(object@molecularProfiles[[mDataType]], assay) <- value\n    }\n    object\n})\n#' @rdname CoreSet-accessors\nsetReplaceMethod(\"molecularProfiles\",\n    signature(object=\"CoreSet\", mDataType =\"character\", assay=\"missing\",\n        value=\"matrix\"), function(object, mDataType, assay, value)\n{\n    if (mDataType %in% names(object@molecularProfiles)) {\n        assay(object@molecularProfiles[[mDataType]], 1) <- value\n    }\n    object\n})\n#' @rdname CoreSet-accessors\nsetReplaceMethod(\"molecularProfiles\", signature(object=\"CoreSet\",\n        mDataType=\"missing\", assay=\"missing\", value=\"list_OR_MAE\"),\n        function(object, mDataType, assay, value) {\n    object@molecularProfiles <- value\n    object\n})\n\n\n##\n## == featureInfo\n\n\n#' @export\nsetGeneric(\"featureInfo\", function(object, mDataType, ...)\n    standardGeneric(\"featureInfo\"))\n\n#' @noRd\n.docs_CoreSet_get_featureInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __featureInfo__: Retrieve a `DataFrame` of feature metadata for the specified\n    `mDataType` from the `molecularProfiles` slot of a `{class_}` object. More\n    specifically, retrieve the `@rowData` slot from the `SummarizedExperiment`\n    from the `@molecularProfiles` of a `{class_}` object with the name\n    `mDataType`.\n    @examples\n    featureInfo({data_}, 'rna')\n\n    @md\n    @aliases featureInfo,{class_}-method featureInfo\n    @importFrom SummarizedExperiment rowData rowData<-\n    @exportMethod featureInfo\n    \",\n    ...\n)\n\n\n## FIXME: Why return NULL and not throw and error instead? Or at least a warning.\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_featureInfo(class_=.local_class, data_=.local_data)\nsetMethod(featureInfo, \"CoreSet\", function(object, mDataType) {\n    if (mDataType %in% names(object@molecularProfiles)) {\n        return(rowData(object@molecularProfiles[[mDataType]]))\n    } else{\n        return(NULL)\n    }\n})\n\n#' @export\nsetGeneric(\"featureInfo<-\", function(object, mDataType, value)\n    standardGeneric(\"featureInfo<-\"))\n\n#' @noRd\n.docs_CoreSet_set_featureInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __featureInfo<-__: Update the `featureInfo(object, mDataType)` `DataFrame`\n    with new feature metadata. Arguments:\n    - value: A `data.frame` or `DataFrame` with updated feature metadata for\n    the specified molecular profile in the `molecularProfiles` slot of a\n    `{class_}` object.\n    @examples\n    featureInfo({data_}, '{mDataType_}') <- featureInfo({data_}, '{mDataType_}')\n\n    @aliases featureInfo<-,{class_},character,data.frame-method\n    featureInfo<-,{class_},character,DataFrame-method featureInfo<-\n    @importFrom SummarizedExperiment rowData rowData<-\n    @importFrom S4Vectors DataFrame\n    @exportMethod featureInfo<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_featureInfo(class_=.local_class, data_=.local_data,\n#'   mDataType_='rna')\nsetReplaceMethod(\"featureInfo\", signature(object=\"CoreSet\",\n    mDataType =\"character\",value=\"data.frame\"),\n    function(object, mDataType, value)\n{\n    if (mDataType %in% names(object@molecularProfiles)) {\n        rowData(object@molecularProfiles[[mDataType]]) <-\n            DataFrame(value, rownames = rownames(value))\n    }\n    object\n})\nsetReplaceMethod(\"featureInfo\", signature(object=\"CoreSet\",\n    mDataType =\"character\",value=\"DataFrame\"),\n    function(object, mDataType, value)\n{\n    if (mDataType %in% names(object@molecularProfiles)) {\n        rowData(object@molecularProfiles[[mDataType]]) <-\n            DataFrame(value, rownames = rownames(value))\n    }\n    object\n})\n\n\n##\n## == phenoInfo\n\n\n#' @export\nsetGeneric(\"phenoInfo\", function(object, mDataType, ...)\n    standardGeneric(\"phenoInfo\"))\n\n#' @noRd\n.docs_CoreSet_get_phenoInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __phenoInfo__: Return the `@colData` slot from the `SummarizedExperiment` of\n    `mDataType`, containing sample-level metadata, from a `{class_}` object.\n\n    @examples\n    phenoInfo({data_}, '{mDataType_}')\n\n    @md\n    @importFrom SummarizedExperiment colData\n    @aliases phenoInfo\n    @exportMethod phenoInfo\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_phenoInfo(class_=.local_class, data_=.local_data, mDataType_='rna')\nsetMethod(phenoInfo, signature(object='CoreSet', mDataType='character'),\n    function(object, mDataType)\n{\n    if (mDataType %in% mDataNames(object)) { # Columns = Samples\n        return(colData(object@molecularProfiles[[mDataType]]))\n    }else{\n        ## FIXME:: Is there a reason we throw a NULL instead of an error?\n        return(NULL)\n    }\n})\n\n#' @export\nsetGeneric(\"phenoInfo<-\", function(object, mDataType, value)\n    standardGeneric(\"phenoInfo<-\"))\n\n#' @noRd\n.docs_CoreSet_set_phenoInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __phenoInfo<-__: Update the `@colData` slot of the `SummarizedExperiment`\n    of `mDataType` in the `@molecularProfiles` slot of a `{class_}` object.\n    This updates the sample-level metadata in-place.\n    - value: A `data.frame` or `DataFrame` object where rows are samples\n    and columns are sample metadata.\n\n    @examples\n    phenoInfo({data_}, '{mDataType_}') <- phenoInfo({data_}, '{mDataType_}')\n\n    @md\n    @importFrom SummarizedExperiment colData colData<-\n    @importFrom S4Vectors DataFrame\n    @aliases phenoInfo<-,{class_},character,data.frame-method\n    phenoInfo<-,{class_},character,DataFrame-method phenoInfo<-\n    @exportMethod phenoInfo<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_phenoInfo(class_=.local_class, data_=.local_data, mDataType_='rna')\nsetReplaceMethod(\"phenoInfo\", signature(object=\"CoreSet\", mDataType =\"character\",\n    value=\"data.frame\"), function(object, mDataType, value)\n{\n    if(mDataType %in% mDataNames(object)) {\n        colData(object@molecularProfiles[[mDataType]]) <-\n            DataFrame(value, rownames = rownames(value))\n    }\n    object\n})\nsetReplaceMethod(\"phenoInfo\", signature(object=\"CoreSet\",\n    mDataType =\"character\", value=\"DataFrame\"),\n    function(object, mDataType, value)\n{\n    if (mDataType %in% mDataNames(object)) {\n        colData(object@molecularProfiles[[mDataType]]) <- value\n    }\n    object\n})\n\n\n##\n## == fNames\n\n#' @export\nsetGeneric('fNames', function(object, mDataType, ...) standardGeneric('fNames'))\n\n#' @noRd\n.docs_CoreSet_get_fNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __fNames__: `character()` The features names from the `rowData` slot of a\n    `SummarizedExperiment` of `mDataType` within a `{class_}` object.\n\n    @examples\n    fNames({data_}, '{mDataType_}')\n\n    @md\n    @aliases fNames,{class_},character-method fNames\n    @exportMethod fNames\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_fNames(class_=.local_class, data_=.local_data,\n#' mDataType_='rna')\nsetMethod('fNames', signature(object='CoreSet', mDataType='character'),\n    function(object, mDataType)\n{\n    rownames(featureInfo(object, mDataType))\n})\n\n\n#' @export\nsetGeneric('fNames<-', function(object, mDataType, ..., value)\n    standardGeneric('fNames<-'))\n\n#' @noRd\n.docs_CoreSet_set_fNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __fNames__: Updates the rownames of the feature metadata (i.e., `rowData`)\n    for a `SummarizedExperiment` of `mDataType` within a `{class_}` object.\n    - value: `character()` A character vector of new features names for the\n    `rowData` of the `SummarizedExperiment` of `mDataType` in the\n    `@molecularProfiles` slot of a `{class_}` object. Must be the same\n    length as `nrow(featureInfo(object, mDataType))`,\n    the number of rows in the feature metadata.\n\n    @examples\n    fNames({data_}, '{mDataType_}') <- fNames({data_}, '{mDataType_}')\n\n    @md\n    @aliases fNames<-,{class_},character,character-method fNames<-\n    @exportMethod fNames<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_fNames(class_=.local_class, data_=.local_data,\n#' mDataType_='rna')\nsetReplaceMethod('fNames', signature(object='CoreSet', mDataType='character',\n    value='character'), function(object, mDataType, value)\n{\n    rownames(featureInfo(object, mDataType)) <- value\n    object\n})\n\n\n##\n## == mDataNames\n\n\n#' @export\nsetGeneric(\"mDataNames\", function(object, ...) standardGeneric(\"mDataNames\"))\n\n#' @noRd\n.docs_CoreSet_get_mDataNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __mDataNames__: `character` Retrieve the names of the molecular data types\n    available in the `molecularProfiles` slot of a `{class_}` object. These\n    are the options which can be used in the `mDataType` parameter of various\n    `molecularProfiles` slot accessors methods.\n    @examples\n    mDataNames({data_})\n\n    @md\n    @aliases mDataNames,{class_}-method mDataNames\n    @exportMethod mDataNames\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_mDataNames(class_=.local_class, data_=.local_data)\nsetMethod(\"mDataNames\", \"CoreSet\", function(object) {\n    return(names(object@molecularProfiles))\n})\n\n\n#' @export\nsetGeneric(\"mDataNames<-\", function(object, ..., value) standardGeneric(\"mDataNames<-\"))\n\n#' @noRd\n.docs_CoreSet_set_mDataNames <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __mDataNames__: Update the molecular data type names of the\n    `molecularProfiles` slot of a {class_} object. Arguments:\n    - value: `character` vector of molecular datatype names, with length\n    equal to `length(molecularProfilesSlot(object))`.\n    @examples\n    mDataNames({data_}) <- mDataNames({data_})\n\n    @md\n    @aliases mDataNames<-,{class_},ANY-method mDataNames<-\n    @exportMethod mDataNames<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_mDataNames(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"mDataNames\", \"CoreSet\", function(object, value) {\n    names(object@molecularProfiles) <- value\n    return(object)\n})\n\n##\n## == molecularProfilesSlot\n\n\n#' @export\nsetGeneric(\"molecularProfilesSlot\", function(object, ...)\n    standardGeneric(\"molecularProfilesSlot\"))\n\n#' @noRd\n.docs_CoreSet_get_molecularProfilesSlot <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __molecularProfilesSlot__: Return the contents of the `@molecularProfiles`\n    slot of a `{class_}` object. This will either be a `list` or\n    `MultiAssayExperiment` of `SummarizedExperiment`s.\n\n    @examples\n    molecularProfilesSlot({data_})\n\n    @md\n    @aliases moleculerProfilesSlot,{class_}-method molecularProfilesSlot\n    @exportMethod molecularProfilesSlot\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_molecularProfilesSlot(class_=.local_class, data_=.local_data)\nsetMethod(\"molecularProfilesSlot\", signature(\"CoreSet\"), function(object) {\n    object@molecularProfiles\n})\n\n\n#' @export\nsetGeneric(\"molecularProfilesSlot<-\",\n    function(object, value) standardGeneric(\"molecularProfilesSlot<-\"))\n\n#' @noRd\n.docs_CoreSet_set_molecularProfilesSlot <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __molecularProfilesSlot<-__: Update the contents of the `@molecularProfiles`\n    slot of a `{class_}` object. Arguemnts:\n    - value: A `list` or `MultiAssayExperiment` of `SummarizedExperiment`s. The\n    `list` and `assays` should be named for the molecular datatype in each\n    `SummarizedExperiment`.\n\n    @examples\n    molecularProfilesSlot({data_}) <- molecularProfilesSlot({data_})\n\n    @md\n    @aliases molecularProfilesSlot<-,{class_},list-method\n    molecularProfilesSlot<-{class_},MultiAssayExperiment-method\n    molecularProfilesSlot<-\n    @exportMethod molecularProfilesSlot<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_molecularProfilesSlot(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"molecularProfilesSlot\", signature(\"CoreSet\", \"list_OR_MAE\"),\n    function(object, value) {\n    # funContext <- .S4MethodContext('molecularProfilesSlot<-', class(object),\n    #     class(value))\n    # if (!is(value, class(object@molecularProfiles)[1])) .error(funContext,\n    #     'The class of value must be the same as the current @molecularProfiles!')\n    object@molecularProfiles <- value\n    object\n})\n\n\n## ---------------------\n## ---- sensitivity slot\n\n\n#\n# == sensitivityInfo\n\n#' @noRd\n.docs_CoreSet_get_sensitivityInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    ## @treatmentResponse\n\n    ### Arguments:\n    - `dimension`: Optional `character(1)` One of 'treatment', 'sample' or\n    'assay' to retrieve `rowData`, `colData` or the 'assay_metadata' assay from\n    the `{class_}` `@sensitvity` `LongTable` object, respectively. Ignored with\n    warning if `@treatmentResponse` is not a `LongTable` object.\n    -  `...`: Additional arguments to the `rowData` or `colData`.\n    `LongTable` methods. Only used if the sensitivity slot contains a\n    `LongTable` object instead of a `list` and the `dimension` argument is\n    specified.\n\n    ### Methods:\n\n    __sensitivityInfo__: `DataFrame` or `data.frame` of sensitivity treatment combo\n    by sample metadata for the `{class_}` object. When the `dimension`\n    parameter is used, it allows retrieval of the dimension specific metadata\n    from the `LongTable` object in `@treatmentResponse` of a {class_} object.\n\n    @examples\n    sensitivityInfo({data_})\n\n    @md\n    @aliases sensitivityInfo,{class_},missing-method\n    sensitivityInfo,{class_},character-method\n    @exportMethod sensitivityInfo\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sensitivityInfo(class_=.local_class,\n#' data_=.local_data)\nsetMethod(sensitivityInfo, signature(\"CoreSet\"),\n        function(object, dimension, ...) {\n    funContext <- .funContext('::sensitivityInfo')\n    # case where sensitivity slot is a LongTable\n    if (is(treatmentResponse(object), 'LongTable')) {\n        if (!missing(dimension)) {\n            switch(dimension,\n                sample={ return(colData(treatmentResponse(object), ...)) },\n                treatment={ return(rowData(treatmentResponse(object), ...)) },\n                assay={ return(assay(treatmentResponse(object), 'assay_metadata')) },\n                .error(funContext, 'Invalid value for the dimension argument.\n                    Please select on of \"sample\", \"treatment\" or \"assay'))\n        } else {\n            return(.rebuildInfo(treatmentResponse(object)))\n        }\n    # sensitivity is a list\n    } else {\n        if (!missing(dimension))\n            .warning(funContext,' The dimension argument is only valid if the\n                sensitivity slot contains a LongTable object. Ignoring the\n                dimension and ... parameters.')\n        return(treatmentResponse(object)$info)\n    }\n})\n\n\n#' Replicate the $info slot in the old sensitivity list from the new LongTable\n#'   object\n#'\n#' @param longTable `LongTable`\n#'\n#' @keywords internal\n#' @importFrom MatrixGenerics colAlls\n#' @importFrom data.table setkeyv merge.data.table `:=` setDF\n#' @noRd\n.rebuildInfo <- function(longTable) {\n\n    # Extract the information needed to reconstruct the sensitivityInfo\n    #   data.frame\n    aidx <- which(assayNames(longTable) %in% \"assay_metadata\")\n    if (!length(aidx)) aidx <- 1\n    assayIndexDT <- assay(longTable, aidx, key=TRUE)\n    if (aidx == 1) assayIndexDT <- assayIndexDT[, .(rowKey, colKey)]\n    setkeyv(assayIndexDT, c('rowKey', 'colKey'))\n    rowDataDT <- rowData(longTable, key=TRUE)\n    setkeyv(rowDataDT, 'rowKey')\n    colDataDT <- colData(longTable, key=TRUE)\n    setkeyv(colDataDT, 'colKey')\n\n    rowIDcols <- rowIDs(longTable)[!grepl('dose$', rowIDs(longTable))]\n    colIDcols <- colIDs(longTable)\n    rownameCols <- c(rowIDcols, colIDcols)\n\n    # join the tables into the original data\n    infoDT <- merge.data.table(assayIndexDT, rowDataDT, all.x=TRUE)\n    setkeyv(infoDT, 'colKey')\n    infoDT <- merge.data.table(infoDT, colDataDT, all.x=TRUE)[,\n        -c('rowKey', 'colKey')\n    ]\n    infoDT <- tryCatch({\n        infoDT[, .SD, .SDcols=!patterns('treatment.*dose$')]\n    }, error=function(e) infoDT)\n\n    # determine which columns map 1:1 with new identifiers and subset to those\n    infoDT_first <- infoDT[, head(.SD, 1), by=rownameCols]\n    infoDT_last <- infoDT[, tail(.SD, 1), by=rownameCols]\n    keepCols <- colnames(infoDT_first)[\n        colAlls(infoDT_first == infoDT_last, na.rm=TRUE)\n        ]\n    infoDT_sub <- unique(infoDT[, ..keepCols])\n\n    # pad the dropped NA values, if they exists\n    if (\"sensitiivtyInfo_NA\" %in% names(metadata(longTable))) {\n            na_info <- copy(metadata(longTable)$sensitivityInfo_NA)\n        setnames(na_info, \"treatmentid\", \"treatment1id\")\n        na_info <- cbind(\n            na_info,\n            unique(infoDT_sub[, .SD, .SDcols=!patterns(\"^treatment1id$|^sampleid$|^replicate_id$|^rn$\")])\n        )\n        na_info[, replicate_id := seq_len(.N), by=.(treatment1id, sampleid)]\n        infoDT_sub <- rbind(infoDT_sub, na_info)\n    }\n    if (\"experiment_metadata\" %in% names(metadata(longTable))) {\n        infoDT_sub <- cbind(\n            infoDT_sub,\n            as.data.table(metadata(longTable)$experiment_metadata)\n        )\n    }\n\n    # rebuild the rownames\n    idCols <- grep(\"^treatment[0-9]*id\", colnames(infoDT_sub), value=TRUE)\n    infoDT_sub[, treatmentid := Reduce(.paste_slashes, mget(..idCols))]\n    infoDT_sub[, treatment_uid := Reduce(.paste_colon, mget(..rowIDcols))]\n    infoDT_sub[, sample_uid := Reduce(.paste_colon, mget(..colIDcols))]\n    infoDT_sub[, exp_id := Reduce(.paste_, .(treatment_uid, sample_uid))]\n\n    # convert to data.frame\n    setDF(infoDT_sub, rownames=infoDT_sub$exp_id)\n    return(infoDT_sub)\n}\n\n#' @noRd\n.docs_CoreSet_set_sensitivityInfo <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    __sensitivityInfo__<-: Update the `@treatmentResponse` slot metadata for a\n    `{class_}` object. When used without the `dimension` argument is behaves\n    similar to the old {class_} implementation, where the `@treatmentResponse` slot\n    contained a list with a `$info` `data.frame` item. When the `dimension`\n    arugment is used, more complicated assignments can occur where 'sample'\n    modifies the `@sensitvity` `LongTable` colData, 'treatment' the rowData and\n    'assay' the 'assay_metadata' assay.\n    Arguments:\n    - value: A `data.frame` of treatment response experiment metadata,\n    documenting experiment level metadata (mapping to treatments and samples). If\n    the `@treatmentResponse` slot doesn't contain a `LongTable` and `dimension` is\n    not specified, you can only modify existing columns as returned by\n    `sensitivityInfo(object)`.\n    @examples\n    sensitivityInfo({data_}) <- sensitivityInfo({data_})\n\n    @md\n    @aliases sensitivityInfo<-,{class_},missing,data.frame-method\n    sensitvityInfo<-,{class_},character,data.frame-method\n    @import data.table\n    @exportMethod sensitivityInfo<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sensitivityInfo(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"sensitivityInfo\", signature(object=\"CoreSet\", value=\"data.frame\"),\n                function(object, dimension, ..., value) {\n\n    funContext <- .funContext('::sensitivityInfo<-')\n    if (is(treatmentResponse(object), 'LongTable')) {\n        # coerce to data.table\n        if (!is.data.table(value)) value <- data.table(value)\n        if (missing(dimension)) {\n            valueCols <- colnames(value)\n            # get existing column names\n            rowDataCols <- colnames(rowData(object@treatmentResponse))\n            colDataCols <- colnames(colData(object@treatmentResponse))\n            # drop any value columns that don't already exist\n            hasValueCols <- valueCols %in% c(rowDataCols, colDataCols)\n            if (!all(hasValueCols))\n                .message(funContext, 'Dropping columns ',\n                    .collapse(valueCols[!hasValueCols]), ' from value. Currently\n                    this setter only allows modifying existing columns when\n                    @treatmentResponse is a LongTable. For more fine grained updates\n                    please use the dimension argument.')\n            # update the object\n            rowData(object@treatmentResponse, ...) <-\n                unique(value[, .SD, .SDcols=valueCols %in% rowDataCols])\n            colData(object@treatmentResponse, ...) <-\n                unique(value[, .SD, .SDcols=valueCols %in% colDataCols])\n        } else {\n            switch(dimension,\n                treatment={ rowData(object@treatmentResponse, ...) <- value },\n                sample={ colData(object@treatmentResponse, ...) <- value },\n                assay={ assay(object@treatmentResponse, 'assay_metadata') <- value },\n                .error(funContext, 'Invalid argument to dimension parameter.\n                    Please choose one of \"sample\", \"treatment\" or \"assay\"'))\n        }\n    } else {\n        if (!missing(dimension))\n            .warning(funContext, 'The dimension argument is only valid if the\n                sensitivity slot contains a LongTable object. Ignoring dimension\n                and ... parameters.')\n        object@treatmentResponse$info <- value\n    }\n    return(object)\n})\n\n\n#\n# == sensitvityMeasures\n\n\n#' @noRd\n.docs_CoreSet_get_sensitivityMeasures <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensitivityMeaures__: Get the 'sensitivityMeasures' available in a `{class_}`\n    object. Each measure reprents some summary of sample sensitivity to a given\n    treatment, such as ic50, ec50, AUC, AAC, etc. The results are returned as a\n    `character` vector with all available metrics for the PSet object.\n    @examples\n    sensitivityMeasures({data_}) <- sensitivityMeasures({data_})\n\n    @md\n    @exportMethod sensitivityMeasures\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sensitivityMeasures(class_=.local_class, data_=.local_data)\nsetMethod(sensitivityMeasures, \"CoreSet\", function(object) {\n    return(colnames(sensitivityProfiles(object)))\n})\n\n#' @noRd\n.docs_CoreSet_set_sensitityMeasures <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensitivityMeaures__: Update the sensitivity meaure in a `{class_}`\n    object. Thesee values are the column names of the 'profiles' assay and\n    represent various compued sensitviity metrics such as ic50, ec50, AUC, AAC,\n    etc.\n    - value: A `character` vector of new sensitivity measure names, the\n    then length of the character vector must matcht he number of columns of the\n    'profiles' assay, excluding metadata and key columns.\n    @examples\n    sensitivityMeasures({data_}) <- sensitivityMeasures({data_})\n\n    @md\n    @exportMethod sensitivityMeasures\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sensitityMeasures(class_=.local_class, data_=.local_data)\nsetReplaceMethod('sensitivityMeasures',\n    signature(object='CoreSet', value='character'),\n    function(object, value)\n{\n    colnames(sensitivityProfiles(object)) <- value\n    object\n})\n\n\n#\n# == sensitivityProfiles\n\n\n#' @noRd\n.docs_CoreSet_get_sensitivityProfiles <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensitivityProfiles__: Return the sensitivity profile summaries from the\n    sensitivity slot. This data.frame cotanins vaarious sensitivity summary\n    metrics, such as ic50, amax, EC50, aac, HS, etc as columns, with rows as\n    treatment by sample experiments.\n    @examples\n    sensitivityProfiles({data_})\n\n    @md\n    @exportMethod sensitivityProfiles\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sensitivityProfiles(class_=.local_class, data_=.local_data)\nsetMethod(sensitivityProfiles, \"CoreSet\", function(object) {\n    funContext <- .funContext('::sensitivityProfiles')\n    if (is(treatmentResponse(object), 'LongTable')) {\n        if (!('profiles' %in% assayNames(treatmentResponse(object)))) {\n            .error(funContext, 'The LongTable object in the sensivitiy slot\n                is not formatted correctly: it must contain an assay\n                named \"profiles\"!')\n        } else {\n            .rebuildProfiles(treatmentResponse(object))\n        }\n    } else {\n        return(object@treatmentResponse$profiles)\n    }\n})\n\n#' @keywords internal\n.rebuildProfiles <- function(object) {\n    profDT <- object$profiles\n    rowCols <- lapply(rowIDs(object)[\n        !grepl(\"treatment[0-9]*dose|drug[0-9]*dose\", rowIDs(object))\n    ], as.name)\n    colCols <- lapply(colIDs(object), as.name)\n    trt <- bquote(paste(..(rowCols), sep=\":\"), splice=TRUE)\n    smp <- bquote(paste(..(colCols), sep=\":\"), splice=TRUE)\n    profDT[, treatment_uid := eval(trt), by=.I]\n    profDT[, sample_uid := eval(smp), by=.I]\n    profDT[, exp_id := paste0(treatment_uid, \"_\", sample_uid), by=.I]\n    assayCols <- setdiff(colnames(assay(object, \"profiles\", raw=TRUE)), \".profiles\")\n    sensProf <- unique(profDT[, .SD, .SDcols=c(assayCols, \"exp_id\")])\n    obsPerExpId <- sensProf[, .N, by=\"exp_id\"][, max(N)]\n    if (obsPerExpId > 1) warning(.warnMsg(\"Multiple profile values per\",\n        \" experiment id, summarizing with mean!\"), call.=FALSE)\n    sensProf <- sensProf[, lapply(.SD, mean, na.rm=TRUE), by=\"exp_id\"]\n    return(sensProf)\n}\n\n#' @noRd\n.docs_CoreSet_set_sensitivityProfiles <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensitivityProfiles<-__: Update the sensitivity profile summaries the\n    sensitivity slot. Arguments:\n    -value: A `data.frame` the the same number of rows as as returned by\n    `sensitivityProfiles(object)`, but potentially modified columns, such as the\n    computation of additional summary metrics.\n    @examples\n    sensitivityProfiles({data_}) <- sensitivityProfiles({data_})\n\n    @md\n    @exportMethod sensitivityProfiles<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sensitivityProfiles(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"sensitivityProfiles\",\n    signature(object=\"CoreSet\", value=\"data.frame\"),\n    function(object, value)\n{\n    if (is(treatmentResponse(object), 'LongTable'))\n        warning(.warnMsg(\"The \", class(object)[1], \" class structure has been\",\n            \" updated! Assignment via sensitivityProfiles no long works, please\",\n            \" see vignette('The LongTable Class', package='CoreGx') for more\",\n            \" information.\"))\n    else\n        object@treatmentResponse$profiles <- value\n    return(object)\n})\n\n\n#\n# == sensitivityRaw\n\n\n#' @noRd\n.docs_CoreSet_get_sensitivityRaw <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensitivityRaw__: Access the raw sensitiity measurents for a {class_}\n    object. A 3D `array` where rows are experiment_ids, columns are doses\n    and the third dimension is metric, either 'Dose' for the doses used or\n    'Viability' for the sample viability at that dose.\n    @examples\n    head(sensitivityRaw({data_}))\n\n    @md\n    @exportMethod sensitivityRaw\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sensitivityRaw(class_=.local_class, data_=.local_data)\nsetMethod(\"sensitivityRaw\", signature(\"CoreSet\"), function(object) {\n    if (is(treatmentResponse(object), 'LongTable'))\n        return(.rebuildRaw(treatmentResponse(object)))\n    else\n        return(object@treatmentResponse$raw)\n})\n\n#' Replicate the $raw slot in the old @treatmentResponse list from a LongTable\n#'\n#' @param longTable `LongTable`\n#'\n#' @return A 3D `array` where rows are experiment_ids, columns are doses\n#' and the third dimension is metric, either 'Dose' for the doses used or\n#' 'Viability' for the sample viability at that dose.\n#'\n#' @keywords internal\n#' @importFrom data.table merge.data.table dcast\n#' @noRd\n.rebuildRaw <- function(longTable) {\n\n    ## TODO:: This function currently assumes there will only be one valid\n    ## dose per treatment combination, which may not be true.\n\n    funContext <- .funContext(':::.rebuildRaw')\n    if (!('sensitivity' %in% assayNames(longTable)))\n        .error(funContext, 'There is no assay named sensitivity. Not sure\n            how to retrieve sensitivityRaw without a sensitivity assay. Try\n            renaming your assays in the @treatmentResponse LongTable object?')\n\n    # Extract the information needed to reconstruct the sensitivityRaw array\n    viability <- longTable$sensitivity\n\n    # Early return for single treatment sensitivity experimentss\n    ## TODO:: refactor this into a helper?\n    if ('assay_metadata' %in% assayNames(longTable) &&\n        'old_column' %in% colnames(longTable$assay_metadata))\n    {\n        metadataDT <- copy(longTable$assay_metadata)\n        sensitivityDT <- copy(longTable$sensitivity)\n        # .NATURAL joins on all identical columns\n        assayDT <- metadataDT[sensitivityDT, on=.NATURAL]\n        if (length(colIDs(longTable)) > 1) {\n            assayDT[, sampleid := Reduce(.paste_colon, mget(colIDs(longTable)))]\n        }\n        assayDT[, exp_id := paste0(treatment1id, '_', sampleid)]\n        .mean <- function(x) mean(as.numeric(x), na.rm=TRUE)\n        doseDT <- dcast(assayDT, exp_id ~ old_column, value.var='treatment1dose',\n            fun.aggregate=.mean)\n        viabDT <- dcast(assayDT, exp_id ~ old_column, value.var='viability',\n            fun.aggregate=.mean)\n        sensRaw <- array(dim=list(nrow(doseDT), ncol(doseDT) -1, 2),\n            dimnames=list(doseDT$exp_id, colnames(doseDT)[-1],\n                c('Dose', 'Viability')))\n        sensRaw[, , 'Dose'] <- as.matrix(doseDT[, !'exp_id'])\n        sensRaw[, , 'Viability'] <- as.matrix(viabDT[, !'exp_id'])\n        return(sensRaw)\n    }\n\n    # Build the rownames\n    .paste_colons <- function(...) paste(..., sep=':')\n    # viability[, row_ids := Reduce(.paste_colons, mget(rowIDs(longTable)))]\n    # viability[, col_ids := Reduce(.paste_colons, mget(colIDs(longTable)))]\n    # viability[, rownames := paste0(row_ids, '_', col_ids)]\n    # viability[, c('row_ids', 'col_ids') := NULL]\n\n    viability[, rownames := {\n        row_ids <- Reduce(.paste_colons, mget(rowIDs(longTable)))\n        col_ids <- Reduce(.paste_colons, mget(colIDs(longTable)))\n        paste0(row_ids, '_', col_ids)\n    }]\n\n    # Merge the doses into vectors in a list column\n    viability[, dose := Reduce(.paste_slashes, mget(colnames(.SD))),\n        .SDcols=patterns('^.*[d|D]ose$')]\n\n    # Repeat the dose values if there are more viabilities\n    numReplicates <- viability[, ncol(.SD), .SDcols=patterns('^[V|v]iability.*')]\n    if (numReplicates > 1) {\n        viability[, paste0('dose', seq_len(numReplicates)) := dose]\n        viability[, dose := NULL]\n    }\n\n    # Build the array\n    sensRaw <- array(dim=list(nrow(viability), numReplicates, 2),\n        dimnames=list(viability$rownames, paste0('dose', seq_len(numReplicates)),\n            c('Dose', 'Viability')))\n    sensRaw[, , 'Dose'] <- as.matrix(viability[, .SD,\n        .SDcols=patterns('^dose.*')])\n    sensRaw[, , 'Viability'] <- as.matrix(viability[, .SD,\n        .SDcols=patterns('^[V|v]iability.*')])\n\n    return(sensRaw)\n}\n\n#' @noRd\n.docs_CoreSet_set_sensitivityRaw <- function(...) .parseToRoxygen(\n    \"\n    @details\n\n    __sensitvityRaw<-__: Update the raw dose and viability data in a `{class_}`.\n    - value: A 3D `array` object where rows are experiment_ids, columns are\n    replicates and pages are c('Dose', 'Viability'), with the corresponding\n    dose or viability measurement for that experiment_id and replicate.\n\n    @examples\n    sensitivityRaw({data_}) <- sensitivityRaw({data_})\n\n    @md\n    @importFrom data.table data.table as.data.table := merge.data.table tstrsplit\n    @exportMethod sensitivityRaw<-\n    \"\n    ,\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sensitivityRaw(class_=.local_class, data_=.local_data)\nsetReplaceMethod('sensitivityRaw', signature(\"CoreSet\", \"array\"),\n    function(object, value)\n{\n    funContext <- .funContext(\"::sensitivityRaw<-\")\n    if (is(treatmentResponse(object), 'LongTable')) {\n\n        ## TODO:: validate value\n        tre <- treatmentResponse(object)\n\n        viabilityCols <- assayCols(tre, \"sensitivity\")\n        # Handle the non-treatment combo case\n        if (length(viabilityCols) != ncol(value)) {\n            valueDT <- as.data.table(value)\n            valueDT <- dcast(valueDT, V1 + V2 ~ V3, value.var='value')\n            setnames(valueDT, old=c('Dose', 'Viability'),\n                new=c('treatment1dose', 'viability'))\n            valueDT[, V2 := NULL]  # delete the array column names\n            valueDT[, (idCols(tre)) := tstrsplit(V1, ':|_', type.convert=TRUE)]\n            valueDT[, V1 := NULL]\n            assay(tre, i='sensitivity') <- valueDT\n        } else {\n            # Process into a the proper format for the sensitivity assay\n            # NOTE: as.matrix deals with the case where there is only a single\n            #   viability column in the sensitivityRaw array object,\n            #   in which case the drop=TRUE argument causes a vector to be\n            #   returned\n            raw <- as.data.table(as.matrix(value[, , 'Viability']),\n                keep.rownames='rn', na.rm=FALSE)\n            coerceCols <- colnames(raw)[-1]\n            raw[, (coerceCols) := lapply(.SD, as.numeric), .SDcols=!'rn']\n            raw[, (idCols(tre)) := tstrsplit(rn, ':|_', type.convert=TRUE)]\n            raw[, c('rn') := NULL]\n            colnames(raw) <- gsub('^dose\\\\d*|^V\\\\d*', 'viability', colnames(raw))\n            # Update the assay\n            assay(tre, i='sensitivity') <- raw\n        }\n\n        # Update the object\n        treatmentResponse(object) <- tre\n    } else {\n        object@treatmentResponse$raw <- value\n        object\n    }\n    return(object)\n})\n\n\n#\n# == sensitivitySlot\n\n\n#' @export\nsetGeneric(\"treatmentResponse\", function(object, ...) standardGeneric(\"treatmentResponse\"))\n\n#' @noRd\n.docs_CoreSet_get_treatmentResponse <- function(...) .parseToRoxygen(\n    \"\n    __treatmentResponse__: Retrive the contents of `@treatmentResponse` from a `{class_}`\n    object.\n\n    @examples\n    treatmentResponse({data_})\n\n    @md\n    @aliases treatmentResponse,{class_}-method treatmentResponse\n    @aliases sensitivitySlot\n    @exportMethod treatmentResponse\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_treatmentResponse(class_=.local_class,\n#'   data_=.local_data)\nsetMethod(\"treatmentResponse\", signature(\"CoreSet\"), function(object) {\n    object@treatmentResponse\n})\n#' @export\nsensitivitySlot <- function(...) treatmentResponse(...)\n\n\n#' @export\nsetGeneric(\"treatmentResponse<-\", function(object, ..., value)\n    standardGeneric(\"treatmentResponse<-\"))\n\n.docs_CoreSet_set_treatmentResponse <- function(...) .parseToRoxygen(\n    \"\n    __treatmentResponse<-__: Assign data to the `@treatmentResponse` slot of a\n    `{class_}` object.\n    - value: Either a `TreatmentResponseExperiment` class object, or a list with\n    an 'info' `data.frame` of experiment metadata, 'profiles' `data.frame` with\n    summary statistics from the sensitivity experiment and a 'raw' 3D array\n    where rows are experiments, columns are replicates and pages are 'Dose'\n    or 'Viability' containing their respective values for that treatment by sample\n    experiment. The type of `value` must match type of the current `@treatmentResponse`\n    slot of the `{class_}` object.\n\n    @examples\n    treatmentResponse({data_}) <- treatmentResponse({data_})\n\n    @md\n    @aliases treatmentResponse<- treamentResponse<-,{class_},list-method\n    treatmentResponse<-,{class_},LongTable-method\n    @aliases sensitivitySlot<-\n    @exportMethod treatmentResponse<-\n    \",\n    ...\n)\n\n\n#' @rdname CoreSet-accessors\n#' @include LongTable-class.R\n#' @eval .docs_CoreSet_set_treatmentResponse(class_=.local_class, data_=.local_data)\nsetReplaceMethod(\"treatmentResponse\", signature(object=\"CoreSet\", value=\"list_OR_LongTable\"),\n    function(object, value)\n{\n    # funContext <- .S4MethodContext('sensitivitySlot<-', class(object), class(value))\n    # ## TODO:: Maybe try coercing the list to a LongTable and vice versa?\n    if (!is(object@treatmentResponse, class(value)[1])) .error(funContext, 'The types\n        of the current and @treatmentResponse slot and the value parameter must be\n        the same!')\n    object@treatmentResponse <- value\n    return(object)\n})\n#' @export\n`sensitivitySlot<-` <- function(..., value) `treatmentResponse<-`(..., value=value)\n\n\n##\n## == sensNumber\n\n\n#' @export\nsetGeneric(\"sensNumber\", function(object, ...) standardGeneric(\"sensNumber\"))\n\n#' @noRd\n.docs_CoreSet_get_sensNumber <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensNumber__: Return a count of viability observations in a `{class_}`\n    object for each treatment-combo by sample combination.\n\n    @examples\n    sensNumber({data_})\n\n    @md\n    @aliases sensNumber\n    @exportMethod sensNumber\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_sensNumber(class_=.local_class, data_=.local_data)\nsetMethod(sensNumber, \"CoreSet\", function(object){\n    return(\n        if (is(object@treatmentResponse, 'LongTable'))\n            .rebuildSensNumber(object@treatmentResponse)\n        else\n            object@treatmentResponse$n\n    )\n})\n\n.rebuildSensNumber <- function(object) {\n    sensitivityDT <- object$sensitivity\n    # Melt replicates so they get counted\n    sensitivityDT_melted <- melt(sensitivityDT,\n        measure=patterns('^viability'), variable.name='replicate',\n        value.name='viability')\n\n    # Determine the treatment and sample combos, ignoring other identifiers\n    .paste_colon <- function(x, y) paste(x, y, sep=':')\n    treatmentidCols <- sensitivityDT[, colnames(.SD), .SDcols=patterns('treatment.*id')]\n    sampleidCols <- sensitivityDT[, colnames(.SD), .SDcols=patterns('sample.*id')]\n\n    # Parse the columns to dcast by to get the counts\n    sensitivityDT_melted[, .treatmentCombo := Reduce(.paste_colon, mget(treatmentidCols))]\n    sensitivityDT_melted[, .sampleCombo := Reduce(.paste_colon, mget(sampleidCols))]\n\n    # Count existing sensitivity measurements\n    .count_not_NA <- function(x) sum(!is.na(x))\n    sensNumbDT <- dcast(sensitivityDT_melted, .treatmentCombo ~ .sampleCombo,\n        value.var='viability', fun.aggregate=.count_not_NA)\n    sensNumberM <- as.matrix(sensNumbDT[, !'.treatmentCombo'])\n    rownames(sensNumberM) <- sensNumbDT[['.treatmentCombo']]\n\n    return(sensNumberM)\n\n    ## TODO:: Pad for any missing treatments or samples\n    allDrugCombos <- rowData(object)[, Reduce(.paste_colon, mget(treatmentidCols))]\n    allSampleCombos <- colData(object)[, Reduce(.paste_colon, mget(sampleidCols))]\n\n}\n\n#' @export\nsetGeneric(\"sensNumber<-\", function(object, value) standardGeneric(\"sensNumber<-\"))\n\n#' @noRd\n.docs_CoreSet_set_sensNumber <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __sensNumber<-__: Update the 'n' item, which holds a matrix with a count\n    of treatment by sample-line experiment counts, in the `list` in `@treatmentResponse`\n    slot of a `{class_}` object. Will error when `@sensitviity` contains\n    a `LongTable` object, since the counts are computed on the fly. Arguments:\n    - value: A `matrix` where rows are samples and columns are treatments, with a\n    count of the number of experiments for each combination as the values.\n\n    @examples\n    sensNumber({data_}) <- sensNumber({data_})\n\n    @md\n    @aliases sensNumber<-\n    @exportMethod sensNumber<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_sensNumber(class_=.local_class, data_=.local_data)\nsetReplaceMethod('sensNumber', signature(object=\"CoreSet\", value=\"matrix\"),\n    function(object, value)\n{\n    if (is(treatmentResponse(object), 'LongTable')) {\n        object\n    } else {\n        object@treatmentResponse$n <- value\n        object\n    }\n})\n\n\n## ======================\n## ---- perturbation slot\n\n##\n## == pertNumber\n\n\n#' @export\nsetGeneric(\"pertNumber\", function(object, ...) standardGeneric(\"pertNumber\"))\n\n#' @noRd\n.docs_CoreSet_get_pertNumber <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __pertNumber__: `array` Summary of available perturbation experiments\n    from in a `{class_}` object. Returns a 3D `array` with the number of\n    perturbation experiments per treatment and sample, and data type.\n\n    @examples\n    pertNumber({data_})\n\n    @md\n    @aliases pertNumber\n    @exportMethod pertNumber\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_get_pertNumber(class_=.local_class, data_=.local_data)\nsetMethod(pertNumber, \"CoreSet\", function(object){\n    return(object@perturbation$n)\n})\n\n#' @export\nsetGeneric(\"pertNumber<-\", function(object, value) standardGeneric(\"pertNumber<-\"))\n\n.docs_CoreSet_set_pertNumber <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __pertNumber<-__: Update the `@perturbation$n` value in a `{class_}` object,\n    which stores a summary of the available perturbation experiments. Arguments:\n    - value: A new 3D `array` with the number of perturbation experiments per\n    treatment and sample, and data type\n\n    @examples\n    pertNumber({data_}) <- pertNumber({data_})\n\n    @md\n    @aliases pertNumber<-\n    @exportMethod pertNumber<-\n    \",\n    ...\n)\n\n#' @rdname CoreSet-accessors\n#' @eval .docs_CoreSet_set_pertNumber(class_=.local_class, data_=.local_data)\nsetReplaceMethod('pertNumber', signature(object=\"CoreSet\", value=\"array\"),\n    function(object, value)\n{\n  object@perturbation$n <- value\n  object\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the .docs_CoreSet_accessors function?",
        "answer": "The .docs_CoreSet_accessors function generates documentation for the accessor methods of the CoreSet class. It creates a template for the documentation that includes details about accessing and modifying information in the slots of a CoreSet object."
      },
      {
        "question": "How does the annotation method work for the CoreSet class?",
        "answer": "The annotation method for the CoreSet class retrieves the contents of the @annotation slot from the CoreSet object. It returns a list containing metadata about the object, such as its name, creation date, session info, and version."
      },
      {
        "question": "What is the purpose of the sensitivityRaw method in the CoreSet class?",
        "answer": "The sensitivityRaw method accesses the raw sensitivity measurements for a CoreSet object. It returns a 3D array where rows are experiment_ids, columns are doses, and the third dimension contains 'Dose' and 'Viability' data for each experiment and dose combination."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('annotation', signature(\"CoreSet\"), function(object) {\n    object@annotation\n})",
        "complete": "setMethod('annotation', signature(\"CoreSet\"), function(object) {\n    object@annotation\n})\n\nsetReplaceMethod(\"annotation\", signature(\"CoreSet\", \"list\"),\n    function(object, value)\n{\n    object@annotation <- value\n    object\n})"
      },
      {
        "partial": "setMethod('dateCreated', signature(\"CoreSet\"), function(object) {\n    object@annotation$dateCreated\n})",
        "complete": "setMethod('dateCreated', signature(\"CoreSet\"), function(object) {\n    object@annotation$dateCreated\n})\n\nsetReplaceMethod('dateCreated', signature(object=\"CoreSet\", value=\"character\"),\n    function(object, value)\n{\n    funContext <- .funContext('dateCreated')\n    if (length(value) > 1) .error(funContext, 'dateCreated must by a character\n        vector of length 1, as returned by the `date()` function.')\n    object@annotation$dateCreated <- value\n    return(object)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/methods-dimnames.R",
    "language": "R",
    "content": "# ==== LongTable Class\n\n#' Get the column names from a `LongTable` object.\n#'\n#' @examples\n#' head(colnames(merckLongTable))\n#'\n#' @describeIn LongTable Retrieve the pseudo-colnames of a LongTable object,\n#'   these are constructed by pasting together the colIDs(longTable) and\n#'   can be used in the subset method for regex based queries.\n#'\n#' @param x A `LongTable` object to get the column names from\n#'\n#' @return `character` Vector of column names.\n#'\n#' @export\nsetMethod('colnames', signature(x='LongTable'), function(x) {\n    return(x@colData$.colnames)\n})\n\n#' Get the row names from a `LongTable` object.\n#'\n#' @examples\n#' head(rownames(merckLongTable))\n#'\n#' @describeIn LongTable Retrieve the pseudo-rownames of a LongTable object,\n#'   these are constructed by pasting together the rowIDs(longTable) and\n#'   can be used in the subset method for regex based queries.\n#'\n#' @param x A `LongTable` object to get the row names from\n#'\n#' @return `character` Vector of row names.\n#'\n#' @export\nsetMethod('rownames', signature(x='LongTable'), function(x) {\n    return(x@rowData$.rownames)\n})\n\n#' Getter for the dimnames of a `LongTable` object\n#'\n#' @examples\n#' lapply(dimnames(merckLongTable), head)\n#'\n#' @describeIn LongTable Get the pseudo-dimnames for a LongTable object. See\n#'   colnames and rownames for more information.\n#'\n#' @param x The `LongTable` object to retrieve the dimnames for.\n#'\n#' @return `list` List with two character vectors, one for row and one for\n#'     column names.\n#'\n#' @importMethodsFrom Biobase dimnames\n#' @export\nsetMethod('dimnames', signature(x='LongTable'), function(x) {\n    return(list(x@rowData$.rownames, x@colData$.colnames))\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `colnames` method for the `LongTable` class, and how does it differ from traditional column names?",
        "answer": "The `colnames` method for the `LongTable` class retrieves pseudo-colnames of a LongTable object. These are constructed by pasting together the colIDs(longTable) and can be used in the subset method for regex-based queries. Unlike traditional column names, these pseudo-colnames are stored in the `x@colData$.colnames` slot of the LongTable object, allowing for more flexible and efficient handling of large datasets."
      },
      {
        "question": "How are the `rownames` and `colnames` methods related to the `dimnames` method in the `LongTable` class?",
        "answer": "The `dimnames` method in the `LongTable` class combines the functionality of `rownames` and `colnames`. It returns a list containing two character vectors: the first vector contains the row names (retrieved using `x@rowData$.rownames`), and the second vector contains the column names (retrieved using `x@colData$.colnames`). This method provides a convenient way to access both row and column names simultaneously, which is consistent with R's standard dimnames functionality for matrices and data frames."
      },
      {
        "question": "What is the significance of using `setMethod` with `signature` in these code snippets, and how does it relate to object-oriented programming in R?",
        "answer": "The use of `setMethod` with `signature` in these code snippets is part of R's S4 object-oriented programming system. It allows for method dispatch based on the class of the arguments. In this case, `setMethod` is used to define specialized versions of `colnames`, `rownames`, and `dimnames` methods for objects of the `LongTable` class. The `signature(x='LongTable')` specifies that these methods should be called when the first argument (x) is of class `LongTable`. This approach enables polymorphism, allowing different implementations of these methods for different classes while maintaining a consistent interface."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('colnames', signature(x='LongTable'), function(x) {\n    # Complete the function body\n})",
        "complete": "setMethod('colnames', signature(x='LongTable'), function(x) {\n    return(x@colData$.colnames)\n})"
      },
      {
        "partial": "setMethod('dimnames', signature(x='LongTable'), function(x) {\n    # Complete the function body\n})",
        "complete": "setMethod('dimnames', signature(x='LongTable'), function(x) {\n    return(list(x@rowData$.rownames, x@colData$.colnames))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/unitest/likelihood_test.R",
    "language": "R",
    "content": "# Given a data_set and network, computes barcode for each edge\n# Returns a matrix of 3 columns where col 1 is the higher value\n# col 2 is the lower value, and col 3 is the frequency of such a\n# relation.\nload('~/Testbed/irinotecan_cgp_ccle.RData')\n`compute.barcode` <- function(data_set, network)\n{\n\tedges <- which(network == 1)\n\tbarcode <- do.call(rbind, lapply(edges, function(edge) {\n\t\t\t\t\t\tj <- edge%%ncol(network)\n\t\t\t\t\t\tif(j == 0)\n\t\t\t\t\t\t\tj <- ncol(network)           \n\t\t\t\t\t\ti <- ceiling(edge/ncol(network))\n\t\t\t\t\t\tc(i, j, mean(data_set[, i] > data_set[, j], use=\"complete.obs\"))\n\t\t\t\t\t}))\n\treturn(barcode)\n}\n\n# Returns the product of likelihoods for a given barcode and sample\n`compute.likelihood` <- function(barcode, sample)\n{\n\tlikelihood <- apply(barcode, 1, function(feature) {\n\t\t\t\tif (sample[feature[1]] > sample[feature[2]])\n\t\t\t\t\treturn(feature[3])\n\t\t\t\telse\n\t\t\t\t\treturn(1 - feature[3])\n\t\t\t})\n\treturn(prod(likelihood))\n}\n\n`discretize.labels` <- function(labels, probabilities)\n{\n\tquantiles <- quantile(labels, probs=probabilities, na.rm=TRUE)\n\tclasses <- Hmisc::cut2(x=labels, cuts=quantiles)\n\tlevels(classes) <- c(0, NA, 1)\n\tnames(classes) <- names(labels)\n\tas.integer(classes) - 1\n}\n\n\n\ntraining_set <- data_cgp\ntraining_labels <- ic50_cgp\nvalidating_set <- data_cgp\n\n\n# Select the top 10 genes most correlated with phenotype\ngenes <- order(apply(training_set, 2, cor, training_labels, use=\"complete.obs\"))[1:10]\n\n# Create empty network\nnetwork <- matrix(0, ncol(training_set), ncol(training_set))\n\n# Connect the 10 selected genes (every pair of nodes)\nsapply(1:(length(genes) - 1), function(i) {\n\t\t\tsapply((i + 1):length(genes), function(j) {\n\t\t\t\t\t\tnetwork[genes[i], genes[j]] <<- 1\n\t\t\t\t\t})\n\t\t})\n\n# Discretize CGP into senstive (0) and resistant (1)\ndiscrete_labels <- discretize.labels(training_labels, c(0.25, 0.75))\n\n# Create barcodes for resistant and senstive cgp samples\nresistant_barcode <- compute.barcode(training_set[which(discrete_labels == 1), ], network)\nsensitive_barcode <- compute.barcode(training_set[which(discrete_labels == 0), ], network)\n\n# Compute the likelihoods\nlikelihoods <- t(apply(validating_set, 1, function(sample) {\n\t\t\tresistant_like <- compute.likelihood(resistant_barcode, sample)\n\t\t\tsensitive_like <- compute.likelihood(sensitive_barcode, sample)\n\t\t\treturn(c(resistant_like, sensitive_like))\n\t\t}))\n\nhist(likelihoods[, 1] / ( likelihoods[, 1] + likelihoods[, 2]))\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `compute.barcode` function in the given code snippet?",
        "answer": "The `compute.barcode` function computes a barcode for each edge in a given network. It takes a data_set and network as input, and returns a matrix with 3 columns. The first column represents the higher value node, the second column represents the lower value node, and the third column represents the frequency of the relation where the value of the first node is greater than the value of the second node across all samples in the data_set."
      },
      {
        "question": "How does the `discretize.labels` function work, and what is its purpose in the context of this code?",
        "answer": "The `discretize.labels` function is used to categorize continuous labels into discrete classes. It takes the labels and a vector of probabilities as input. It then calculates quantiles based on these probabilities and uses them to cut the labels into classes. In this code, it's used to discretize the CGP (Cancer Genome Project) data into 'sensitive' (0) and 'resistant' (1) categories, using the 25th and 75th percentiles as cutoff points. This discretization is crucial for creating separate barcodes for resistant and sensitive samples in the subsequent analysis."
      },
      {
        "question": "What is the significance of the final histogram plotted in this code?",
        "answer": "The final histogram plots the distribution of the ratio of resistant likelihood to total likelihood (resistant + sensitive) for each sample in the validating set. This ratio represents the probability of a sample being resistant. A ratio close to 1 indicates a high probability of resistance, while a ratio close to 0 indicates a high probability of sensitivity. The histogram provides a visual representation of how well the model distinguishes between resistant and sensitive samples in the validation set, which can be used to assess the performance of the barcode-based classification method."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Function to compute barcode for each edge\ncompute.barcode <- function(data_set, network) {\n  edges <- which(network == 1)\n  barcode <- do.call(rbind, lapply(edges, function(edge) {\n    j <- edge %% ncol(network)\n    if (j == 0) j <- ncol(network)\n    i <- ceiling(edge / ncol(network))\n    # Complete the function body\n  }))\n  return(barcode)\n}",
        "complete": "# Function to compute barcode for each edge\ncompute.barcode <- function(data_set, network) {\n  edges <- which(network == 1)\n  barcode <- do.call(rbind, lapply(edges, function(edge) {\n    j <- edge %% ncol(network)\n    if (j == 0) j <- ncol(network)\n    i <- ceiling(edge / ncol(network))\n    c(i, j, mean(data_set[, i] > data_set[, j], use = \"complete.obs\"))\n  }))\n  return(barcode)\n}"
      },
      {
        "partial": "# Function to compute likelihood for a given barcode and sample\ncompute.likelihood <- function(barcode, sample) {\n  likelihood <- apply(barcode, 1, function(feature) {\n    # Complete the function body\n  })\n  return(prod(likelihood))\n}",
        "complete": "# Function to compute likelihood for a given barcode and sample\ncompute.likelihood <- function(barcode, sample) {\n  likelihood <- apply(barcode, 1, function(feature) {\n    if (sample[feature[1]] > sample[feature[2]]) feature[3] else 1 - feature[3]\n  })\n  return(prod(likelihood))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat/test-LongTable-utils.R",
    "language": "R",
    "content": "library(testthat)\nlibrary(CoreGx)\nlibrary(data.table)\n\ndata(nci_TRE_small)\ntre <- nci_TRE_small\n\n# == subset\n\ntestthat::test_that(\"`subset,LongTable-method` works with call queries\", {\n    ntre <- subset(tre,\n        treatment1id %in% unique(treatment1id)[1:5],\n        sampleid %in% unique(sampleid)[1:5]\n    )\n    testthat::expect_s4_class(ntre, \"LongTable\")\n    ## These tests need to be updated to use expect_true with .table_is_subset\n    ## instead of expect_equal due the fact that the subset,LongTable-method\n    ## will drop additional rowKey or colKey values than those in the initial\n    ## subset statement if there are no assay observations using those keys.\n    ## This change fixed #148, but now makes it impossible to store metadata\n    ## when there are no observations, which may not be ideal?\n    ## Alternative would be to rework the assayIndex to be free of NA values\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            rowData(ntre),\n            rowData(tre)[treatment1id %in% unique(treatment1id)[1:5]]\n        )\n    )\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            colData(ntre),\n            colData(tre)[sampleid %in% unique(sampleid)[1:5]]\n        )\n    )\n    # check for NA values in the key column of the assay\n    testthat::expect_true(\n        !anyNA(assays(ntre, raw=TRUE)[[\"sensitivity\"]]$sensitivity)\n    )\n    ntre2 <- tre[\n        .(treatment1id %in% unique(treatment1id)[1:5]),\n        .(sampleid %in% unique(sampleid)[1:5])\n    ]\n    testthat::expect_s4_class(ntre2, \"LongTable\")\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            rowData(ntre2),\n            rowData(tre)[treatment1id %in% unique(treatment1id)[1:5]]\n        )\n    )\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            colData(ntre2),\n            colData(tre)[sampleid %in% unique(sampleid)[1:5]]\n        )\n    )\n    # check for NA values in the key column of the assay\n    testthat::expect_true(\n        !anyNA(assays(ntre2, raw=TRUE)[[\"sensitivity\"]]$sensitivity)\n    )\n    testthat::expect_equal(ntre, ntre2)\n})\n\ntestthat::test_that(\"`subset,LongTable-method` works with regex queries\", {\n    ntre <- subset(tre,\n        c(\"Vinblastine\", \"Temozolomide\"),\n        c(\"HT*\", \"MOLT*\")\n    )\n    testthat::expect_s4_class(ntre, \"LongTable\")\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            rowData(ntre),\n            rowData(tre)[grepl(\"Vinblastine|Temozolomide\", rownames(tre)), ]\n        )\n    )\n    testthat::expect_true(\n        CoreGx:::.table_is_subset(\n            colData(ntre),\n            colData(tre)[grepl(\"HT*|MOLT-*\", colnames(tre)), ]\n        )\n    )\n})\n\ntestthat::test_that(\"`CoreGx:::.subsetByIndex` is equivalent to subsetting the raw data\", {\n    keepRows <- rowData(tre, key=TRUE)[treatment1id %in% treatment1id[1:5], ]\n    fullAssay <- tre$sensitivity\n    rawSubset <- fullAssay[treatment1id %in% keepRows$treatment1id, ]\n    aindex <- mutable(getIntern(tre, \"assayIndex\"))\n    subindex <- aindex[rowKey %in% keepRows$rowKey, ]\n    ntre <- CoreGx:::.subsetByIndex(tre, subindex)\n    testthat::expect_true(\n        !anyNA(assays(ntre, raw=TRUE)[[\"sensitivity\"]]$sensitivity)\n    )\n    assayByIndex <- ntre$sensitivity\n    testthat::expect_true(all.equal(rawSubset, assayByIndex))\n})\n\ntestthat::test_that(\"`subset,LongTable-method` works with row and column names\", {\n    ntre <- subset(tre, rownames(tre)[1:5], colnames(tre)[1:5])\n    testthat::expect_equal(rownames(ntre), rownames(tre)[1:5])\n    testthat::expect_true(all.equal(rowData(ntre), rowData(tre)[1:5, ]))\n    testthat::expect_equal(colnames(ntre), colnames(tre)[1:5])\n    testthat::expect_true(all.equal(colData(ntre), colData(tre)[1:5, ]))\n})\n\ntestthat::test_that(\"`subset,LongTable-method` doesn't produce non-existing assay observations from joining\", {\n    all_assays <- assays(tre, key = FALSE, withDimnames = TRUE)\n    select_row_idx <- seq.int(1, dim(tre)[1], by = 2)\n    select_col_idx <- seq.int(1, dim(tre)[2], by = 2)\n    sub_tre <- subset(tre, i = select_row_idx, j = select_col_idx)\n    for (a in seq_along(all_assays)) {\n        assay_sub <- assay(sub_tre, a, key = FALSE, withDimnames = TRUE)\n        obs_exists <- dim(\n            assay_sub[!all_assays[[a]], on = names(assay_sub)]\n            )[1] == 0 ## anti-join to check elements not a subset\n        testthat::expect_true({ obs_exists })\n    }\n})\n\ntestthat::test_that(\"`subset,LongTable-method` doesn't miss assay observations for either selected row/columns\", {\n    all_assays <- assays(tre, key = FALSE, withDimnames = TRUE)\n    select_row_idx <- sample.int(n = dim(tre)[1], size = 1, replace = FALSE)\n    sub_tre <- subset(tre, i = select_row_idx)\n    select_row <- rowData(tre)[select_row_idx, rowIDs(tre), with = FALSE]\n    for (a in seq_along(all_assays)) {\n        assay_sub1 <- assay(sub_tre, a, key = FALSE, withDimnames = TRUE)\n        assay_sub2 <- all_assays[[a]][select_row, ]\n        testthat::expect_equal(assay_sub1, assay_sub2)\n    }\n    select_col_idx <- sample.int(n = dim(tre)[2], size = 1, replace = FALSE)\n    sub_tre <- subset(tre, j = select_col_idx)\n    select_col <- colData(tre)[select_col_idx, colIDs(tre), with = FALSE]\n    assay_names <- assayNames(sub_tre)\n    for (a in seq_along(assay_names)) {\n        assay_sub1 <- assay(sub_tre, a, key = FALSE, withDimnames = TRUE)\n        assay_sub2 <- all_assays[[a]][sampleid == select_col, ]\n        testthat::expect_equal(assay_sub1, assay_sub2)\n    }\n    sub_tre <- tre[select_row_idx, select_col_idx]\n    select_both <- cbind(select_row, select_col)\n    for (a in seq_along(assay_names)) {\n        assay_sub1 <- assay(sub_tre, a, key = FALSE, withDimnames = TRUE)\n        assay_sub2 <- all_assays[[a]][select_both, ]\n        testthat::expect_equal(assay_sub1, assay_sub2)\n    }\n})\n\ntestthat::test_that(\"`subset,LongTable-method` subset indexing behaves the same as data.table\", {\n    ## controled by .subsetByIndex\n    sub_tre <- subset(tre, i = NULL) ## subset with row index by NULL\n    testthat::expect_equal(dim(sub_tre), c(0, 0))\n    sub_tre <- subset(tre, j = NULL) ## subset with column index by NULL\n    testthat::expect_equal(dim(sub_tre), c(0, 0))\n    sub_tre <- subset(tre, i = \"\") ## subset with row by empty rowname string\n    testthat::expect_equal(sub_tre, tre)\n    sub_tre <- subset(tre, j = \"\") ## subset with column by empty column name\n    testthat::expect_equal(sub_tre, tre)\n    sub_tre <- subset(tre, i = \"\", j = \"\") ## subset by empty row+column names\n    testthat::expect_equal(sub_tre, tre)\n    ## Get a subset with 2-Fluoro Ara-A of dose 6e-06 as second treatment in combination therapies\n    sub_tre <- subset(tre, i = \"*:2-Fluoro Ara-A:*:6e-06\")\n    regex <- \"(?=.*\\\\:2-Fluoro Ara-A)(?=.*6e-06\\\\:*)^\" ## rowData regex\n    testthat::expect_equal(\n        rowData(tre)[grepl(regex, rownames(tre), perl = TRUE), ],\n        rowData(sub_tre)\n    ) ## much nicer to query at the TRE level\n    ## Subset containing ovarian cancer cell line\n    sub_tre <- subset(tre, j = \".*OVCAR.*\")\n    testthat::expect_equal(\n        colData(tre)[grepl(\".*OVCAR.*\", colnames(tre), perl = TRUE), ],\n        colData(sub_tre)\n    )\n    ## Subset by negative index: TRE behaves the same as data.table\n    i <- sample.int(n = dim(tre)[1], size = 1, replace = FALSE)\n    sub_tre_1 <- tre[-i, ] ## Drop the i-th row\n    sub_tre_2 <- tre[i, ] ## Extract the i-th row\n    testthat::expect_equal(\n        rowData(tre)[!rowData(sub_tre_1), on = names(rowData(tre))],\n        rowData(sub_tre_2) # rowData(tre)\\rowData(sub_tre_1)=rowData(sub_tre_2)\n    )\n    j <- sample.int(n = dim(tre)[2], size = 1, replace = FALSE)\n    sub_tre_3 <- tre[, -j] ## Drop the j-th column\n    sub_tre_4 <- tre[, j] ## Extract the j-th column\n    testthat::expect_equal(\n        colData(tre)[!colData(sub_tre_3), on = names(colData(tre))],\n        colData(sub_tre_4) # colData(tre)\\colData(sub_tre_3)=colData(sub_tre_4)\n    )\n    sub_tre_5 <- tre[-i, -j] ## Drop data containing i-th row OR j-th column\n    sub_tre_6 <- tre[i, j] ## Extract i-th row AND j-th column\n    all_assays <- assays(tre, key = FALSE, withDimnames = TRUE)\n    for (a in seq_along(all_assays)) {\n        testthat::expect_equal(\n            all_assays[[a]][\n                !assay(sub_tre_1, a, key = FALSE, withDimnames = TRUE),\n            ],\n            assay(sub_tre_2, i = a, key = FALSE, withDimnames = TRUE)\n         )\n        testthat::expect_equal(\n            all_assays[[a]][\n                !assay(sub_tre_3, a, key = FALSE, withDimnames = TRUE),\n            ],\n            assay(sub_tre_4, i = a, key = FALSE, withDimnames = TRUE)\n        )\n        ## tre[i, ] UNION tre[, j] + (tre[i, ] INTERSECT tre[, j])\n        union_assay <- rbind(\n            assay(sub_tre_2, i = a, key = FALSE, withDimnames = TRUE),\n            assay(sub_tre_4, i = a, key = FALSE, withDimnames = TRUE)\n        ) ## contains double count, not a union yet\n        double_count_idx <- which(duplicated(union_assay))\n        # Show that the double counted element is the intersect\n        testthat::expect_equal(\n            union_assay[double_count_idx, ],\n            ## tre[i, ] INTERSECT tre[, j]\n            assay(sub_tre_6, i = a, key = FALSE, withDimnames = TRUE),\n            ignore_attr = TRUE\n        )\n        ## Show that these two produce equivalent union sets\n #       union_assay <- setorderv(union_assay[-double_count_idx, ],\n #                                cols = idCols(tre))\n #       testthat::expect_equal(\n #           union_assay,\n #           ## This indirect approach for tre[i, ] UNION tre[, j] is faster\n #           all_assays[[a]][\n #               !assay(sub_tre_5, a, key = FALSE, withDimnames = TRUE),\n #               on = idCols(tre)\n #           ], ## reordering done by internal reindexing\n #           ignore_attr = TRUE\n #       )\n    }\n})\n\n# == reindex\n\ntestthat::test_that(\"`reindex,LongTale-method` does not mutate by reference\", {\n    .tre <- copy(tre)\n    ntre <- reindex(tre)\n    testthat::expect_true(all.equal(.tre, tre))\n})\n\ntestthat::test_that(\"`reindex,LongTable-method` has same index as LongTable constructor\", {\n    ntre <- reindex(tre)\n    testthat::expect_true(all.equal(getIntern(ntre, \"assayIndex\"), getIntern(tre, \"assayIndex\")))\n    testthat::expect_true(all.equal(assays(ntre, raw=TRUE), assays(tre, raw=TRUE)))\n})\n\ntestthat::test_that(\"`reindex,LongTable-method` does not corrupt data relationships\", {\n    ntre <- reindex(tre)\n    for (i in seq_along(assayNames(tre))) {\n        assay1 <- assay(tre, i, withDimnames=TRUE)\n        setkeyv(assay1, idCols(tre))\n        assay2 <- assay(ntre, i, withDimnames=TRUE)\n        setkeyv(assay2, idCols(ntre))\n        testthat::expect_true(all.equal(assay1, assay2))\n    }\n    assayL1 <- assays(tre)\n    assayL2 <- assays(ntre)\n    for (i in seq_along(assayL1)) {\n        testthat::expect_true(all.equal(assayL1[[i]], assayL2[[i]]))\n    }\n})\n\ntestthat::test_that(\"`reindex,LongTable-method` removes gaps in keys in subset LongTable\", {\n    select_row <- seq.int(1, dim(tre)[1], by = 2)\n    stre <- tre[select_row, ] ## subset data\n    stre <- reindex(stre)\n    ## check if rowData and colData keys have gaps\n    row_keys <- rowData(stre, key = TRUE)$rowKey\n    col_keys <- colData(stre, key = TRUE)$colKey\n    has_no_gaps_in_row <- rle(diff(row_keys))$value == 1\n    has_no_gaps_in_col <- rle(diff(col_keys))$value == 1\n    testthat::expect_true(has_no_gaps_in_row)\n    testthat::expect_true(has_no_gaps_in_col)\n    ## check if assays' keys have gaps\n    for (i in seq_along(assayNames(stre))) {\n        assay_name <- assayNames(stre)[i]\n        assay_keys <- assay(stre, i, key = FALSE, withDimnames = FALSE, metadata=FALSE)[[paste0(\".\", assay_name)]]\n        has_no_gaps_in_assay <- rle(diff(assay_keys))$value == 1\n        if (length(has_no_gaps_in_assay) > 1) print(i)\n        testthat::expect_true(has_no_gaps_in_assay)\n    } # Leave summary assay out for now\n})\n\n# == [[\n\n#testthat::test_that(\"`[[,LongTable-method` returns assay metadata always with dimnames\",{\n#    testthat::expect_warning({ tre[[1, withDimnames = FALSE, metadata = TRUE]] },\n#        regexp = \".*Unable.to.return.metadata.without.dimnames,.proceeding.as.if.withDimnames=TRUE.*\"\n#    )\n#})\n#\n#testthat::test_that(\"`[[,LongTable-method` when keys = TRUE, ignore withDimnames and metadata\",{\n#    testthat::expect_warning({ tre[[1, keys = TRUE]] },\n#        regexp = \".*Ignoring withDimnames and metadata arguments when keys=TRUE.*\"\n#    )\n#})\n\n#testthat::test_that(\"`[[,LongTable-method` allows only one assay selection at a time\",{\n#    testthat::expect_error({ tre[[1:2]] },\n#        regexp = \".*Please specifying a single string assay name or integer index.*\"\n#    )\n#    testthat::expect_error({ tre[[c(\"sensitivity\", \"profiles\")]] },\n#        regexp = \".*Please specifying a single string assay name or integer index.*\"\n#    )\n#})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `subset` method for the `LongTable` class in this code, and how does it handle different types of queries?",
        "answer": "The `subset` method for the `LongTable` class is used to create a subset of the original data based on specified criteria. It can handle different types of queries:\n1. Call queries: Using conditions like `treatment1id %in% unique(treatment1id)[1:5]`\n2. Regex queries: Using patterns like `c(\"Vinblastine\", \"Temozolomide\")`\n3. Row and column names: Directly specifying row and column names\n4. Index-based subsetting: Using numerical indices\n\nThe method ensures that the resulting subset maintains the correct structure and relationships between rowData, colData, and assays, while also handling edge cases like empty subsets or NA values in key columns."
      },
      {
        "question": "How does the `reindex` method for the `LongTable` class work, and what are its key features?",
        "answer": "The `reindex` method for the `LongTable` class is used to rebuild the internal index of the object. Its key features include:\n1. It does not mutate the original object by reference.\n2. It produces the same index as the LongTable constructor.\n3. It maintains data relationships between assays, rowData, and colData.\n4. It removes gaps in keys for subset LongTable objects, ensuring continuous key values.\n5. It works on all assays in the LongTable, including the main assays and potentially summary assays.\n\nThe method is useful for optimizing the internal structure of a LongTable object, especially after subsetting operations that might leave gaps in the key values."
      },
      {
        "question": "What are the main test cases covered in this code for the `subset` and `reindex` methods of the `LongTable` class?",
        "answer": "The main test cases covered for the `subset` and `reindex` methods include:\n\nFor `subset`:\n1. Subsetting with call queries\n2. Subsetting with regex queries\n3. Comparing subsetting by index to raw data subsetting\n4. Subsetting with row and column names\n5. Ensuring no non-existing assay observations are produced\n6. Checking that no assay observations are missed for selected rows/columns\n7. Verifying that subsetting behavior matches data.table for various edge cases (e.g., NULL, empty string, negative indices)\n\nFor `reindex`:\n1. Verifying that reindexing doesn't mutate by reference\n2. Checking that reindexed object has the same index as a newly constructed LongTable\n3. Ensuring that reindexing doesn't corrupt data relationships\n4. Confirming that reindexing removes gaps in keys for subset LongTables\n\nThese tests cover a wide range of scenarios to ensure the robustness and correctness of the `subset` and `reindex` methods."
      }
    ],
    "completion_tasks": [
      {
        "partial": "testthat::test_that(\"reindex,LongTable-method removes gaps in keys in subset LongTable\", {\n    select_row <- seq.int(1, dim(tre)[1], by = 2)\n    stre <- tre[select_row, ] ## subset data\n    stre <- reindex(stre)\n    ## check if rowData and colData keys have gaps\n    row_keys <- rowData(stre, key = TRUE)$rowKey\n    col_keys <- colData(stre, key = TRUE)$colKey\n    has_no_gaps_in_row <- rle(diff(row_keys))$value == 1\n    has_no_gaps_in_col <- rle(diff(col_keys))$value == 1\n    testthat::expect_true(has_no_gaps_in_row)\n    testthat::expect_true(has_no_gaps_in_col)\n    ## check if assays' keys have gaps\n    for (i in seq_along(assayNames(stre))) {\n        assay_name <- assayNames(stre)[i]\n        assay_keys <- assay(stre, i, key = FALSE, withDimnames = FALSE, metadata=FALSE)[[paste0(\".\", assay_name)]]\n        has_no_gaps_in_assay <- rle(diff(assay_keys))$value == 1\n        testthat::expect_true(has_no_gaps_in_assay)\n    }\n})",
        "complete": "testthat::test_that(\"reindex,LongTable-method removes gaps in keys in subset LongTable\", {\n    select_row <- seq.int(1, dim(tre)[1], by = 2)\n    stre <- tre[select_row, ] ## subset data\n    stre <- reindex(stre)\n    ## check if rowData and colData keys have gaps\n    row_keys <- rowData(stre, key = TRUE)$rowKey\n    col_keys <- colData(stre, key = TRUE)$colKey\n    has_no_gaps_in_row <- all(rle(diff(row_keys))$values == 1)\n    has_no_gaps_in_col <- all(rle(diff(col_keys))$values == 1)\n    testthat::expect_true(has_no_gaps_in_row)\n    testthat::expect_true(has_no_gaps_in_col)\n    ## check if assays' keys have gaps\n    for (i in seq_along(assayNames(stre))) {\n        assay_name <- assayNames(stre)[i]\n        assay_keys <- assay(stre, i, key = FALSE, withDimnames = FALSE, metadata=FALSE)[[paste0(\".\", assay_name)]]\n        has_no_gaps_in_assay <- all(rle(diff(assay_keys))$values == 1)\n        testthat::expect_true(has_no_gaps_in_assay)\n    }\n})"
      },
      {
        "partial": "testthat::test_that(\"subset,LongTable-method works with row and column names\", {\n    ntre <- subset(tre, rownames(tre)[1:5], colnames(tre)[1:5])\n    testthat::expect_equal(rownames(ntre), rownames(tre)[1:5])\n    testthat::expect_true(all.equal(rowData(ntre), rowData(tre)[1:5, ]))\n    testthat::expect_equal(colnames(ntre), colnames(tre)[1:5])\n    testthat::expect_true(all.equal(colData(ntre), colData(tre)[1:5, ]))\n})",
        "complete": "testthat::test_that(\"subset,LongTable-method works with row and column names\", {\n    ntre <- subset(tre, rownames(tre)[1:5], colnames(tre)[1:5])\n    testthat::expect_equal(rownames(ntre), rownames(tre)[1:5])\n    testthat::expect_true(all.equal(rowData(ntre), rowData(tre)[1:5, ]))\n    testthat::expect_equal(colnames(ntre), colnames(tre)[1:5])\n    testthat::expect_true(all.equal(colData(ntre), colData(tre)[1:5, ]))\n    # Check if assays are correctly subsetted\n    for (assay_name in assayNames(tre)) {\n        original_assay <- assay(tre, assay_name)\n        subsetted_assay <- assay(ntre, assay_name)\n        testthat::expect_true(all(subsetted_assay$rowKey %in% rowData(ntre)$rowKey))\n        testthat::expect_true(all(subsetted_assay$colKey %in% colData(ntre)$colKey))\n    }\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/allGenerics.R",
    "language": "R",
    "content": "# ==== CoreSet\n\n#' Summarize across replicates for a sensitivity dose-response experiment\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to summarize sensitivity profiles for.\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"summarizeSensitivityProfiles\",\n    function(object, ...) standardGeneric(\"summarizeSensitivityProfiles\"))\n\n\n#' Summarize molecular profile data such that there is a single entry for each\n#'   sample line/treatment combination\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to summarize the molecular profiles for.\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"summarizeMolecularProfiles\",\n    function(object, ...) standardGeneric(\"summarizeMolecularProfiles\"))\n\n\n#' Get the annotations for a `Signature` class object, as returned by\n#'   `drugSensitivitysig` or `radSensitivtySig` functions available in\n#'   `PharmacoGx` and `RadioGx`, respectively.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object A `Signature` class object\n#' @param ... Allow definition of new arguments to this generic\n#'\n#' @return NULL Prints the signature annotations to console\n#'\n#' @export\nsetGeneric(\"showSigAnnot\",\n    function(object, ...) standardGeneric(\"showSigAnnot\"))\n\n\n#' Generic function to get the annotations for a treatment response experiment\n#'   from an S4 class\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to get treatment response experiment\n#'    annotations from.\n#' @param ... Allow new arguments to be defined for this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityInfo\",\n    function(object, ...) standardGeneric(\"sensitivityInfo\"))\n\n\n#' sensitivityInfo<- Generic Method\n#'\n#' Generic function to get the annotations for a treatment response experiment\n#'   from an S4 class.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to set treatment response experiment\n#'    annotations for.\n#' @param ... Allow new arguments to be defined for this generic.\n#' @param value The new treatment response experiment annotations.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityInfo<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityInfo<-\"))\n\n\n#' sensitivityRaw Generic Method\n#'\n#' Generic function to get the raw data array for a treatment response experiment\n#'   from an S4 class.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to extract the raw sensitivity experiment\n#'     data from.\n#' @param ... `pairlist`  Allow new parameters to be defined for this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityRaw\",\n    function(object, ...) standardGeneric(\"sensitivityRaw\"))\n\n#' sensitivityRaw<- Generic\n#'\n#' Generic function to set the raw data array for a treatment response experiment\n#'   in an S4 class.\n#'\n#' @param object An `S4` object to extract the raw sensitivity data from.\n#' @param ... `pairlist` Allow new parameters to be defined for this generic.\n#' @param value An object containing dose and viability metrics to update\n#'   the object with.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityRaw<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityRaw<-\"))\n\n#' sensitivityProfiles Generic\n#'\n#' A generic for sensitivityProfiles getter method\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object The `S4` object to retrieve sensitivity profile summaries\n#'   from.\n#' @param ... `pairlist` Allow defining new arguments for this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityProfiles\", function(object, ...) standardGeneric(\"sensitivityProfiles\"))\n\n#' sensitivityProfiles<- Generic\n#'\n#' A generic for the sensitivityProfiles replacement method\n#'\n#' @param object An `S4` object to update the sensitivity profile summaries\n#'    for.\n#' @param ... Fallthrough arguments for defining new methods\n#' @param value An object with the new sensitivity profiles. If a\n#'   matrix object is passed in, converted to data.frame before assignment\n#'\n#' @return Updated \\code{CoreSet}\n#'\n#' @export\nsetGeneric(\"sensitivityProfiles<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityProfiles<-\"))\n\n#' sensitivityMeasures Generic\n#'\n#' Get the names of the sensitivity summary metrics available in an S4\n#'   object.\n#'\n#' @examples\n#' sensitivityMeasures(clevelandSmall_cSet)\n#'\n#' @param object An `S4` object to retrieve the names of sensitivty summary\n#'    measurements for.\n#' @param ... Fallthrough arguements for defining new methods\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric(\"sensitivityMeasures\",\n    function(object, ...) standardGeneric(\"sensitivityMeasures\"))\n\n#' sensitivityMeasures<- Generic\n#'\n#' Set the names of the sensitivity summary metrics available in an S4\n#'   object.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to update.\n#' @param ... Allow new methods to be defined for this generic.\n#' @param value A set of names for sensitivity measures to use to\n#'   update the object with.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric('sensitivityMeasures<-',\n    function(object, ..., value) standardGeneric('sensitivityMeasures<-'))\n\n#' sensitivitySlotToLongTable Generic\n#'\n#' Convert the sensitivity slot in an object inheriting from a CoreSet from a\n#'   list to a LongTable.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `CoreSet` Object inheriting from CoreSet.\n#' @param ... Allow new arguments to be defined on this generic.\n#'\n#' @return A `LongTable` object containing the data in the sensitivity slot.\n#'\n#' @export\nsetGeneric('sensitivitySlotToLongTable',\n    function(object, ...) standardGeneric('sensitivitySlotToLongTable'))\n\n# ==== LongTable Class\n\n#' Generic method for resetting indexing in an S4 object\n#'\n#' This method allows integer indexes used to maintain referential integrity\n#'   internal to an S4 object to be reset. This is useful particularly after\n#'   subsetting an object, as certain indexes may no longer be present in the\n#'   object data. Reindexing removes gaps integer indexes and ensures that the\n#'   smallest contiguous integer values are used in an objects indexes.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to redo indexing for\n#' @param ... `pairlist` Allow definition of new parameters to this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric('reindex', function(object, ...) standardGeneric('reindex'))\n\n#' Build a LongTable object\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param from What to build the LongTable from?\n#' @param ... `pairlist` Allow definition of new parameters for\n#'     implementations of this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric('buildLongTable',\n    function(from, ...) standardGeneric('buildLongTable'))\n\n\n#' Perform aggregation over an S4 object, but return an object of the same\n#' class.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param x An `S4` object to endomorphically aggregate over.\n#' @param ... `pairlist` Allow definition of new parameters for\n#'     implementations of this generic.\n#'\n#' @return An object with the same class as `x`.\n#'\n#' @export\nsetGeneric(\"endoaggregate\", function(x, ...) standardGeneric(\"endoaggregate\"))\n\n#' Retrieve a set of assayKeys\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param x An `S4` object.\n#' @param ... `pairlist` Allow definition of new parameters for\n#'     implementations of this generic.\n#'\n#' @return An object representing the \"assayKeys\" of an `S4` object.\n#'\n#' @export\nsetGeneric(\"assayKeys\", function(x, ...) standardGeneric(\"assayKeys\"))\n\n\n#' Retrieve and assayIndex\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param x An `S4` object.\n#' @param ... `pairlist` Allow definition of new parameters for\n#'     implementations of this generic.\n#'\n#' @return An object representing the \"assayIndex\" of an `S4` object.\n#'\n#' @export\nsetGeneric(\"assayIndex\", function(x, ...) standardGeneric(\"assayIndex\"))\n\n# ===== Other Generics\n\n\n#' Retrieve the specified item from object internal metadata.\n#'\n#' Internal slot for storing metadata relevant to the internal operation of an\n#'     S4 object.\n#'\n#' Warning: This method is intended for developer use and can be ignored by\n#'   users.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object with an @.itern slot containing an environment.\n#' @param x `character` One or more symbol names to retrieve from the\n#'    object@.intern environment.\n#' @param ... Allow new parmeters to be defined for this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export getIntern\nsetGeneric('getIntern',\n    function(object, x, ...) standardGeneric('getIntern'))\n\n\n#' Set the internal structural metadata for an S4 class\n#'\n#' @param object An R object to update internal structural metadata for.\n#' @param value An `immutable_list` object, being a class union between `list`\n#'   and `immutable` S3 classes.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @return Updates the object and returns invisibly.\n#'\n#' @keywords internal\nsetGeneric(\"getIntern<-\",\n    function(object, ..., value) standardGeneric(\"getIntern<-\"))\n\n\n#' Generic to access the row identifiers from\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to get row id columns from.\n#' @param ... Allow new arguments to this generic.\n#'\n#' @return Depends on the implemented method.\n#'\n#' @export\nsetGeneric('rowIDs', function(object, ...) standardGeneric('rowIDs'))\n\n\n#' Generic to access the row identifiers from\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to get row metadata columns from.\n#' @param ... Allow new arguments to this generic.\n#'\n#' @return Depends on the implemented method.\n#'\n#' @export\nsetGeneric('rowMeta', function(object, ...) standardGeneric('rowMeta'))\n\n\n#' Generic to access the row identifiers for an object.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to get column id columns from.\n#' @param ... ALlow new arguments to this generic\n#'\n#' @return Depends on the implemented method.\n#'\n#' @export\nsetGeneric('colIDs', function(object, ...) standardGeneric('colIDs'))\n\n\n#' Generic to access the column identifiers for a rectangular object.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to get column metadata columns from.\n#' @param ... ALlow new arguments to this generic\n#'\n#' @return Depends on impemented method.\n#'\n#' @export\nsetGeneric('colMeta', function(object, ...) standardGeneric('colMeta'))\n\n\n#' Generic to access the assay columns of a rectangular object.\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object `S4` An object to get assay ids from.\n#' @param ... Allow new arguments to this generic.\n#'\n#' @return Depends on the implemented method.\n#'\n#' @export\nsetGeneric('assayCols',\n    function(object, ...) standardGeneric('assayCols'))\n\n\n#' Generic to access the unique id columns in an S4 object used to\n#'\n#' @examples\n#' print(\"Generics shouldn't need examples?\")\n#'\n#' @param object An `S4` object to get id columns from.\n#' @param ... Allow new arguments to this generic.\n#'\n#' @return Depends on the implemented method\n#'\n#' @export\nsetGeneric('idCols',\n    function(object, ...) standardGeneric('idCols'))\n\n##' Generic to access the build configuration for an S4 object.\n##'\n##' @param object `S4` The object to retireve the configuration from.\n##'\n##'\n#setGeneric('getConfig', function(object, ...) standardGeneric(''))",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `setGeneric` function in this code snippet?",
        "answer": "The `setGeneric` function is used to define generic methods in R's S4 object-oriented system. It creates a new generic function or adds a method to an existing generic. In this code, it's used to define several generic methods like `summarizeSensitivityProfiles`, `sensitivityInfo`, and `sensitivityRaw`, allowing for method dispatch based on the class of the object passed to these functions."
      },
      {
        "question": "How does the `standardGeneric` function work within the `setGeneric` calls?",
        "answer": "The `standardGeneric` function is used within the body of each generic function defined by `setGeneric`. It serves as a placeholder for method dispatch, indicating that the actual implementation of the function will be provided by specific methods defined for different classes. When the generic function is called, `standardGeneric` ensures that the appropriate method is selected and executed based on the class of the object passed to the function."
      },
      {
        "question": "What is the significance of the `...` parameter in the generic function definitions?",
        "answer": "The `...` (ellipsis) parameter in the generic function definitions allows for additional arguments to be passed to the function. This provides flexibility for different implementations of the generic to accept and use additional parameters as needed. It's particularly useful when creating a generic interface that can be extended with new functionality in specific method implementations without modifying the generic definition itself."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setGeneric(\"summarizeSensitivityProfiles\",\n    function(object, ...) standardGeneric(\"summarizeSensitivityProfiles\"))\n\nsetGeneric(\"summarizeMolecularProfiles\",\n    function(object, ...) standardGeneric(\"summarizeMolecularProfiles\"))\n\nsetGeneric(\"showSigAnnot\",\n    function(object, ...) standardGeneric(\"showSigAnnot\"))\n\nsetGeneric(\"sensitivityInfo\",\n    function(object, ...) standardGeneric(\"sensitivityInfo\"))\n\nsetGeneric(\"sensitivityInfo<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityInfo<-\"))\n\nsetGeneric(\"sensitivityRaw\",\n    function(object, ...) standardGeneric(\"sensitivityRaw\"))\n\nsetGeneric(\"sensitivityRaw<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityRaw<-\"))\n\nsetGeneric(\"sensitivityProfiles\", function(object, ...) standardGeneric(\"sensitivityProfiles\"))\n\nsetGeneric(\"sensitivityProfiles<-\",\n    function(object, ..., value) standardGeneric(\"sensitivityProfiles<-\"))\n\nsetGeneric(\"sensitivityMeasures\",\n    function(object, ...) standardGeneric(\"sensitivityMeasures\"))\n\nsetGeneric('sensitivityMeasures<-',\n    function(object, ..., value) standardGeneric('sensitivityMeasures<-'))\n\nsetGeneric('sensitivitySlotToLongTable',\n    function(object, ...) standardGeneric('sensitivitySlotToLongTable'))\n\nsetGeneric('reindex', function(object, ...) standardGeneric('reindex'))\n\nsetGeneric('buildLongTable',\n    function(from, ...) standardGeneric('buildLongTable'))\n\nsetGeneric(\"endoaggregate\", function(x, ...) standardGeneric(\"endoaggregate\"))\n\nsetGeneric(\"assayKeys\", function(x, ...) standardGeneric(\"assayKeys\"))\n\nsetGeneric(\"assayIndex\", function(x, ...) standardGeneric(\"assayIndex\"))\n\nsetGeneric('getIntern',\n    function(object, x, ...) standardGeneric('getIntern'))\n\nsetGeneric(\"getIntern<-\",\n    function(object, ..., value) standardGeneric(\"getIntern<-\"))\n\nsetGeneric('rowIDs', function(object, ...) standardGeneric('rowIDs'))\n\nsetGeneric('rowMeta', function(object, ...) standardGeneric('rowMeta'))\n\nsetGeneric('colIDs', function(object, ...) standardGeneric('colIDs'))\n\nsetGeneric('colMeta', function(object, ...) standardGeneric('colMeta'))\n\nsetGeneric('assayCols',\n    function(object, ...) standardGeneric('assayCols'))\n\nsetGeneric('idCols',\n    function(object, ...) standardGeneric('idCols'))",
        "complete": "setGeneric(\"summarizeSensitivityProfiles\", function(object, ...) standardGeneric(\"summarizeSensitivityProfiles\"))\nsetGeneric(\"summarizeMolecularProfiles\", function(object, ...) standardGeneric(\"summarizeMolecularProfiles\"))\nsetGeneric(\"showSigAnnot\", function(object, ...) standardGeneric(\"showSigAnnot\"))\nsetGeneric(\"sensitivityInfo\", function(object, ...) standardGeneric(\"sensitivityInfo\"))\nsetGeneric(\"sensitivityInfo<-\", function(object, ..., value) standardGeneric(\"sensitivityInfo<-\"))\nsetGeneric(\"sensitivityRaw\", function(object, ...) standardGeneric(\"sensitivityRaw\"))\nsetGeneric(\"sensitivityRaw<-\", function(object, ..., value) standardGeneric(\"sensitivityRaw<-\"))\nsetGeneric(\"sensitivityProfiles\", function(object, ...) standardGeneric(\"sensitivityProfiles\"))\nsetGeneric(\"sensitivityProfiles<-\", function(object, ..., value) standardGeneric(\"sensitivityProfiles<-\"))\nsetGeneric(\"sensitivityMeasures\", function(object, ...) standardGeneric(\"sensitivityMeasures\"))\nsetGeneric('sensitivityMeasures<-', function(object, ..., value) standardGeneric('sensitivityMeasures<-'))\nsetGeneric('sensitivitySlotToLongTable', function(object, ...) standardGeneric('sensitivitySlotToLongTable'))\nsetGeneric('reindex', function(object, ...) standardGeneric('reindex'))\nsetGeneric('buildLongTable', function(from, ...) standardGeneric('buildLongTable'))\nsetGeneric(\"endoaggregate\", function(x, ...) standardGeneric(\"endoaggregate\"))\nsetGeneric(\"assayKeys\", function(x, ...) standardGeneric(\"assayKeys\"))\nsetGeneric(\"assayIndex\", function(x, ...) standardGeneric(\"assayIndex\"))\nsetGeneric('getIntern', function(object, x, ...) standardGeneric('getIntern'))\nsetGeneric(\"getIntern<-\", function(object, ..., value) standardGeneric(\"getIntern<-\"))\nsetGeneric('rowIDs', function(object, ...) standardGeneric('rowIDs'))\nsetGeneric('rowMeta', function(object, ...) standardGeneric('rowMeta'))\nsetGeneric('colIDs', function(object, ...) standardGeneric('colIDs'))\nsetGeneric('colMeta', function(object, ...) standardGeneric('colMeta'))\nsetGeneric('assayCols', function(object, ...) standardGeneric('assayCols'))\nsetGeneric('idCols', function(object, ...) standardGeneric('idCols'))"
      },
      {
        "partial": "setGeneric(\"summarizeSensitivityProfiles\", function(object, ...) standardGeneric(\"summarizeSensitivityProfiles\"))\n\nsetGeneric(\"summarizeMolecularProfiles\", function(object, ...) standardGeneric(\"summarizeMolecularProfiles\"))\n\nsetGeneric(\"showSigAnnot\", function(object, ...) standardGeneric(\"showSigAnnot\"))\n\nsetGeneric(\"sensitivityInfo\", function(object, ...) standardGeneric(\"sensitivityInfo\"))\n\nsetGeneric(\"sensitivityInfo<-\", function(object, ..., value) standardGeneric(\"sensitivityInfo<-\"))\n\nsetGeneric(\"sensitivityRaw\", function(object, ...) standardGeneric(\"sensitivityRaw\"))\n\nsetGeneric(\"sensitivityRaw<-\", function(object, ..., value) standardGeneric(\"sensitivityRaw<-\"))\n\nsetGeneric(\"sensitivityProfiles\", function(object, ...) standardGeneric(\"sensitivityProfiles\"))\n\nsetGeneric(\"sensitivityProfiles<-\", function(object, ..., value) standardGeneric(\"sensitivityProfiles<-\"))\n\nsetGeneric(\"sensitivityMeasures\", function(object, ...) standardGeneric(\"sensitivityMeasures\"))\n\nsetGeneric('sensitivityMeasures<-', function(object, ..., value) standardGeneric('sensitivityMeasures<-'))\n\nsetGeneric('sensitivitySlotToLongTable', function(object, ...) standardGeneric('sensitivitySlotToLongTable'))\n\nsetGeneric('reindex', function(object, ...) standardGeneric('reindex'))\n\nsetGeneric('buildLongTable', function(from, ...) standardGeneric('buildLongTable'))\n\nsetGeneric(\"endoaggregate\", function(x, ...) standardGeneric(\"endoaggregate\"))\n\nsetGeneric(\"assayKeys\", function(x, ...) standardGeneric(\"assayKeys\"))\n\nsetGeneric(\"assayIndex\", function(x, ...) standardGeneric(\"assayIndex\"))\n\nsetGeneric('getIntern', function(object, x, ...) standardGeneric('getIntern'))\n\nsetGeneric(\"getIntern<-\", function(object, ..., value) standardGeneric(\"getIntern<-\"))\n\nsetGeneric('rowIDs', function(object, ...) standardGeneric('rowIDs'))\n\nsetGeneric('rowMeta', function(object, ...) standardGeneric('rowMeta'))\n\nsetGeneric('colIDs', function(object, ...) standardGeneric('colIDs'))\n\nsetGeneric('colMeta', function(object, ...) standardGeneric('colMeta'))\n\nsetGeneric('assayCols', function(object, ...) standardGeneric('assayCols'))\n\nsetGeneric('idCols', function(object, ...) standardGeneric('idCols'))",
        "complete": "setGeneric(\"summarizeSensitivityProfiles\", function(object, ...) standardGeneric(\"summarizeSensitivityProfiles\"))\nsetGeneric(\"summarizeMolecularProfiles\", function(object, ...) standardGeneric(\"summarizeMolecularProfiles\"))\nsetGeneric(\"showSigAnnot\", function(object, ...) standardGeneric(\"showSigAnnot\"))\nsetGeneric(\"sensitivityInfo\", function(object, ...) standardGeneric(\"sensitivityInfo\"))\nsetGeneric(\"sensitivityInfo<-\", function(object, ..., value) standardGeneric(\"sensitivityInfo<-\"))\nsetGeneric(\"sensitivityRaw\", function(object, ...) standardGeneric(\"sensitivityRaw\"))\nsetGeneric(\"sensitivityRaw<-\", function(object, ..., value) standardGeneric(\"sensitivityRaw<-\"))\nsetGeneric(\"sensitivityProfiles\", function(object, ...) standardGeneric(\"sensitivityProfiles\"))\nsetGeneric(\"sensitivityProfiles<-\", function(object, ..., value) standardGeneric(\"sensitivityProfiles<-\"))\nsetGeneric(\"sensitivityMeasures\", function(object, ...) standardGeneric(\"sensitivityMeasures\"))\nsetGeneric('sensitivityMeasures<-', function(object, ..., value) standardGeneric('sensitivityMeasures<-'))\nsetGeneric('sensitivitySlotToLongTable', function(object, ...) standardGeneric('sensitivitySlotToLongTable'))\nsetGeneric('reindex', function(object, ...) standardGeneric('reindex'))\nsetGeneric('buildLongTable', function(from, ...) standardGeneric('buildLongTable'))\nsetGeneric(\"endoaggregate\", function(x, ...) standardGeneric(\"endoaggregate\"))\nsetGeneric(\"assayKeys\", function(x, ...) standardGeneric(\"assayKeys\"))\nsetGeneric(\"assayIndex\", function(x, ...) standardGeneric(\"assayIndex\"))\nsetGeneric('getIntern', function(object, x, ...) standardGeneric('getIntern'))\nsetGeneric(\"getIntern<-\", function(object, ..., value) standardGeneric(\"getIntern<-\"))\nsetGeneric('rowIDs', function(object, ...) standardGeneric('rowIDs'))\nsetGeneric('rowMeta', function(object, ...) standardGeneric('rowMeta'))\nsetGeneric('colIDs', function(object, ...) standardGeneric('colIDs'))\nsetGeneric('colMeta', function(object, ...) standardGeneric('colMeta'))\nsetGeneric('assayCols', function(object, ...) standardGeneric('assayCols'))\nsetGeneric('idCols', function(object, ...) standardGeneric('idCols'))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/callingWaterfall.R",
    "language": "R",
    "content": "#' Drug sensitivity calling using waterfall plots\n#'\n#' 1. Sensitivity calls were made using one of IC50, ActArea or Amax\n#'\n#' 2. Sort log IC50s (or ActArea or Amax) of the samples to generate a\n#'   \u201cwaterfall distribution\u201d\n#'\n#' 3. Identify cutoff:\n#'\n#'  3.1 If the waterfall distribution is non-linear (pearson cc to the linear\n#'    fit <=0.95), estimate the major inflection point of the log IC50 curve as\n#'    the point on the curve with the maximal distance to a line drawn between\n#'    the start and end points of the distribution.\n#'\n#'  3.2 If the waterfall distribution appears linear (pearson cc to the linear\n#'    fit > 0.95), then use the median IC50 instead.\n#'\n#' 4. Samples within a 4-fold IC50 (or within a 1.2-fold ActArea or 20% Amax\n#'   difference) difference centered around this inflection point are classified\n#'   as being \u201cintermediate\u201d,  samples with lower IC50s (or ActArea/Amax\n#'   values) than this range are defined as sensitive, and those with IC50s (or\n#'   ActArea/Amax) higher than this range are called \u201cinsensitive\u201d.\n#'\n#' 5. Require at least x sensitive and x insensitive samples after applying\n#'   these criteria (x=5 in our case).\n#'\n## FIXME:: Write a real example\n#' @examples\n#' # Dummy example\n#' 1 + 1\n#'\n## FIXME:: Clarify the parameters of this function\n#' @param x What type of object does this take in?\n#' @param type\n#'   ic50: IC50 values in micro molar (positive values)\n#'   actarea: Activity Area, that is area under the drug activity curve (positive values)\n#'   amax: Activity at max concentration (positive values)\n#'\n#' @param intermediate.fold vector of fold changes used to define the intermediate sensitivities for ic50, actarea and amax respectively\n#' @param cor.min.linear \\code{numeric} The minimum linear correlation to\n#'   require?\n#' @param name \\code{character} The name of the output to use in plot\n#' @param plot \\code{boolean} Whether to plot the results\n#'\n#' @return \\code{factor} Containing the drug sensitivity status of each\n#'   sample.\n#'\n#' @importFrom stats complete.cases  cor.test lm median\n#' @importFrom graphics par points abline lines legend\n#' @importFrom grDevices rainbow\n#'\n#' @export\n#' @keywords internal\ncallingWaterfall <- function(x, type = c(\"IC50\", \"AUC\", \"AMAX\"), intermediate.fold = c(4, 1.2, 1.2), cor.min.linear = 0.95, name = \"Drug\",\n    plot = FALSE) {\n\n    type <- match.arg(type)\n    if (any(!is.na(intermediate.fold) & intermediate.fold < 0)) {\n        intermediate.fold <- intermediate.fold[!is.na(intermediate.fold) & intermediate.fold < 0] <- 0\n    }\n    if (is.null(names(x))) {\n        names(x) <- paste(\"X\", seq_along(x), sep = \".\")\n    }\n\n    xx <- x[complete.cases(x)]\n    switch(type, IC50 = {\n        xx <- -log10(xx)\n        ylabel <- \"-log10(IC50)\"\n        ## 4 fold difference around IC50 cutoff\n        if (length(intermediate.fold) == 3) {\n            intermediate.fold <- intermediate.fold[1]\n        }\n        if (intermediate.fold != 0) {\n            interfold <- log10(intermediate.fold)\n        } else {\n            interfold <- 0\n        }\n    }, AUC = {\n        ylabel <- \"AUC\"\n        ## 1.2 fold difference around Activity Area cutoff\n        if (length(intermediate.fold) == 3) {\n            intermediate.fold <- intermediate.fold[2]\n        }\n        interfold <- intermediate.fold\n    }, AMAX = {\n        ylabel <- \"Amax\"\n        ## 1.2 fold difference around Amax\n        if (length(intermediate.fold) == 3) {\n            intermediate.fold <- intermediate.fold[3]\n        }\n        interfold <- intermediate.fold\n    })\n\n    if (length(xx) < 3) {\n        tt <- array(NA, dim = length(x), dimnames = list(names(x)))\n        if (interfold == 0) {\n            tt <- factor(tt, levels = c(\"resistant\", \"sensitive\"))\n        } else {\n            tt <- factor(tt, levels = c(\"resistant\", \"intermediate\", \"sensitive\"))\n        }\n        return(tt)\n    }\n\n    oo <- order(xx, decreasing = TRUE)\n    ## test linearity with Pearson correlation\n    cc <- stats::cor.test(-xx[oo], seq_along(oo), method = \"pearson\")\n    ## line between the two extreme sensitivity values\n    dd <- cbind(y = xx[oo][c(1, length(oo))], x = c(1, length(oo)))\n    rr <- lm(y ~ x, data = data.frame(dd))\n    ## compute distance from sensitivity values and the line between the two extreme sensitivity values\n    ddi <- apply(cbind(seq_along(oo), xx[oo]), 1, function(x, slope, intercept) {\n        return(.distancePointLine(x = x[1], y = x[2], a = slope, b = intercept))\n    }, slope = rr$coefficients[2], intercept = rr$coefficients[1])\n    if (cc$estimate > cor.min.linear) {\n        ## approximately linear waterfall\n        cutoff <- which.min(abs(xx[oo] - median(xx[oo])))\n        cutoffn <- names(cutoff)[1]\n    } else {\n        ## non linear waterfall identify cutoff as the maximum distance\n        cutoff <- which.max(abs(ddi))\n        cutoffn <- names(ddi)[cutoff]\n    }\n    ## identify intermediate sensitivities\n    switch(type, IC50 = {\n        if (interfold == 0) {\n            rang <- c(xx[oo][cutoff], xx[oo][cutoff])\n        } else {\n            rang <- c(xx[oo][cutoff] - interfold, xx[oo][cutoff] + interfold)\n        }\n    }, AUC = {\n        if (interfold == 0) {\n            rang <- c(xx[oo][cutoff], xx[oo][cutoff])\n        } else {\n            rang <- c(xx[oo][cutoff]/interfold, xx[oo][cutoff] * interfold)\n        }\n    }, AMAX = {\n        if (interfold == 0) {\n            rang <- c(xx[oo][cutoff], xx[oo][cutoff])\n        } else {\n            rang <- c(xx[oo][cutoff]/interfold, xx[oo][cutoff] * interfold)\n        }\n    })\n\n\n    ## check whether range is either min or max\n    if (rang[2] >= max(xx)) {\n        rang[2] <- sort(unique(xx), decreasing = TRUE)[2]\n    }\n    if (rang[2] <= min(xx)) {\n        rang[2] <- sort(unique(xx), decreasing = FALSE)[2]\n    }\n    if (rang[1] <= min(xx)) {\n        rang[1] <- sort(unique(xx), decreasing = FALSE)[2]\n    }\n    if (rang[1] >= max(xx)) {\n        rang[1] <- sort(unique(xx), decreasing = TRUE)[2]\n    }\n\n    ## compute calls\n    calls <- rep(NA, length(xx))\n    names(calls) <- names(xx)\n    calls[xx < rang[1]] <- \"resistant\"\n    calls[xx >= rang[2]] <- \"sensitive\"\n    calls[xx >= rang[1] & xx < rang[2]] <- \"intermediate\"\n\n    if (plot) {\n        par(mfrow = c(2, 1))\n        ccols <- rainbow(4)\n        mycol <- rep(\"grey\", length(xx))\n        names(mycol) <- names(xx)\n        mycol[calls == \"sensitive\"] <- ccols[2]\n        mycol[calls == \"intermediate\"] <- ccols[3]\n        mycol[calls == \"resistant\"] <- ccols[4]\n        mycol[cutoffn] <- ccols[1]\n        mypch <- rep(16, length(xx))\n        names(mypch) <- names(xx)\n        mypch[cutoffn] <- 19\n        plot(xx[oo], col = mycol[oo], pch = mypch[oo], ylab = ylabel, main = sprintf(\"%s\\nWaterfall\", name))\n        points(x = cutoff, y = xx[cutoffn], pch = mypch[cutoffn], col = mycol[cutoffn])\n        graphics::abline(a = rr$coefficients[1], b = rr$coefficients[2], lwd = 2, col = \"darkgrey\")\n        lines(x = c(cutoff, cutoff), y = c(par(\"usr\")[3], xx[cutoffn]), col = \"red\")\n        lines(x = c(par(\"usr\")[1], cutoff), y = c(xx[cutoffn], xx[cutoffn]), col = \"red\")\n        legend(\"topright\", legend = c(sprintf(\"resistant (n=%i)\", sum(!is.na(calls) & calls == \"resistant\")), sprintf(\"intermediate (n=%i)\",\n            sum(!is.na(calls) & calls == \"intermediate\")), sprintf(\"sensitive (n=%i)\", sum(!is.na(calls) & calls == \"sensitive\")), \"cutoff\",\n            sprintf(\"R=%.3g\", cc$estimate)), col = c(rev(ccols), NA), pch = c(16, 16, 16, 19, NA), bty = \"n\")\n\n        plot(ddi, pch = mypch[oo], col = mycol[oo], ylab = \"Distance\", main = sprintf(\"%s\\n%s\", name, \"Distance from min--max line\"))\n        points(x = cutoff, y = ddi[cutoffn], pch = mypch[cutoffn], col = mycol[cutoffn])\n        legend(\"topright\", legend = c(\"resistant\", \"intermediate\", \"sensitive\", \"cutoff\"), col = rev(ccols), pch = c(16, 16, 16, 19), bty = \"n\")\n    }\n\n    tt <- rep(NA, length(x))\n    names(tt) <- names(x)\n    tt[names(calls)] <- calls\n    if (interfold == 0) {\n        tt <- factor(tt, levels = c(\"resistant\", \"sensitive\"))\n    } else {\n        tt <- factor(tt, levels = c(\"resistant\", \"intermediate\", \"sensitive\"))\n    }\n    return(tt)\n}\n\n\n# Helper Functions --------------------------------------------------------\n\n#' Calculate shortest distance between point and line\n#'\n#' @examples .distancePointLine(0, 0, 1, -1, 1)\n#'\n#' @description This function calculates the shortest distance between a point\n#'   and a line in 2D space.\n#'\n#' @param x x-coordinate of point\n#' @param y y-coordinate of point\n#' @param a `numeric(1)` The coefficient in line equation a * x + b * y + c = 0.\n#'   Defaults to 1.\n#' @param b `numeric(1)` The coefficient in line equation a * x + b * y + c = 0.\n#'   Defaults to 1.\n#' @param c `numeric(1)` The intercept in line equation a * x + b * y + c = 0.\n#'   Defaults to 0.\n#'\n#' @return `numeric` The shortest distance between a point and a line.\n#'\n#' @export\n#' @keywords internal\n.distancePointLine <- function(x, y, a=1, b=1, c=0) {\n\n    if (!(all(is.finite(c(x, y, a, b, c))))) {\n        stop(\"All inputs to .distancePointLine must be real numbers.\")\n    }\n\n    return(abs(a * x + b * y + c) / sqrt(a^2 + b^2))\n}\n\n#' @export\n#' @keywords internal\n.magnitude <- function(p1, p2) {\n    return(sqrt(sum((p2 - p1)^2)))\n}\n\n#' Calculate shortest distance between point and line segment\n#'\n#' @description This function calculates the shortest distance between a point\n#'   and a line segment in 2D space.\n#'\n#' @param x x-coordinate of point\n#' @param y y-coordinate of point\n#' @param x1 x-coordinate of one endpoint of the line segment\n#' @param y1 y-coordinate of line segment endpoint with x-coordinate x1\n#' @param x2 x-coordinate of other endpoint of line segment\n#' @param y2 y-coordinate of line segment endpoint with x-coordinate x2\n#'\n#' @return \\code{numeric} The shortest distance between a point and a line\n#'   segment\n#'\n#' @examples .distancePointSegment(0, 0, -1, 1, 1, -1)\n#'\n#' @export\n#' @keywords internal\n.distancePointSegment <- function(x, y, x1, y1, x2, y2) {\n    if (!(all(is.finite(c(x, y, x1, x2, y1, y2))))) {\n        stop(\"All inputs to linePtDist must be real numbers.\")\n    }\n\n    bestEndpointDistance <- min(c(.magnitude(c(x, y), c(x1, y1)), .magnitude(c(x, y), c(x2, y2))))\n\n    if (.magnitude(c(x, y), c((x1 + x2)/2, (y1 + y2)/2)) < bestEndpointDistance) {\n        # length to point has only one local minimum which is the global minimum; iff this condition is true then the shortest distance is to a\n        # point on the line segment vertical line segment\n        if (x1 == x2) {\n            a <- 1\n            b <- 0\n            c <- -x1\n        } else {\n            a <- (y2 - y1)/(x2 - x1)\n            b <- -1\n            c <- y1 - a * x1\n        }\n        return(.distancePointLine(x, y, a, b, c))\n    } else {\n        return(bestEndpointDistance)\n    }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the main purpose of the `callingWaterfall` function in this code snippet?",
        "answer": "The `callingWaterfall` function is designed to perform drug sensitivity calling using waterfall plots. It analyzes drug sensitivity data (IC50, AUC, or AMAX) to classify samples as resistant, intermediate, or sensitive based on their response to a drug. The function uses a waterfall distribution approach to determine cutoffs for these classifications."
      },
      {
        "question": "How does the function determine if the waterfall distribution is linear or non-linear, and why is this important?",
        "answer": "The function uses Pearson correlation to test the linearity of the waterfall distribution. If the correlation coefficient is greater than `cor.min.linear` (default 0.95), it's considered linear. For linear distributions, the median value is used as the cutoff. For non-linear distributions, the point of maximum distance from a line between the start and end points is used. This distinction is important because it affects how the sensitivity cutoff is determined, which in turn impacts the classification of samples."
      },
      {
        "question": "What are the three helper functions included in this code snippet, and what do they do?",
        "answer": "The three helper functions are:\n1. `.distancePointLine`: Calculates the shortest distance between a point and a line in 2D space.\n2. `.magnitude`: Computes the magnitude (distance) between two points.\n3. `.distancePointSegment`: Calculates the shortest distance between a point and a line segment in 2D space.\nThese functions are used to support the main `callingWaterfall` function in its calculations, particularly when determining cutoffs in non-linear distributions."
      }
    ],
    "completion_tasks": [
      {
        "partial": "callingWaterfall <- function(x, type = c(\"IC50\", \"AUC\", \"AMAX\"), intermediate.fold = c(4, 1.2, 1.2), cor.min.linear = 0.95, name = \"Drug\", plot = FALSE) {\n    type <- match.arg(type)\n    if (any(!is.na(intermediate.fold) & intermediate.fold < 0)) {\n        intermediate.fold <- intermediate.fold[!is.na(intermediate.fold) & intermediate.fold < 0] <- 0\n    }\n    if (is.null(names(x))) {\n        names(x) <- paste(\"X\", seq_along(x), sep = \".\")\n    }\n\n    xx <- x[complete.cases(x)]\n    switch(type,\n        IC50 = {\n            xx <- -log10(xx)\n            ylabel <- \"-log10(IC50)\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[1]\n            }\n            interfold <- if (intermediate.fold != 0) log10(intermediate.fold) else 0\n        },\n        AUC = {\n            ylabel <- \"AUC\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[2]\n            }\n            interfold <- intermediate.fold\n        },\n        AMAX = {\n            ylabel <- \"Amax\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[3]\n            }\n            interfold <- intermediate.fold\n        }\n    )\n\n    # Complete the function here\n}",
        "complete": "callingWaterfall <- function(x, type = c(\"IC50\", \"AUC\", \"AMAX\"), intermediate.fold = c(4, 1.2, 1.2), cor.min.linear = 0.95, name = \"Drug\", plot = FALSE) {\n    type <- match.arg(type)\n    if (any(!is.na(intermediate.fold) & intermediate.fold < 0)) {\n        intermediate.fold <- intermediate.fold[!is.na(intermediate.fold) & intermediate.fold < 0] <- 0\n    }\n    if (is.null(names(x))) {\n        names(x) <- paste(\"X\", seq_along(x), sep = \".\")\n    }\n\n    xx <- x[complete.cases(x)]\n    switch(type,\n        IC50 = {\n            xx <- -log10(xx)\n            ylabel <- \"-log10(IC50)\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[1]\n            }\n            interfold <- if (intermediate.fold != 0) log10(intermediate.fold) else 0\n        },\n        AUC = {\n            ylabel <- \"AUC\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[2]\n            }\n            interfold <- intermediate.fold\n        },\n        AMAX = {\n            ylabel <- \"Amax\"\n            if (length(intermediate.fold) == 3) {\n                intermediate.fold <- intermediate.fold[3]\n            }\n            interfold <- intermediate.fold\n        }\n    )\n\n    if (length(xx) < 3) {\n        tt <- array(NA, dim = length(x), dimnames = list(names(x)))\n        return(factor(tt, levels = if (interfold == 0) c(\"resistant\", \"sensitive\") else c(\"resistant\", \"intermediate\", \"sensitive\")))\n    }\n\n    oo <- order(xx, decreasing = TRUE)\n    cc <- stats::cor.test(-xx[oo], seq_along(oo), method = \"pearson\")\n    dd <- cbind(y = xx[oo][c(1, length(oo))], x = c(1, length(oo)))\n    rr <- lm(y ~ x, data = data.frame(dd))\n    ddi <- apply(cbind(seq_along(oo), xx[oo]), 1, function(x, slope, intercept) {\n        return(.distancePointLine(x = x[1], y = x[2], a = slope, b = intercept))\n    }, slope = rr$coefficients[2], intercept = rr$coefficients[1])\n\n    if (cc$estimate > cor.min.linear) {\n        cutoff <- which.min(abs(xx[oo] - median(xx[oo])))\n        cutoffn <- names(cutoff)[1]\n    } else {\n        cutoff <- which.max(abs(ddi))\n        cutoffn <- names(ddi)[cutoff]\n    }\n\n    rang <- switch(type,\n        IC50 = if (interfold == 0) c(xx[oo][cutoff], xx[oo][cutoff]) else c(xx[oo][cutoff] - interfold, xx[oo][cutoff] + interfold),\n        AUC = if (interfold == 0) c(xx[oo][cutoff], xx[oo][cutoff]) else c(xx[oo][cutoff]/interfold, xx[oo][cutoff] * interfold),\n        AMAX = if (interfold == 0) c(xx[oo][cutoff], xx[oo][cutoff]) else c(xx[oo][cutoff]/interfold, xx[oo][cutoff] * interfold)\n    )\n\n    rang[2] <- min(max(rang[2], sort(unique(xx), decreasing = FALSE)[2]), sort(unique(xx), decreasing = TRUE)[2])\n    rang[1] <- max(min(rang[1], sort(unique(xx), decreasing = TRUE)[2]), sort(unique(xx), decreasing = FALSE)[2])\n\n    calls <- cut(xx, breaks = c(-Inf, rang[1], rang[2], Inf), labels = c(\"resistant\", \"intermediate\", \"sensitive\"), include.lowest = TRUE)\n\n    if (plot) {\n        # Plotting code here (omitted for brevity)\n    }\n\n    tt <- rep(NA, length(x))\n    names(tt) <- names(x)\n    tt[names(calls)] <- as.character(calls)\n    return(factor(tt, levels = if (interfold == 0) c(\"resistant\", \"sensitive\") else c(\"resistant\", \"intermediate\", \"sensitive\")))\n}"
      },
      {
        "partial": ".distancePointLine <- function(x, y, a=1, b=1, c=0) {\n    if (!(all(is.finite(c(x, y, a, b, c))))) {\n        stop(\"All inputs to .distancePointLine must be real numbers.\")\n    }\n\n    # Complete the function here\n}",
        "complete": ".distancePointLine <- function(x, y, a=1, b=1, c=0) {\n    if (!(all(is.finite(c(x, y, a, b, c))))) {\n        stop(\"All inputs to .distancePointLine must be real numbers.\")\n    }\n\n    return(abs(a * x + b * y + c) / sqrt(a^2 + b^2))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/LongTableDataMapper-accessors.R",
    "language": "R",
    "content": "#' @include LongTableDataMapper-class.R\nNULL\n\n## =====================================\n## LongTableDataMapper Accessors Methods\n## -------------------------------------\n\n\n## ---------------------\n## ---- all slot helpers\n\n\n#' Method to subset the rawdata with the corresponding dimensions \"dimDataMap\"\n#'   method.\n#'\n#' @param x `LongTableDataMapper` or inheriting class.\n#' @param key `logical(1)` Should the returned value be keyed by the 'id_columns'\n#'   item of the dimDataMap? Ignored when dim is \"meta\".\n#' @param dim `character(1)` Which dimension should rawdata to subset for?\n#'   Options are \"row\", \"col\" and \"meta\", corresponding to the associated\n#'   slots of the `LongTableDataMapper`.\n#'\n#' @importFrom checkmate assertClass assertLogical\n#' @importFrom methods getPackageName\n#' @noRd\n#' @keywords internal\n.get_dimData <- function(x, key, dim=c(\"row\", \"col\", \"meta\")) {\n\n    # Input validation\n    assertClass(x, \"LongTableDataMapper\")\n    assertLogical(key)\n\n    # Determine which slot and accessor function to use\n    dim <- match.arg(dim)\n    dimSlot <- paste0(dim, \"DataMap\")\n    dimFun <- get(dimSlot)\n\n    # Get method name to simplify debugging from S4 classes\n    funContext <- paste0(\"\\n[\", getPackageName(), \"::\", dimSlot, \",\",\n        class(x)[1], \"-method\\n\\t\")\n\n    .dimDataMap <- dimFun(x)\n\n    # Ensure required data is present\n    if (length(unlist(.dimDataMap)) < 1) stop(.errorMsg(funContext,\n        \"The \", dimSlot, \" slot must contain valid data!\"))\n\n    return(.get_dimDataFromMap(x=x, key=(key && dim != \"meta\"),\n        dataMap=.dimDataMap, funContext=funContext))\n}\n\n#' Method to subset the rawdata with the corresponding dimensions \"dimDataMap\"\n#'   method.\n#'\n#' @param x `LongTableDataMapper` or inheriting class.\n#' @param dataMap `list` The map of a `LongTableDataMapper` dimension, as\n#'   returned by the '*DataMap' methods. Can also be used with a single assay\n#'   from the `assayMap` method, but not the entire list of assays.\n#' @param key `logical(1)` Should the returned value be keyed by the 'id_columns'\n#'   item of the dimDataMap? Default is `TRUE`.\n#' @param rename `logical(1)` Should columns be renamed from their value to\n#'   their name, if the item has a name in the `dataMap`. Default is `TRUE`.\n#' @param funContext `character(1)` Contextual information about the calling\n#'   function, for debugging. Users don't need to worry about this.\n#'\n#' @importFrom checkmate assertClass assertLogical assertList\n#' @importFrom methods getPackageName\n#' @importFrom data.table setkeyv\n#' @noRd\n#' @keywords internal\n.get_dimDataFromMap <- function(x, dataMap, key=TRUE, rename=TRUE, funContext) {\n\n    if (missing(funContext))\n        funContext <- paste0(\"\\n[\", getPackageName(), \"::.get_dimDataMap]\\n\\t\")\n\n    # Input validation\n    checkmate::assertClass(x, \"LongTableDataMapper\")\n    checkmate::assertLogical(key)\n    checkmate::assertList(dataMap, types=c(\"character\", \"NULL\"), max.len=2)\n\n    # Extract relevant data\n    .rawdata <- rawdata(x)\n\n    # Ensure required data is present\n    if (length(.rawdata) < 1) .error(funContext,\n        \"The rawdata slot must contain valid data!\")\n    hasDimDataCols <- unlist(dataMap) %in% colnames(.rawdata)\n    if (!all(hasDimDataCols)) .error(funContext, \"Columns \",\n        .collapse(unlist(dataMap)[!hasDimDataCols]),\n        \" are missing from rawdata!\")\n\n    # Subset rawdata, optionally keying table and/or renaming columns\n    .dimData <- .rawdata[, .SD, .SDcols=unlist(dataMap)]\n    if (key) setkeyv(.dimData, dataMap$id_columns)\n    if (rename) {\n        old <- unlist(unname(dataMap))\n        new <- names(old)\n        if (!is.null(new)) {\n            names_idx <- new != \"\" & !is.na(new)\n            data.table::setnames(.dimData, old[names_idx], new[names_idx])\n        }\n    }\n\n    return(unique(.dimData))\n}\n\n\n## ---------------\n## -- rawdata slot\n\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_DataMapper_set_rawdata(class_=.local_class_3,\n#' class1_='list')\nsetReplaceMethod('rawdata', signature=c(object='LongTableDataMapper',\n        value='list'), function(object, value) {\n    funContext <- .S4MethodContext('rawdata<-', class(object)[1],\n        class(value)[1])\n\n    rows <- unlist(rowDataMap(object))\n    cols <- unlist(colDataMap(object))\n    assays <- unlist(assayMap(object))\n    meta <- unlist(metadataMap(object))\n\n    ## TODO:: Improve parsing here such that it only throws warnings if meta-\n    ##>data columns are missing\n\n    mandatory <- c(rows, cols, assays, meta)\n    if (!length(mandatory) || !length(value)) {\n        object@rawdata <- value\n    } else if (length(mandatory) && !length(rawdata(object))) {\n        hasMandatory <- mandatory %in% colnames(value)\n        if (!all(hasMandatory)) {\n            stop(.errorMsg(funContext, \"One or more map column is missing from value\",\n                \": \", paste0(mandatory[!hasMandatory], collapse=', '), '!'))\n        }\n        object@rawdata <- value\n    } else {\n        stop(.errorMsg(funContext, \"In order to assign to the rawdata slot of \",\n            \"a LongTableDataMapper, either all the map slots must be \",\n            \"empty or the rawdata slot must be an empty list!\"))\n    }\n    return(object)\n})\n\n\n## --------------------\n## ---- rowDataMap slot\n\n\n##\n## -- rowDataMap\n\n.docs_LongTableDataMapper_get_dimDataMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __{dim_}DataMap__: `list` of two `character` vectors, the first are the\n    columns required to uniquely identify each row of a `{class_}` and the\n    second any additional {dim_}-level metadata. If the character vectors\n    have names, the resulting columns are automatically renamed to the\n    item name of the specified column.\n\n    @examples\n    {dim_}DataMap({data_})\n\n    @md\n    @aliases {dim_}DataMap,{class_}-method\n    @exportMethod {dim_}DataMap\n    \",\n    ...\n)\n\n#' @export\nsetGeneric('rowDataMap', function(object, ...) standardGeneric('rowDataMap'))\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_get_dimDataMap(dim_='row', class_=.local_class_3,\n#' data_=.local_data_3)\nsetMethod('rowDataMap', signature(object='LongTableDataMapper'),\n        function(object) {\n    object@rowDataMap\n})\n\n#' @export\nsetGeneric('rowDataMap<-', function(object, ..., value)\n    standardGeneric('rowDataMap<-'))\n\n.docs_LongTableDataMapper_set_dimDataMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __{dim_}DataMap<-__: Update the `@{dim_}DataMap` slot of a `{class_}` object,\n    returning an invisible NULL. Arguments:\n    - value: A `list` or `List` where the first item is the names of the\n    identifier columns -- columns needed to uniquely identify each row in\n    {dim_}Data -- and the second item is the metadata associated with those\n    the identifier columns, but not required to uniquely identify rows in\n    the object rowData.\n\n    @examples\n    {dim_}DataMap({data_}) <- list(c('{id_col_}'), c())\n\n    @md\n    @aliases rowDataMap<-,{class_},list-method {dim_}DataMap<-{class_},List-method\n    @exportMethod {dim_}DataMap<-\n    \",\n    ...\n)\n\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_set_dimDataMap(dim_='row', class_=.local_class_3,\n#' data_=.local_data_3, id_col_='treatmentid')\nsetReplaceMethod('rowDataMap', signature(object='LongTableDataMapper',\n        value='list_OR_List'), function(object, value) {\n    funContext <- '[CoreGx::`rowDataMap<-`,LongTableDataMapper-method]\\n\\t'\n    rawdataCols <- colnames(rawdata(object))\n\n    # -- Handle error conditions\n    if (length(value) > 2) {\n        stop(.errorMsg(funContext, 'Assignments to rowDataMap should be a list ',\n            'of length 2, where the first item is the name of the id columns ',\n            'and the second item is the name of the metadata columns which ',\n            'map to those id columns.'))\n    }\n\n    hasIDcols <- value[[1]] %in% rawdataCols\n    if (!all(hasIDcols) && length(rawdata(object))) {\n        stop(.errorMsg(funContext, 'One or more of the id columns specified ',\n            'in value[[1]] are not valid column names in the rawdata slot of ',\n            'this ', class(object)[1], ' object!'))\n    }\n\n    if (length(value) > 1 && length(value[[2]]) != 0 && length(rawdata(object))) {\n        hasMetaCols <- value[[2]] %in% rawdataCols\n        if (!all(hasMetaCols)) {\n            stop(.errorMsg(funContext, 'The follow metadata columns in value[[2]] ',\n                'are not present in rawdata(object): ',\n                .collapse(value[[2]][!hasMetaCols]), '!'))\n        }\n        hasOneToOneRelationship <-\n            value[[2]] %in% cardinality(rawdata(object), group=value[[1]])\n        if (!all(hasOneToOneRelationship)) {\n            stop(.errorMsg(funContext, 'The columns ',\n                .collapse(value[[2]][!hasOneToOneRelationship], ' do not have a ',\n                '1:1 relationship with the specified ID columns!')))\n        }\n    }\n\n    # -- Function body\n    object@rowDataMap <- value\n    return(object)\n})\n\n\n##\n## -- rowData\n\n\n#' Convenience method to subset the `rowData` out of the `rawdata` slot using\n#'   the assigned `rowDataMap` metadata.\n#'\n#' @param x `LongTableDataMapper` object with valid data in the `rawdata` and\n#'   `colDataMap` slots.\n#' @param key `logical(1)` Should the table be keyed according to the\n#'   `id_columns` of the `rowDataMap` slot? This will sort the table in memory.\n#'   Default is TRUE.\n#'\n#' @return `data.table` The `rowData` as specified in the `rowDataMap` slot.\n#'\n#' @export\nsetMethod(\"rowData\", signature(\"LongTableDataMapper\"), function(x, key=TRUE) {\n    .get_dimData(x, key, dim=\"row\")\n})\n\n\n## --------------------\n## ---- colDataMap slot\n\n\n##\n## -- colDataMap\n\n#' @export\nsetGeneric('colDataMap', function(object, ...) standardGeneric('colDataMap'))\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_get_dimDataMap(dim_='col', class_=.local_class_3,\n#' data_=.local_data_3)\nsetMethod('colDataMap', signature(object='LongTableDataMapper'),\n        function(object) {\n    object@colDataMap\n})\n\n#' @export\nsetGeneric('colDataMap<-', function(object, ..., value) standardGeneric('colDataMap<-'))\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval\n#' .docs_LongTableDataMapper_set_dimDataMap(dim_='col', class_=.local_class_3,\n#' data_=.local_data_3, id_col_='sampleid')\nsetReplaceMethod('colDataMap',\n        signature(object='LongTableDataMapper', value='list_OR_List'),\n        function(object, value) {\n    funContext <- '[CoreGx::`colDataMap<-`,LongTableDataMapper-method]\\n\\t'\n    rawdataCols <- colnames(rawdata(object))\n\n    # -- Handle error conditions\n    if (length(value) > 2 || !is.list(value)) {\n        .error(funContext, 'Assignments to colDataMap should be a list ',\n            'of length 2, where the first item is the name of the id columns ',\n            'and the second item is the name of the metadata columns which ',\n            'map to those id columns.')\n    }\n\n    hasIDcols <- value[[1]] %in% rawdataCols\n    if (!all(hasIDcols) && length(rawdata(object))) {\n        .error(funContext, 'One or more of the id columns specified ',\n            'in value[[1]] are not valid column names in the rawdata slot of ',\n            'this ', class(object)[1], ' object!')\n    }\n\n    if (length(value) > 1 && length(value[[2]]) != 0 &&\n            length(rawdata(object))) {\n        hasMetaCols <- value[[2]] %in% rawdataCols\n        if (!all(hasMetaCols)) {\n            .error(funContext,\n                'The follow metadata columns in value[[2]] ',\n                'are not present in rawdata(object): ',\n                .collapse(value[[2]][!hasMetaCols]), '!')\n        }\n        hasOneToOneRelationship <-\n            value[[2]] %in% cardinality(rawdata(object), group=value[[1]])\n        if (!all(hasOneToOneRelationship)) {\n            .error(funContext, 'The columns ',\n                .collapse(value[[2]][!hasOneToOneRelationship]),\n                ' do not have a 1:1 relationship with the specified ID ',\n                'columns!')\n        }\n    }\n\n    # -- Function body\n    object@colDataMap <- value\n    return(object)\n})\n\n\n##\n## -- colData\n\n\n#' Convenience method to subset the `colData` out of the `rawdata` slot using\n#'   the assigned `colDataMap` metadata.\n#'\n#' @param x `LongTableDataMapper` object with valid data in the `rawdata` and\n#'   `colDataMap` slots.\n#' @param key `logical(1)` Should the table be keyed according to the\n#'   `id_columns` of the `colDataMap` slot? This will sort the table in memory.\n#'   Default is TRUE.\n#'\n#' @return `data.table` The `colData` as specified in the `colDataMap` slot.\n#'\n#' @export\nsetMethod(\"colData\", signature(\"LongTableDataMapper\"), function(x, key=TRUE) {\n    .get_dimData(x, key, dim=\"col\")\n})\n\n\n## ----------------\n## ---- assayMap slot\n\n\n#' @export\nsetGeneric('assayMap', function(object, ...) standardGeneric('assayMap'))\n\n.docs_LongTableDataMapper_get_assayMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __assayMap__:  A `list` of character vectors. The name of each list item\n    will be the assay in a `LongTableDataMapper` object that the columns in the\n    `character` vector will be assigned to. Column renaming occurs automatically\n    when the character vectors have names (from the value to the name).\n\n    @examples\n    assayMap({data_})\n\n    @md\n    @aliases assayMap,{class_},list-method assayMap,{class_},List-method\n    @exportMethod assayMap\n    \",\n    ...\n)\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_get_assayMap(class_=.local_class_3, data_=.local_data_3)\nsetMethod('assayMap', signature(object='LongTableDataMapper'),\n        function(object) {\n    object@assayMap\n})\n\n\n#' @export\nsetGeneric('assayMap<-', function(object, ..., value) standardGeneric('assayMap<-'))\n\n#' @noRd\n.docs_LongTableDataMapper_set_assayMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __assayMap<-__: Updates the `@assayMap` slot of a `{class_}` object,\n    returning an invisible NULL. Arguments:\n    - value:  A `list` of character vectors, where the name of each list\n    item is the name of an assay and the values of each character vector\n    specify the columns mapping to the assay in the `S4` object the\n    `{class_}` constructs.\n\n    @examples\n    assayMap({data_}) <- list(sensitivity=c(viability1='viability'))\n\n    @md\n    @aliases assayMap<-,{class_},list-method assayMap<-,{class_},List-methhod\n    @exportMethod assayMap<-\n    \",\n    ...\n)\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_set_assayMap(class_=.local_class_3, data_=.local_data_3)\nsetReplaceMethod('assayMap', signature(object='LongTableDataMapper',\n        value='list_OR_List'), function(object, value) {\n    funContext <- '[CoreGx::`assayMap<-,LongTableDataMapper-method`]\\n\\t'\n    rawdataCols <- colnames(rawdata(object))\n    if (length(names(value)) == 0) stop(.errorMsg('The value argument must\n        be a named list-like of column name character vectors!'))\n\n    for (i in seq_along(value)) {\n        hasRawdataCols <- unlist(value[[i]]) %in% rawdataCols\n        if (!all(hasRawdataCols) && length(rawdata(object))) {\n            stop(.errorMsg(funContext, 'There are no columns named ',\n                .collapse(unlist(value[[i]])[!hasRawdataCols]),\n                ' in the rawdata of this ', class(object)[1],\n                ' object. Please ensure item ',\n                names(value)[i], ' of value has valid column names.'))\n        }\n    }\n\n    object@assayMap <- value\n    return(object)\n})\n\n\n#' Extract the data for an assay from a `LongTableDataMapper`\n#'\n#' @param x `LongTableDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param i `character(1)` Name of an assay in the `assayMap` slot of `x`.\n#' @param withDimnames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `data.table` Data for the specified assay extracted from the\n#'   `rawdata` slot of `x`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assay\", signature(x=\"LongTableDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n\n    # Input validation\n    .assayMap <- assayMap(x)\n    assertCharacter(i, max.len=1)\n    assertSubset(i, names(.assayMap))\n\n    # Execution context\n    funContext <- paste0(\"\\n[\", getPackageName(), \"::assay,\", class(x)[1],\n        \"-method]\")\n\n    return(.get_dimDataFromMap(x, key=TRUE, .assayMap[[i]],\n        funContext=funContext))\n})\n\n\n#' Extract the data for all assays from a `LongTableDataMapper`\n#'\n#' @param x `LongTableDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param withDimNames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `list` Data for all assays extracted from the\n#'   `rawdata` slot of `x` as a `list` of `data.tables`, where the `keys` for\n#'   each table are their `id_columns`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assays\", signature(x=\"LongTableDataMapper\"),\n        function(x, withDimnames=TRUE) {\n    lapply(names(assayMap(x)), FUN=assay, x=x) |>\n        setNames(names(assayMap(x)))\n})\n\n# -- metadataMap\n\n\n#' @export\nsetGeneric('metadataMap', function(object, ...) standardGeneric('metadataMap'))\n\n#' @noRd\n.docs_LongTableDataMapper_get_metadataMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __metadataMap__:  A `list` of `character` vectors. Each item is an element\n    of the constructed objects `@metadata` slot.\n\n    @examples\n    metadataMap({data_})\n\n    @md\n    @aliases metadataMap,{class_}-method\n    @exportMethod metadataMap\n    \",\n    ...\n)\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_get_metadataMap(class_=.local_class_3, data_=.local_data_3)\nsetMethod('metadataMap', signature(object='LongTableDataMapper'),\n        function(object) {\n    object@metadataMap\n})\n\n\n#' @export\nsetGeneric('metadataMap<-', function(object, ..., value)\n    standardGeneric('metadataMap<-'))\n\n#' @noRd\n.docs_LongTableDataMapper_set_metadataMap <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __metadataMap<-__: Updates `{class_}` object in-place, then returns an\n    `invisible(NULL)`. Arguments:\n    - value:  A `list` of `character` vectors. The name of each list item\n    is the name of the item in the `@metadata` slot of the `{class_}` object\n    created when `metaConstruct` is called on the `DataMapper`, and a\n    character vector specifies the columns of `@rawdata` to assign to each item.\n\n    @examples\n    metadataMap({data_}) <- list(object_metadata=c('metadata'))\n\n    @md\n    @aliases metadataMap<-,{class_}-method\n    @exportMethod metadataMap<-\n    \",\n    ...\n)\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_LongTableDataMapper_set_metadataMap(class_=.local_class_3, data_=.local_data_3, col_='metadata')\nsetReplaceMethod('metadataMap', signature(object='LongTableDataMapper',\n    value='list_OR_List'), function(object, value) {\n    funContext <- '[CoreGx::`metadataMap<-,LongTableDataMapper-method`]\\n\\t'\n    rawdataCols <- colnames(rawdata(object))\n    if (length(names(value)) == 0) stop(.errorMsg('The value argument must\n        be a named list-like of column name character vectors!'))\n\n    for (i in seq_along(value)) {\n        hasRawdataCols <- value[[i]] %in% rawdataCols\n        if (!all(hasRawdataCols) && length(rawdata(object))) {\n            stop(.errorMsg(funContext, 'There are no columns named ',\n                .collapse(value[[i]][!hasRawdataCols]), ' in the rawdata ',\n                'of this ', class(object)[1], ' object. Please ensure item ',\n                names(value)[i], ' of value has valid column names.'))\n        }\n    }\n\n    object@metadataMap <- value\n    return(object)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.get_dimData` function in this code snippet?",
        "answer": "The `.get_dimData` function is an internal helper method used to subset the rawdata of a LongTableDataMapper object based on a specified dimension (row, column, or metadata). It retrieves the appropriate data map, validates inputs, and calls `.get_dimDataFromMap` to perform the actual subsetting."
      },
      {
        "question": "How does the `rowDataMap<-` method handle error conditions when assigning new values to the rowDataMap slot?",
        "answer": "The `rowDataMap<-` method checks for several error conditions: 1) It ensures the input value is a list of length 2 or less. 2) It verifies that all specified ID columns exist in the rawdata. 3) If metadata columns are provided, it checks that they exist in the rawdata and have a one-to-one relationship with the ID columns. If any of these conditions are not met, it throws an error with a descriptive message."
      },
      {
        "question": "What is the purpose of the `assay` method for LongTableDataMapper objects, and what does it return?",
        "answer": "The `assay` method for LongTableDataMapper objects is used to extract data for a specific assay from the rawdata slot according to the assayMap. It takes the object, an assay name, and an unused withDimnames parameter. The method validates inputs, retrieves the appropriate assay map, and returns a data.table containing the extracted assay data, with keys set to the ID columns."
      }
    ],
    "completion_tasks": [
      {
        "partial": "## ---------------\n## -- rawdata slot\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_DataMapper_set_rawdata(class_=.local_class_3,\n#' class1_='list')\nsetReplaceMethod('rawdata', signature=c(object='LongTableDataMapper',\n        value='list'), function(object, value) {\n    funContext <- .S4MethodContext('rawdata<-', class(object)[1],\n        class(value)[1])\n\n    rows <- unlist(rowDataMap(object))\n    cols <- unlist(colDataMap(object))\n    assays <- unlist(assayMap(object))\n    meta <- unlist(metadataMap(object))\n\n    mandatory <- c(rows, cols, assays, meta)\n    if (!length(mandatory) || !length(value)) {\n        object@rawdata <- value\n    } else if (length(mandatory) && !length(rawdata(object))) {\n        hasMandatory <- mandatory %in% colnames(value)\n        if (!all(hasMandatory)) {\n            stop(.errorMsg(funContext, \"One or more map column is missing from value\",\n                \": \", paste0(mandatory[!hasMandatory], collapse=', '), '!'))\n        }\n        object@rawdata <- value\n    } else {\n        stop(.errorMsg(funContext, \"In order to assign to the rawdata slot of \",\n            \"a LongTableDataMapper, either all the map slots must be \",\n            \"empty or the rawdata slot must be an empty list!\"))\n    }\n    return(object)\n})",
        "complete": "## ---------------\n## -- rawdata slot\n\n#' @rdname LongTableDataMapper-accessors\n#' @eval .docs_DataMapper_set_rawdata(class_=.local_class_3,\n#' class1_='list')\nsetReplaceMethod('rawdata', signature=c(object='LongTableDataMapper',\n        value='list'), function(object, value) {\n    funContext <- .S4MethodContext('rawdata<-', class(object)[1],\n        class(value)[1])\n\n    rows <- unlist(rowDataMap(object))\n    cols <- unlist(colDataMap(object))\n    assays <- unlist(assayMap(object))\n    meta <- unlist(metadataMap(object))\n\n    mandatory <- c(rows, cols, assays, meta)\n    if (!length(mandatory) || !length(value)) {\n        object@rawdata <- value\n    } else if (length(mandatory) && !length(rawdata(object))) {\n        hasMandatory <- mandatory %in% colnames(value)\n        if (!all(hasMandatory)) {\n            stop(.errorMsg(funContext, \"One or more map column is missing from value\",\n                \": \", paste0(mandatory[!hasMandatory], collapse=', '), '!'))\n        }\n        object@rawdata <- value\n    } else {\n        stop(.errorMsg(funContext, \"In order to assign to the rawdata slot of \",\n            \"a LongTableDataMapper, either all the map slots must be \",\n            \"empty or the rawdata slot must be an empty list!\"))\n    }\n    return(object)\n})"
      },
      {
        "partial": "#' Extract the data for an assay from a `LongTableDataMapper`\n#'\n#' @param x `LongTableDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param i `character(1)` Name of an assay in the `assayMap` slot of `x`.\n#' @param withDimnames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `data.table` Data for the specified assay extracted from the\n#'   `rawdata` slot of `x`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assay\", signature(x=\"LongTableDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n\n    # Input validation\n    .assayMap <- assayMap(x)\n    assertCharacter(i, max.len=1)\n    assertSubset(i, names(.assayMap))\n\n    # Execution context\n    funContext <- paste0(\"\\n[\", getPackageName(), \"::assay,\", class(x)[1],\n        \"-method]\")\n\n    return(.get_dimDataFromMap(x, key=TRUE, .assayMap[[i]],\n        funContext=funContext))\n})",
        "complete": "#' Extract the data for an assay from a `LongTableDataMapper`\n#'\n#' @param x `LongTableDataMapper` The object to retrive assay data form according\n#'   to the `assayMap` slot.\n#' @param i `character(1)` Name of an assay in the `assayMap` slot of `x`.\n#' @param withDimnames `logical(1)` For compatibility with\n#'   `SummarizedExperiment::assay` generic. Not used.\n#'\n#' @return `data.table` Data for the specified assay extracted from the\n#'   `rawdata` slot of `x`.\n#'\n#' @importFrom checkmate assertSubset assertCharacter\n#' @keywords internal\nsetMethod(\"assay\", signature(x=\"LongTableDataMapper\"),\n        function(x, i, withDimnames=TRUE) {\n\n    # Input validation\n    .assayMap <- assayMap(x)\n    assertCharacter(i, max.len=1)\n    assertSubset(i, names(.assayMap))\n\n    # Execution context\n    funContext <- paste0(\"\\n[\", getPackageName(), \"::assay,\", class(x)[1],\n        \"-method]\")\n\n    return(.get_dimDataFromMap(x, key=TRUE, .assayMap[[i]],\n        funContext=funContext))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/plotCurve.R",
    "language": "R",
    "content": "#' Plot radiation dose-response curve\n#'\n#' This function plots doses of radiation against the cancer cell survival fractions thereby observed.\n#'\n#' @examples plotCurve(c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n#'   c(1.1, 0.8, 0.7, 0.45, 0.15, -0.1, -0.1, -0.4, -0.65, -0.75, -1.1),\n#'   filename = NULL)\n#'\n#' @param D vector of radiation doses\n#' @param SF vector of survival fractions corresponding to the doses\n#' @param pars parameters (alpha, beta) in the equation SF = exp(-alpha * D - beta * D ^ 2)\n#' @param filename name of PDF which will be created by the function\n#' @param fit_curve should the graph include a linear-quadratic curve of best fit? Defaults to TRUE\n#' @param SF_as_log should SF be expressed in log10 on the graph? Defaults to TRUE\n#'\n#' @return \\code{nothing} Function works by side effects only\n#'\n#' @importFrom graphics lines plot points axis\n#' @importFrom grDevices dev.off pdf\n#'\n#' @export\nplotCurve <- function(D, SF, pars, filename = \"dose_response_plot.pdf\", fit_curve = TRUE, SF_as_log = TRUE) {\n  CoreGx::.sanitizeInput(x = D,\n                          y = SF,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  padding <- 1.1 # whitespace on graph around function range\n\n  if (fit_curve) {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D, SF))\n    } else {\n      CoreGx::.sanitizeInput(pars = pars,\n                              x_as_log = FALSE,\n                              y_as_log = FALSE,\n                              y_as_pct = FALSE,\n                              trunc = FALSE,\n                              verbose = FALSE)\n    }\n    message(paste0(\"A linear-quadratic curve was fit to the data with parameters alpha = \", pars[[1]], \" and beta = \", pars[[2]], \".\"))\n    trendlineDs <- CoreGx::.getSupportVec(D)\n    trendlineSFs <- .linearQuadratic(trendlineDs, pars = pars, SF_as_log = TRUE)\n  }\n\n  xlim <- range(D)\n  xlim <- mean(xlim) + padding * c((xlim[1] - mean(xlim)), xlim[2] - mean(xlim))\n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D,\n                                 y = SF,\n                                 x_to_log = FALSE,\n                                 y_to_log = TRUE,\n                                 y_to_frac = FALSE,\n                                 trunc = FALSE)\n    D <- DSF[[\"x\"]]\n    SF <- DSF[[\"y\"]]\n  }\n\n\n  if (TRUE) {\n    if (!missing(SF)) {\n      if (fit_curve) {\n        ylim <- padding * c(min(c(SF, trendlineSFs[length(trendlineSFs)])), 0)\n      } else {\n        ylim <- padding * c(min(SF), 0)\n      }\n    } else {\n      ylim <- padding * c(trendlineSFs[length(trendlineSFs)], 0)\n    }\n  } else {\n    ylim <- c(0, 1)\n  }\n\n  pdf(file = filename)\n\n  plot(NULL,\n       xlim = xlim,\n       ylim = ylim,\n       xlab = \"Dose (Gy)\",\n       ylab = \"Survival Fraction\",\n       col = \"red\",\n       yaxt=\"n\")\n\n  if (!missing(SF)) {\n    points(D, SF, col = \"red\", pch = 19)\n  }\n\n  if (missing(SF) || fit_curve) {\n    lines(trendlineDs, trendlineSFs, col = \"blue\", pch = 19)\n  }\n\n  ticks <- CoreGx::.getSupportVec(x=signif(ylim,1), 10)\n  labels <- unlist(lapply(ticks, function(i) as.expression(bquote(10^ .(round(i, 2))))))\n  axis(2, at=ticks, labels=labels)\n  dev.off()\n\n  return(invisible(0))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `plotCurve` function and what are its main input parameters?",
        "answer": "The `plotCurve` function is designed to plot radiation dose-response curves. It takes vectors of radiation doses (D) and corresponding survival fractions (SF) as main inputs. Optional parameters include `pars` for curve fitting, `filename` for output, `fit_curve` to toggle curve fitting, and `SF_as_log` to control y-axis scaling."
      },
      {
        "question": "How does the function handle the y-axis (Survival Fraction) representation, and what method is used for curve fitting?",
        "answer": "The function represents the Survival Fraction (SF) on a logarithmic scale by default (SF_as_log = TRUE). For curve fitting, it uses a linear-quadratic model, defined by the equation SF = exp(-alpha * D - beta * D^2). The `linearQuadraticModel` function is used to calculate the parameters (alpha and beta) if not provided."
      },
      {
        "question": "What are the side effects of the `plotCurve` function, and how does it handle input sanitization?",
        "answer": "The main side effect of `plotCurve` is creating a PDF file with the plot. It doesn't return any value (returns invisible(0)). For input sanitization, it uses the `CoreGx::.sanitizeInput` function to check and process the input data (D and SF vectors, and pars if provided) before plotting. This ensures the input is in the correct format and range for plotting."
      }
    ],
    "completion_tasks": [
      {
        "partial": "plotCurve <- function(D, SF, pars, filename = \"dose_response_plot.pdf\", fit_curve = TRUE, SF_as_log = TRUE) {\n  CoreGx::.sanitizeInput(x = D,\n                          y = SF,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  padding <- 1.1\n\n  if (fit_curve) {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D, SF))\n    } else {\n      CoreGx::.sanitizeInput(pars = pars,\n                              x_as_log = FALSE,\n                              y_as_log = FALSE,\n                              y_as_pct = FALSE,\n                              trunc = FALSE,\n                              verbose = FALSE)\n    }\n    message(paste0(\"A linear-quadratic curve was fit to the data with parameters alpha = \", pars[[1]], \" and beta = \", pars[[2]], \".\"))\n    trendlineDs <- CoreGx::.getSupportVec(D)\n    trendlineSFs <- .linearQuadratic(trendlineDs, pars = pars, SF_as_log = TRUE)\n  }\n\n  # Complete the function by adding code to plot the data and save it as a PDF\n}",
        "complete": "plotCurve <- function(D, SF, pars, filename = \"dose_response_plot.pdf\", fit_curve = TRUE, SF_as_log = TRUE) {\n  CoreGx::.sanitizeInput(x = D,\n                          y = SF,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  padding <- 1.1\n\n  if (fit_curve) {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D, SF))\n    } else {\n      CoreGx::.sanitizeInput(pars = pars,\n                              x_as_log = FALSE,\n                              y_as_log = FALSE,\n                              y_as_pct = FALSE,\n                              trunc = FALSE,\n                              verbose = FALSE)\n    }\n    message(paste0(\"A linear-quadratic curve was fit to the data with parameters alpha = \", pars[[1]], \" and beta = \", pars[[2]], \".\"))\n    trendlineDs <- CoreGx::.getSupportVec(D)\n    trendlineSFs <- .linearQuadratic(trendlineDs, pars = pars, SF_as_log = TRUE)\n  }\n\n  xlim <- range(D)\n  xlim <- mean(xlim) + padding * c((xlim[1] - mean(xlim)), xlim[2] - mean(xlim))\n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = FALSE)\n    D <- DSF[\"x\"]\n    SF <- DSF[\"y\"]\n  }\n\n  ylim <- if (SF_as_log) {\n    if (!missing(SF)) {\n      if (fit_curve) padding * c(min(c(SF, trendlineSFs[length(trendlineSFs)])), 0) else padding * c(min(SF), 0)\n    } else {\n      padding * c(trendlineSFs[length(trendlineSFs)], 0)\n    }\n  } else {\n    c(0, 1)\n  }\n\n  pdf(file = filename)\n  plot(NULL, xlim = xlim, ylim = ylim, xlab = \"Dose (Gy)\", ylab = \"Survival Fraction\", col = \"red\", yaxt = \"n\")\n  if (!missing(SF)) points(D, SF, col = \"red\", pch = 19)\n  if (missing(SF) || fit_curve) lines(trendlineDs, trendlineSFs, col = \"blue\", pch = 19)\n  ticks <- CoreGx::.getSupportVec(x = signif(ylim, 1), 10)\n  labels <- lapply(ticks, function(i) as.expression(bquote(10^.(round(i, 2)))))\n  axis(2, at = ticks, labels = labels)\n  dev.off()\n\n  invisible(0)\n}"
      },
      {
        "partial": "plotCurve <- function(D, SF, pars, filename = \"dose_response_plot.pdf\", fit_curve = TRUE, SF_as_log = TRUE) {\n  # Add input sanitization and parameter initialization here\n\n  # Calculate xlim and ylim\n  xlim <- range(D)\n  xlim <- mean(xlim) + padding * c((xlim[1] - mean(xlim)), xlim[2] - mean(xlim))\n  \n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = FALSE)\n    D <- DSF[\"x\"]\n    SF <- DSF[\"y\"]\n  }\n\n  ylim <- if (SF_as_log) {\n    # Calculate ylim based on SF_as_log condition\n  } else {\n    c(0, 1)\n  }\n\n  # Complete the function by adding code to create the plot and save it as a PDF\n}",
        "complete": "plotCurve <- function(D, SF, pars, filename = \"dose_response_plot.pdf\", fit_curve = TRUE, SF_as_log = TRUE) {\n  CoreGx::.sanitizeInput(x = D, y = SF, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = FALSE, verbose = FALSE)\n  padding <- 1.1\n\n  if (fit_curve) {\n    if (missing(pars)) {\n      pars <- unlist(linearQuadraticModel(D, SF))\n    } else {\n      CoreGx::.sanitizeInput(pars = pars, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = FALSE, verbose = FALSE)\n    }\n    message(paste0(\"A linear-quadratic curve was fit to the data with parameters alpha = \", pars[[1]], \" and beta = \", pars[[2]], \".\"))\n    trendlineDs <- CoreGx::.getSupportVec(D)\n    trendlineSFs <- .linearQuadratic(trendlineDs, pars = pars, SF_as_log = TRUE)\n  }\n\n  xlim <- range(D)\n  xlim <- mean(xlim) + padding * c((xlim[1] - mean(xlim)), xlim[2] - mean(xlim))\n  \n  if (!missing(SF)) {\n    DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = FALSE)\n    D <- DSF[\"x\"]\n    SF <- DSF[\"y\"]\n  }\n\n  ylim <- if (SF_as_log) {\n    if (!missing(SF)) {\n      if (fit_curve) padding * c(min(c(SF, trendlineSFs[length(trendlineSFs)])), 0) else padding * c(min(SF), 0)\n    } else {\n      padding * c(trendlineSFs[length(trendlineSFs)], 0)\n    }\n  } else {\n    c(0, 1)\n  }\n\n  pdf(file = filename)\n  plot(NULL, xlim = xlim, ylim = ylim, xlab = \"Dose (Gy)\", ylab = \"Survival Fraction\", col = \"red\", yaxt = \"n\")\n  if (!missing(SF)) points(D, SF, col = \"red\", pch = 19)\n  if (missing(SF) || fit_curve) lines(trendlineDs, trendlineSFs, col = \"blue\", pch = 19)\n  ticks <- CoreGx::.getSupportVec(x = signif(ylim, 1), 10)\n  labels <- lapply(ticks, function(i) as.expression(bquote(10^.(round(i, 2)))))\n  axis(2, at = ticks, labels = labels)\n  dev.off()\n\n  invisible(0)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/summarizeSensitivityProfiles-methods.R",
    "language": "R",
    "content": "#' Takes the sensitivity data from a RadioSet, and summarises them into a\n#' drug vs cell line table\n#'\n#' This function creates a table with cell lines as rows and radiation types as columns,\n#' summarising the drug senstitivity data of a RadioSet into drug-cell line\n#' pairs\n#'\n#' @examples\n#' data(clevelandSmall)\n#' GDSCauc <- summarizeSensitivityProfiles(clevelandSmall, sensitivity.measure='AUC_published')\n#'\n#' @param object `RadioSet` The RadioSet from which to extract the data\n#' @param sensitivity.measure `character` which sensitivity sensitivity.measure to use? Use the\n#'   sensitivityMeasures function to find out what measures are available for each PSet.\n#' @param cell.lines `character` The cell lines to be summarized.\n#'    If any cell lines has no data, it will be filled with\n#'   missing values\n#' @param radiation.types `character` The radiation types to be summarized.\n#'   If any radiation type has no data, it will be filled with\n#'   missing values\n#' @param summary.stat `character` which summary method to use if there are repeated\n#'   cell line-drug experiments? Choices are \"mean\", \"median\", \"first\", or \"last\"\n#' @param fill.missing `logical(1)` should the missing cell lines not in the\n#'   molecular data object be filled in with missing values?\n#' @param verbose Should the function print progress messages?\n#'\n#' @return [matrix] A matrix with cell lines going down the rows, radiation types across\n#'   the columns, with the selected sensitivity statistic for each pair.\n#'\n#' @importMethodsFrom CoreGx summarizeSensitivityProfiles\n#' @export\nsetMethod('summarizeSensitivityProfiles',\n          signature(object=\"RadioSet\"),\n          function(object, sensitivity.measure=\"AUC_recomputed\", cell.lines, radiation.types,\n                   summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"), fill.missing=TRUE,\n                   verbose=TRUE) {\n            .summarizeSensitivityProfilesRadioSet(\n              object, sensitivity.measure, cell.lines, radiation.types, summary.stat, fill.missing, verbose\n            )\n          })\n\n# Takes the sensitivity data from a RadioSet, and summarises them into a\n# drug vs cell line table\n#\n# This function creates a table with cell lines as rows and radiation types as columns,\n# summarising the drug senstitivity data of a RadioSet into drug-cell line\n# pairs\n#\n# @examples\n# data(clevelandSmall)\n# GDSCauc <- summarizeSensitivityProfiles(clevelandSmall, sensitivity.measure='AUC_published')\n#\n# @param object [RadioSet] The RadioSet from which to extract the data\n# @param sensitivity.measure `character` which sensitivity sensitivity.measure to use? Use the\n#   sensitivityMeasures function to find out what measures are available for each PSet.\n# @param cell.lines \\code{character} The cell lines to be summarized.\n#    If any cell lines has no data, it will be filled with\n#   missing values\n# @param radiation.types \\code{character} The radiation types to be summarized.\n#   If any radiation type has no data, it will be filled with\n#   missing values\n# @param summary.stat \\code{character} which summary method to use if there are repeated\n#   cell line-drug experiments? Choices are \"mean\", \"median\", \"first\", or \"last\"\n# @param fill.missing \\code{boolean} should the missing cell lines not in the\n#   molecular data object be filled in with missing values?\n# @param verbose Should the function print progress messages?\n#\n# @return [matrix] A matrix with cell lines going down the rows, radiation types across\n#   the columns, with the selected sensitivity statistic for each pair.\n#\n#' @importFrom utils setTxtProgressBar txtProgressBar\n#' @importFrom stats median\n#' @importFrom reshape2 acast\n#' @keywords internal\n.summarizeSensitivityProfilesRadioSet <- function(\n  object,\n  sensitivity.measure=\"AUC_recomputed\",\n  cell.lines,\n  radiation.types,\n  summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"),\n  fill.missing=TRUE,\n  verbose=TRUE)\n{\n\tsummary.stat <- match.arg(summary.stat)\n  #sensitivity.measure <- match.arg(sensitivity.measure)\n  if (!(sensitivity.measure %in% c(colnames(sensitivityProfiles(object)),\"max.conc\"))) {\n    stop (sprintf(\"Invalid sensitivity measure for %s, choose among: %s\",\n                  annotation(object)$name,\n                  paste(colnames(sensitivityProfiles(object)),\n                        collapse=\", \")))\n  }\n  if (missing(cell.lines)) {\n    cell.lines <- sampleNames(object)\n  }\n  if (missing(radiation.types)) {\n    if (sensitivity.measure != \"Synergy_score\")\n    {\n      radTypes <- treatmentNames(object)\n    }else{\n      radTypes <- sensitivityInfo(object)[grep(\"///\",\n                                             sensitivityInfo(object)$treatmentid),\n                                        \"treatmentid\"]\n    }\n  }\n\n  pp <- sensitivityInfo(object)\n  ##FIXME: deal with duplicated rownames!\n  ppRows <- which(pp$sampleid %in% cell.lines & pp$treatmentid %in% radTypes)\n  if(sensitivity.measure != \"max.conc\") {\n    dd <- sensitivityProfiles(object)\n  } else {\n\n    if(!\"max.conc\"%in% colnames(sensitivityInfo(object))){\n\n      object <- updateMaxConc(object)\n\n    }\n    dd <- sensitivityInfo(object)\n\n  }\n\n  result <- matrix(NA_real_, nrow=length(radTypes), ncol=length(cell.lines))\n  rownames(result) <- radTypes\n  colnames(result) <- cell.lines\n\n  pp_dd <- cbind(pp[,c(\"sampleid\", \"treatmentid\")],\n                 \"sensitivity.measure\"=dd[, sensitivity.measure])\n\n  summary.function <- function(x) {\n    if(all(is.na(x))){\n      return(NA_real_)\n    }\n    switch(summary.stat,\n        \"mean\" = {\n          return(mean(as.numeric(x), na.rm=TRUE))\n        },\n        \"median\" = {\n          return(median(as.numeric(x), na.rm=TRUE))\n        },\n        \"first\" = {\n          return(as.numeric(x)[[1]])\n        },\n        \"last\" = {\n          return(as.numeric(x)[[length(x)]])\n        },\n        \"max\"= {\n          return(max(as.numeric(x), na.rm=TRUE))\n        },\n        \"min\" = {\n          return(min(as.numeric(x), na.rm=TRUE))\n        })\n  }\n\n  pp_dd <- pp_dd[pp_dd[,\"sampleid\"]%in%cell.lines &\n                   pp_dd[,\"treatmentid\"]%in%radTypes,]\n\n  tt <- reshape2::acast(pp_dd, treatmentid~sampleid,\n                        fun.aggregate=summary.function,\n                        value.var=\"sensitivity.measure\")\n\n  result[rownames(tt), colnames(tt)] <- tt\n\n\tif (!fill.missing) {\n    myRows <- apply(result, 1, function(x) !all(is.na(x)))\n    myCols <- apply(result, 2, function(x) !all(is.na(x)))\n    result <- result[myRows, myCols]\n\t}\n  return(result)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `summarizeSensitivityProfiles` function in the given code snippet?",
        "answer": "The `summarizeSensitivityProfiles` function is designed to create a summary table of drug sensitivity data from a RadioSet object. It generates a matrix with cell lines as rows and radiation types as columns, summarizing the drug sensitivity data into drug-cell line pairs. The function allows users to specify various parameters such as the sensitivity measure, cell lines, radiation types, and summary statistics to customize the output."
      },
      {
        "question": "How does the function handle missing data in the sensitivity profiles?",
        "answer": "The function handles missing data in several ways: 1) If any specified cell lines or radiation types have no data, they are filled with missing values (NA). 2) The `fill.missing` parameter determines whether missing cell lines not in the molecular data object should be filled with missing values. 3) When summarizing repeated cell line-drug experiments, the function uses the specified `summary.stat` (e.g., mean, median, first, last) to aggregate the data, ignoring NA values when possible."
      },
      {
        "question": "What is the significance of the `@importMethodsFrom CoreGx summarizeSensitivityProfiles` line in the code?",
        "answer": "The `@importMethodsFrom CoreGx summarizeSensitivityProfiles` line is an Roxygen2 documentation tag that indicates the function is importing the `summarizeSensitivityProfiles` method from the `CoreGx` package. This suggests that the current implementation is extending or overriding a method from the `CoreGx` package, specifically for objects of class 'RadioSet'. It's part of the S4 object-oriented system in R, where methods can be defined for specific classes."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('summarizeSensitivityProfiles',\n          signature(object=\"RadioSet\"),\n          function(object, sensitivity.measure=\"AUC_recomputed\", cell.lines, radiation.types,\n                   summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"), fill.missing=TRUE,\n                   verbose=TRUE) {\n            # Complete the function body\n          })",
        "complete": "setMethod('summarizeSensitivityProfiles',\n          signature(object=\"RadioSet\"),\n          function(object, sensitivity.measure=\"AUC_recomputed\", cell.lines, radiation.types,\n                   summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"), fill.missing=TRUE,\n                   verbose=TRUE) {\n            .summarizeSensitivityProfilesRadioSet(\n              object, sensitivity.measure, cell.lines, radiation.types, summary.stat, fill.missing, verbose\n            )\n          })"
      },
      {
        "partial": ".summarizeSensitivityProfilesRadioSet <- function(\n  object,\n  sensitivity.measure=\"AUC_recomputed\",\n  cell.lines,\n  radiation.types,\n  summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"),\n  fill.missing=TRUE,\n  verbose=TRUE\n) {\n  summary.stat <- match.arg(summary.stat)\n  if (!(sensitivity.measure %in% c(colnames(sensitivityProfiles(object)),\"max.conc\"))) {\n    stop(sprintf(\"Invalid sensitivity measure for %s, choose among: %s\",\n                 annotation(object)$name,\n                 paste(colnames(sensitivityProfiles(object)), collapse=\", \")))\n  }\n  # Complete the rest of the function\n}",
        "complete": ".summarizeSensitivityProfilesRadioSet <- function(\n  object,\n  sensitivity.measure=\"AUC_recomputed\",\n  cell.lines,\n  radiation.types,\n  summary.stat=c(\"mean\", \"median\", \"first\", \"last\", \"max\", \"min\"),\n  fill.missing=TRUE,\n  verbose=TRUE\n) {\n  summary.stat <- match.arg(summary.stat)\n  if (!(sensitivity.measure %in% c(colnames(sensitivityProfiles(object)),\"max.conc\"))) {\n    stop(sprintf(\"Invalid sensitivity measure for %s, choose among: %s\",\n                 annotation(object)$name,\n                 paste(colnames(sensitivityProfiles(object)), collapse=\", \")))\n  }\n  if (missing(cell.lines)) cell.lines <- sampleNames(object)\n  if (missing(radiation.types)) {\n    radTypes <- if(sensitivity.measure != \"Synergy_score\") treatmentNames(object) else sensitivityInfo(object)[grep(\"///\", sensitivityInfo(object)$treatmentid), \"treatmentid\"]\n  }\n  pp <- sensitivityInfo(object)\n  ppRows <- which(pp$sampleid %in% cell.lines & pp$treatmentid %in% radTypes)\n  dd <- if(sensitivity.measure != \"max.conc\") sensitivityProfiles(object) else {\n    if(!\"max.conc\" %in% colnames(sensitivityInfo(object))) object <- updateMaxConc(object)\n    sensitivityInfo(object)\n  }\n  result <- matrix(NA_real_, nrow=length(radTypes), ncol=length(cell.lines), dimnames=list(radTypes, cell.lines))\n  pp_dd <- cbind(pp[,c(\"sampleid\", \"treatmentid\")], \"sensitivity.measure\"=dd[, sensitivity.measure])\n  summary.function <- function(x) {\n    if(all(is.na(x))) return(NA_real_)\n    switch(summary.stat,\n           mean = mean(as.numeric(x), na.rm=TRUE),\n           median = median(as.numeric(x), na.rm=TRUE),\n           first = as.numeric(x)[[1]],\n           last = as.numeric(x)[[length(x)]],\n           max = max(as.numeric(x), na.rm=TRUE),\n           min = min(as.numeric(x), na.rm=TRUE))\n  }\n  pp_dd <- pp_dd[pp_dd[,\"sampleid\"] %in% cell.lines & pp_dd[,\"treatmentid\"] %in% radTypes,]\n  tt <- reshape2::acast(pp_dd, treatmentid~sampleid, fun.aggregate=summary.function, value.var=\"sensitivity.measure\")\n  result[rownames(tt), colnames(tt)] <- tt\n  if (!fill.missing) {\n    myRows <- apply(result, 1, function(x) !all(is.na(x)))\n    myCols <- apply(result, 2, function(x) !all(is.na(x)))\n    result <- result[myRows, myCols]\n  }\n  return(result)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/TreatmentResponseExperiment-class.R",
    "language": "R",
    "content": "#' @include LongTable-class.R\n#' @noRd\nNULL\n\n#' @title TreatmentResponseExperiment class definition\n#'\n#' @description Define a private constructor method to be used to build a\n#'   `TreatmentResponseExperiment` object.\n#'\n#' @slot rowData See Slots section.\n#' @slot colData See Slots section.\n#' @slot assays See Slots section.\n#' @slot metadata See Slots section.\n#' @slot .intern See Slots section.\n#'\n#' @section Slots:\n#' - *rowData*: A `data.table` containing the metadata associated with the\n#'   row dimension of a `TreatmentResponseExperiment`.\n#' - *colData*: A `data.table` containing the metadata associated with the\n#'   column dimension of a `TreatmentResponseExperiment`.\n#' - *assays*: A `list` of `data.table`s, one for each assay in a\n#'   `TreatmentResponseExperiment`.\n#' - *metadata*: An optional `list` of additional metadata for a\n#'   `TreatmentResponseExperiment` which doesn't map to one of the dimensions.\n#' - *.intern*: An `environment` that holds internal structural metadata\n#'   about a `TreatmentResponseExperiment` object, such as which columns are\n#'   required to key the object. An environment has been used to allow locking\n#'   items, which can prevent accidental modification of a property required\n#'   for the class to work.\n#'\n#' @return `TreatmentResponseExperiment` object containing the assay data from\n#'   a treatment response experiment\n#'\n#' @md\n#' @import data.table\n#' @keywords internal\n#' @rdname TreatmentResponseExperiment-class\n#' @aliases .TreatmentResponseExperiment\n#' @exportClass TreatmentResponseExperiment\n.TreatmentResponseExperiment <- setClass(\"TreatmentResponseExperiment\",\n    contains=\"LongTable\")\n\n\n#' @title TreatmentResponseExperiment constructor method\n#'\n#' @rdname TreatmentResponseExperiment\n#'\n#' @description Builds a `TreatmentResponseExperiment` object from rectangular\n#' objects. The `rowData` argument should contain row level metadata, while\n#' the `colData` argument should contain column level metadata, for the\n#' experimental assays\n#' in the `assays` list. The `rowIDs` and `colIDs` lists are used to configure\n#' the internal keys mapping rows or columns to rows in the assays. Each list\n#' should contain at minimum one character vector, specifying which columns\n#' in `rowData` or `colData` are required to uniquely identify each row. An\n#' optional second character vector can be included, specifying any metadata\n#' columns for either dimension. These should contain information about each\n#' row but NOT be required to uniquely identify a row in the `colData` or\n#' `rowData` objects. Additional metadata can be attached to a\n#' `TreatmentResponseExperiment` by passing a list to the metadata argument.\n#'\n#' @details\n#' For now this class is simply a wrapper around a `LongTable` class. In the\n#' future we plan to refactor CoreGx such that the `LongTable` class is in a\n#' separate pacakge. We can then specialize the implementation of\n#' `TreatmentResponseExperiment` to better capture the biomedical nature of\n#' this object.\n#'\n#' @param rowData `data.table`, `data.frame`, `matrix` A table like object\n#'   coercible to a `data.table` containing the a unique `rowID` column which\n#'   is used to key assays, as well as additional row metadata to subset on.\n#' @param rowIDs `character`, `integer` A vector specifying\n#'   the names or integer indexes of the row data identifier columns. These\n#'   columns will be pasted together to make up the rownames of the\n#'   `TreatmentResponseExperiment` object.\n#' @param colData `data.table`, `data.frame`, `matrix` A table like object\n#'   coercible to a `data.table` containing the a unique `colID` column which\n#'   is used to key assays, as well as additional column metadata to subset on.\n#' @param colIDs `character`, `integer` A vector specifying\n#'   the names or integer indexes of the column data identifier columns. These\n#'   columns will be pasted together to make up the colnames of the\n#'   `TreatmentResponseExperiment` object.\n#' @param assayIDs `list` A list of `character` vectors specifying the columns\n#'   needed to uniquely identify each row in an `assay`. Names must match the\n#'   `assays` list.\n#' @param assays A `list` containing one or more objects coercible to a\n#'   `data.table`, and keyed by rowIDs and colIDs corresponding to the rowID and\n#'   colID columns in colData and rowData.\n#' @param metadata A `list` of metadata associated with the\n#'   `TreatmentResponseExperiment` object being constructed\n#' @param keep.rownames `logical`, `character`\n#'   Logical: whether rownames should be added as a column if coercing to a\n#'   `data.table`, default is FALSE. If TRUE, rownames are added to the column\n#'   'rn'.\n#'   Character: specify a custom column name to store the rownames in.\n#'\n#' @return A `TreatmentResponseExperiment` object containing the data for a\n#'   treatment response experiment configured according to the rowIDs and\n#'   colIDs arguments.\n#'\n#'\n#' @import data.table\n#' @export\nTreatmentResponseExperiment <- function(rowData, rowIDs, colData, colIDs,\n        assays, assayIDs, metadata=list(), keep.rownames=FALSE) {\n    if (!missing(rowData) && is(rowData, \"LongTable\")) {\n        LT <- rowData\n    } else {\n        LT <- LongTable(rowData=rowData, rowIDs=rowIDs, colData=colData,\n            colIDs=colIDs, assays=assays, assayIDs=assayIDs, metadata=metadata,\n            keep.rownames=keep.rownames)\n    }\n    .TreatmentResponseExperiment(\n        rowData=LT@rowData,\n        colData=LT@colData,\n        assays=LT@assays,\n        .intern=LT@.intern,\n        metadata=LT@metadata\n    )\n}\n\n#' @name as\n#'\n#' @title\n#' Coerce a `LongTable` to a `TreatmentResponseExperiment`\n#'\n#' @param from `LongTable` object to coerce to a `TreatmentResponseExperiment`.\n#'\n#' @return The data in `object`, as the child-class\n#'   `TreatmentResponseExperiment`.\n#'\n#' @seealso [`TreatmentResponseExperiment`]\n#'\n#' @examples\n#' data(clevelandSmall_cSet)\n#' TRE <- as(treatmentResponse(clevelandSmall_cSet),\n#'     \"TreatmentResponseExperiment\")\n#' TRE\n#'\n#' @md\n#' @export\nsetAs(\"LongTable\", \"TreatmentResponseExperiment\", function(from) {\n    TreatmentResponseExperiment(from)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `TreatmentResponseExperiment` class and how does it relate to the `LongTable` class?",
        "answer": "The `TreatmentResponseExperiment` class is designed to represent data from treatment response experiments. It is currently implemented as a wrapper around the `LongTable` class, with plans to refactor it in the future to better capture the biomedical nature of the data. The class contains slots for rowData, colData, assays, metadata, and internal structural metadata."
      },
      {
        "question": "Explain the purpose of the `rowIDs` and `colIDs` parameters in the `TreatmentResponseExperiment` constructor function.",
        "answer": "The `rowIDs` and `colIDs` parameters in the `TreatmentResponseExperiment` constructor function are used to configure the internal keys mapping rows or columns to rows in the assays. They should be character vectors specifying which columns in `rowData` or `colData` are required to uniquely identify each row. These columns will be pasted together to make up the rownames and colnames of the `TreatmentResponseExperiment` object, respectively."
      },
      {
        "question": "How can a `LongTable` object be coerced into a `TreatmentResponseExperiment` object?",
        "answer": "A `LongTable` object can be coerced into a `TreatmentResponseExperiment` object using the `as()` function. The code defines a method for this coercion using `setAs()`. To perform the coercion, you would use: `as(longTableObject, \"TreatmentResponseExperiment\")`. This will create a new `TreatmentResponseExperiment` object containing the data from the `LongTable` object."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' @title TreatmentResponseExperiment class definition\n#'\n#' @description Define a private constructor method to be used to build a\n#'   `TreatmentResponseExperiment` object.\n#'\n#' @slot rowData See Slots section.\n#' @slot colData See Slots section.\n#' @slot assays See Slots section.\n#' @slot metadata See Slots section.\n#' @slot .intern See Slots section.\n#'\n#' @section Slots:\n#' - *rowData*: A `data.table` containing the metadata associated with the\n#'   row dimension of a `TreatmentResponseExperiment`.\n#' - *colData*: A `data.table` containing the metadata associated with the\n#'   column dimension of a `TreatmentResponseExperiment`.\n#' - *assays*: A `list` of `data.table`s, one for each assay in a\n#'   `TreatmentResponseExperiment`.\n#' - *metadata*: An optional `list` of additional metadata for a\n#'   `TreatmentResponseExperiment` which doesn't map to one of the dimensions.\n#' - *.intern*: An `environment` that holds internal structural metadata\n#'   about a `TreatmentResponseExperiment` object, such as which columns are\n#'   required to key the object. An environment has been used to allow locking\n#'   items, which can prevent accidental modification of a property required\n#'   for the class to work.\n#'\n#' @return `TreatmentResponseExperiment` object containing the assay data from\n#'   a treatment response experiment\n#'\n#' @md\n#' @import data.table\n#' @keywords internal\n#' @rdname TreatmentResponseExperiment-class\n#' @aliases .TreatmentResponseExperiment\n#' @exportClass TreatmentResponseExperiment\n.TreatmentResponseExperiment <- setClass(\"TreatmentResponseExperiment\",\n    contains=\"LongTable\")\n\n# Complete the constructor method",
        "complete": "#' @title TreatmentResponseExperiment class definition\n#'\n#' @description Define a private constructor method to be used to build a\n#'   `TreatmentResponseExperiment` object.\n#'\n#' @slot rowData See Slots section.\n#' @slot colData See Slots section.\n#' @slot assays See Slots section.\n#' @slot metadata See Slots section.\n#' @slot .intern See Slots section.\n#'\n#' @section Slots:\n#' - *rowData*: A `data.table` containing the metadata associated with the\n#'   row dimension of a `TreatmentResponseExperiment`.\n#' - *colData*: A `data.table` containing the metadata associated with the\n#'   column dimension of a `TreatmentResponseExperiment`.\n#' - *assays*: A `list` of `data.table`s, one for each assay in a\n#'   `TreatmentResponseExperiment`.\n#' - *metadata*: An optional `list` of additional metadata for a\n#'   `TreatmentResponseExperiment` which doesn't map to one of the dimensions.\n#' - *.intern*: An `environment` that holds internal structural metadata\n#'   about a `TreatmentResponseExperiment` object, such as which columns are\n#'   required to key the object. An environment has been used to allow locking\n#'   items, which can prevent accidental modification of a property required\n#'   for the class to work.\n#'\n#' @return `TreatmentResponseExperiment` object containing the assay data from\n#'   a treatment response experiment\n#'\n#' @md\n#' @import data.table\n#' @keywords internal\n#' @rdname TreatmentResponseExperiment-class\n#' @aliases .TreatmentResponseExperiment\n#' @exportClass TreatmentResponseExperiment\n.TreatmentResponseExperiment <- setClass(\"TreatmentResponseExperiment\",\n    contains=\"LongTable\")\n\n#' @title TreatmentResponseExperiment constructor method\n#'\n#' @rdname TreatmentResponseExperiment\n#'\n#' @description Builds a `TreatmentResponseExperiment` object from rectangular\n#' objects. The `rowData` argument should contain row level metadata, while\n#' the `colData` argument should contain column level metadata, for the\n#' experimental assays in the `assays` list.\n#'\n#' @param rowData `data.table`, `data.frame`, `matrix` A table like object\n#'   coercible to a `data.table` containing the a unique `rowID` column which\n#'   is used to key assays, as well as additional row metadata to subset on.\n#' @param rowIDs `character`, `integer` A vector specifying\n#'   the names or integer indexes of the row data identifier columns.\n#' @param colData `data.table`, `data.frame`, `matrix` A table like object\n#'   coercible to a `data.table` containing the a unique `colID` column which\n#'   is used to key assays, as well as additional column metadata to subset on.\n#' @param colIDs `character`, `integer` A vector specifying\n#'   the names or integer indexes of the column data identifier columns.\n#' @param assayIDs `list` A list of `character` vectors specifying the columns\n#'   needed to uniquely identify each row in an `assay`. Names must match the\n#'   `assays` list.\n#' @param assays A `list` containing one or more objects coercible to a\n#'   `data.table`, and keyed by rowIDs and colIDs corresponding to the rowID and\n#'   colID columns in colData and rowData.\n#' @param metadata A `list` of metadata associated with the\n#'   `TreatmentResponseExperiment` object being constructed\n#' @param keep.rownames `logical`, `character`\n#'   Logical: whether rownames should be added as a column if coercing to a\n#'   `data.table`, default is FALSE. If TRUE, rownames are added to the column\n#'   'rn'.\n#'   Character: specify a custom column name to store the rownames in.\n#'\n#' @return A `TreatmentResponseExperiment` object containing the data for a\n#'   treatment response experiment configured according to the rowIDs and\n#'   colIDs arguments.\n#'\n#' @import data.table\n#' @export\nTreatmentResponseExperiment <- function(rowData, rowIDs, colData, colIDs,\n        assays, assayIDs, metadata=list(), keep.rownames=FALSE) {\n    if (!missing(rowData) && is(rowData, \"LongTable\")) {\n        LT <- rowData\n    } else {\n        LT <- LongTable(rowData=rowData, rowIDs=rowIDs, colData=colData,\n            colIDs=colIDs, assays=assays, assayIDs=assayIDs, metadata=metadata,\n            keep.rownames=keep.rownames)\n    }\n    .TreatmentResponseExperiment(\n        rowData=LT@rowData,\n        colData=LT@colData,\n        assays=LT@assays,\n        .intern=LT@.intern,\n        metadata=LT@metadata\n    )\n}"
      },
      {
        "partial": "#' @name as\n#'\n#' @title\n#' Coerce a `LongTable` to a `TreatmentResponseExperiment`\n#'\n#' @param from `LongTable` object to coerce to a `TreatmentResponseExperiment`.\n#'\n#' @return The data in `object`, as the child-class\n#'   `TreatmentResponseExperiment`.\n#'\n#' @seealso [`TreatmentResponseExperiment`]\n#'\n#' @examples\n#' data(clevelandSmall_cSet)\n#' TRE <- as(treatmentResponse(clevelandSmall_cSet),\n#'     \"TreatmentResponseExperiment\")\n#' TRE\n#'\n#' @md\n#' @export\nsetAs(\"LongTable\", \"TreatmentResponseExperiment\", function(from) {\n    # Complete the coercion function\n})",
        "complete": "#' @name as\n#'\n#' @title\n#' Coerce a `LongTable` to a `TreatmentResponseExperiment`\n#'\n#' @param from `LongTable` object to coerce to a `TreatmentResponseExperiment`.\n#'\n#' @return The data in `object`, as the child-class\n#'   `TreatmentResponseExperiment`.\n#'\n#' @seealso [`TreatmentResponseExperiment`]\n#'\n#' @examples\n#' data(clevelandSmall_cSet)\n#' TRE <- as(treatmentResponse(clevelandSmall_cSet),\n#'     \"TreatmentResponseExperiment\")\n#' TRE\n#'\n#' @md\n#' @export\nsetAs(\"LongTable\", \"TreatmentResponseExperiment\", function(from) {\n    TreatmentResponseExperiment(from)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/signatureClass.R",
    "language": "R",
    "content": "setOldClass('sessionInfo', sessionInfo)\n\n#' @importFrom utils sessionInfo\n.RadioSig <- setClass('RadioSig', slots=list(\n\n            RSetName='character',\n            DateCreated = 'character',\n            SigType = 'character',\n            SessionInfo = 'sessionInfo',\n            Call = 'character'), contains='array')\n\n#' Radiation Signature Class Constructor\n#'\n#' A documented constructor to provide user friendly interface to .RadioSig\n#'\n#' @param Data The data\n#' @param RSetName The name of the pSet\n#' @param DateCreated The date the object was created\n#' @param SigType The type of sensitivyt signature\n#' @param SessionInfo The package version used to generate the object\n#' @param Call The calls for sensitivity vs not\n#'\n#' @return A \\code{RadioSig} object\n#'\n#' @export\nRadioSig <- function(Data=array(NA, dim=c(0,0,0)),\n                     RSetName='',\n                     DateCreated=date(),\n                     SigType='sensitivity',\n                     SessionInfo=sessionInfo(),\n                     Call='No Call Recorded')\n{\nreturn(.RadioSig(Data,\n                 RSetName=RSetName,\n                 DateCreated=DateCreated,\n                 SigType=SigType,\n                 SessionInfo=SessionInfo,\n                 Call=Call))\n}\n\n#' Show RadioGx Signatures\n#'\n#' @examples\n#' data(clevelandSmall)\n#' rad.sensitivity <- radSensitivitySig(clevelandSmall, mDataType=\"rna\",\n#'              nthread=1, features = fNames(clevelandSmall, \"rna\")[1])\n#' rad.sensitivity\n#'\n#' @param object \\code{RadioSig}\n#'\n#' @return Prints the RadioGx Signatures object to the output stream, and returns invisible NULL.\n#'\n#' @export\nsetMethod(\"show\", signature=signature(object='RadioSig'),\n        function(object) {\n        cat('RadioSet Name: ', attr(object, 'RSetName'), \"\\n\")\n        cat('Signature Type: ', attr(object, 'SigType'), \"\\n\")\n        cat(\"Date Created: \", attr(object, 'DateCreated'), \"\\n\")\n        cat(\"Number of Radiation Types: \", dim(object)[[2]], \"\\n\")\n        cat(\"Number of Genes/Probes: \", dim(object)[[1]], \"\\n\")\n           })\n\n#' Show the Annotations of a signature object\n#'\n#' This funtion prints out the information about the call used to compute the rad signatures, and the session info\n#' for the session in which the computation was done. Useful for determining the exact conditions used to generate signatures.\n#'\n#' @examples\n#' data(clevelandSmall)\n#' rad.sensitivity <- radSensitivitySig(clevelandSmall, mDataType=\"rna\",\n#'              nthread=1, features = fNames(clevelandSmall, \"rna\")[1])\n#' showSigAnnot(rad.sensitivity)\n#'\n#' @param object An object of the \\code{RadioSig} Class, as\n#' returned by \\code{radPerturbationSig} or \\code{radSensitivitySig}\n#'\n#' @return Prints the RadioGx Signatures annotations to the output stream, and returns invisible NULL.\n#'\n#' @importMethodsFrom CoreGx showSigAnnot\n#' @export\nsetMethod(\"showSigAnnot\", signature(object='RadioSig'), function(object) {\n  .showSigAnnotRadioSig(object)\n})\n\n\n#' @keywords internal\n.showSigAnnotRadioSig <- function(object) {\n  print(attr(object, 'Call'))\n  print(attr(object, 'SessionInfo'))\n  return(invisible(NULL))\n}\n\n\n\n\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'RadioSig' class and its constructor function in this code snippet?",
        "answer": "The 'RadioSig' class is defined to represent radiation signatures. Its constructor function provides a user-friendly interface to create 'RadioSig' objects. It takes parameters such as Data, RSetName, DateCreated, SigType, SessionInfo, and Call to initialize the object. The constructor ensures proper encapsulation and standardization of radiation signature data."
      },
      {
        "question": "How does the 'show' method for the 'RadioSig' class work, and what information does it display?",
        "answer": "The 'show' method is defined for the 'RadioSig' class using setMethod(). When called on a 'RadioSig' object, it displays key information about the radiation signature, including: the RadioSet Name, Signature Type, Date Created, Number of Radiation Types, and Number of Genes/Probes. This method provides a quick summary of the object's contents without revealing all the underlying data."
      },
      {
        "question": "What is the purpose of the 'showSigAnnot' method, and how does it differ from the 'show' method?",
        "answer": "The 'showSigAnnot' method is designed to display detailed annotations of a 'RadioSig' object. Unlike the 'show' method, which provides a summary, 'showSigAnnot' prints out information about the call used to compute the radiation signatures and the session info in which the computation was done. This method is useful for determining the exact conditions used to generate signatures, providing more in-depth information for reproducibility and debugging purposes."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setOldClass('sessionInfo', sessionInfo)\n\n#' @importFrom utils sessionInfo\n.RadioSig <- setClass('RadioSig', slots=list(\n            RSetName='character',\n            DateCreated = 'character',\n            SigType = 'character',\n            SessionInfo = 'sessionInfo',\n            Call = 'character'), contains='array')\n\n#' Radiation Signature Class Constructor\n#'\n#' A documented constructor to provide user friendly interface to .RadioSig\n#'\n#' @param Data The data\n#' @param RSetName The name of the pSet\n#' @param DateCreated The date the object was created\n#' @param SigType The type of sensitivyt signature\n#' @param SessionInfo The package version used to generate the object\n#' @param Call The calls for sensitivity vs not\n#'\n#' @return A \\code{RadioSig} object\n#'\n#' @export\nRadioSig <- function(Data=array(NA, dim=c(0,0,0)),\n                     RSetName='',\n                     DateCreated=date(),\n                     SigType='sensitivity',\n                     SessionInfo=sessionInfo(),\n                     Call='No Call Recorded')\n{\n# Complete the function body\n}",
        "complete": "setOldClass('sessionInfo', sessionInfo)\n\n#' @importFrom utils sessionInfo\n.RadioSig <- setClass('RadioSig', slots=list(\n            RSetName='character',\n            DateCreated = 'character',\n            SigType = 'character',\n            SessionInfo = 'sessionInfo',\n            Call = 'character'), contains='array')\n\n#' Radiation Signature Class Constructor\n#'\n#' A documented constructor to provide user friendly interface to .RadioSig\n#'\n#' @param Data The data\n#' @param RSetName The name of the pSet\n#' @param DateCreated The date the object was created\n#' @param SigType The type of sensitivyt signature\n#' @param SessionInfo The package version used to generate the object\n#' @param Call The calls for sensitivity vs not\n#'\n#' @return A \\code{RadioSig} object\n#'\n#' @export\nRadioSig <- function(Data=array(NA, dim=c(0,0,0)),\n                     RSetName='',\n                     DateCreated=date(),\n                     SigType='sensitivity',\n                     SessionInfo=sessionInfo(),\n                     Call='No Call Recorded')\n{\nreturn(.RadioSig(Data,\n                 RSetName=RSetName,\n                 DateCreated=DateCreated,\n                 SigType=SigType,\n                 SessionInfo=SessionInfo,\n                 Call=Call))\n}"
      },
      {
        "partial": "#' Show RadioGx Signatures\n#'\n#' @examples\n#' data(clevelandSmall)\n#' rad.sensitivity <- radSensitivitySig(clevelandSmall, mDataType=\"rna\",\n#'              nthread=1, features = fNames(clevelandSmall, \"rna\")[1])\n#' rad.sensitivity\n#'\n#' @param object \\code{RadioSig}\n#'\n#' @return Prints the RadioGx Signatures object to the output stream, and returns invisible NULL.\n#'\n#' @export\nsetMethod(\"show\", signature=signature(object='RadioSig'),\n        function(object) {\n        # Complete the function body\n        })",
        "complete": "#' Show RadioGx Signatures\n#'\n#' @examples\n#' data(clevelandSmall)\n#' rad.sensitivity <- radSensitivitySig(clevelandSmall, mDataType=\"rna\",\n#'              nthread=1, features = fNames(clevelandSmall, \"rna\")[1])\n#' rad.sensitivity\n#'\n#' @param object \\code{RadioSig}\n#'\n#' @return Prints the RadioGx Signatures object to the output stream, and returns invisible NULL.\n#'\n#' @export\nsetMethod(\"show\", signature=signature(object='RadioSig'),\n        function(object) {\n        cat('RadioSet Name: ', attr(object, 'RSetName'), \"\\n\")\n        cat('Signature Type: ', attr(object, 'SigType'), \"\\n\")\n        cat(\"Date Created: \", attr(object, 'DateCreated'), \"\\n\")\n        cat(\"Number of Radiation Types: \", dim(object)[[2]], \"\\n\")\n        cat(\"Number of Genes/Probes: \", dim(object)[[1]], \"\\n\")\n        })"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/datasets.R",
    "language": "R",
    "content": "#' Cleaveland_mut RadioSet subsetted and cast as CoreSet\n#'\n#' This dataset is just a dummy object derived from the Cleveland_mut RadioSet\n#'   in the RadioGx R package. It's contents should not be interpreted and it\n#'   is only present to test the functions in this package and provide\n#'   examples\n#' \n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect \n#' small molecules, genes, and disease. Science, 2006.\n#' \n#' @docType data\n#' @name clevelandSmall_cSet\n#' @usage data(clevelandSmall_cSet)\n#' @keywords datasets\n#' @format CoreSet object\nNULL\n\n#' Merck Drug Combination Data LongTable\n#'\n#' This is a LongTable object created from some drug combination data provided\n#'   to our lab by Merck.\n#'\n#' @references\n#' TODO:: Include a reference\n#'\n#' @docType data\n#' @name merckLongTable\n#' @usage data(merckLongTable)\n#' @keywords datasets\n#' @format LongTable object\nNULL\n\n#' Example LongTableDataMapper\n#'\n#' A dummy LongTableDataMapper object to be used in package examples.\n#'\n#' @docType data\n#' @name exampleDataMapper\n#' @usage data(exampleDataMapper)\n#' @keywords datasets\n#' @format LongTableDataMapper object\nNULL\n\n#' NCI-ALMANAC Drug Combination Data TreatmentResponseExperiment Subset\n#'\n#' This is a `TreatmentResponseExperiment` object containing a subset of\n#'   NCI-ALMANAC drug combination screening data,\n#'   with 2347 unique treatment combinations on 10 cancer cell lines selected.\n#'\n#' @references\n#' Susan L. Holbeck, Richard Camalier, James A. Crowell, Jeevan Prasaad Govindharajulu, Melinda Hollingshead, Lawrence W. Anderson, Eric Polley, Larry Rubinstein, Apurva Srivastava, Deborah Wilsker, Jerry M. Collins, James H. Doroshow; The National Cancer Institute ALMANAC: A Comprehensive Screening Resource for the Detection of Anticancer Drug Pairs with Enhanced Therapeutic Activity. Cancer Res 1 July 2017; 77 (13): 3564\u20133576. https://doi.org/10.1158/0008-5472.CAN-17-0489\n#'\n#' @docType data\n#' @name nci_TRE_small\n#' @usage data(nci_TRE_small)\n#' @keywords datasets\n#' @format TreatmentResponseExperiment object\nNULL",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'NULL' statement at the end of each data object declaration in this R code snippet?",
        "answer": "The 'NULL' statement at the end of each data object declaration is used to create a placeholder for the data object without actually defining its contents. This is a common practice in R package development when documenting datasets. It allows the package to include documentation for the data without including the actual data in the source code."
      },
      {
        "question": "How are the dataset objects in this code snippet documented, and what key information is provided for each?",
        "answer": "The dataset objects are documented using Roxygen2 syntax, which starts with #'. Each dataset documentation includes: 1) A brief description of the dataset, 2) @references for citing the data source (when applicable), 3) @docType data to specify it's a dataset, 4) @name to provide the object name, 5) @usage to show how to load the data, 6) @keywords datasets for categorization, and 7) @format to specify the object type."
      },
      {
        "question": "What is the significance of the @format tag in the documentation of these dataset objects?",
        "answer": "The @format tag in the documentation specifies the type of R object that each dataset represents. This is important for users to understand how to interact with the data. For example, 'clevelandSmall_cSet' is a CoreSet object, 'merckLongTable' is a LongTable object, 'exampleDataMapper' is a LongTableDataMapper object, and 'nci_TRE_small' is a TreatmentResponseExperiment object. Each of these object types likely has specific methods and properties associated with it."
      }
    ],
    "completion_tasks": null,
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat/test-LongTable-class.R",
    "language": "R",
    "content": "library(testthat)\nlibrary(CoreGx)\nlibrary(data.table)\n\ndata(nci_TRE_small)\ndata(merckLongTable)\n\nlt <- merckLongTable\ntre <- nci_TRE_small\n\n# == LongTable constructor\n\ntestthat::test_that(\"`LongTable` is coercible to TRE\", {\n    tre <- as(lt, \"TreatmentResponseExperiment\")\n    testthat::expect_s4_class(tre, \"TreatmentResponseExperiment\")\n})\n\ntestthat::test_that(\"`LongTable` constructor method works with valid inputs\", {\n    ## Extract required parameters to create an TRE object\n    parameters <- formalArgs(LongTable)\n    parameters <- parameters[\n        !(parameters %in% c(\"metadata\", \"keep.rownames\"))\n    ]\n    row_data <- rowData(tre)\n    row_ids <- rowIDs(tre)\n    col_data <- colData(tre)\n    col_ids <- colIDs(tre)\n    assays_ <- assays(tre)\n    assay_ids <- replicate(3, idCols(tre), simplify = FALSE)\n    names(assay_ids) <- assayNames(tre)\n    ## regex lookaheads to check for ALL missing parameters\n    regex <- paste0(sprintf(\"(?=.*%s)\", parameters), collapse = \"\")\n    regex <- paste0(\"(?s)^\", regex) ## handle line breaks in error messages\n    ## Line 87: Report all missing parameters in error message\n    testthat::expect_error({ ntre <- LongTable() },\n        regexp = regex, perl = TRUE\n    )\n    ## Check for wrong input rowData class (those not coercible to data.frame)\n    ## FIX-ME:: We might need extra check for rowData, colData, assays: even NULL is coercible to data.table\n    #testthat::expect_error({\n    #    ntre <- LongTable(rowData  = NULL,\n    #                      rowIDs   = row_ids,\n    #                      colData  = col_data,\n    #                      colIDs   = col_ids,\n    #                      assays   = assays_,\n    #                      assayIDs = array_ids)\n    #},\n    #    regexp = \".*rowData must be coerceible to a data\\\\.frame\"\n    #)\n    ## Question: should we handle the case where assays' IDs are mislabeled?\n    ## Question: should we check for unequal length of names(assays) and names(assayIDs)? (refer to line 171)\n    ## Line 172\n    testthat::expect_error({\n        ntre <- LongTable(rowData = row_data[, -row_ids[1:2], with = FALSE],\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = array_ids)\n    },\n        regexp = paste0(\".*Row IDs not in rowData: \",\n                        row_ids[1:2],\n                        collapse = \",\")\n    )\n    ## Question: should we handle the case where assays' IDs are mislabeled?\n    ## Question: should we check for unequal length of names(assays) and names(assayIDs)? (refer to line 171)\n    ## Line 172\n    testthat::expect_error({\n        names(assay_ids)[1] <- \"not sensitivity\"\n        ntre <- LongTable(rowData = row_data,\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = assay_ids)\n    },\n        regexp = paste0(\".*Mismatched names between \",\n                        \"assays and assayIDs for\\\\:\\n\\t\",\n                        paste0(names(assays_)[\n                                    names(assays_) != names(assay_ids)\n                               ],\n                               collapse = \", \"),\n                        \".*\", collapse = \"\")\n    )\n})\n\n# == assayCols\n\ntestthat::test_that(\"`assayCols,LongTable-method` retrieves specified assay's column names\",{\n    testthat::expect_error({ assayCols(tre, i = 1:2) })\n    testthat::expect_error({ assayCols(tre, i = (length(assayNames(tre))) + 1) })\n    testthat::expect_error({ assayCols(tre, i = paste0(assayNames(tre), collapse = \"\")) })\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `LongTable` constructor in this code, and what error checking does it perform?",
        "answer": "The `LongTable` constructor is used to create a TreatmentResponseExperiment (TRE) object from a long-format data table. It performs several error checks, including:\n1. Ensuring all required parameters are provided (using regex lookaheads).\n2. Verifying that the specified row IDs exist in the rowData.\n3. Checking for mismatched names between assays and assayIDs.\nThese checks help ensure the integrity and consistency of the data being used to create the TRE object."
      },
      {
        "question": "How does the code test the coercion of a `LongTable` object to a `TreatmentResponseExperiment` object?",
        "answer": "The code tests the coercion of a `LongTable` object to a `TreatmentResponseExperiment` object using the `testthat` framework. Specifically, it uses the `test_that` function with the description '`LongTable` is coercible to TRE'. Inside this test, it performs the following steps:\n1. Coerces the `lt` object (a LongTable) to a TreatmentResponseExperiment using `as(lt, \"TreatmentResponseExperiment\")`.\n2. Uses `expect_s4_class` to verify that the resulting object (`tre`) is indeed of class \"TreatmentResponseExperiment\".\nThis test ensures that the coercion method is working correctly and produces the expected output."
      },
      {
        "question": "What is the purpose of the `assayCols` method test in this code, and what specific cases does it check?",
        "answer": "The `assayCols` method test checks the behavior of the `assayCols` function when applied to a LongTable object. The test verifies that the function correctly handles various input scenarios:\n1. It checks that an error is raised when trying to retrieve columns for multiple assays simultaneously (using `i = 1:2`).\n2. It ensures an error occurs when requesting an assay index that is out of bounds (using `i = (length(assayNames(tre))) + 1`).\n3. It verifies that an error is thrown when providing an invalid assay name (by concatenating all assay names into a single string).\nThese tests help ensure that the `assayCols` method behaves correctly and provides appropriate error messages for invalid inputs."
      }
    ],
    "completion_tasks": [
      {
        "partial": "testthat::test_that(\"`LongTable` constructor method works with valid inputs\", {\n    parameters <- formalArgs(LongTable)\n    parameters <- parameters[!(parameters %in% c(\"metadata\", \"keep.rownames\"))]\n    row_data <- rowData(tre)\n    row_ids <- rowIDs(tre)\n    col_data <- colData(tre)\n    col_ids <- colIDs(tre)\n    assays_ <- assays(tre)\n    assay_ids <- replicate(3, idCols(tre), simplify = FALSE)\n    names(assay_ids) <- assayNames(tre)\n    regex <- paste0(sprintf(\"(?=.*%s)\", parameters), collapse = \"\")\n    regex <- paste0(\"(?s)^\", regex)\n    \n    testthat::expect_error({ ntre <- LongTable() },\n        regexp = regex, perl = TRUE\n    )\n    \n    testthat::expect_error({\n        ntre <- LongTable(rowData = row_data[, -row_ids[1:2], with = FALSE],\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = array_ids)\n    },\n        regexp = paste0(\".*Row IDs not in rowData: \",\n                        row_ids[1:2],\n                        collapse = \",\")\n    )\n    \n    testthat::expect_error({\n        names(assay_ids)[1] <- \"not sensitivity\"\n        ntre <- LongTable(rowData = row_data,\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = assay_ids)\n    },\n        regexp = paste0(\".*Mismatched names between \",\n                        \"assays and assayIDs for\\:\\n\\t\",\n                        paste0(names(assays_)[names(assays_) != names(assay_ids)],\n                               collapse = \", \"),\n                        \".*\", collapse = \"\")\n    )\n})",
        "complete": "testthat::test_that(\"`LongTable` constructor method works with valid inputs\", {\n    parameters <- formalArgs(LongTable)\n    parameters <- parameters[!(parameters %in% c(\"metadata\", \"keep.rownames\"))]\n    row_data <- rowData(tre)\n    row_ids <- rowIDs(tre)\n    col_data <- colData(tre)\n    col_ids <- colIDs(tre)\n    assays_ <- assays(tre)\n    assay_ids <- replicate(3, idCols(tre), simplify = FALSE)\n    names(assay_ids) <- assayNames(tre)\n    regex <- paste0(sprintf(\"(?=.*%s)\", parameters), collapse = \"\")\n    regex <- paste0(\"(?s)^\", regex)\n    \n    testthat::expect_error({ ntre <- LongTable() },\n        regexp = regex, perl = TRUE\n    )\n    \n    testthat::expect_error({\n        ntre <- LongTable(rowData = row_data[, -row_ids[1:2], with = FALSE],\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = assay_ids)\n    },\n        regexp = paste0(\".*Row IDs not in rowData: \",\n                        row_ids[1:2],\n                        collapse = \",\")\n    )\n    \n    testthat::expect_error({\n        names(assay_ids)[1] <- \"not sensitivity\"\n        ntre <- LongTable(rowData = row_data,\n                          rowIDs = row_ids,\n                          colData = col_data,\n                          colIDs = col_ids,\n                          assays = assays_,\n                          assayIDs = assay_ids)\n    },\n        regexp = paste0(\".*Mismatched names between \",\n                        \"assays and assayIDs for\\:\\n\\t\",\n                        paste0(names(assays_)[names(assays_) != names(assay_ids)],\n                               collapse = \", \"),\n                        \".*\", collapse = \"\")\n    )\n})"
      },
      {
        "partial": "testthat::test_that(\"`assayCols,LongTable-method` retrieves specified assay's column names\",{\n    testthat::expect_error({ assayCols(tre, i = 1:2) })\n    testthat::expect_error({ assayCols(tre, i = (length(assayNames(tre))) + 1) })\n    testthat::expect_error({ assayCols(tre, i = paste0(assayNames(tre), collapse = \"\")) })\n    # Add expectations for successful retrieval of column names\n})",
        "complete": "testthat::test_that(\"`assayCols,LongTable-method` retrieves specified assay's column names\",{\n    testthat::expect_error({ assayCols(tre, i = 1:2) })\n    testthat::expect_error({ assayCols(tre, i = (length(assayNames(tre))) + 1) })\n    testthat::expect_error({ assayCols(tre, i = paste0(assayNames(tre), collapse = \"\")) })\n    testthat::expect_type(assayCols(tre, i = 1), \"character\")\n    testthat::expect_equal(assayCols(tre, i = assayNames(tre)[1]), colnames(assays(tre)[[1]]))\n    testthat::expect_true(all(assayCols(tre, i = assayNames(tre)[1]) %in% colnames(assays(tre)[[1]])))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utils-updateS4.R",
    "language": "R",
    "content": "#' Convert the old sensitivity slot format into a `LongTable` and update the\n#' `CoreSet` object.\n#'\n#' @param object Inheriting from `CoreSet`.\n#' @param mapper Should the `LongTableDataMapper` object be early returned,\n#' instead of the `LongTable` object. This can be useful if the conversion\n#' fails or corrupts your data. You can then modify the `DataMapper` as\n#' necessary to fix the sensititivity data.\n#'\n#' @return A `LongTable` constructed from `object@treatmentResponse`, or a\n#' `LongTableDataMapper` if `mapper`=TRUE.\n#'\n#' @keywords internal\n#' @noRd\n#' @importFrom data.table data.table as.data.table merge.data.table\n#' melt.data.table\n.sensitivityToTRE <- function(object, mapper=FALSE) {\n\n    # -- validate input\n    funContext <- .funContext(':::.sensitivitySlotToLongTable')\n    if (!is(object, 'CoreSet')) .error(funContext, ' object must inherit from\n        the CoreSet class.')\n    oldSensitivity <- treatmentResponse(object)\n\n    if (!is(oldSensitivity, 'list')) .error(funContext, ' @sensitivty slot\n        is not a `list`?')\n\n    # -- extract the old data as data.tables\n\n    # sensitivityInfo\n    infoDT <- as.data.table(oldSensitivity$info, keep.rownames=TRUE)\n    rowCols <- c(treatment1id=\"treatmentid\", treatment1dose='dose')\n    colCols <- c(sampleid=\"sampleid\")\n\n    # sensitivityProfiles\n    profDT <- as.data.table(oldSensitivity$profiles, keep.rownames=TRUE)\n\n    # sensitivityRaw\n    doseDT <- as.data.table(oldSensitivity$raw[, , 1], keep.rownames=TRUE)\n    meltedDoseDT <- na.omit(melt.data.table(doseDT, id.vars='rn',\n        variable.name='old_column', value.name='dose'))\n    meltedDoseDT[, dose := as.numeric(dose)]\n    viabDT <- as.data.table(oldSensitivity$raw[, , 2], keep.rownames=TRUE)\n    meltedViabDT <- na.omit(melt.data.table(viabDT, id.vars='rn',\n        variable.name='old_column', value.name='viability'))\n    meltedViabDT[, viability := as.numeric(viability)]\n\n    # -- merge into a single long format data.table\n    assayDT <- merge.data.table(meltedDoseDT, meltedViabDT,\n        by=c('rn', 'old_column'))\n    assayMap <- list(sensitivity=c('viability'),\n        profiles=setdiff(colnames(profDT), 'rn'))\n\n    rawdataDT <- merge.data.table(assayDT, profDT, by='rn')\n    rawdataDT <- merge.data.table(rawdataDT, infoDT, by='rn')\n    rawdataDT[, replicate_id := seq_len(.N), by=c(rowCols, colCols)]\n\n    if (max(rawdataDT$replicate_id) > 1) {\n        # Handle case where there is only 1 drug (i.e., radiation in RadioGx)\n        if (length(unique(rawdataDT[[rowCols[1]]])) == 1) {\n            rowCols <- c(rowCols, 'replicate_id')\n        } else {\n            colCols <- c(colCols, 'replicate_id')\n        }\n    } else {\n        rawdataDT[, replicate_id := NULL]\n    }\n\n    groups <- list(\n        rowDataMap=rowCols,\n        colDataMap=colCols,\n        assayMap=c(rowCols, colCols)\n    )\n\n    # -- capute the na rownames to make recreation easier in .rebuildInfo\n    missing_rows <- setdiff(infoDT$rn, rawdataDT$rn)\n    na_index <- infoDT[rn %in% missing_rows, .(rn, treatmentid, sampleid)]\n\n    # -- build a LongTableDataMapper object\n    TREdataMapper <- TREDataMapper(rawdata=rawdataDT)\n    guess <- guessMapping(TREdataMapper, groups, subset=TRUE)\n\n    assayCols <- unlist(assayMap)\n\n    # do not steal any assay columns for the row or column data\n    guess$rowDataMap[[2]] <- setdiff(guess$rowDataMap[[2]], assayCols)\n    guess$colDataMap[[2]] <- setdiff(guess$colDataMap[[2]], assayCols)\n    guess$metadata[[2]] <- setdiff(guess$metadata[[2]],\n        c(assayCols, guess$rowDataMap[[2]], guess$colDataMap[[2]]))\n    assayMap$assay_metadata <- setdiff(guess$assayMap$mapped_columns, assayCols)\n    assayMap <- lapply(assayMap, FUN=function(x, y) list(y, x),  # add id columns\n        y=guess$assayMap[[1]])\n\n    # update the data mapper\n    rowDataMap(TREdataMapper) <- guess$rowDataMap\n    colDataMap(TREdataMapper) <- guess$colDataMap\n    assayMap(TREdataMapper) <- assayMap\n    metadataMap(TREdataMapper) <-\n        list(experiment_metadata=guess$metadata$mapped_columns)\n    metadata(TREdataMapper) <- list(sensitivityInfo_NA=na_index)\n\n    # build the object\n    return(if (!mapper) metaConstruct(TREdataMapper) else TREdataMapper)\n}\n\n\n#' Compare the values of sensitivityInfo before and after use of\n#' .sensitivityToTRE\n#'\n#' @param object `CoreSet` to be updated to the new\n#' `TreatmentResponseExperiment` sensitivity format.\n#' @param FUN `function` The function to compare results from.\n#'\n#' @return None, displays results of `all.equal` on the sensitivityInfo for\n#'   the columns which should be conserved.\n#'\n#' @keywords internal\n#' @noRd\n#' @importFrom data.table data.table as.data.table merge.data.table\n#' melt.data.table\n.compareTreatmentResponse <- function(object, FUN) {\n\n    new_object <- copy(object)\n    tre <- CoreGx:::.sensitivityToTRE(object)\n    new_object@treatmentResponse <- tre\n\n    old_res <- copy(FUN(object))\n    new_res <- copy(FUN(new_object))\n\n    setDT(old_res, keep.rownames=\"rownames\")\n    setDT(new_res, keep.rownames=\"rownames\")\n\n    equal_columns <- colnames(old_res)\n    all.equal(\n        old_res[order(rownames), .SD, .SDcols=equal_columns],\n        new_res[order(rownames), .SD, .SDcols=equal_columns]\n    )\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.sensitivityToTRE` function and what are its main steps?",
        "answer": "The `.sensitivityToTRE` function converts an old sensitivity slot format into a `LongTable` format and updates a `CoreSet` object. Its main steps are:\n1. Validate input\n2. Extract old data as data.tables (sensitivityInfo, sensitivityProfiles, sensitivityRaw)\n3. Merge data into a single long format data.table\n4. Handle replicates\n5. Build a LongTableDataMapper object\n6. Update the data mapper with row, column, assay, and metadata mappings\n7. Return either the constructed LongTable or the DataMapper object"
      },
      {
        "question": "How does the function handle replicates in the data, and what conditions determine how replicates are treated?",
        "answer": "The function handles replicates by:\n1. Creating a `replicate_id` column\n2. If max(replicate_id) > 1:\n   a. If there's only one unique drug (e.g., radiation in RadioGx), add `replicate_id` to `rowCols`\n   b. Otherwise, add `replicate_id` to `colCols`\n3. If max(replicate_id) == 1, remove the `replicate_id` column\n\nThis approach ensures proper grouping of replicates based on the data structure, accommodating different experimental designs."
      },
      {
        "question": "What is the purpose of the `.compareTreatmentResponse` function and how does it work?",
        "answer": "The `.compareTreatmentResponse` function compares the values of sensitivityInfo before and after using `.sensitivityToTRE`. It works by:\n1. Creating a copy of the input object\n2. Applying `.sensitivityToTRE` to create a new TreatmentResponseExperiment\n3. Updating the copy with the new TreatmentResponseExperiment\n4. Applying a user-provided function (FUN) to both the original and updated objects\n5. Converting results to data.tables and ordering them\n6. Using `all.equal` to compare the results for columns that should be conserved\n\nThis function helps validate that the conversion process preserves important information."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Partial code for .sensitivityToTRE function\n.sensitivityToTRE <- function(object, mapper=FALSE) {\n    funContext <- .funContext(':::.sensitivitySlotToLongTable')\n    if (!is(object, 'CoreSet')) .error(funContext, ' object must inherit from the CoreSet class.')\n    oldSensitivity <- treatmentResponse(object)\n\n    if (!is(oldSensitivity, 'list')) .error(funContext, ' @sensitivty slot is not a `list`?')\n\n    infoDT <- as.data.table(oldSensitivity$info, keep.rownames=TRUE)\n    profDT <- as.data.table(oldSensitivity$profiles, keep.rownames=TRUE)\n\n    # TODO: Complete the function by extracting dose and viability data,\n    # merging into a single long format data.table, and creating a LongTableDataMapper object\n\n    # Return the result based on the mapper parameter\n    return(if (!mapper) metaConstruct(TREdataMapper) else TREdataMapper)\n}",
        "complete": "#' Convert the old sensitivity slot format into a `LongTable` and update the `CoreSet` object.\n#'\n#' @param object Inheriting from `CoreSet`.\n#' @param mapper Should the `LongTableDataMapper` object be early returned,\n#' instead of the `LongTable` object.\n#'\n#' @return A `LongTable` constructed from `object@treatmentResponse`, or a\n#' `LongTableDataMapper` if `mapper`=TRUE.\n#'\n#' @keywords internal\n#' @noRd\n#' @importFrom data.table data.table as.data.table merge.data.table melt.data.table\n.sensitivityToTRE <- function(object, mapper=FALSE) {\n    funContext <- .funContext(':::.sensitivitySlotToLongTable')\n    if (!is(object, 'CoreSet')) .error(funContext, ' object must inherit from the CoreSet class.')\n    oldSensitivity <- treatmentResponse(object)\n\n    if (!is(oldSensitivity, 'list')) .error(funContext, ' @sensitivty slot is not a `list`?')\n\n    infoDT <- as.data.table(oldSensitivity$info, keep.rownames=TRUE)\n    rowCols <- c(treatment1id=\"treatmentid\", treatment1dose='dose')\n    colCols <- c(sampleid=\"sampleid\")\n\n    profDT <- as.data.table(oldSensitivity$profiles, keep.rownames=TRUE)\n\n    doseDT <- as.data.table(oldSensitivity$raw[, , 1], keep.rownames=TRUE)\n    meltedDoseDT <- na.omit(melt.data.table(doseDT, id.vars='rn', variable.name='old_column', value.name='dose'))\n    meltedDoseDT[, dose := as.numeric(dose)]\n    viabDT <- as.data.table(oldSensitivity$raw[, , 2], keep.rownames=TRUE)\n    meltedViabDT <- na.omit(melt.data.table(viabDT, id.vars='rn', variable.name='old_column', value.name='viability'))\n    meltedViabDT[, viability := as.numeric(viability)]\n\n    assayDT <- merge.data.table(meltedDoseDT, meltedViabDT, by=c('rn', 'old_column'))\n    assayMap <- list(sensitivity=c('viability'), profiles=setdiff(colnames(profDT), 'rn'))\n\n    rawdataDT <- merge.data.table(assayDT, profDT, by='rn')\n    rawdataDT <- merge.data.table(rawdataDT, infoDT, by='rn')\n    rawdataDT[, replicate_id := seq_len(.N), by=c(rowCols, colCols)]\n\n    if (max(rawdataDT$replicate_id) > 1) {\n        if (length(unique(rawdataDT[[rowCols[1]]])) == 1) {\n            rowCols <- c(rowCols, 'replicate_id')\n        } else {\n            colCols <- c(colCols, 'replicate_id')\n        }\n    } else {\n        rawdataDT[, replicate_id := NULL]\n    }\n\n    groups <- list(rowDataMap=rowCols, colDataMap=colCols, assayMap=c(rowCols, colCols))\n\n    missing_rows <- setdiff(infoDT$rn, rawdataDT$rn)\n    na_index <- infoDT[rn %in% missing_rows, .(rn, treatmentid, sampleid)]\n\n    TREdataMapper <- TREDataMapper(rawdata=rawdataDT)\n    guess <- guessMapping(TREdataMapper, groups, subset=TRUE)\n\n    assayCols <- unlist(assayMap)\n    guess$rowDataMap[[2]] <- setdiff(guess$rowDataMap[[2]], assayCols)\n    guess$colDataMap[[2]] <- setdiff(guess$colDataMap[[2]], assayCols)\n    guess$metadata[[2]] <- setdiff(guess$metadata[[2]], c(assayCols, guess$rowDataMap[[2]], guess$colDataMap[[2]]))\n    assayMap$assay_metadata <- setdiff(guess$assayMap$mapped_columns, assayCols)\n    assayMap <- lapply(assayMap, FUN=function(x, y) list(y, x), y=guess$assayMap[[1]])\n\n    rowDataMap(TREdataMapper) <- guess$rowDataMap\n    colDataMap(TREdataMapper) <- guess$colDataMap\n    assayMap(TREdataMapper) <- assayMap\n    metadataMap(TREdataMapper) <- list(experiment_metadata=guess$metadata$mapped_columns)\n    metadata(TREdataMapper) <- list(sensitivityInfo_NA=na_index)\n\n    return(if (!mapper) metaConstruct(TREdataMapper) else TREdataMapper)\n}"
      },
      {
        "partial": "# Partial code for .compareTreatmentResponse function\n.compareTreatmentResponse <- function(object, FUN) {\n    new_object <- copy(object)\n    tre <- CoreGx:::.sensitivityToTRE(object)\n    new_object@treatmentResponse <- tre\n\n    old_res <- copy(FUN(object))\n    new_res <- copy(FUN(new_object))\n\n    setDT(old_res, keep.rownames=\"rownames\")\n    setDT(new_res, keep.rownames=\"rownames\")\n\n    # TODO: Complete the function by comparing the old and new results\n}",
        "complete": "#' Compare the values of sensitivityInfo before and after use of .sensitivityToTRE\n#'\n#' @param object `CoreSet` to be updated to the new `TreatmentResponseExperiment` sensitivity format.\n#' @param FUN `function` The function to compare results from.\n#'\n#' @return None, displays results of `all.equal` on the sensitivityInfo for the columns which should be conserved.\n#'\n#' @keywords internal\n#' @noRd\n#' @importFrom data.table data.table as.data.table merge.data.table melt.data.table\n.compareTreatmentResponse <- function(object, FUN) {\n    new_object <- copy(object)\n    tre <- CoreGx:::.sensitivityToTRE(object)\n    new_object@treatmentResponse <- tre\n\n    old_res <- copy(FUN(object))\n    new_res <- copy(FUN(new_object))\n\n    setDT(old_res, keep.rownames=\"rownames\")\n    setDT(new_res, keep.rownames=\"rownames\")\n\n    equal_columns <- colnames(old_res)\n    all.equal(\n        old_res[order(rownames), .SD, .SDcols=equal_columns],\n        new_res[order(rownames), .SD, .SDcols=equal_columns]\n    )\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/subsetTo-methods.R",
    "language": "R",
    "content": "#' @include RadioSet-accessors.R\nNULL\n\n#'`[`\n#'\n#' @examples\n#' data(clevelandSmall)\n#' clevelandSmall[sampleNames(clevelandSmall)[1], treatmentNames(clevelandSmall)[1]]\n#'\n#' @param x object\n#' @param i Cell lines to keep in object\n#' @param j Drugs to keep in object\n#' @param ... further arguments\n#' @param drop A boolean flag of whether to drop single dimensions or not\n#'\n#' @return Returns the subsetted object\n#'\n#' @export\nsetMethod(`[`, \"RadioSet\", function(x, i, j, ..., drop = FALSE) {\n    if (is.character(i)&&is.character(j)) {\n        return(subsetTo(x, cells=i, radiations=j,  molecular.data.cells=i))\n    }\n    else if (is.numeric(i) && is.numeric(j) && (as.integer(i)==i) &&\n            (as.integer(j)==j)){\n        return(subsetTo(x, cells=sampleNames(x)[i], radiations=treatmentNames(x)[j],\n                        molecular.data.cells=sampleNames(x)[i]))\n    }\n})\n\n## FIXED? TODO:: Subset function breaks if it doesnt find cell line in sensitivity info\n#' A function to subset a RadioSet to data containing only specified radiations,\n#'   cells and genes\n#'\n#' This is the prefered method of subsetting a RadioSet. This function allows\n#' abstraction of the data to the level of biologically relevant objects:\n#'   radiations and cells. The function will automatically go through all of the\n#' combined data in the RadioSet and ensure only the requested radiations\n#' and cell lines are found in any of the slots. This allows quickly picking out\n#' all the experiments for a radiation or cell of interest, as well removes the\n#' need to keep track of all the metadata conventions between different\n#' datasets.\n#'\n#' @examples\n#' clevelandRadiationTypes  <- treatmentNames(clevelandSmall)\n#' clevelandCells <- sampleNames(clevelandSmall)\n#' RSet <- subsetTo(clevelandSmall, radiationTypes = clevelandRadiationTypes[1],\n#'   cells = clevelandCells[1])\n#' RSet\n#'\n#' @param object A \\code{RadioSet} to be subsetted\n#' @param cells A list or vector of cell names as used in the dataset to which\n#'   the object will be subsetted. If left blank, then all cells will be left in\n#'   the dataset.\n#' @param radiationTypes A list or vector of radiation names as used in the\n#'   dataset to which the object will be subsetted. If left blank, then all\n#'   radiationTypes will be left in the dataset.\n#' @param molecular.data.cells A list or vector of cell names to keep in the\n#'   molecular data\n#' @param keep.controls If the dataset has perturbation type experiments, should\n#'   the controls be kept in the dataset? Defaults to true.\n#' @param ... Other arguments passed by other function within the package\n#'\n#' @return A RadioSet with only the selected radiation types and cells\n#'\n#' @importMethodsFrom CoreGx subsetTo\n#' @export\nsetMethod(\"subsetTo\",\n          signature(object=\"RadioSet\"),\n          function(object , cells=NULL, radiationTypes=NULL, molecular.data.cells=NULL, keep.controls=TRUE, ...){\n              .subsetToRadioSet(object, cells, radiationTypes,\n              molecular.data.cells, keep.controls, ...)\n          })\n\n# @param object A `RadioSet` to be subsetted\n# @param cells A list or vector of cell names as used in the dataset to which\n#   the object will be subsetted. If left blank, then all cells will be left in\n#   the dataset.\n# @param radiationTypes A list or vector of radiation names as used in the\n#   dataset to which the object will be subsetted. If left blank, then all\n#   radiationTypes will be left in the dataset.\n# @param molecular.data.cells A list or vector of cell names to keep in the\n#   molecular data\n# @param keep.controls If the dataset has perturbation type experiments, should\n#   the controls be kept in the dataset? Defaults to true.\n# @param ... Other arguments passed by other function within the package\n# @return A RadioSet with only the selected radiation types and cells\n#' @importFrom CoreGx .unionList .message .warning .error\n#' @keywords internals\n.subsetToRadioSet <- function(object,\n                     cells=NULL,\n                     radiationTypes=NULL,\n                     molecular.data.cells=NULL,\n                     keep.controls=TRUE,\n                     ...)\n{\n    drop=FALSE\n\n    adArgs = list(...)\n    if (\"exps\" %in% names(adArgs)) {\n        exps <- adArgs[[\"exps\"]]\n        if(is(exps,\"data.frame\")){\n            exps2 <- exps[[name(object)]]\n            names(exps2) <- rownames(exps)\n            exps <- exps2\n        } else{\n            exps <- exps[[name(object)]]\n        }\n    }else {\n        exps <- NULL\n    }\n    if(!missing(cells)){\n        cells <- unique(cells)\n    }\n\n    if(!missing(radiationTypes)){\n        radiationTypes <- unique(radiationTypes)\n    }\n\n    if(!missing(molecular.data.cells)){\n        molecular.data.cells <- unique(molecular.data.cells)\n    }\n\n    ### TODO:: implement strict subsetting at this level!!!!\n\n    ### the function missing does not work as expected in the context below,\n    ### because the arguments are passed to the anonymous\n    ### function in lapply, so it does not recognize them as missing\n\n    molecularProfilesSlot(object) <-\n        lapply(molecularProfilesSlot(object),\n            function(SE, cells, radiationTypes, molecular.data.cells) {\n                molecular.data.type <-\n                    if (length(grep(\"rna\", S4Vectors::metadata(SE)$annotation) > 0))\n                        \"rna\"\n                    else\n                        S4Vectors::metadata(SE)$annotation\n                if (length(grep(molecular.data.type, names(molecular.data.cells))) > 0)\n                    cells <- molecular.data.cells[[molecular.data.type]]\n\n                column_indices <- NULL\n\n                if (length(cells)==0 && length(radiationTypes) == 0) {\n                    column_indices <- seq_len(ncol(SE)) # This still returns the number of samples in an SE, but without a label\n                }\n                if (length(cells) == 0 && datasetType(object) == \"sensitivity\") {\n                    column_indices <- seq_len(ncol(SE))\n                }\n\n                cell_line_index <- NULL\n                if(length(cells)!=0) {\n                    if (!all(cells %in% sampleNames(object))) {\n                        stop(\"Some of the cell names passed to function did not match to names in the RadoSet. Please ensure you are using cell names as returned by the cellNames function\")\n                    }\n                    cell_line_index <- which(SummarizedExperiment::colData(SE)[[\"sampleid\"]] %in% cells)\n                }\n                radiationTypes_index <- NULL\n                if(datasetType(object)==\"perturbation\" || datasetType(object)==\"both\"){\n                    if(length(radiationTypes) != 0) {\n                        if (!all(radiationTypes %in% treatmentNames(object))) {\n                            stop(\"Some of the radiation types passed to function did not match\n               to names in the RadioSet. Please ensure you are using radiation\n               names as returned by the radiations function\")\n                                                        }\n                                                        radiationTypes_index <- which(SummarizedExperiment::colData(SE)[[\"treatmentid\"]] %in% radiationTypes)\n                                                        if(keep.controls) {\n                                                            control_indices <- which(SummarizedExperiment::colData(SE)[[\"xptype\"]]==\"control\")\n                                                            radiationTypes_index <- c(radiationTypes_index, control_indices)\n                                                        }\n                                                    }\n                                                }\n\n                                                if(length(radiationTypes_index) != 0 && length(cell_line_index) != 0) {\n                                                    if(length(intersect(radiationTypes_index, cell_line_index)) == 0) {\n                                                        stop(\"This Drug - Cell Line combination was not tested together.\")\n                                                    }\n                                                    column_indices <- intersect(radiationTypes_index, cell_line_index)\n                                                } else {\n                                                    if(length(radiationTypes_index) !=0) {\n                                                        column_indices <- radiationTypes_index\n                                                    }\n                                                    if(length(cell_line_index) !=0) {\n                                                        column_indices <- cell_line_index\n                                                    }\n                                                }\n\n                                                row_indices <- seq_len(nrow(SummarizedExperiment::assay(SE, 1)))\n\n                                                SE <- SE[row_indices, column_indices]\n                                                return(SE)\n\n                                            }, cells=cells, radiationTypes=radiationTypes, molecular.data.cells=molecular.data.cells)\n\n    if ((datasetType(object) == \"sensitivity\" | datasetType(object) == \"both\") & length(exps) != 0) {\n        sensitivityInfo(object) <- sensitivityInfo(object)[exps, , drop=drop]\n        rownames(sensitivityInfo(object)) <- names(exps)\n        if(length(sensitivityRaw(object)) > 0) {\n            sensitivityRaw(object) <- sensitivityRaw(object)[exps, , , drop=drop]\n            dimnames(sensitivityRaw(object))[[1]] <- names(exps)\n        }\n        sensitivityProfiles(object) <- sensitivityProfiles(object)[exps, , drop=drop]\n        rownames(sensitivityProfiles(object)) <- names(exps)\n\n        sensNumber(object) <- .summarizeSensitivityNumbers(object)\n    }\n    else if ((datasetType(object) == \"sensitivity\" | datasetType(object) == \"both\") & (length(radiationTypes) != 0 | length(cells) != 0)) {\n\n        radiationTypes_index <- which (sensitivityInfo(object)[, \"treatmentid\"] %in% radiationTypes)\n        cell_line_index <- which (sensitivityInfo(object)[,\"sampleid\"] %in% cells)\n        if (length(radiationTypes_index) !=0 & length(cell_line_index) !=0 ) {\n            if (length(intersect(radiationTypes_index, cell_line_index)) == 0) {\n                stop(\"This Drug - Cell Line combination was not tested together.\")\n            }\n            row_indices <- intersect(radiationTypes_index, cell_line_index)\n        } else {\n            if(length(radiationTypes_index)!=0 & length(cells)==0) {\n                row_indices <- radiationTypes_index\n            } else {\n                if(length(cell_line_index)!=0 & length(radiationTypes)==0){\n                    row_indices <- cell_line_index\n                } else {\n                    row_indices <- vector()\n                }\n            }\n        }\n        treatmentResponse(object)[names(treatmentResponse(object))[names(treatmentResponse(object))!=\"n\"]] <-\n            lapply(treatmentResponse(object)[names(treatmentResponse(object))[names(treatmentResponse(object))!=\"n\"]],\n                   function(x,i, drop){\n\n                       if (length(dim(x))==2){\n                           return(x[i,,drop=drop])\n                       }\n                       if (length(dim(x))==3){\n                           return(x[i,,,drop=drop])\n                       }\n                   }, i=row_indices, drop=drop)\n    }\n\n    if (length(radiationTypes)==0) {\n        if(datasetType(object) == \"sensitivity\" | datasetType(object) == \"both\"){\n            radiationTypes <- unique(sensitivityInfo(object)[[\"treatmentid\"]])\n        }\n        if(datasetType(object) == \"perturbation\" | datasetType(object) == \"both\"){\n            radiationTypes <- union(radiationTypes, na.omit(.unionList(lapply(molecularProfilesSlot(object), function(SE){unique(colData(SE)[[\"treatmentid\"]])}))))\n        }\n    }\n    if (length(cells)==0) {\n        cells <- union(cells, na.omit(.unionList(lapply(molecularProfilesSlot(object), function(SE){unique(colData(SE)[[\"sampleid\"]])}))))\n        if (datasetType(object) ==\"sensitivity\" | datasetType(object) == \"both\"){\n            cells <- union(cells, sensitivityInfo(object)[[\"sampleid\"]])\n        }\n    }\n    treatmentInfo(object) <- treatmentInfo(object)[radiationTypes , , drop=drop]\n    sampleInfo(object) <- sampleInfo(object)[cells , , drop=drop]\n    curation(object)$radiation <- curation(object)$radiation[radiationTypes , , drop=drop]\n    curation(object)$sample <- curation(object)$sample[cells , , drop=drop]\n    curation(object)$tissue <- curation(object)$tissue[cells , , drop=drop]\n    if (datasetType(object) == \"sensitivity\" | datasetType(object) == \"both\"  & length(exps) == 0) {\n        sensNumber(object) <- sensNumber(object)[cells, radiationTypes , drop=drop]\n    }\n    if (datasetType(object) == \"perturbation\" | datasetType(object) == \"both\") {\n        object@perturbation$n <- object@perturbation$n[cells,radiationTypes, , drop=drop]\n    }\n    return(object)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `subsetTo` method for the `RadioSet` class?",
        "answer": "The `subsetTo` method for the `RadioSet` class is used to subset a RadioSet object to contain only specified radiations, cells, and genes. It allows for abstraction of data to biologically relevant objects (radiations and cells) and automatically ensures that only the requested radiations and cell lines are present in all slots of the RadioSet. This method is the preferred way to subset a RadioSet as it simplifies the process of selecting experiments for specific radiations or cells of interest."
      },
      {
        "question": "How does the `.subsetToRadioSet` function handle subsetting of molecular profiles?",
        "answer": "The `.subsetToRadioSet` function handles subsetting of molecular profiles by applying a lambda function to each element in the `molecularProfilesSlot`. This function determines the molecular data type (RNA or other), selects the appropriate cells based on the input parameters, and then subsets the SummarizedExperiment object using column indices. It considers both cell lines and radiation types when subsetting, ensuring that only the requested data is retained in the molecular profiles."
      },
      {
        "question": "What happens if the `cells` or `radiationTypes` parameters are not provided when calling the `subsetTo` method?",
        "answer": "If the `cells` or `radiationTypes` parameters are not provided (i.e., they are NULL or empty), the function behaves as follows: 1) For `cells`, it will use all unique sample IDs from the molecular profiles and sensitivity information (if available). 2) For `radiationTypes`, it will use all unique treatment IDs from the sensitivity information (if available) and molecular profiles. This ensures that the RadioSet object retains all relevant data when no specific subset is requested."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(`[`, \"RadioSet\", function(x, i, j, ..., drop = FALSE) {\n    if (is.character(i) && is.character(j)) {\n        return(subsetTo(x, cells=i, radiations=j, molecular.data.cells=i))\n    }\n    else if (is.numeric(i) && is.numeric(j) && (as.integer(i)==i) &&\n            (as.integer(j)==j)){\n        # Complete the code here\n    }\n})",
        "complete": "setMethod(`[`, \"RadioSet\", function(x, i, j, ..., drop = FALSE) {\n    if (is.character(i) && is.character(j)) {\n        return(subsetTo(x, cells=i, radiations=j, molecular.data.cells=i))\n    }\n    else if (is.numeric(i) && is.numeric(j) && (as.integer(i)==i) &&\n            (as.integer(j)==j)){\n        return(subsetTo(x, cells=sampleNames(x)[i], radiations=treatmentNames(x)[j],\n                        molecular.data.cells=sampleNames(x)[i]))\n    }\n})"
      },
      {
        "partial": "setMethod(\"subsetTo\",\n          signature(object=\"RadioSet\"),\n          function(object, cells=NULL, radiationTypes=NULL, molecular.data.cells=NULL, keep.controls=TRUE, ...) {\n              # Complete the function body here\n          })",
        "complete": "setMethod(\"subsetTo\",\n          signature(object=\"RadioSet\"),\n          function(object, cells=NULL, radiationTypes=NULL, molecular.data.cells=NULL, keep.controls=TRUE, ...) {\n              .subsetToRadioSet(object, cells, radiationTypes,\n              molecular.data.cells, keep.controls, ...)\n          })"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/exports.cpp",
    "language": "cpp",
    "content": "#include \"exports.h\"\n#include <R.h>\n// borrowed from Matrix/rcpp\n#define CALLDEF(name, n)  {#name, (DL_FUNC) &name, n}\n\nstatic const R_CallMethodDef callEntries[] = {\n    CALLDEF(export_concordance_index, 13),\n    CALLDEF(export_filters, 16),\n    CALLDEF(export_filters_bootstrap, 17),\n    CALLDEF(export_mim, 13),\n    CALLDEF(set_thread_count, 1),\n    CALLDEF(get_thread_count, 1),\n    {NULL, NULL, 0}\n};\n\nextern \"C\" void\nR_init_mRMRe(DllInfo* info) {\n  R_registerRoutines(info, NULL, callEntries, NULL, NULL);\n  R_useDynamicSymbols(info, FALSE);\n}\n\nextern \"C\" SEXP\nexport_concordance_index(SEXP samplesA, SEXP samplesB, SEXP samplesC, SEXP samplesD,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP sampleStratumCount, SEXP outX, SEXP ratio,\n        SEXP concordantWeights, SEXP discordantWeights, SEXP uninformativeWeights,\n        SEXP relevantWeights)\n{\n    unsigned int const sample_count = LENGTH(samplesA);\n    unsigned int** p_sample_indices_per_stratum = new unsigned int*[INTEGER(sampleStratumCount)[0]];\n    unsigned int* const p_sample_count_per_stratum =\n            new unsigned int[INTEGER(sampleStratumCount)[0]];\n    Math::placeStratificationData(INTEGER(sampleStrata), REAL(sampleWeights),\n            p_sample_indices_per_stratum, p_sample_count_per_stratum,\n            INTEGER(sampleStratumCount)[0], sample_count);\n\n    if (LENGTH(samplesD) != 0 && LENGTH(samplesC) != 0)\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(samplesC), REAL(samplesD), REAL(sampleWeights), p_sample_indices_per_stratum,\n                p_sample_count_per_stratum, INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0,\n                REAL(concordantWeights), REAL(discordantWeights), REAL(uninformativeWeights),\n                REAL(relevantWeights));\n    else if (LENGTH(samplesC) != 0)\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(samplesC), REAL(sampleWeights), p_sample_indices_per_stratum,\n                p_sample_count_per_stratum, INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0,\n                REAL(concordantWeights), REAL(discordantWeights), REAL(uninformativeWeights),\n                REAL(relevantWeights));\n    else\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(sampleWeights), p_sample_indices_per_stratum, p_sample_count_per_stratum,\n                INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0, REAL(concordantWeights),\n                REAL(discordantWeights), REAL(uninformativeWeights), REAL(relevantWeights));\n\n    delete[] p_sample_count_per_stratum;\n    for (unsigned int i = 0; i < INTEGER(sampleStratumCount)[0]; ++i)\n        delete[] p_sample_indices_per_stratum[i];\n    delete[] p_sample_indices_per_stratum;\n\n    return R_NilValue;\n}\n\nextern \"C\" SEXP\nexport_filters(SEXP childrenCountPerLevel, SEXP dataMatrix, SEXP priorsMatrix, SEXP priorsWeight,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP featureTypes, SEXP sampleCount,\n        SEXP featureCount, SEXP sampleStratumCount, SEXP targetFeatureIndices, SEXP fixedFeatureCount,\n        SEXP continuousEstimator, SEXP outX, SEXP bootstrapCount, SEXP miMatrix)\n{\n    Matrix const priors_matrix(REAL(priorsMatrix), INTEGER(featureCount)[0],\n            INTEGER(featureCount)[0]);\n    Matrix const* const p_priors_matrix =\n            LENGTH(priorsMatrix) == INTEGER(featureCount)[0] * INTEGER(featureCount)[0] ?\n                    &priors_matrix : 0;\n    Data data(REAL(dataMatrix), p_priors_matrix, REAL(priorsWeight)[0], INTEGER(sampleCount)[0],\n            INTEGER(featureCount)[0], INTEGER(sampleStrata), REAL(sampleWeights),\n            INTEGER(featureTypes), INTEGER(sampleStratumCount)[0], INTEGER(continuousEstimator)[0],\n            INTEGER(outX)[0] != 0, INTEGER(bootstrapCount)[0]);\n    MutualInformationMatrix mi_matrix(&data, REAL(miMatrix));\n\n    unsigned int solution_count = 1;\n    for (unsigned int i = 0; i < LENGTH(childrenCountPerLevel); ++i)\n        solution_count *= INTEGER(childrenCountPerLevel)[i];\n    unsigned int const feature_count_per_solution = LENGTH(childrenCountPerLevel);\n    unsigned int const chunk_size = solution_count * feature_count_per_solution;\n\n    SEXP result;\n    PROTECT(result = allocVector(VECSXP, 3));\n\n    SET_VECTOR_ELT(result, 0, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 1, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 2, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n\n    for (unsigned int i = 0; i < LENGTH(targetFeatureIndices); ++i)\n    {\n        Filter filter(INTEGER(childrenCountPerLevel), LENGTH(childrenCountPerLevel), &mi_matrix,\n                INTEGER(targetFeatureIndices)[i], INTEGER(fixedFeatureCount)[0]);\n        filter.build();\n\n        SET_VECTOR_ELT(VECTOR_ELT(result, 0), i, allocVector(INTSXP, chunk_size));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 1), i, allocVector(REALSXP, INTEGER(featureCount)[0]));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 2), i, allocVector(REALSXP, chunk_size));\n\n        filter.getSolutions(INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), i)));\n        filter.getScores(REAL(VECTOR_ELT(VECTOR_ELT(result, 2), i)));\n\n        for (unsigned int k = 0; k < INTEGER(featureCount)[0]; ++k)\n            REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i))[k] =\n                    std::numeric_limits<double>::quiet_NaN();\n\n        Math::computeCausality(REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i)), &mi_matrix,\n                INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), i)), solution_count,\n                feature_count_per_solution, INTEGER(featureCount)[0],\n                INTEGER(targetFeatureIndices)[i]);\n    }\n    //PrintValue(result);\n    UNPROTECT(1);\n\n    return result;\n}\n\nextern \"C\" SEXP\nexport_filters_bootstrap(SEXP solutionCount, SEXP solutionLength, SEXP dataMatrix,\n        SEXP priorsMatrix, SEXP priorsWeight, SEXP sampleStrata, SEXP sampleWeights,\n        SEXP featureTypes, SEXP sampleCount, SEXP featureCount, SEXP sampleStratumCount,\n        SEXP targetFeatureIndices, SEXP fixedFeatureCount, SEXP continuousEstimator, SEXP outX, SEXP bootstrapCount,\n        SEXP miMatrix)\n{\n    Matrix const priors_matrix(REAL(priorsMatrix), INTEGER(featureCount)[0],\n            INTEGER(featureCount)[0]);\n    Matrix const* const p_priors_matrix =\n            LENGTH(priorsMatrix) == INTEGER(featureCount)[0] * INTEGER(featureCount)[0] ?\n                    &priors_matrix : 0;\n    Data data(REAL(dataMatrix), p_priors_matrix, REAL(priorsWeight)[0], INTEGER(sampleCount)[0],\n            INTEGER(featureCount)[0], INTEGER(sampleStrata), REAL(sampleWeights),\n            INTEGER(featureTypes), INTEGER(sampleStratumCount)[0], INTEGER(continuousEstimator)[0],\n            INTEGER(outX)[0] != 0, INTEGER(bootstrapCount)[0]);\n    //MutualInformationMatrix mi_matrix(&data, REAL(miMatrix));\n\n    unsigned int solution_count = INTEGER(solutionCount)[0];\n    unsigned int const feature_count_per_solution = INTEGER(solutionLength)[0];\n    unsigned int const chunk_size = solution_count * feature_count_per_solution;\n\n    int* const p_children_count_per_level = new int[feature_count_per_solution];\n    for (unsigned int i = 0; i < feature_count_per_solution; ++i)\n        p_children_count_per_level[i] = 1;\n\n    SEXP result;\n    PROTECT(result = allocVector(VECSXP, 3));\n\n    SET_VECTOR_ELT(result, 0, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 1, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 2, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n\n    for (unsigned int i = 0; i < LENGTH(targetFeatureIndices); ++i)\n    {\n        SET_VECTOR_ELT(VECTOR_ELT(result, 0), i, allocVector(INTSXP, chunk_size));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 1), i, allocVector(REALSXP, INTEGER(featureCount)[0]));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 2), i, allocVector(REALSXP, chunk_size));\n\n        for (unsigned int k = 0; k < INTEGER(featureCount)[0]; ++k)\n            REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i))[k] =\n                    std::numeric_limits<double>::quiet_NaN();\n    }\n\n    for (unsigned int i = 0; i < solution_count; ++i)\n    {\n        MutualInformationMatrix mi_matrix(&data);\n\n        for (unsigned int j = 0; j < LENGTH(targetFeatureIndices); ++j)\n        {\n            Filter filter(p_children_count_per_level, feature_count_per_solution, &mi_matrix,\n                    INTEGER(targetFeatureIndices)[j], INTEGER(fixedFeatureCount)[0]);\n            filter.build();\n            filter.getSolutions(\n                    INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), j))\n                            + (i * feature_count_per_solution));\n            //filter.getScores(\n             //       REAL(VECTOR_ELT(VECTOR_ELT(result, 2), i)) + (i * feature_count_per_solution));\n\n            /*            Math::computeCausality(REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i)), &mi_matrix,\n             INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), i)) + (i * chunk_size), 1,\n             feature_count_per_solution, INTEGER(featureCount)[0],\n             INTEGER(targetFeatureIndices)[i]);*/\n        }\n\n        data.bootstrap();\n    }\n\n    UNPROTECT(1);\n    delete[] p_children_count_per_level;\n    return result;\n}\n\nextern \"C\" SEXP\nexport_mim(SEXP dataMatrix, SEXP priorsMatrix, SEXP priorsWeight, SEXP sampleStrata,\n        SEXP sampleWeights, SEXP featureTypes, SEXP sampleCount, SEXP featureCount,\n        SEXP sampleStratumCount, SEXP continuousEstimator, SEXP outX, SEXP bootstrapCount,\n        SEXP miMatrix)\n{\n    Matrix const priors_matrix(REAL(priorsMatrix), INTEGER(featureCount)[0],\n            INTEGER(featureCount)[0]);\n    Matrix const* const p_priors_matrix =\n            LENGTH(priorsMatrix) == INTEGER(featureCount)[0] * INTEGER(featureCount)[0] ?\n                    &priors_matrix : 0;\n    Data data(REAL(dataMatrix), p_priors_matrix, REAL(priorsWeight)[0], INTEGER(sampleCount)[0],\n            INTEGER(featureCount)[0], INTEGER(sampleStrata), REAL(sampleWeights),\n            INTEGER(featureTypes), INTEGER(sampleStratumCount)[0], INTEGER(continuousEstimator)[0],\n            INTEGER(outX)[0] != 0, INTEGER(bootstrapCount)[0]);\n    MutualInformationMatrix mi_matrix(&data, REAL(miMatrix));\n    mi_matrix.build();\n\n    return R_NilValue;\n}\n\nextern \"C\" SEXP\nget_thread_count(SEXP threadCount)\n{\n#ifdef _OPENMP\n    INTEGER(threadCount)[0] = omp_get_max_threads();\n#endif\n\n    return R_NilValue;\n}\n\nextern \"C\" SEXP\nset_thread_count(SEXP threadCount)\n{\n#ifdef _OPENMP\n    omp_set_num_threads(INTEGER(threadCount)[0]);\n#endif\n\n    return R_NilValue;\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `CALLDEF` macro in this code, and how is it used?",
        "answer": "The `CALLDEF` macro is used to create entries in the `callEntries` array. It takes two arguments: the name of a function and the number of parameters it expects. The macro expands to create a structure that includes the function name as a string, a cast of the function pointer to `DL_FUNC`, and the number of parameters. This is used to register C functions that can be called from R."
      },
      {
        "question": "Explain the purpose of the `R_init_mRMRe` function and what it does.",
        "answer": "The `R_init_mRMRe` function is an initialization function for the R package. It is called when the package is loaded. Its main purpose is to register the C functions defined in `callEntries` with R, making them available for use within R. It uses `R_registerRoutines` to register the functions and `R_useDynamicSymbols` to disable dynamic symbol lookup for better performance and safety."
      },
      {
        "question": "What is the significance of the `extern \"C\"` declarations in this code?",
        "answer": "The `extern \"C\"` declarations are used to specify C linkage for the functions. This is necessary when compiling C++ code that needs to be called from C or other languages (like R in this case). It ensures that the function names are not mangled by the C++ compiler, allowing them to be correctly linked and called from R or C code."
      }
    ],
    "completion_tasks": [
      {
        "partial": "extern \"C\" SEXP\nexport_concordance_index(SEXP samplesA, SEXP samplesB, SEXP samplesC, SEXP samplesD,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP sampleStratumCount, SEXP outX, SEXP ratio,\n        SEXP concordantWeights, SEXP discordantWeights, SEXP uninformativeWeights,\n        SEXP relevantWeights)\n{\n    unsigned int const sample_count = LENGTH(samplesA);\n    unsigned int** p_sample_indices_per_stratum = new unsigned int*[INTEGER(sampleStratumCount)[0]];\n    unsigned int* const p_sample_count_per_stratum =\n            new unsigned int[INTEGER(sampleStratumCount)[0]];\n    Math::placeStratificationData(INTEGER(sampleStrata), REAL(sampleWeights),\n            p_sample_indices_per_stratum, p_sample_count_per_stratum,\n            INTEGER(sampleStratumCount)[0], sample_count);\n\n    // TODO: Implement concordance index computation\n\n    delete[] p_sample_count_per_stratum;\n    for (unsigned int i = 0; i < INTEGER(sampleStratumCount)[0]; ++i)\n        delete[] p_sample_indices_per_stratum[i];\n    delete[] p_sample_indices_per_stratum;\n\n    return R_NilValue;\n}",
        "complete": "extern \"C\" SEXP\nexport_concordance_index(SEXP samplesA, SEXP samplesB, SEXP samplesC, SEXP samplesD,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP sampleStratumCount, SEXP outX, SEXP ratio,\n        SEXP concordantWeights, SEXP discordantWeights, SEXP uninformativeWeights,\n        SEXP relevantWeights)\n{\n    unsigned int const sample_count = LENGTH(samplesA);\n    unsigned int** p_sample_indices_per_stratum = new unsigned int*[INTEGER(sampleStratumCount)[0]];\n    unsigned int* const p_sample_count_per_stratum =\n            new unsigned int[INTEGER(sampleStratumCount)[0]];\n    Math::placeStratificationData(INTEGER(sampleStrata), REAL(sampleWeights),\n            p_sample_indices_per_stratum, p_sample_count_per_stratum,\n            INTEGER(sampleStratumCount)[0], sample_count);\n\n    if (LENGTH(samplesD) != 0 && LENGTH(samplesC) != 0)\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(samplesC), REAL(samplesD), REAL(sampleWeights), p_sample_indices_per_stratum,\n                p_sample_count_per_stratum, INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0,\n                REAL(concordantWeights), REAL(discordantWeights), REAL(uninformativeWeights),\n                REAL(relevantWeights));\n    else if (LENGTH(samplesC) != 0)\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(samplesC), REAL(sampleWeights), p_sample_indices_per_stratum,\n                p_sample_count_per_stratum, INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0,\n                REAL(concordantWeights), REAL(discordantWeights), REAL(uninformativeWeights),\n                REAL(relevantWeights));\n    else\n        REAL(ratio)[0] = Math::computeConcordanceIndex(REAL(samplesA), REAL(samplesB),\n                REAL(sampleWeights), p_sample_indices_per_stratum, p_sample_count_per_stratum,\n                INTEGER(sampleStratumCount)[0], INTEGER(outX)[0] != 0, REAL(concordantWeights),\n                REAL(discordantWeights), REAL(uninformativeWeights), REAL(relevantWeights));\n\n    delete[] p_sample_count_per_stratum;\n    for (unsigned int i = 0; i < INTEGER(sampleStratumCount)[0]; ++i)\n        delete[] p_sample_indices_per_stratum[i];\n    delete[] p_sample_indices_per_stratum;\n\n    return R_NilValue;\n}"
      },
      {
        "partial": "extern \"C\" SEXP\nexport_filters(SEXP childrenCountPerLevel, SEXP dataMatrix, SEXP priorsMatrix, SEXP priorsWeight,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP featureTypes, SEXP sampleCount,\n        SEXP featureCount, SEXP sampleStratumCount, SEXP targetFeatureIndices, SEXP fixedFeatureCount,\n        SEXP continuousEstimator, SEXP outX, SEXP bootstrapCount, SEXP miMatrix)\n{\n    Matrix const priors_matrix(REAL(priorsMatrix), INTEGER(featureCount)[0],\n            INTEGER(featureCount)[0]);\n    Matrix const* const p_priors_matrix =\n            LENGTH(priorsMatrix) == INTEGER(featureCount)[0] * INTEGER(featureCount)[0] ?\n                    &priors_matrix : 0;\n    Data data(REAL(dataMatrix), p_priors_matrix, REAL(priorsWeight)[0], INTEGER(sampleCount)[0],\n            INTEGER(featureCount)[0], INTEGER(sampleStrata), REAL(sampleWeights),\n            INTEGER(featureTypes), INTEGER(sampleStratumCount)[0], INTEGER(continuousEstimator)[0],\n            INTEGER(outX)[0] != 0, INTEGER(bootstrapCount)[0]);\n    MutualInformationMatrix mi_matrix(&data, REAL(miMatrix));\n\n    // TODO: Implement filter logic and result generation\n\n    return R_NilValue;\n}",
        "complete": "extern \"C\" SEXP\nexport_filters(SEXP childrenCountPerLevel, SEXP dataMatrix, SEXP priorsMatrix, SEXP priorsWeight,\n        SEXP sampleStrata, SEXP sampleWeights, SEXP featureTypes, SEXP sampleCount,\n        SEXP featureCount, SEXP sampleStratumCount, SEXP targetFeatureIndices, SEXP fixedFeatureCount,\n        SEXP continuousEstimator, SEXP outX, SEXP bootstrapCount, SEXP miMatrix)\n{\n    Matrix const priors_matrix(REAL(priorsMatrix), INTEGER(featureCount)[0],\n            INTEGER(featureCount)[0]);\n    Matrix const* const p_priors_matrix =\n            LENGTH(priorsMatrix) == INTEGER(featureCount)[0] * INTEGER(featureCount)[0] ?\n                    &priors_matrix : 0;\n    Data data(REAL(dataMatrix), p_priors_matrix, REAL(priorsWeight)[0], INTEGER(sampleCount)[0],\n            INTEGER(featureCount)[0], INTEGER(sampleStrata), REAL(sampleWeights),\n            INTEGER(featureTypes), INTEGER(sampleStratumCount)[0], INTEGER(continuousEstimator)[0],\n            INTEGER(outX)[0] != 0, INTEGER(bootstrapCount)[0]);\n    MutualInformationMatrix mi_matrix(&data, REAL(miMatrix));\n\n    unsigned int solution_count = 1;\n    for (unsigned int i = 0; i < LENGTH(childrenCountPerLevel); ++i)\n        solution_count *= INTEGER(childrenCountPerLevel)[i];\n    unsigned int const feature_count_per_solution = LENGTH(childrenCountPerLevel);\n    unsigned int const chunk_size = solution_count * feature_count_per_solution;\n\n    SEXP result;\n    PROTECT(result = allocVector(VECSXP, 3));\n\n    SET_VECTOR_ELT(result, 0, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 1, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n    SET_VECTOR_ELT(result, 2, allocVector(VECSXP, LENGTH(targetFeatureIndices)));\n\n    for (unsigned int i = 0; i < LENGTH(targetFeatureIndices); ++i)\n    {\n        Filter filter(INTEGER(childrenCountPerLevel), LENGTH(childrenCountPerLevel), &mi_matrix,\n                INTEGER(targetFeatureIndices)[i], INTEGER(fixedFeatureCount)[0]);\n        filter.build();\n\n        SET_VECTOR_ELT(VECTOR_ELT(result, 0), i, allocVector(INTSXP, chunk_size));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 1), i, allocVector(REALSXP, INTEGER(featureCount)[0]));\n        SET_VECTOR_ELT(VECTOR_ELT(result, 2), i, allocVector(REALSXP, chunk_size));\n\n        filter.getSolutions(INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), i)));\n        filter.getScores(REAL(VECTOR_ELT(VECTOR_ELT(result, 2), i)));\n\n        for (unsigned int k = 0; k < INTEGER(featureCount)[0]; ++k)\n            REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i))[k] =\n                    std::numeric_limits<double>::quiet_NaN();\n\n        Math::computeCausality(REAL(VECTOR_ELT(VECTOR_ELT(result, 1), i)), &mi_matrix,\n                INTEGER(VECTOR_ELT(VECTOR_ELT(result, 0), i)), solution_count,\n                feature_count_per_solution, INTEGER(featureCount)[0],\n                INTEGER(targetFeatureIndices)[i]);\n    }\n\n    UNPROTECT(1);\n    return result;\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utils-messages.R",
    "language": "R",
    "content": "# ======================================================\n# Utilty functions for message, warnings, errors and cat\n# ------------------------------------------------------\n\n#' @title .formatMessage\n#'\n#' @description Format one or more strings to fit nicely displayed in the\n#' R console at any given width.\n#'\n#' @param ... One or more `character` vectors containing the strings to be\n#' formatted\n#' @param collapse `character(1)` A string of characters to collapse vectors\n#' inside `...` with.\n#'\n#' @md\n#' @keywords internal\n#' @export\n#' @noRd\n.formatMessage <- function(..., collapse=', ') {\n    paste0(strwrap(paste0(..., collapse=collapse)), collapse='\\n')\n}\n\n#' @title .message\n#'\n#' @description Alternative to message which respects the local package\n#' settings for verbosity in `options()`. The message is displayed if either\n#' the general R option 'verbose' is TRUE, or if '<packageName()>.verbose'\n#' is TRUE.\n#'\n#' @details\n#' Defaults for package verbosity are determined in zzz.R via the .onAttach\n#' function. When loading the package, if the session is interactive the\n#' default verbosity is TRUE, otherwise it is FALSE.\n#'\n#' @md\n#' @importFrom crayon blue\n#' @keywords internal\n#' @export\n#' @noRd\n.message <- function(...) {\n    optionName <- paste0(packageName(), '.verbose')\n    optionIsTRUE <- !is.null(getOption(optionName)) && getOption(optionName)\n    verboseIsTRUE <- getOption('verbose')\n    if (optionIsTRUE || verboseIsTRUE)\n        message(crayon::blue$bold(.formatMessage(...)))\n}\n\n#' @title .warning\n#'\n#' @description Alternative to message which respects the local package\n#' settings for verbosity in `options()`. The message is displayed if either\n#' the general R option 'verbose' is TRUE, or if '<packageName()>.verbose'\n#' is TRUE.\n#'\n#' @details\n#' Defaults for package verbosity are determined in zzz.R via the .onAttach\n#' function. When loading the package, if the session is interactive the\n#' default verbosity is TRUE, otherwise it is FALSE.\n#'\n#' @md\n#' @importFrom crayon cyan\n#' @keywords internal\n#' @export\n#' @noRd\n.warning <- function(...) {\n    warning(crayon::cyan$bold(.formatMessage(...)), call.=FALSE)\n}\n\n#' @title .error\n#'\n#' @description Alternative to error which formats the error to fit the\n#' console and prints it in magenta.\n#'\n#' @details\n#' Defaults for package verbosity are determined in zzz.R via the .onAttach\n#' function. When loading the package, if the session is interactive the\n#' default verbosity is TRUE, otherwise it is FALSE.\n#'\n#' @md\n#' @importFrom crayon magenta\n#' @keywords internal\n#' @export\n#' @noRd\n.error <- function(...) {\n    stop(crayon::magenta$bold(.formatMessage(...)), call.=FALSE)\n}\n\n#' @title .funContext\n#'\n#' @description Build a string with the package and function name for a current\n#'   function. Prepended to error message to make it easier to determine where\n#'   the error or warning came from.\n#'\n#' @param funName `character(1)` A string with the function name, prepended\n#'   with the correct connection to the package NAMESPACE. For exported functions\n#'   use '::', for non-exported functions use ':::'.\n#'\n#' @keywords internal\n#' @export\n#' @noRd\n.funContext <- function(funName) paste0('[', packageName(), funName, ']\\n')\n\n\n#' @title .parseToRoxygen\n#'\n#' @description Takes a string block of roxygen2 tags sepearated by new-line\n#'   characteres and parses it to the appropriate format for the @eval tag,\n#'   subtituting any string in { } for the argument of the same name in `...`.\n#'\n#' @keywords internal\n#' @export\n#' @noRd\n.parseToRoxygen <- function(string, ...) {\n    unlist(strsplit(\n        with(list(...), glue::glue(string)),\n    '\\n'))\n}\n\n#' @keywords internal\n.paste_ <- function(x, y) paste(x, y, sep='_')\n\n#' @keywords internal\n.paste_colon <- function(x, y) paste(x, y, sep=':')\n\n#' @keywords interanl\n.paste_slashes <- function(...) paste(..., sep='///')",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.formatMessage` function in this code snippet?",
        "answer": "The `.formatMessage` function is designed to format one or more strings to fit nicely when displayed in the R console at any given width. It takes multiple character vectors as input, collapses them with a specified separator, and then wraps the resulting string to fit the console width using `strwrap`. The formatted message is then returned as a single string with line breaks."
      },
      {
        "question": "How does the `.message` function differ from the standard R `message` function?",
        "answer": "The `.message` function is an alternative to the standard R `message` function that respects local package settings for verbosity. It only displays the message if either the general R option 'verbose' is TRUE, or if '<packageName()>.verbose' is TRUE. Additionally, it formats the message using `.formatMessage` and applies blue bold styling using the `crayon` package. This allows for more controlled and visually distinct message output based on package-specific verbosity settings."
      },
      {
        "question": "What is the purpose of the `.funContext` function and how might it be used in error handling?",
        "answer": "The `.funContext` function builds a string containing the package name and function name for the current function. Its purpose is to create a context prefix that can be prepended to error or warning messages. This makes it easier to determine the origin of an error or warning within the package. For example, it could be used in combination with the `.error` function to provide more informative error messages, like this: `.error(.funContext('::someFunction'), 'An error occurred')`."
      }
    ],
    "completion_tasks": [
      {
        "partial": ".formatMessage <- function(..., collapse=', ') {\n    # Complete the function to format messages\n}",
        "complete": ".formatMessage <- function(..., collapse=', ') {\n    paste0(strwrap(paste0(..., collapse=collapse)), collapse='\n')\n}"
      },
      {
        "partial": ".message <- function(...) {\n    optionName <- paste0(packageName(), '.verbose')\n    optionIsTRUE <- !is.null(getOption(optionName)) && getOption(optionName)\n    verboseIsTRUE <- getOption('verbose')\n    # Complete the function to display messages based on verbosity settings\n}",
        "complete": ".message <- function(...) {\n    optionName <- paste0(packageName(), '.verbose')\n    optionIsTRUE <- !is.null(getOption(optionName)) && getOption(optionName)\n    verboseIsTRUE <- getOption('verbose')\n    if (optionIsTRUE || verboseIsTRUE)\n        message(crayon::blue$bold(.formatMessage(...)))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/unitest/test_unit_set_association.R",
    "language": "R",
    "content": "library(Hmisc)\nlibrary(mRMRe)\n\n##\n## Tests\n##\n\n#\n# correlate - Testing the correlate method against other known and proven methods\n#\n\n## Cont vs Cont\n\na <- runif(100)\nb <- runif(100)\n\ntest_correlate(a,b, method = \"pearson\")\ntest_correlate(a,b, method = \"spearman\")\ntest_correlate(a,b, method = \"kendall\")\ntest_correlate(a,b, method = \"cindex\")\ntest_correlate(a,b, method = \"frequency\")\n\n## Cat vs Cont\n\na <- sample(0:3, 100, T)\nb <- runif(100)\n\ntest_correlate(a,b, method = \"pearson\")\ntest_correlate(a,b, method = \"spearman\")\ntest_correlate(a,b, method = \"kendall\")\ntest_correlate(a,b, method = \"cindex\")\ntest_correlate(a,b, method = \"frequency\")\n\n## Cat vs Cat\n\na <- sample(0:3, 100, T)\nb <- sample(0:5, 100, T)\n\ntest_correlate(a,b, method = \"pearson\")\ntest_correlate(a,b, method = \"spearman\")\ntest_correlate(a,b, method = \"kendall\")\ntest_correlate(a,b, method = \"cindex\")\ntest_correlate(a,b, method = \"frequency\")\ntest_correlate(a,b, method = \"cramersv\")\n\n#\n# mim - Testing the mim method against the correlate method\n#\n\ndd <- data.frame(\n        \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont1\" = runif(100),\n        \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n        \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n        \"cont2\" = runif(100),\n        \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE))\n\ndata <- mRMR.data(data = dd)\ncors <- mim(data, method = \"cor\")\ncombinations <- combn(featureNames(data), 2)\n# results <- apply(combinations, 2, function(i) cors[i[[1]], i[[2]]] == correlate(i, j))\n# FIXME: Finish this test\n\n##\n## Methods\n##\n\ntest_correlate <- function(a,b, method)\n{\n\trun_correlate_test(a, b, method)\n\ta[sample(1:length(a), round(length(a) / 10))] <- NA\n\tb[sample(1:length(b), round(length(b) / 10))] <- NA\n\tmessage(\"Test with NA\")\n\trun_correlate_test(a, b, method)\n}\n\nrun_correlate_test <- function(a, b, method)\n{\n\tmessage(\"Testing with 3rd party\")\n\tif (method == \"pearson\" || method == \"spearman\" || method == \"kendall\")\n\t\tconfirmation <- cor(a, b, method = method, use = \"complete.obs\")\n\telse if (method == \"frequency\")\n\t\tconfirmation <- mean (a > b, na.rm = T)\n\telse if (method == \"cindex\")\n\t\tconfirmation <- as.numeric(Hmisc::rcorr.cens(a,b)[1])\n\telse if (method == \"cramersv\")\n\t\tconfirmation <- as.numeric(sqrt(chisq.test(a, b, correct=FALSE)$statistic /\n\t\t\t\t\t\t\t\t(length(a) * (min(length(unique(a)),length(unique(b))) - 1))))\n\t\n\tcorrelation <- correlate(a,b, method=method)$s\n\tif(abs(confirmation - correlation) > 1e5)\n\t\tstop(\"Correlation is different that confirmation\", confirmation, correlation)\n\telse\n\t\tmessage(\"\\t3rd Party OK\")\n\t\n\tmessage(\"Testing for symmetry\")\n\tif (abs(correlate(b,a, method=method)$s - correlation) > 1e10)\n\t\tstop(\"Correlation is not symmetric\")\n\telse\n\t\tmessage(\"\\tSymmetry OK\")\n\t\n\tmessage(\"Testing for stratification\")\n\ts <- as.factor(c(rep(0,length(a)),rep(1,length(a)), rep(2,length(a))))\n\tw <- c(rep(runif(1),length(a)),rep(runif(1),length(a)), rep(runif(1),length(a)))\n\ta <- c(a,a,a)\n\tb <- c(b,b,b)\n\t\n\tif (abs(correlate(a,b, method=method, strata=s)$s - correlation) > 1e10)\n\t\tstop(\"Stratification is wrong\")\n\telse if (abs(correlate(a,b, method=method, strata=s)$s - correlation) > 1e10)\n\t\tstop(\"Stratification is not symmetric\")\n\telse\n\t\tmessage(\"\\tStratification OK\")\n\tmessage(\"Testing for weights\")\n\tif (abs(correlate(a,b, method=method, weights=w)$s - correlation) > 1e10)\n\t\tstop(\"Weighting is wrong\")\n\telse if (abs(correlate(b,a, method=method, weights=w)$s - correlation) > 1e10)\n\t\tstop(\"Weighting is not symmetric\")\n\telse\n\t\tmessage(\"\\tWeighting OK\")\n\t\n\tmessage(\"Test for strata+weights\")\n\tif(abs(correlate(a,b, method=method, weights=w, strata=s)$s - correlation) > 1e10)\n\t\tstop(\"Stratification + Weighting is wrong\")\n\telse if (abs(correlate(b,a, method=method, weights=w, strata=s)$s - correlation) > 1e10)\n\t\tstop(\"Stratification + Weighting is not symmetric\")\n\telse\n\t\tmessage(\"\\tStratification + Weighting OK\")\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `test_correlate` function in this code snippet?",
        "answer": "The `test_correlate` function is designed to test the `correlate` method against other known and proven correlation methods. It performs the following tasks:\n1. Runs a correlation test on the input data (a and b) using the specified method.\n2. Introduces NA values to about 10% of the data points in both a and b.\n3. Runs the correlation test again with the NA values to ensure the method handles missing data correctly.\nThis function helps validate the robustness and accuracy of the `correlate` method under different conditions."
      },
      {
        "question": "How does the code test for symmetry in correlation calculations?",
        "answer": "The code tests for symmetry in correlation calculations by comparing the results of `correlate(a,b)` and `correlate(b,a)`. Specifically:\n1. It calculates the correlation between 'a' and 'b' using the specified method.\n2. It then calculates the correlation between 'b' and 'a' using the same method.\n3. The absolute difference between these two results is compared to a small threshold (1e-10).\n4. If the difference is larger than the threshold, it raises an error indicating that the correlation is not symmetric.\n5. If the difference is within the threshold, it confirms that the symmetry test passed.\nThis ensures that the correlation method produces consistent results regardless of the order of input variables."
      },
      {
        "question": "What is the purpose of testing correlation with stratification and weights in this code?",
        "answer": "The code tests correlation with stratification and weights to ensure that the `correlate` function can handle more complex scenarios accurately. Specifically:\n1. Stratification: It creates a factor variable 's' to group the data into strata and tests if the correlation remains consistent when accounting for these groups.\n2. Weights: It generates a weight vector 'w' and tests if the correlation calculation correctly incorporates these weights.\n3. Combined effect: It tests both stratification and weights together to ensure they work correctly in combination.\n\nThese tests are important because:\n- They verify that the `correlate` function can handle grouped data analysis (stratification).\n- They confirm that the function can properly account for the importance of different observations (weights).\n- They ensure that these advanced features don't introduce errors or inconsistencies in the correlation calculations.\n\nBy testing these scenarios, the code validates that the `correlate` function is robust and reliable for various types of statistical analyses."
      }
    ],
    "completion_tasks": [
      {
        "partial": "test_correlate <- function(a, b, method) {\n  run_correlate_test(a, b, method)\n  # Add NA values to a and b\n  # Run the test again with NA values\n  # TODO: Complete the function\n}",
        "complete": "test_correlate <- function(a, b, method) {\n  run_correlate_test(a, b, method)\n  a[sample(1:length(a), round(length(a) / 10))] <- NA\n  b[sample(1:length(b), round(length(b) / 10))] <- NA\n  message(\"Test with NA\")\n  run_correlate_test(a, b, method)\n}"
      },
      {
        "partial": "run_correlate_test <- function(a, b, method) {\n  message(\"Testing with 3rd party\")\n  # Calculate confirmation based on method\n  # Compare correlation with confirmation\n  # Test for symmetry\n  # Test for stratification\n  # Test for weights\n  # Test for strata+weights\n  # TODO: Complete the function\n}",
        "complete": "run_correlate_test <- function(a, b, method) {\n  message(\"Testing with 3rd party\")\n  if (method %in% c(\"pearson\", \"spearman\", \"kendall\"))\n    confirmation <- cor(a, b, method = method, use = \"complete.obs\")\n  else if (method == \"frequency\")\n    confirmation <- mean(a > b, na.rm = TRUE)\n  else if (method == \"cindex\")\n    confirmation <- as.numeric(Hmisc::rcorr.cens(a, b)[1])\n  else if (method == \"cramersv\")\n    confirmation <- as.numeric(sqrt(chisq.test(a, b, correct=FALSE)$statistic /\n                  (length(a) * (min(length(unique(a)), length(unique(b))) - 1))))\n  \n  correlation <- correlate(a, b, method=method)$s\n  if (abs(confirmation - correlation) > 1e-5)\n    stop(\"Correlation is different than confirmation\", confirmation, correlation)\n  else\n    message(\"\\t3rd Party OK\")\n  \n  message(\"Testing for symmetry\")\n  if (abs(correlate(b, a, method=method)$s - correlation) > 1e-10)\n    stop(\"Correlation is not symmetric\")\n  else\n    message(\"\\tSymmetry OK\")\n  \n  message(\"Testing for stratification\")\n  s <- as.factor(rep(0:2, each=length(a)))\n  w <- rep(runif(3), each=length(a))\n  a <- rep(a, 3)\n  b <- rep(b, 3)\n  \n  if (abs(correlate(a, b, method=method, strata=s)$s - correlation) > 1e-10)\n    stop(\"Stratification is wrong\")\n  else if (abs(correlate(b, a, method=method, strata=s)$s - correlation) > 1e-10)\n    stop(\"Stratification is not symmetric\")\n  else\n    message(\"\\tStratification OK\")\n  \n  message(\"Testing for weights\")\n  if (abs(correlate(a, b, method=method, weights=w)$s - correlation) > 1e-10)\n    stop(\"Weighting is wrong\")\n  else if (abs(correlate(b, a, method=method, weights=w)$s - correlation) > 1e-10)\n    stop(\"Weighting is not symmetric\")\n  else\n    message(\"\\tWeighting OK\")\n  \n  message(\"Test for strata+weights\")\n  if (abs(correlate(a, b, method=method, weights=w, strata=s)$s - correlation) > 1e-10)\n    stop(\"Stratification + Weighting is wrong\")\n  else if (abs(correlate(b, a, method=method, weights=w, strata=s)$s - correlation) > 1e-10)\n    stop(\"Stratification + Weighting is not symmetric\")\n  else\n    message(\"\\tStratification + Weighting OK\")\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/aggregate-methods.R",
    "language": "R",
    "content": "#' @include LongTable-class.R\n#' @include LongTable-accessors.R\n#' @include TreatmentResponseExperiment-class.R\nNULL\n\n#' @importFrom BiocParallel bpparam bpworkers<- bpworkers bpprogressbar<-\n#' bpprogressbar bplapply\n#' @importFrom data.table rbindlist setDT merge.data.table\n#' @importMethodsFrom S4Vectors aggregate\nNULL\n\n#' @noRd\n.docs_CoreGx_aggregate <- function(...) CoreGx:::.parseToRoxygen(\n    \"\n    @param by `character` One or more valid column names in `x` to compute\n    groups using.\n    @param ... `call` One or more aggregations to compute for each group by in x.\n    If you name aggregation calls, that will be the column name of the value\n    in the resulting `data.table` otherwise a default name will be parsed from\n    the function name and its first argument, which is assumed to be the name\n    of the column being aggregated over.\n    @param nthread `numeric(1)` Number of threads to use for split-apply-combine\n    parallelization. Uses `BiocParllel::bplapply` if nthread > 1 or you pass in\n    `BPPARAM`. Does not modify data.table threads, so be sure to use\n    setDTthreads for reasonable nested parallelism. See details for performance\n    considerations.\n    @param progress `logical(1)` Display a progress bar for parallelized\n    computations? Only works if `bpprogressbar<-` is defined for the current\n    BiocParallel back-end.\n    @param BPPARAM `BiocParallelParam` object. Use to customized the\n    the parallization back-end of bplapply. Note, nthread over-rides any\n    settings from BPPARAM as long as `bpworkers<-` is defined for that class.\n    @param enlist `logical(1)` Default is `TRUE`. Set to `FALSE` to evaluate\n    the first call in `...` within `data.table` groups. See details for more\n    information.\n    @param moreArgs `list()` A named list where each item is an argument one of\n    the calls in `...` which is not a column in the table being aggregated. Use\n    to further parameterize you calls. Please note that these are not added\n    to your aggregate calls unless you specify the names in the call.\n\n    @details\n    ## Use of Non-Standard Evaluation\n    Arguments in `...` are substituted and wrapped in a list, which is passed\n    through to the j argument of `[.data.table` internally. The function currently\n    tries to build informative column names for unnamed arguments in `...` by\n    appending the name of each function call with the name of its first argument,\n    which is assumed to be the column name being aggregated over. If an argument\n    to `...` is named, that will be the column name of its value in the resulting\n    `data.table`.\n\n    ## Enlisting\n    The primary use case for `enlist=FALSE` is to allow computation of dependent\n    aggregations, where the output from a previous aggregation is required in a\n    subsequent one. For this case, wrap your call in `{curly}` and assign intermediate\n    results to variables, returning the final results as a list where each list\n    item will become a column in the final table with the corresponding name.\n    Name inference is disabled for this case, since it is assumed you will name\n    the returned list items appropriately.\n    A major advantage over multiple calls to `aggregate` is that\n    the overhead of parallelization is paid only once even for complex multi-step\n    computations like fitting a model, capturing its paramters, and making\n    predictions using it. It also allows capturing arbitrarily complex calls\n    which can be recomputed later using the\n    `update,TreatmentResponseExperiment-method`\n    A potential disadvantage is increased RAM usage per\n    thread due to storing intermediate values in variables, as well as any\n    memory allocation overhead associate therewith.\n    \",\n    ...\n)\n\n#' Functional API for aggregation over a `LongTable` or inheriting class\n#'\n#' @description\n#' Compute a group-by operation over a `LongTable` object or it's inhering\n#' classes.\n#'\n#' @param x `LongTable` or inheriting class to compute aggregation on.\n#' @param assay `character(1)` The assay to aggregate over.\n#' @param subset `call` An R call to evaluate before perfoming an aggregate.\n#' This allows you to aggregate over a subset of columns in an assay but have\n#' it be assigned to the parent object. Default is TRUE, which includes all\n#' rows. Passed through as the `i` argument in `[.data.table`.\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return `data.table` of aggregation results.\n#'\n#' @seealso `data.table::[.data.table`, `BiocParallel::bplapply`\n#'\n#' @export\nsetMethod(\"aggregate\", signature(x=\"LongTable\"),\n        function(x, assay, by, ...,  subset=TRUE, nthread=1, progress=TRUE,\n        BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[[assay]][eval(i), ]\n    aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n            moreArgs=moreArgs)\n})\n\n\n#' Functional S4 API for aggregation over a `data.table` object.\n#'\n#' @description\n#' Compute a group-by operation over a `data.table` in a functional, pipe\n#' compatible format.\n#'\n#' @details\n#' This S4 method override the default `aggregate` method for a `data.frame`\n#' and as such you need to call `aggregate.data.frame` directly to get the\n#' original S3 method for a `data.table`.\n#'\n#' @param x `data.table` to compute aggregation over.\n#' @param subset `call` An R call to evaluate before perfoming an aggregate.\n#' This allows you to aggregate over a subset of columns in an assay but have\n#' it be assigned to the parent object. Default is TRUE, which includes all\n#' rows. Passed through as the `i` argument in `[.data.table`.\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return `data.table` of aggregated results with an `aggregations` attribute\n#' capturing metadata about the last aggregation performed on the table.\n#'\n#' @export\nsetMethod(\"aggregate\", signature=\"data.table\",\n        function(x, by, ..., subset=TRUE, nthread=1, progress=TRUE,\n        BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[eval(i), ]\n    aggregate2(\n        x,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n            moreArgs=moreArgs)\n})\n\n#' Functional API for data.table aggregation which allows capture of associated\n#' aggregate calls so they can be recomputed later.\n#'\n#' @param x `data.table`\n#' @eval .docs_CoreGx_aggregate(curly=\"{\")\n#'\n#' @return `data.table` of aggregation results.\n#'\n#' @seealso `data.table::[.data.table`, `BiocParallel::bplapply`\n#'\n#' @export\naggregate2 <- function(x, by, ..., nthread=1, progress=interactive(), BPPARAM=NULL,\n        enlist=TRUE, moreArgs=list()) {\n    ## TODO:: refator to checkmate\n    stopifnot(is.data.table(x))\n    stopifnot(is.character(by) && all(by %in% colnames(x)))\n    stopifnot(is.logical(progress) && length(progress) == 1)\n    stopifnot(is.logical(enlist) && length(enlist) == 1)\n    stopifnot(is.list(moreArgs))\n    stopifnot(length(moreArgs) == 0 || all(names(moreArgs) != \"\"))\n\n    # -- assign moreArgs to the function scope, if it is able to find the values\n    for (nm in names(moreArgs)) assign(nm, moreArgs[[nm]])\n\n    # -- capture dots as a call and parse dot names, adding default names if\n    # --   they are missing\n    agg_call <- if (enlist) substitute(list(...)) else substitute(...)\n    if (!enlist && ...length() > 1) warning(.warnMsg(\"Only one call can be \",\n        \"passed via ... when enlist=FALSE, ignoring all but first arugment!\"))\n    dot_names <- if (enlist) names(agg_call)[-1L] else ...names()\n    if (is.null(dot_names) && enlist) dot_names <- rep(\"\", length(agg_call) - 1)\n    for (i in which(dot_names == \"\")) {\n        dot_call <- agg_call[[i + 1]]\n        # assumes the first argument in a function call is always the column name!\n        dot_names[i] <- paste0(dot_call[1:max(2, length(dot_call))], collapse=\"_\")\n    }\n    call_idx <- if (!enlist) 2L else seq(2L, length(agg_call))\n    if (length(dot_names)) names(agg_call)[call_idx] <- dot_names\n\n    # -- compute the aggregates, parallelizing if nthread > 1\n    if (nthread == 1 && is.null(BPPARAM)) {\n        res <- x[, eval(agg_call), by=c(by)]\n    } else {\n        x <- copy(x) # prevent modifying the source by reference\n        # compute groups such that there is one table per thread\n        x[, group_id := .GRP, by=by]\n        ngrp <- x[, max(group_id)]\n        grp_size <- ceiling(ngrp / nthread)\n        x[, split_id := ceiling(group_id / grp_size)]\n        x_split <- split(x, by=\"split_id\")\n        stopifnot(length(x_split) == nthread)\n        if (is.null(BPPARAM)) {\n            BPPARAM <- BiocParallel::bpparam()\n        }\n        # optionally add progressbar\n        if (hasMethod(\"bpprogressbar<-\", signature=c(class(BPPARAM), \"logical\"))) {\n            BiocParallel::bpprogressbar(BPPARAM) <- progress\n        } else if (isTRUE(progress)) {\n            warning(.warnMsg(\n                \"Unable to set progressbar for BiocParallel backend: \",\n                class(BPPARAM)[1]), .call=FALSE)\n        }\n        # optionally set nthread\n        if (hasMethod(\"bpworkers<-\", signature=c(class(BPPARAM), \"integer\"))) {\n            BiocParallel::bpworkers(BPPARAM) <- nthread\n        } else if (nthread > 1) {\n            warning(.warnMsg(\"Unable to set nthread for BiocParallel backend: \",\n                class(BPPARAM)[1]), .call=FALSE)\n        }\n        res <- BiocParallel::bplapply(\n            x_split,\n            function(x, agg_call, by) x[, eval(substitute(agg_call)), by=c(by)],\n            agg_call=agg_call, by=by,\n            BPPARAM=BPPARAM\n        )\n        res <- rbindlist(res)\n    }\n    attributes(res)[[\"aggregations\"]] <- c(\n        attributes(res)[[\"aggregations\"]],\n        list(\n            agg_call=agg_call,\n            by=by,\n            enlist=enlist,\n            moreArgs=moreArgs\n        )\n    )\n    return(res)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.docs_CoreGx_aggregate` function in this code snippet?",
        "answer": "The `.docs_CoreGx_aggregate` function is used to generate Roxygen documentation for the `aggregate` method. It parses and formats the documentation string, including parameter descriptions, details, and other relevant information for the function's documentation."
      },
      {
        "question": "How does the `aggregate` method for the `LongTable` class differ from the `aggregate` method for the `data.table` class?",
        "answer": "The `aggregate` method for the `LongTable` class first extracts the specified assay from the `LongTable` object and applies any subset condition before calling `aggregate2`. In contrast, the `aggregate` method for the `data.table` class directly applies the subset condition to the input `data.table` before calling `aggregate2`. Both methods ultimately use the `aggregate2` function to perform the aggregation."
      },
      {
        "question": "What is the purpose of the `enlist` parameter in the `aggregate2` function, and how does it affect the aggregation process?",
        "answer": "The `enlist` parameter in the `aggregate2` function determines how the aggregation calls are processed. When `enlist=TRUE` (default), multiple aggregation calls can be passed and are wrapped in a list. When `enlist=FALSE`, only the first call in `...` is evaluated within `data.table` groups, allowing for dependent aggregations where the output from a previous aggregation is required in a subsequent one. This affects how the aggregation calls are captured and evaluated during the process."
      }
    ],
    "completion_tasks": [
      {
        "partial": "aggregate2 <- function(x, by, ..., nthread=1, progress=interactive(), BPPARAM=NULL,\n        enlist=TRUE, moreArgs=list()) {\n    stopifnot(is.data.table(x))\n    stopifnot(is.character(by) && all(by %in% colnames(x)))\n    stopifnot(is.logical(progress) && length(progress) == 1)\n    stopifnot(is.logical(enlist) && length(enlist) == 1)\n    stopifnot(is.list(moreArgs))\n    stopifnot(length(moreArgs) == 0 || all(names(moreArgs) != \"\"))\n\n    for (nm in names(moreArgs)) assign(nm, moreArgs[[nm]])\n\n    agg_call <- if (enlist) substitute(list(...)) else substitute(...)\n    if (!enlist && ...length() > 1) warning(\"Only one call can be passed via ... when enlist=FALSE, ignoring all but first argument!\")\n    dot_names <- if (enlist) names(agg_call)[-1L] else ...names()\n    if (is.null(dot_names) && enlist) dot_names <- rep(\"\", length(agg_call) - 1)\n    for (i in which(dot_names == \"\")) {\n        dot_call <- agg_call[[i + 1]]\n        dot_names[i] <- paste0(dot_call[1:max(2, length(dot_call))], collapse=\"_\")\n    }\n    call_idx <- if (!enlist) 2L else seq(2L, length(agg_call))\n    if (length(dot_names)) names(agg_call)[call_idx] <- dot_names\n\n    # Complete the function here\n}",
        "complete": "aggregate2 <- function(x, by, ..., nthread=1, progress=interactive(), BPPARAM=NULL,\n        enlist=TRUE, moreArgs=list()) {\n    stopifnot(is.data.table(x))\n    stopifnot(is.character(by) && all(by %in% colnames(x)))\n    stopifnot(is.logical(progress) && length(progress) == 1)\n    stopifnot(is.logical(enlist) && length(enlist) == 1)\n    stopifnot(is.list(moreArgs))\n    stopifnot(length(moreArgs) == 0 || all(names(moreArgs) != \"\"))\n\n    for (nm in names(moreArgs)) assign(nm, moreArgs[[nm]])\n\n    agg_call <- if (enlist) substitute(list(...)) else substitute(...)\n    if (!enlist && ...length() > 1) warning(\"Only one call can be passed via ... when enlist=FALSE, ignoring all but first argument!\")\n    dot_names <- if (enlist) names(agg_call)[-1L] else ...names()\n    if (is.null(dot_names) && enlist) dot_names <- rep(\"\", length(agg_call) - 1)\n    for (i in which(dot_names == \"\")) {\n        dot_call <- agg_call[[i + 1]]\n        dot_names[i] <- paste0(dot_call[1:max(2, length(dot_call))], collapse=\"_\")\n    }\n    call_idx <- if (!enlist) 2L else seq(2L, length(agg_call))\n    if (length(dot_names)) names(agg_call)[call_idx] <- dot_names\n\n    if (nthread == 1 && is.null(BPPARAM)) {\n        res <- x[, eval(agg_call), by=c(by)]\n    } else {\n        x <- copy(x)\n        x[, group_id := .GRP, by=by]\n        ngrp <- x[, max(group_id)]\n        grp_size <- ceiling(ngrp / nthread)\n        x[, split_id := ceiling(group_id / grp_size)]\n        x_split <- split(x, by=\"split_id\")\n        stopifnot(length(x_split) == nthread)\n        if (is.null(BPPARAM)) BPPARAM <- BiocParallel::bpparam()\n        if (hasMethod(\"bpprogressbar<-\", signature=c(class(BPPARAM), \"logical\"))) {\n            BiocParallel::bpprogressbar(BPPARAM) <- progress\n        } else if (isTRUE(progress)) {\n            warning(\"Unable to set progressbar for BiocParallel backend: \", class(BPPARAM)[1], call.=FALSE)\n        }\n        if (hasMethod(\"bpworkers<-\", signature=c(class(BPPARAM), \"integer\"))) {\n            BiocParallel::bpworkers(BPPARAM) <- nthread\n        } else if (nthread > 1) {\n            warning(\"Unable to set nthread for BiocParallel backend: \", class(BPPARAM)[1], call.=FALSE)\n        }\n        res <- BiocParallel::bplapply(\n            x_split,\n            function(x, agg_call, by) x[, eval(substitute(agg_call)), by=c(by)],\n            agg_call=agg_call, by=by,\n            BPPARAM=BPPARAM\n        )\n        res <- rbindlist(res)\n    }\n    attributes(res)[[\"aggregations\"]] <- c(\n        attributes(res)[[\"aggregations\"]],\n        list(\n            agg_call=agg_call,\n            by=by,\n            enlist=enlist,\n            moreArgs=moreArgs\n        )\n    )\n    return(res)\n}"
      },
      {
        "partial": "setMethod(\"aggregate\", signature=\"data.table\",\n        function(x, by, ..., subset=TRUE, nthread=1, progress=TRUE,\n        BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[eval(i), ]\n    # Complete the function here\n})",
        "complete": "setMethod(\"aggregate\", signature=\"data.table\",\n        function(x, by, ..., subset=TRUE, nthread=1, progress=TRUE,\n        BPPARAM=NULL, enlist=TRUE, moreArgs=list()) {\n    i <- substitute(subset)\n    assay_ <- x[eval(i), ]\n    aggregate2(\n        assay_,\n        by=by,\n        ...,\n        nthread=nthread, progress=progress, BPPARAM=BPPARAM, enlist=enlist,\n            moreArgs=moreArgs)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/src/MutualInformationMatrix.cpp",
    "language": "cpp",
    "content": "#include \"MutualInformationMatrix.h\"\n\nMutualInformationMatrix::MutualInformationMatrix(Data const* const pData) :\n        Matrix(pData->getFeatureCount() * pData->getFeatureCount(), pData->getFeatureCount(),\n                pData->getFeatureCount()), mpData(pData)\n{\n    for (unsigned int i = 0; i < mColumnCount; ++i)\n        for (unsigned int j = 0; j < mColumnCount; ++j)\n            Matrix::at(i, j) = std::numeric_limits<double>::quiet_NaN();\n}\n\nMutualInformationMatrix::MutualInformationMatrix(Data const* const pData,\n        double* const pInternalData) :\n        Matrix(pInternalData, pData->getFeatureCount(), pData->getFeatureCount()), mpData(pData)\n{\n\n}\n\n/* virtual */\nMutualInformationMatrix::~MutualInformationMatrix()\n{\n\n}\n\n/* virtual */double&\nMutualInformationMatrix::at(unsigned int const i, unsigned int const j)\n{\n    if (Matrix::at(i, j) != Matrix::at(i, j))\n        mpData->computeMiBetweenFeatures(i, j, &Matrix::at(i, j), &Matrix::at(j, i));\n\n    return Matrix::at(i, j);\n}\n\n/* virtual */double const&\nMutualInformationMatrix::at(unsigned int const i, unsigned int const j) const\n{\n    return Matrix::at(i, j);\n}\n\nvoid const\nMutualInformationMatrix::build()\n{\n#ifdef _OPENMP\n#pragma omp parallel for schedule(static)\n#endif\n    for (unsigned int i = 0; i < mColumnCount; ++i)\n        for (unsigned int j = 0; j < mColumnCount; ++j)\n            at(i, j);\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the MutualInformationMatrix class and how does it initialize its elements in the constructor?",
        "answer": "The MutualInformationMatrix class is a specialized matrix for storing mutual information between features in a dataset. In its main constructor, it initializes all elements to quiet NaN (Not a Number) using std::numeric_limits<double>::quiet_NaN(). This initialization allows the class to lazily compute mutual information values only when they are accessed, as seen in the 'at' method."
      },
      {
        "question": "How does the 'at' method in the MutualInformationMatrix class differ from a standard matrix access method, and why is it implemented this way?",
        "answer": "The 'at' method in MutualInformationMatrix is overridden to provide lazy computation of mutual information. When an element is accessed, it first checks if the value is NaN. If it is, it computes the mutual information between the corresponding features using mpData->computeMiBetweenFeatures(). This approach saves computation time by only calculating values when they are needed, and it ensures that each pair of features has its mutual information computed only once."
      },
      {
        "question": "What is the purpose of the 'build' method in the MutualInformationMatrix class, and how does it optimize performance?",
        "answer": "The 'build' method is used to pre-compute all mutual information values in the matrix. It uses OpenMP parallelization (if available) to distribute the computation across multiple threads, potentially speeding up the process on multi-core systems. The method calls 'at(i, j)' for all pairs of features, which triggers the computation of mutual information for each pair. This can be useful when all values are needed upfront or to avoid lazy computation overhead in subsequent operations."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#include \"MutualInformationMatrix.h\"\n\nMutualInformationMatrix::MutualInformationMatrix(Data const* const pData) :\n        Matrix(pData->getFeatureCount() * pData->getFeatureCount(), pData->getFeatureCount(),\n                pData->getFeatureCount()), mpData(pData)\n{\n    // TODO: Initialize matrix elements\n}",
        "complete": "#include \"MutualInformationMatrix.h\"\n\nMutualInformationMatrix::MutualInformationMatrix(Data const* const pData) :\n        Matrix(pData->getFeatureCount() * pData->getFeatureCount(), pData->getFeatureCount(),\n                pData->getFeatureCount()), mpData(pData)\n{\n    for (unsigned int i = 0; i < mColumnCount; ++i)\n        for (unsigned int j = 0; j < mColumnCount; ++j)\n            Matrix::at(i, j) = std::numeric_limits<double>::quiet_NaN();\n}"
      },
      {
        "partial": "void const\nMutualInformationMatrix::build()\n{\n    // TODO: Implement parallel computation of mutual information\n}",
        "complete": "void const\nMutualInformationMatrix::build()\n{\n#ifdef _OPENMP\n#pragma omp parallel for schedule(static)\n#endif\n    for (unsigned int i = 0; i < mColumnCount; ++i)\n        for (unsigned int j = 0; j < mColumnCount; ++j)\n            at(i, j);\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat/test-utils-optimization.R",
    "language": "R",
    "content": "library(testthat)\ntestthat::local_edition(3)\n\n# Create some dummy data\nhillEqn <- function(x, Emin, Emax, EC50, lambda) {\n    (Emin + Emax * (x / EC50)^lambda) / (1 + (x / EC50)^lambda)\n}\n# Set parameters for function testing\ndoses <- rev(1000 / (5^(1:10)))\nlambda <- 0.6\nEmin <- 1\nEmax <- 0.5\nEC50 <- median(doses)\n# Helper to combine\nfx <- if (is_optim_compatible(hillEqn)) hillEqn else\n    make_optim_function(hillEqn, lambda=lambda, Emin=Emin)\nresponse <- hillEqn(doses, Emin=Emin, lambda=lambda, Emax=Emax, EC50=EC50)\nnresponse <- response + rnorm(length(response), sd=sd(response)*0.1)\n\n# -- Loss function tests\nlmsg <- c(\"LOSS FUNCTION: \")\ntestthat::test_that(paste0(lmsg, \".residual and .normal_loss produce equal results.\"), {\n    trunc_vals <- c(FALSE, TRUE, FALSE, TRUE)\n    nvals <- c(1, 1, 3, 3)\n    for (i in seq_along(trunc_vals)) {\n        n1 <- .residual(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, f=fx,\n            family=\"normal\", n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        n2 <- CoreGx:::.normal_loss(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, fn=fx,\n            n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        testthat::expect_equal(n1, n2,\n            info=paste0(\"trunc: \", trunc_vals[i], \", n: \", nvals[i])\n        )\n    }\n})\n\ntestthat::test_that(paste0(lmsg, \".residual and .cauchy_loss produce equal results.\"), {\n    trunc_vals <- c(FALSE, TRUE, FALSE, TRUE)\n    nvals <- c(1, 1, 3, 3)\n    for (i in seq_along(trunc_vals)) {\n        c1 <- .residual(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, f=fx,\n            family=\"Cauchy\", n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        c2 <- CoreGx:::.cauchy_loss(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, fn=fx,\n            n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        testthat::expect_equal(c1, c2,\n            info=paste0(\"trunc: \", trunc_vals[i], \", n: \", nvals[i])\n        )\n    }\n})\n\n# -- Curve fitting\ncmsg <- \"CURVE FITTING: \"\ntestthat::test_that(paste0(cmsg, \".fitCurve and .fitCurve2 produce equal results for 2-parameter Hill curve.\"), {\n    par_list <- list(c(Emax=0.1, EC50=0.1), c(Emax=0.5, EC5O=500), c(Emax=0.9, EC50=100))\n    for (i in seq_along(par_list)) {\n        pars <- par_list[[i]]\n        normal_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"normal\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses)),\n            lower_bound=c(0, min(doses)),\n            density=c(2, 10),\n            precision=1e-4,\n            step=0.5 / c(2, 10)\n        )\n        normal_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.normal_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            lambda=lambda,\n            upper=c(2, max(doses)),\n            lower=c(0, min(doses)),\n            density=c(2, 10),\n            precision=1e-4,\n            step=0.5 / c(2, 10)\n        )\n        testthat::expect_equal(normal_par1, normal_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n        cauchy_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"Cauchy\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses)),\n            lower_bound=c(0, min(doses)),\n            density=c(2, 10),\n            precision=1e-4,\n            step=0.5 / c(2, 10)\n        )\n        cauchy_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.cauchy_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            lambda=lambda,\n            upper=c(2, max(doses)),\n            lower=c(0, min(doses)),\n            density=c(2, 10),\n            precision=1e-4,\n            step=0.5 / c(2, 10)\n        )\n        testthat::expect_equal(cauchy_par1, cauchy_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n    }\n})\n\n\ntestthat::test_that(\n    paste0(cmsg, \".fitCurve and .fitCurve2 produce equal results for 3-parameter Hill curve.\"), {\n    par_list <- list(\n        c(Emax=0.1, EC50=0.1, lambda=1),\n        c(Emax=0.5, EC5O=500, lambda=0.75),\n        c(Emax=0.9, EC50=100, lambda=2)\n    )\n    fx <- make_optim_function(hillEqn, Emin=Emin)\n    for (i in seq_along(par_list)) {\n        pars <- par_list[[i]]\n        normal_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"normal\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses), 6),\n            lower_bound=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        normal_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.normal_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            upper=c(2, max(doses), 6),\n            lower=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        testthat::expect_equal(normal_par1, normal_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n        cauchy_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"Cauchy\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses), 6),\n            lower_bound=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        cauchy_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.cauchy_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            upper=c(2, max(doses), 6),\n            lower=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        testthat::expect_equal(cauchy_par1, cauchy_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n    }\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `hillEqn` function in this code, and how is it used to generate test data?",
        "answer": "The `hillEqn` function represents the Hill equation, which is commonly used in dose-response modeling. In this code, it's used to generate synthetic dose-response data for testing purposes. The function takes parameters Emin (minimum effect), Emax (maximum effect), EC50 (half-maximal effective concentration), and lambda (Hill slope). Test data is created by calling this function with specific parameter values and a range of doses, then adding random noise to simulate real-world variability."
      },
      {
        "question": "How do the `.fitCurve` and `.fitCurve2` functions differ, and what is the purpose of comparing their results in the test cases?",
        "answer": "`.fitCurve` and `.fitCurve2` are two different implementations for fitting dose-response curves. The test cases compare their results to ensure they produce equivalent outputs for both 2-parameter and 3-parameter Hill curve fittings. This comparison is crucial for validating that any refactoring or optimization in the curve fitting process (likely represented by `.fitCurve2`) maintains the same functionality as the original method (`.fitCurve`). The tests check for equality under various conditions, including different initial parameter guesses, normal and Cauchy distributions, and different parameter constraints."
      },
      {
        "question": "What is the significance of the `trunc` and `n` parameters in the loss function tests, and how are they varied in the test cases?",
        "answer": "The `trunc` and `n` parameters are important options in the loss function calculations. `trunc` likely refers to whether the loss function should use truncated distributions, while `n` might represent the number of replicates or a smoothing parameter. In the test cases, these parameters are systematically varied using boolean values for `trunc` (TRUE/FALSE) and different integer values for `n` (1 and 3). This variation ensures that the loss functions (`.residual`, `.normal_loss`, and `.cauchy_loss`) produce consistent results across different configurations, thus thoroughly testing the robustness of the implementation."
      }
    ],
    "completion_tasks": [
      {
        "partial": "testthat::test_that(paste0(lmsg, \".residual and .normal_loss produce equal results.\"), {\n    trunc_vals <- c(FALSE, TRUE, FALSE, TRUE)\n    nvals <- c(1, 1, 3, 3)\n    for (i in seq_along(trunc_vals)) {\n        n1 <- .residual(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, f=fx,\n            family=\"normal\", n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        n2 <- CoreGx:::.normal_loss(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, fn=fx,\n            n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        # Complete the test expectation\n    }\n})",
        "complete": "testthat::test_that(paste0(lmsg, \".residual and .normal_loss produce equal results.\"), {\n    trunc_vals <- c(FALSE, TRUE, FALSE, TRUE)\n    nvals <- c(1, 1, 3, 3)\n    for (i in seq_along(trunc_vals)) {\n        n1 <- .residual(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, f=fx,\n            family=\"normal\", n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        n2 <- CoreGx:::.normal_loss(par=c(Emax=0.2, EC50=10), x=doses, y=nresponse, fn=fx,\n            n=nvals[i], trunc=trunc_vals[i], scale=0.07)\n        testthat::expect_equal(n1, n2,\n            info=paste0(\"trunc: \", trunc_vals[i], \", n: \", nvals[i])\n        )\n    }\n})"
      },
      {
        "partial": "testthat::test_that(paste0(cmsg, \".fitCurve and .fitCurve2 produce equal results for 3-parameter Hill curve.\"), {\n    par_list <- list(\n        c(Emax=0.1, EC50=0.1, lambda=1),\n        c(Emax=0.5, EC5O=500, lambda=0.75),\n        c(Emax=0.9, EC50=100, lambda=2)\n    )\n    fx <- make_optim_function(hillEqn, Emin=Emin)\n    for (i in seq_along(par_list)) {\n        pars <- par_list[[i]]\n        normal_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"normal\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses), 6),\n            lower_bound=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        normal_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.normal_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            upper=c(2, max(doses), 6),\n            lower=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        # Complete the test expectation and add Cauchy distribution test\n    }\n})",
        "complete": "testthat::test_that(paste0(cmsg, \".fitCurve and .fitCurve2 produce equal results for 3-parameter Hill curve.\"), {\n    par_list <- list(\n        c(Emax=0.1, EC50=0.1, lambda=1),\n        c(Emax=0.5, EC5O=500, lambda=0.75),\n        c(Emax=0.9, EC50=100, lambda=2)\n    )\n    fx <- make_optim_function(hillEqn, Emin=Emin)\n    for (i in seq_along(par_list)) {\n        pars <- par_list[[i]]\n        normal_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"normal\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses), 6),\n            lower_bound=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        normal_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.normal_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            upper=c(2, max(doses), 6),\n            lower=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        testthat::expect_equal(normal_par1, normal_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n        cauchy_par1 <- .fitCurve(\n            gritty_guess=pars,\n            x=doses,\n            y=nresponse,\n            f=fx,\n            family=\"Cauchy\",\n            trunc=FALSE,\n            median_n=1,\n            scale=0.07,\n            upper_bound=c(2, max(doses), 6),\n            lower_bound=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        cauchy_par2 <-.fitCurve2(\n            par=pars,\n            x=doses,\n            y=nresponse,\n            fn=hillEqn,\n            loss=CoreGx:::.cauchy_loss,\n            loss_args=list(trunc=FALSE, n=1, scale=0.07),\n            Emin=Emin,\n            upper=c(2, max(doses), 6),\n            lower=c(0, min(doses), 0),\n            density=c(2, 10, 5),\n            precision=1e-4,\n            step=0.5 / c(2, 10, 5)\n        )\n        testthat::expect_equal(cauchy_par1, cauchy_par2,\n            info=paste0(\"Emax: \", pars[1], \", EC50: \", pars[2]))\n    }\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/R/mRMRe.Filter.R",
    "language": "R",
    "content": "## Definition\n\nsetClass(\"mRMRe.Filter\", representation(filters = \"list\", scores = \"list\", \n    mi_matrix = \"matrix\", causality_list = \"list\", sample_names = \"character\", \n    feature_names = \"character\", target_indices = \"integer\", \n    fixed_feature_count = \"numeric\", levels = \"integer\"))\n\n## Wrappers\n\n`mRMR.ensemble` <- function(solution_count, feature_count, ...)\n{\n    return(new(\"mRMRe.Filter\", levels = c(solution_count, rep(1, feature_count - 1)), ...))\n}\n\n`mRMR.classic` <- function(feature_count, ...)\n{\n    return(new(\"mRMRe.Filter\", levels = rep(1, feature_count), ...))\n}\n\n## initialize\n\nsetMethod(\"initialize\", signature(\"mRMRe.Filter\"),\n        function(.Object, data, prior_weight, target_indices, levels, \n          method = c(\"exhaustive\", \"bootstrap\"), \n          continuous_estimator = c(\"pearson\", \"spearman\", \"kendall\", \"frequency\"), \n          fixed_feature_count = 0,\n          outX = TRUE,\n          bootstrap_count = 0)\n{\n    method <- match.arg(method)\n    continuous_estimator <- match.arg(continuous_estimator)\n    \n    if (class(data) != \"mRMRe.Data\")\n        stop(\"data must be of type mRMRe.Data\")\n    \n    ## Prior Processing\n    \n    if (length(priors(data)) != 0)\n    {\n        if (missing(prior_weight))\n            stop(\"prior weight must be provided if there are priors\")\n        else if  (prior_weight < 0 || prior_weight > 1)\n            stop(\"prior weight must be a value ranging from 0 to 1\")\n    }\n    else\n        prior_weight <- 0\n    \n    ## Target Processing\n\n    if (sum(sapply(target_indices, function(index) index < 1 || index > featureCount(data))) > 1)\n        stop(\"target_indices must only contain values ranging from 1 to the number of features in data\")\n    \n    ## Level Processing\n    \n    if (missing(levels))\n      stop(\"levels must be provided\")\n    \n            \n    ## Fixed selected feature processing\n    if (fixed_feature_count > length(levels))\n        stop(\"The number of fixed selected features can not be larger the length of solutions\")\n    \n    if (fixed_feature_count > 0)\n        length(levels) <- length(levels) - fixed_feature_count\n    \n\n    .Object@fixed_feature_count <- fixed_feature_count\n    \n    .Object@target_indices <- as.integer(c(target_indices))\n    .Object@levels <- as.integer(c(levels))\n    \n    target_indices <- as.integer(.expandFeatureIndices(data, target_indices)) - 1\n    \n    \n    \n    ## Filter; Mutual Information and Causality Matrix\n\n    mi_matrix <- as.numeric(matrix(NA, ncol = ncol(data@data), nrow = ncol(data@data)))\n    \n    \n\tif(method == \"exhaustive\"){\n\t  \n\t    ## Level Processing\n\t    if ((prod(levels) - 1) > choose(featureCount(data) - 1, length(levels)))\n\t      stop(\"user cannot request for more solutions than is possible given the data set\")\n    \n    \tresult <- .Call(.C_export_filters, as.integer(.Object@levels), as.numeric(data@data),\n        \t    as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata), as.numeric(data@weights),\n            \tas.integer(data@feature_types), as.integer(nrow(data@data)), as.integer(ncol(data@data)),\n            \tas.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n            \tas.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n            \tas.integer(bootstrap_count), mi_matrix)\n\t}\n\telse if(method == \"bootstrap\")\n\t\tresult <- .Call(.C_export_filters_bootstrap, as.integer(.Object@levels[1]), as.integer(length(.Object@levels)),\n\t\t\t\tas.numeric(data@data), as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata),\n\t\t\t\tas.numeric(data@weights), as.integer(data@feature_types), as.integer(nrow(data@data)),\n\t\t\t\tas.integer(ncol(data@data)), as.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n\t\t\t\tas.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n\t\t\t\tas.integer(bootstrap_count), mi_matrix)\n\telse\n\t\tstop(\"Unrecognized method: use exhaustive or bootstrap\")\n    \n    \n    \n    .Object@filters <- lapply(result[[1]], function(solutions) matrix(.compressFeatureIndices(data, solutions + 1),\n                        nrow = length(levels), ncol = prod(levels)))\n\t\n    names(.Object@filters) <- .Object@target_indices\n    .Object@causality_list <- result[[2]]\n\t.Object@scores <- lapply(result[[3]], function(scores) matrix(scores,\tnrow = length(levels), ncol = prod(levels)))\n\tnames(.Object@scores) <- .Object@target_indices\n    \n\tcols_to_drop <- duplicated(.compressFeatureIndices(data, seq(ncol(data@data))))\n    \n    .Object@causality_list <- lapply(result[[2]], function(causality_array) causality_array[!cols_to_drop])\n    names(.Object@causality_list) <- .Object@target_indices\n    \n    .Object@mi_matrix <- .compressFeatureMatrix(data, matrix(mi_matrix, ncol = ncol(data@data), nrow = ncol(data@data)))\n    .Object@feature_names <- featureNames(data)\n    .Object@sample_names <- sampleNames(data)\n\n    return(.Object)\n})\n\n## show\n\nsetMethod(\"show\", signature(\"mRMRe.Filter\"), function(object)\n{\n    str(object)\n})\n\n## sampleCount\n\nsetMethod(\"sampleCount\", signature(\"mRMRe.Filter\"), function(object)\n{\n    return(length(object@sample_names))\n})\n\n## sampleNames\n\nsetMethod(\"sampleNames\", signature(\"mRMRe.Filter\"), function(object)\n{\n    return(object@sample_names)\n})\n\n\n## featureCount\n\nsetMethod(\"featureCount\", signature(\"mRMRe.Filter\"), function(object)\n{\n    return(length(object@feature_names))\n})\n\n## featureNames\n\nsetMethod(\"featureNames\", signature(\"mRMRe.Filter\"), function(object)\n{\n    return(object@feature_names)\n})\n\n## solutions\n\nsetMethod(\"solutions\", signature(\"mRMRe.Filter\"), \n    function(object, mi_threshold = -Inf, causality_threshold = Inf, \n    with_fixed_features = TRUE)\n{\n    # filters[[target]][solution, ] is a vector of selected features\n    # in a solution for a target; missing values denote removed features\n            \n    filters <- lapply(object@target_indices, function(target_index)\n    {\n        result_matrix <- object@filters[[as.character(target_index)]]\n        causality_dropped <- which(object@causality_list[[as.character(target_index)]] > causality_threshold &\n                        !is.na(object@causality_list[[as.character(target_index)]]))\n        mi_dropped <- which(-.5 * log(1 - object@mi_matrix[, target_index, drop = TRUE]^2) < mi_threshold)\n        result_matrix[result_matrix %in% c(causality_dropped, mi_dropped)] <- NA\n\n        pre_return_matrix <- apply(as.matrix(result_matrix), 2, rev)\n\n        return(pre_return_matrix)\n    })\n    \n\n    # Concate the fixed selected features\n    if (object@fixed_feature_count > 0 && with_fixed_features)\n    {\n  \n        prefix <- matrix(seq(object@fixed_feature_count), nrow = object@fixed_feature_count, ncol = as.numeric(dim(filters[[1]])[2]), byrow = FALSE)\n        \n        filters <- lapply(seq(length(filters)), function(i)\n        {\n            filters[[i]] <- rbind(prefix, filters[[i]])\n            return(filters[[i]])\n        })\n        \n    }\n    \n    names(filters) <- object@target_indices\n    return(filters)\n})\n\n## scores\nsetMethod(\"scores\", signature(\"mRMRe.Filter\"), function(object)\n{\n\tmi_matrix <- mim(object)\n\ttargets <- as.character(target(object))\n\tscores <- lapply(targets, function(target) {\n\t\t\t\tapply(solutions(object)[[target]], 2, function(solution) {\n\t\t\t\t\t\t\tsapply(1:length(solution), function(i) {\n\t\t\t\t\t\t\t\t\t\tfeature_i <- solution[i] \n\t\t\t\t\t\t\t\t\t\tif(i == 1)\n\t\t\t\t\t\t\t\t\t\t\treturn(mi_matrix[as.numeric(target), feature_i])\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tancestry_score <- mean(sapply((i-1):1, function(j) mi_matrix[feature_i, solution[j]]))\n\t\t\t\t\t\t\t\t\t\treturn(mi_matrix[as.numeric(target), feature_i] - ancestry_score)\n\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t})\n\t\t\t})\n\tnames(scores) <- targets\n\treturn(scores)\n})\n\n## mim\n\nsetMethod(\"mim\", signature(\"mRMRe.Filter\"), function(object, method=c(\"mi\", \"cor\"))\n{\n    method <- match.arg(method)\n    # mi_matrix[i, j] contains the biased correlation between\n    # features i and j (i -> j directionality)\n    return(object@mi_matrix)\n})\n\n## causality\n\nsetMethod(\"causality\", signature(\"mRMRe.Filter\"), function(object)\n{\n    # causality_matrix[[target]][feature] contains the causality coefficient\n    # between feature and target (feature -> target directionality)\n    return(object@causality_list)\n})\n    \n## target\n\nsetMethod(\"target\", signature(\"mRMRe.Filter\"), function(object)\n{\n    return(object@target_indices)\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mRMR.ensemble` and `mRMR.classic` functions in this code?",
        "answer": "The `mRMR.ensemble` and `mRMR.classic` functions are wrapper functions that create instances of the 'mRMRe.Filter' class with specific configurations. `mRMR.ensemble` creates a filter with multiple solutions (ensemble) by setting different levels for feature selection, while `mRMR.classic` creates a filter with a single solution by setting all levels to 1. Both functions simplify the process of creating 'mRMRe.Filter' objects with predefined parameters."
      },
      {
        "question": "How does the `initialize` method handle the processing of fixed selected features?",
        "answer": "The `initialize` method processes fixed selected features as follows:\n1. It checks if the number of fixed features (`fixed_feature_count`) is greater than the length of the `levels` parameter. If so, it throws an error.\n2. If `fixed_feature_count` is greater than 0, it reduces the length of the `levels` vector by subtracting `fixed_feature_count`.\n3. It stores the `fixed_feature_count` in the object's `@fixed_feature_count` slot.\n4. Later in the method, it passes the `fixed_feature_count` to the C++ function call that performs the actual filtering.\n5. In the `solutions` method, if `fixed_feature_count` is greater than 0 and `with_fixed_features` is TRUE, it prepends the fixed features to the solution matrices."
      },
      {
        "question": "Explain the purpose and functionality of the `solutions` method in the 'mRMRe.Filter' class.",
        "answer": "The `solutions` method in the 'mRMRe.Filter' class serves to retrieve and process the feature selection solutions. Its main functionalities are:\n1. It extracts solutions for each target index from the `@filters` slot.\n2. It applies thresholds for mutual information and causality, removing features that don't meet these criteria.\n3. It reverses the order of features in each solution.\n4. If there are fixed selected features and `with_fixed_features` is TRUE, it prepends these features to the solutions.\n5. It returns a list of matrices, where each matrix represents the selected features for a target, with columns corresponding to different solutions and rows representing the selected features in order of importance.\nThis method allows users to access the feature selection results with optional filtering and inclusion of fixed features."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"initialize\", signature(\"mRMRe.Filter\"),\n        function(.Object, data, prior_weight, target_indices, levels, \n          method = c(\"exhaustive\", \"bootstrap\"), \n          continuous_estimator = c(\"pearson\", \"spearman\", \"kendall\", \"frequency\"), \n          fixed_feature_count = 0,\n          outX = TRUE,\n          bootstrap_count = 0)\n{\n    method <- match.arg(method)\n    continuous_estimator <- match.arg(continuous_estimator)\n    \n    if (class(data) != \"mRMRe.Data\")\n        stop(\"data must be of type mRMRe.Data\")\n    \n    ## Prior Processing\n    \n    if (length(priors(data)) != 0)\n    {\n        if (missing(prior_weight))\n            stop(\"prior weight must be provided if there are priors\")\n        else if  (prior_weight < 0 || prior_weight > 1)\n            stop(\"prior weight must be a value ranging from 0 to 1\")\n    }\n    else\n        prior_weight <- 0\n    \n    ## Target Processing\n\n    if (sum(sapply(target_indices, function(index) index < 1 || index > featureCount(data))) > 1)\n        stop(\"target_indices must only contain values ranging from 1 to the number of features in data\")\n    \n    ## Level Processing\n    \n    if (missing(levels))\n      stop(\"levels must be provided\")\n    \n            \n    ## Fixed selected feature processing\n    if (fixed_feature_count > length(levels))\n        stop(\"The number of fixed selected features can not be larger the length of solutions\")\n    \n    if (fixed_feature_count > 0)\n        length(levels) <- length(levels) - fixed_feature_count\n    \n\n    .Object@fixed_feature_count <- fixed_feature_count\n    \n    .Object@target_indices <- as.integer(c(target_indices))\n    .Object@levels <- as.integer(c(levels))\n    \n    target_indices <- as.integer(.expandFeatureIndices(data, target_indices)) - 1\n    \n    \n    \n    ## Filter; Mutual Information and Causality Matrix\n\n    mi_matrix <- as.numeric(matrix(NA, ncol = ncol(data@data), nrow = ncol(data@data)))\n    \n    \n\tif(method == \"exhaustive\"){\n\t  \n\t    ## Level Processing\n\t    if ((prod(levels) - 1) > choose(featureCount(data) - 1, length(levels)))\n\t      stop(\"user cannot request for more solutions than is possible given the data set\")\n    \n    \tresult <- .Call(.C_export_filters, as.integer(.Object@levels), as.numeric(data@data),\n        \t    as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata), as.numeric(data@weights),\n            \tas.integer(data@feature_types), as.integer(nrow(data@data)), as.integer(ncol(data@data)),\n            \tas.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n            \tas.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n            \tas.integer(bootstrap_count), mi_matrix)\n\t}\n\telse if(method == \"bootstrap\")\n\t\tresult <- .Call(.C_export_filters_bootstrap, as.integer(.Object@levels[1]), as.integer(length(.Object@levels)),\n\t\t\t\tas.numeric(data@data), as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata),\n\t\t\t\tas.numeric(data@weights), as.integer(data@feature_types), as.integer(nrow(data@data)),\n\t\t\t\tas.integer(ncol(data@data)), as.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n\t\t\t\tas.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n\t\t\t\tas.integer(bootstrap_count), mi_matrix)\n\telse\n\t\tstop(\"Unrecognized method: use exhaustive or bootstrap\")\n    \n    \n    \n    .Object@filters <- lapply(result[[1]], function(solutions) matrix(.compressFeatureIndices(data, solutions + 1),\n                        nrow = length(levels), ncol = prod(levels)))\n\t\n    names(.Object@filters) <- .Object@target_indices\n    .Object@causality_list <- result[[2]]\n\t.Object@scores <- lapply(result[[3]], function(scores) matrix(scores,\tnrow = length(levels), ncol = prod(levels)))\n\tnames(.Object@scores) <- .Object@target_indices\n    \n\tcols_to_drop <- duplicated(.compressFeatureIndices(data, seq(ncol(data@data))))\n    \n    .Object@causality_list <- lapply(result[[2]], function(causality_array) causality_array[!cols_to_drop])\n    names(.Object@causality_list) <- .Object@target_indices\n    \n    .Object@mi_matrix <- .compressFeatureMatrix(data, matrix(mi_matrix, ncol = ncol(data@data), nrow = ncol(data@data)))\n    .Object@feature_names <- featureNames(data)\n    .Object@sample_names <- sampleNames(data)\n\n    return(.Object)\n})",
        "complete": "setMethod(\"initialize\", signature(\"mRMRe.Filter\"),\n        function(.Object, data, prior_weight, target_indices, levels, \n          method = c(\"exhaustive\", \"bootstrap\"), \n          continuous_estimator = c(\"pearson\", \"spearman\", \"kendall\", \"frequency\"), \n          fixed_feature_count = 0,\n          outX = TRUE,\n          bootstrap_count = 0)\n{\n    method <- match.arg(method)\n    continuous_estimator <- match.arg(continuous_estimator)\n    \n    if (class(data) != \"mRMRe.Data\")\n        stop(\"data must be of type mRMRe.Data\")\n    \n    if (length(priors(data)) != 0) {\n        if (missing(prior_weight))\n            stop(\"prior weight must be provided if there are priors\")\n        else if (prior_weight < 0 || prior_weight > 1)\n            stop(\"prior weight must be a value ranging from 0 to 1\")\n    } else prior_weight <- 0\n    \n    if (sum(sapply(target_indices, function(index) index < 1 || index > featureCount(data))) > 1)\n        stop(\"target_indices must only contain values ranging from 1 to the number of features in data\")\n    \n    if (missing(levels))\n      stop(\"levels must be provided\")\n    \n    if (fixed_feature_count > length(levels))\n        stop(\"The number of fixed selected features can not be larger the length of solutions\")\n    \n    if (fixed_feature_count > 0)\n        length(levels) <- length(levels) - fixed_feature_count\n    \n    .Object@fixed_feature_count <- fixed_feature_count\n    .Object@target_indices <- as.integer(c(target_indices))\n    .Object@levels <- as.integer(c(levels))\n    \n    target_indices <- as.integer(.expandFeatureIndices(data, target_indices)) - 1\n    \n    mi_matrix <- as.numeric(matrix(NA, ncol = ncol(data@data), nrow = ncol(data@data)))\n    \n    if (method == \"exhaustive\") {\n        if ((prod(levels) - 1) > choose(featureCount(data) - 1, length(levels)))\n          stop(\"user cannot request for more solutions than is possible given the data set\")\n        \n        result <- .Call(.C_export_filters, as.integer(.Object@levels), as.numeric(data@data),\n                as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata), as.numeric(data@weights),\n                as.integer(data@feature_types), as.integer(nrow(data@data)), as.integer(ncol(data@data)),\n                as.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n                as.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n                as.integer(bootstrap_count), mi_matrix)\n    } else if (method == \"bootstrap\") {\n        result <- .Call(.C_export_filters_bootstrap, as.integer(.Object@levels[1]), as.integer(length(.Object@levels)),\n                as.numeric(data@data), as.numeric(data@priors), as.numeric(prior_weight), as.integer(data@strata),\n                as.numeric(data@weights), as.integer(data@feature_types), as.integer(nrow(data@data)),\n                as.integer(ncol(data@data)), as.integer(length(unique(data@strata))), as.integer(target_indices), as.integer(fixed_feature_count),\n                as.integer(.map.continuous.estimator(continuous_estimator)), as.integer(outX),\n                as.integer(bootstrap_count), mi_matrix)\n    } else stop(\"Unrecognized method: use exhaustive or bootstrap\")\n    \n    .Object@filters <- lapply(result[[1]], function(solutions) matrix(.compressFeatureIndices(data, solutions + 1),\n                        nrow = length(levels), ncol = prod(levels)))\n    names(.Object@filters) <- .Object@target_indices\n    .Object@causality_list <- result[[2]]\n    .Object@scores <- lapply(result[[3]], function(scores) matrix(scores, nrow = length(levels), ncol = prod(levels)))\n    names(.Object@scores) <- .Object@target_indices\n    \n    cols_to_drop <- duplicated(.compressFeatureIndices(data, seq(ncol(data@data))))\n    \n    .Object@causality_list <- lapply(result[[2]], function(causality_array) causality_array[!cols_to_drop])\n    names(.Object@causality_list) <- .Object@target_indices\n    \n    .Object@mi_matrix <- .compressFeatureMatrix(data, matrix(mi_matrix, ncol = ncol(data@data), nrow = ncol(data@data)))\n    .Object@feature_names <- featureNames(data)\n    .Object@sample_names <- sampleNames(data)\n\n    return(.Object)\n})"
      },
      {
        "partial": "setMethod(\"solutions\", signature(\"mRMRe.Filter\"), \n    function(object, mi_threshold = -Inf, causality_threshold = Inf, \n    with_fixed_features = TRUE)\n{\n    filters <- lapply(object@target_indices, function(target_index)\n    {\n        result_matrix <- object@filters[[as.character(target_index)]]\n        causality_dropped <- which(object@causality_list[[as.character(target_index)]] > causality_threshold &\n                        !is.na(object@causality_list[[as.character(target_index)]]))\n        mi_dropped <- which(-.5 * log(1 - object@mi_matrix[, target_index, drop = TRUE]^2) < mi_threshold)\n        result_matrix[result_matrix %in% c(causality_dropped, mi_dropped)] <- NA\n\n        pre_return_matrix <- apply(as.matrix(result_matrix), 2, rev)\n\n        return(pre_return_matrix)\n    })\n    \n\n    if (object@fixed_feature_count > 0 && with_fixed_features)\n    {\n  \n        prefix <- matrix(seq(object@fixed_feature_count), nrow = object@fixed_feature_count, ncol = as.numeric(dim(filters[[1]])[2]), byrow = FALSE)\n        \n        filters <- lapply(seq(length(filters)), function(i)\n        {\n            filters[[i]] <- rbind(prefix, filters[[i]])\n            return(filters[[i]])\n        })\n        \n    }\n    \n    names(filters) <- object@target_indices\n    return(filters)\n})",
        "complete": "setMethod(\"solutions\", signature(\"mRMRe.Filter\"), \n    function(object, mi_threshold = -Inf, causality_threshold = Inf, \n    with_fixed_features = TRUE)\n{\n    filters <- lapply(object@target_indices, function(target_index) {\n        result_matrix <- object@filters[[as.character(target_index)]]\n        causality_dropped <- which(object@causality_list[[as.character(target_index)]] > causality_threshold &\n                        !is.na(object@causality_list[[as.character(target_index)]]))\n        mi_dropped <-"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  }
]