[
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/unitest/test_unit_mi_matrix.R",
    "language": "R",
    "content": "library(mRMRe)\n\n##\n## Tests\n##\n\ndd <- data.frame(\"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n                 \"cont1\" = runif(100),\n                 \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n                 \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n                 \"cont2\" = runif(100),\n                 \"cont3\" = runif(100),\n                 \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n                 \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE))\n\ndata <- mRMR.data(data = dd)\nfilter_1 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = sample(1:8, 4, replace = FALSE),\n        feature_count = 2, solution_count = 2)\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1, 2), feature_count = 2, solution_count = 3)\n\nmi_master <- mim(data)\ndiag(mi_master) <- 0\n\nmi_slave_list <- list()\nmi_slave_list[[1]] <- mim(filter_1)\nmi_slave_list[[2]] <- mim(filter_2)\n\nfor (slave_index in seq(length(mi_slave_list)))\n{\n    diag(mi_slave_list[[slave_index]]) <- 0\n    mi_slave <- as.vector(mi_slave_list[[slave_index]])\n    \n    mi_slave_list[[slave_index]] <- 0\n    \n    for (feature in seq(mi_slave))\n    {\n        if (!is.na(mi_slave[[feature]]))\n            mi_slave_list[[slave_index]] <- mi_slave_list[[slave_index]] +\n                    (abs(mi_slave[[feature]] - mi_master[[feature]]) < 1e-5)\n    }\n    \n    mi_slave_list[[slave_index]] <- length(mi_slave) - mi_slave_list[[slave_index]]\n}\n\nerror_rate <- mean(as.integer(mi_slave_list)) / length(as.numeric(mi_master))\n\nprint(paste(\"Error rate: \", error_rate))\n\n# FIXME: Add tests on network object",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mRMR.data()` function in this code, and how is it used?",
        "answer": "The `mRMR.data()` function is used to create a data object suitable for use with the mRMRe package. In this code, it's used to convert the `dd` data frame into a format that can be processed by other mRMRe functions. The resulting `data` object is then used as input for the `mRMR.ensemble()` function calls."
      },
      {
        "question": "Explain the difference between `filter_1` and `filter_2` in terms of their parameters and potential outputs.",
        "answer": "Both `filter_1` and `filter_2` use the `mRMR.ensemble()` function, but with different parameters. `filter_1` uses randomly sampled target indices (4 out of 8), while `filter_2` specifically targets indices 1 and 2. `filter_1` generates 2 solutions, while `filter_2` generates 3. This means `filter_2` will produce more consistent results focused on specific targets, while `filter_1` explores a broader range of feature combinations."
      },
      {
        "question": "What is the purpose of the nested loop in the code, and how does it contribute to calculating the error rate?",
        "answer": "The nested loop compares the mutual information matrices (MIM) of the master data and the filtered data. It counts the number of elements that differ by more than 1e-5 between the master and slave MIMs. This count is used to calculate a difference score for each slave MIM. The final error rate is computed as the average of these difference scores divided by the total number of elements in the master MIM, providing a measure of how much the filtered data differs from the original in terms of mutual information."
      }
    ],
    "completion_tasks": [
      {
        "partial": "library(mRMRe)\n\ndd <- data.frame(\n  \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont1\" = runif(100),\n  \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n  \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont2\" = runif(100),\n  \"cont3\" = runif(100),\n  \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE)\n)\n\ndata <- mRMR.data(data = dd)\nfilter_1 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = sample(1:8, 4, replace = FALSE),\n        feature_count = 2, solution_count = 2)\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1, 2), feature_count = 2, solution_count = 3)\n\nmi_master <- mim(data)\ndiag(mi_master) <- 0\n\nmi_slave_list <- list()\nmi_slave_list[[1]] <- mim(filter_1)\nmi_slave_list[[2]] <- mim(filter_2)\n\n# Complete the code to calculate the error rate",
        "complete": "library(mRMRe)\n\ndd <- data.frame(\n  \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont1\" = runif(100),\n  \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n  \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont2\" = runif(100),\n  \"cont3\" = runif(100),\n  \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE)\n)\n\ndata <- mRMR.data(data = dd)\nfilter_1 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = sample(1:8, 4, replace = FALSE),\n        feature_count = 2, solution_count = 2)\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1, 2), feature_count = 2, solution_count = 3)\n\nmi_master <- mim(data)\ndiag(mi_master) <- 0\n\nmi_slave_list <- list()\nmi_slave_list[[1]] <- mim(filter_1)\nmi_slave_list[[2]] <- mim(filter_2)\n\nfor (slave_index in seq_along(mi_slave_list)) {\n  diag(mi_slave_list[[slave_index]]) <- 0\n  mi_slave <- as.vector(mi_slave_list[[slave_index]])\n  mi_slave_list[[slave_index]] <- sum(!is.na(mi_slave) & abs(mi_slave - mi_master) >= 1e-5)\n}\n\nerror_rate <- mean(unlist(mi_slave_list)) / length(as.vector(mi_master))\nprint(paste(\"Error rate:\", error_rate))"
      },
      {
        "partial": "library(mRMRe)\n\n# Create a data frame with various types of data\ndd <- data.frame(\n  \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont1\" = runif(100),\n  \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n  \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont2\" = runif(100),\n  \"cont3\" = runif(100),\n  \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE)\n)\n\n# Create mRMR data object and filters\ndata <- mRMR.data(data = dd)\nfilter_1 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = sample(1:8, 4, replace = FALSE),\n        feature_count = 2, solution_count = 2)\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1, 2), feature_count = 2, solution_count = 3)\n\n# Calculate mutual information matrices\nmi_master <- mim(data)\ndiag(mi_master) <- 0\n\nmi_slave_list <- list(mim(filter_1), mim(filter_2))\n\n# Complete the code to process mi_slave_list and calculate the error rate",
        "complete": "library(mRMRe)\n\n# Create a data frame with various types of data\ndd <- data.frame(\n  \"surv1\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont1\" = runif(100),\n  \"cat1\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE),\n  \"surv2\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cont2\" = runif(100),\n  \"cont3\" = runif(100),\n  \"surv3\" = Surv(runif(100), sample(0:1, 100, replace = TRUE)),\n  \"cat2\"  = factor(sample(1:5, 100, replace = TRUE), ordered = TRUE)\n)\n\n# Create mRMR data object and filters\ndata <- mRMR.data(data = dd)\nfilter_1 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = sample(1:8, 4, replace = FALSE),\n        feature_count = 2, solution_count = 2)\nfilter_2 <- mRMR.ensemble(\"mRMRe.Filter\", data = data, target_indices = c(1, 2), feature_count = 2, solution_count = 3)\n\n# Calculate mutual information matrices\nmi_master <- mim(data)\ndiag(mi_master) <- 0\n\nmi_slave_list <- list(mim(filter_1), mim(filter_2))\n\n# Process mi_slave_list and calculate error rate\nmi_slave_list <- lapply(mi_slave_list, function(mi_slave) {\n  diag(mi_slave) <- 0\n  sum(!is.na(mi_slave) & abs(mi_slave - mi_master) >= 1e-5)\n})\n\nerror_rate <- mean(unlist(mi_slave_list)) / length(as.vector(mi_master))\nprint(paste(\"Error rate:\", error_rate))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/globals.R",
    "language": "R",
    "content": "# Define global variables for data.table functions\nutils::globalVariables(c('..idCols', 'rowKey', 'colKey', 'capture.output',\n    'filePath', '..cols', 'head', 'tail', 'sharedIDCols'))",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `utils::globalVariables()` function in this code snippet, and why might it be necessary?",
        "answer": "The `utils::globalVariables()` function is used to declare global variables for data.table functions. This is necessary to prevent R CMD check from generating NOTE messages about undefined global variables. It's particularly useful when using non-standard evaluation in packages, where variables are created dynamically or used within data.table operations."
      },
      {
        "question": "What are some of the global variables being defined in this code snippet, and what might they be used for in a data.table context?",
        "answer": "Some of the global variables being defined are 'rowKey', 'colKey', 'filePath', and 'sharedIDCols'. These variables are likely used in data.table operations: 'rowKey' and 'colKey' might be used for reshaping or merging operations, 'filePath' could be used for reading or writing files, and 'sharedIDCols' might represent shared identifier columns in join operations."
      },
      {
        "question": "Why does this code snippet use `utils::globalVariables()` instead of just `globalVariables()`?",
        "answer": "The code uses `utils::globalVariables()` to explicitly specify that the `globalVariables()` function is being called from the `utils` package. This is a good practice as it makes the code more robust and less dependent on the current search path. It ensures that the correct function is always called, even if another package with a similarly named function is loaded."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# Define global variables for data.table functions\nutils::globalVariables(c('..idCols', 'rowKey', 'colKey', 'capture.output',\n    'filePath', '..cols', 'head', 'tail', # Complete the list",
        "complete": "# Define global variables for data.table functions\nutils::globalVariables(c('..idCols', 'rowKey', 'colKey', 'capture.output',\n    'filePath', '..cols', 'head', 'tail', 'sharedIDCols'))"
      },
      {
        "partial": "# Define global variables for data.table functions\nutils::globalVariables(# Add the list of variables)",
        "complete": "# Define global variables for data.table functions\nutils::globalVariables(c('..idCols', 'rowKey', 'colKey', 'capture.output',\n    'filePath', '..cols', 'head', 'tail', 'sharedIDCols'))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/immutable-class.R",
    "language": "R",
    "content": "#' @title Constructor for \"immutable\" S3-class property\n#'\n#' @description\n#' This method should allow any S3 object in R to become immutable by\n#' intercepting `[<-`, `[[<-`, `$<-` and `c` during S3-method dispatch and\n#' returning an error.\n#'\n#' Reverse with call to the `mutable` function.\n#'\n#' @details\n#' The motivation for this class was to create pseudo-private slots in an R\n#' S4 object by preventing mutation of those slots outside of the accessors\n#' written for the class. It should behave as expected for R object which\n#' operate with 'copy-on-modify' semantics, including most base R functions and\n#' S3 objects.\n#'\n#' An environment was not suitable for this case due\n#' to the 'copy-by-reference' semantics, such that normal R assignment, which\n#' users assume makes a copy of the object, actually references the same\n#' environment in both the original and copy of the object.\n#'\n#' WARNING: This implementation is unable to intercept modifications to a\n#' `data.table` via the `set*` group of methods. This is because these methods\n#' are not S3 generics and therefore no mechanism exists for hooking into them\n#' to extend their functionality. In general, this helper class will only work\n#' for objects with an S3 interface.\n#'\n#' @param object,x Any R object which uses S3 method dispatch\n#'\n#' @return The `object` with \"immutable\" prepended to its class attribute.\n#'\n#' @examples\n#' immutable_list <- immutable(as.list(1:5))\n#' class(immutable_list)\n#' # errors during assignment operations\n#' tryCatch({ immutable_list$new <- 1 }, error=print)\n#'\n#' @seealso\n#' [`assignment-immutable`], [`setOps-immutable`]\n#'\n#' @md\n#' @rdname immutable\n#' @name immutable\n#' @export\nimmutable <- function(object) {\n    if (isS4(object)) stop(\"Can only set immutability for base and S3 classes!\")\n    # call mutable to prevent assigning immutable class twice\n    structure(mutable(object), class=c(\"immutable\", attributes(object)$class))\n}\n\n# register the new S3 class, so it can be used in S4 method dispatch\n#' @rdname immutable\n#' @name immutable\n#' @export\nsetOldClass(\"immutable\")\n\n#' @rdname immutable\n#' @export\nsetClassUnion(\"immutable_list\", c(\"immutable\", \"list\"))\n\n\n#' @title Check if an R object inherits from the immutable S3-class.\n#'\n#' @return `logical(1)` Does the object inherit from the \"immutable\" S3-class?\n#'\n#' @examples\n#' immutable_list <- immutable(as.list(1:5))\n#' is.immutable(immutable_list)\n#'\n#' @rdname immutable\n#' @export\nis.immutable <- function(object) {\n    is(object, \"immutable\")\n}\n\n\n#' @title Print method for objects inheriting from the \"immutable\" S3-class\n#'\n#' @param ... Fallthrough arguments to `print.default`.\n#'\n#' @return None, `invisible(NULL)`\n#'\n#' @rdname immutable\n#' @md\n#' @export\nprint.immutable <- function(x, ...) {\n    other_cls <- setdiff(attributes(x)$class, \"immutable\")\n    class(x) <- other_cls\n    cat(\"immutable\", class(x), \"\\n\")\n    print(x, ...)\n}\n\n#' @rdname immutable\n#' @export\nshow.immutable <- function(x) print(x)\n\n\n# -- Intercept subset and concatentate operations to return another \"immutable\"\n\n#' @title Intercept concatenation for \"immutable\" class objects to return another \"immutable\" class object.\n#'\n#' @description\n#' Ensures that `c` and `append` to an \"immutable\" class object return an\n#' immutable class object.\n#'\n#' @param x An R object inheriting from the \"immutable\" S3-clas\n#' @param ... Objects to concatenate to `x`.\n#'\n#' @return x with one or more values appended to it.\n#'\n#' @md\n#' @export\nc.immutable <- function(x, ...) {\n    new_obj <- NextMethod()\n    immutable(new_obj)\n}\n\n.immutable_emsg <- \"Object is immutable! Use `mutable(object)` to return a mutable copy.\"\n\n#' @name setOps-immutable\n#' @rdname setOps-immutable\n#'\n#' @title Subset an immutable object, returning another immutable object.\n#'\n#' @param x An R object inheriting from the \"immutable\" S3-class.\n#' @param ... Catch any additional parameters. Lets objects with arbitrary\n#' dimensions be made immutable.\n#'\n#' @return An immutable subset of `x`.\n#'\n#' @examples\n#' immut_mat <- immutable(matrix(1:100, 10, 10))\n#' immut_mat[1:5, 1:5]\n#'\n#' @md\n#' @aliases subset, [.immutable, [[.immutable, $.immutable\n#' @export\nsubset.immutable <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n#' @name [\n#' @rdname setOps-immutable\n#' @export\n`[.immutable` <- function(x, ...) {\n    if (is.data.table(x)) {\n        dots <- substitute(alist(...))\n        j_expr <- dots[[\"j\"]]\n        if (is.null(j_expr) && length(dots) > 2)\n            j_expr <- dots[[2 + 1]]  # index plus one due to alist call\n        if (!is.null(j_expr))\n            j_txt <- deparse(j_expr)\n            if (grepl(\":=|let[ ]*\\\\(|set[ ]*\\\\(\", j_txt))\n                stop(\"This data.table is immutable! No assignment by reference \",\n                \"allowed. Use `mutable(x)` to return a mutable copy.\",\n                    call.=FALSE)\n    }\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n#' @name [[\n#' @rdname setOps-immutable\n#' @export\n`[[.immutable` <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n#' @name $\n#' @rdname setOps-immutable\n#' @export\n`$.immutable` <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n\n# -- Intercept assignment to prevent modification\n\n#' @name assignment-immutable\n#' @rdname assignment-immutable\n#'\n#' @title Intercept assignment operations for \"immutable\" S3 objects.\n#'\n#' @description\n#' Prevents modification of objects labelled with the \"immutable\" S3-class by\n#' intercepting assignment during S3-method dispatch and returning an error.\n#'\n#' @param object,x An R object inherting from the \"immutable\" S3-class.\n#' @param ... Catch subset arguments for various dimensions.\n#' @param value Not used.\n#'\n#' @return None, throws an error.\n#'\n#' @examples\n#' immutable_df <- immutable(data.frame(a=1:5, b=letters[1:5]))\n#' # return immutable data.frame\n#' immutable_df[1:4, ]\n#' # return immutable vector\n#' immutable_df$a\n#'\n#' @md\n#' @usage \\\\method{subset}{immutable}(object, ...) <- value\n#' @aliases subset<-.immutable, [<-.immutable, [[<-.immutable, $<-.immubtale,\n#' colnames<-.immutable, rownames<-.immutable, dimnames<-.immutable,\n#' names<-.immutable\n#' @export\n`subset<-.immutable` <- function(object, ..., value) {\n    stop(.immutable_emsg, call.=FALSE)\n}\n#' @name [<-\n#' @rdname assignment-immutable\n#' @export\n`[<-.immutable` <- function(object, ..., value) {\n    stop(.immutable_emsg, call.=FALSE)\n}\n#' @name [[<-\n#' @rdname assignment-immutable\n#' @export\n`[[<-.immutable` <- function(object, ..., value) {\n    stop(.immutable_emsg, call.=FALSE)\n}\n#' @name $<-\n#' @rdname assignment-immutable\n#' @export\n`$<-.immutable` <- function(object, ..., value) {\n    stop(.immutable_emsg, call.=FALSE)\n}\n#' @name names<-\n#' @rdname assignment-immutable\n#' @export\n`names<-.immutable` <- function(x, value)\n    stop(.immutable_emsg, call.=FALSE)\n#' @name dimnames<-\n#' @rdname assignment-immutable\n#' @export\n`dimnames<-.immutable` <- function(x, value)\n    stop(.immutable_emsg, call.=FALSE)\n#' @name colnames<-\n#' @rdname assignment-immutable\n#' @usage \\\\method{colnames}{immutable}(x) <- value\n#' @export\n`colnames<-.immutable` <- function(x, value)\n    stop(.immutable_emsg, call.=FALSE)\n#' @name rownames<-\n#' @rdname assignment-immutable\n#' @usage \\\\method{rownames}{immutable}(x) <- value\n#' @export\n`rownames<-.immutable` <- function(x, value)\n    stop(.immutable_emsg, call.=FALSE)\n\n\n# -- Remove immutability from an R object\n\n\n#' @title Remove the \"immutable\" S3-class from an R object, allowing it to be\n#' modified normally again.\n#'\n#' @param object An R object inheriting from the \"immutable\" class.\n#'\n#' @return The `object` with the \"immutable\" class stripped from it.\n#'\n#' @examples\n#' immut_list <- immutable(list())\n#' mutable(immut_list)\n#'\n#' @md\n#' @export\nmutable <- function(object) UseMethod(\"mutable\", object)\n#'\n#' @md\n#' @importFrom data.table copy\n#' @export\nmutable.default <- function(object) {\n    new_class <- setdiff(attributes(object)$class, \"immutable\")\n    structure(copy(object), class=new_class)\n}\n\n\n# -- Make comparisons work for immutable objects\n\n#' @export\nOps.immutable <- function(e1, e2) {\n    get(.Generic)(mutable(e1), mutable(e2))\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `immutable` function in this code snippet?",
        "answer": "The `immutable` function is used to create an 'immutable' version of an R object. It prepends the 'immutable' class to the object's existing classes, which prevents modification of the object through assignment operations. This is achieved by intercepting methods like `[<-`, `[[<-`, `$<-`, and `c` during S3 method dispatch and returning an error when attempting to modify the object."
      },
      {
        "question": "How does the code handle subset operations on immutable objects?",
        "answer": "The code intercepts subset operations (`[`, `[[`, and `$`) for immutable objects. When these operations are performed on an immutable object, the code first applies the operation using `NextMethod()`, then wraps the result in the `immutable()` function. This ensures that any subset of an immutable object is also immutable, maintaining the immutability property throughout derived objects."
      },
      {
        "question": "What is the purpose of the `mutable` function, and how does it differ from `immutable`?",
        "answer": "The `mutable` function is used to remove the 'immutable' class from an object, allowing it to be modified normally again. It strips the 'immutable' class from the object's class attribute and returns a copy of the object. This is essentially the reverse operation of `immutable`, providing a way to make an immutable object mutable again when needed."
      }
    ],
    "completion_tasks": [
      {
        "partial": "immutable <- function(object) {\n    if (isS4(object)) stop(\"Can only set immutability for base and S3 classes!\")\n    # call mutable to prevent assigning immutable class twice\n    structure(mutable(object), class=c(\"immutable\", attributes(object)$class))\n}\n\nsetOldClass(\"immutable\")\n\nsetClassUnion(\"immutable_list\", c(\"immutable\", \"list\"))\n\nis.immutable <- function(object) {\n    # Complete the function body\n}\n\nprint.immutable <- function(x, ...) {\n    # Complete the function body\n}",
        "complete": "immutable <- function(object) {\n    if (isS4(object)) stop(\"Can only set immutability for base and S3 classes!\")\n    # call mutable to prevent assigning immutable class twice\n    structure(mutable(object), class=c(\"immutable\", attributes(object)$class))\n}\n\nsetOldClass(\"immutable\")\n\nsetClassUnion(\"immutable_list\", c(\"immutable\", \"list\"))\n\nis.immutable <- function(object) {\n    is(object, \"immutable\")\n}\n\nprint.immutable <- function(x, ...) {\n    other_cls <- setdiff(attributes(x)$class, \"immutable\")\n    class(x) <- other_cls\n    cat(\"immutable\", class(x), \"\\n\")\n    print(x, ...)\n}"
      },
      {
        "partial": "c.immutable <- function(x, ...) {\n    new_obj <- NextMethod()\n    immutable(new_obj)\n}\n\n.immutable_emsg <- \"Object is immutable! Use `mutable(object)` to return a mutable copy.\"\n\nsubset.immutable <- function(x, ...) {\n    # Complete the function body\n}\n\n`[.immutable` <- function(x, ...) {\n    # Complete the function body\n}\n\n`[[.immutable` <- function(x, ...) {\n    # Complete the function body\n}\n\n`$.immutable` <- function(x, ...) {\n    # Complete the function body\n}",
        "complete": "c.immutable <- function(x, ...) {\n    new_obj <- NextMethod()\n    immutable(new_obj)\n}\n\n.immutable_emsg <- \"Object is immutable! Use `mutable(object)` to return a mutable copy.\"\n\nsubset.immutable <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n\n`[.immutable` <- function(x, ...) {\n    if (is.data.table(x)) {\n        dots <- substitute(alist(...))\n        j_expr <- dots[[\"j\"]]\n        if (is.null(j_expr) && length(dots) > 2)\n            j_expr <- dots[[2 + 1]]\n        if (!is.null(j_expr)) {\n            j_txt <- deparse(j_expr)\n            if (grepl(\":=|let[ ]*\\\\(|set[ ]*\\\\(\", j_txt))\n                stop(\"This data.table is immutable! No assignment by reference \",\n                \"allowed. Use `mutable(x)` to return a mutable copy.\",\n                    call.=FALSE)\n        }\n    }\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n\n`[[.immutable` <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}\n\n`$.immutable` <- function(x, ...) {\n    sub_obj <- NextMethod()\n    immutable(sub_obj)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/makeGrittyGuess.R",
    "language": "R",
    "content": "# Generate initial model parameters for fitting linear models\n#\n# @return Estimated parameters for first model fit\n#\n.makeGrittyGuess <- function(lower_bounds, upper_bounds, D, SF) {\n    dFromD2 <- abs(D - 2)\n    dFromSF10 <- abs(exp(SF) - 0.1)\n    D10Ind <- which.min(dFromSF10)[1]\n    SF2Ind <- which.min(dFromD2)[1]\n\n    if (D10Ind == SF2Ind) {\n        dFromD2[SF2Ind] <- dFromD2[SF2Ind] + dFromD2[1] #make it not the smallest anymore\n        SF2Ind <- which.min(dFromD2)[1]\n    }\n\n    DSF2 <- D[SF2Ind]\n    SF2 <- SF[SF2Ind]\n    D10 <- D[D10Ind]\n    SFD10 <- SF[D10Ind]\n\n    if(any(c(DSF2, D10, D[D10Ind] - D[SF2Ind])==0)){\n        return(c(0.25, 0.25))\n    }   \n    gritty_guess <- pmin(pmax(c((SF[D10Ind] * D[SF2Ind] ^ 2 - SF[SF2Ind] * D[D10Ind] ^ 2) / D[SF2Ind] / D[D10Ind] / (D[D10Ind] - D[SF2Ind]),\n                                (SF[D10Ind] * D[SF2Ind] - SF[SF2Ind] * D[D10Ind]) / D[SF2Ind] / D[D10Ind] / (D[SF2Ind] - D[D10Ind])), \n                                lower_bounds), \n                                upper_bounds) # assumes the SF2Indth point is SF2 and D10Indth point is D10 and imputes alpha, \n                                              # beta from that assumption unless either would thus be out of bounds \n    return(gritty_guess)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.makeGrittyGuess` function and what are its input parameters?",
        "answer": "The `.makeGrittyGuess` function is designed to generate initial model parameters for fitting linear models. It takes four input parameters: `lower_bounds`, `upper_bounds`, `D`, and `SF`. The function aims to estimate parameters for the first model fit based on these inputs, particularly focusing on finding points where D is close to 2 and SF is close to log(0.1)."
      },
      {
        "question": "How does the function handle the case when the indices for the closest points to D=2 and SF=log(0.1) are the same?",
        "answer": "When the indices for the closest points to D=2 and SF=log(0.1) are the same (i.e., D10Ind == SF2Ind), the function artificially increases the distance from D=2 for that index by adding the smallest distance to it. This ensures that different indices are used for D=2 and SF=log(0.1) in subsequent calculations, preventing potential issues in parameter estimation."
      },
      {
        "question": "What is the significance of the `pmin` and `pmax` functions in the final calculation of `gritty_guess`, and how do they relate to the `lower_bounds` and `upper_bounds` parameters?",
        "answer": "The `pmin` and `pmax` functions are used to ensure that the calculated `gritty_guess` values fall within the specified `lower_bounds` and `upper_bounds`. `pmax` first ensures that the calculated values are not less than the `lower_bounds`, and then `pmin` ensures that these values do not exceed the `upper_bounds`. This approach guarantees that the returned initial parameter estimates are within the acceptable range defined by the input bounds."
      }
    ],
    "completion_tasks": [
      {
        "partial": ".makeGrittyGuess <- function(lower_bounds, upper_bounds, D, SF) {\n    dFromD2 <- abs(D - 2)\n    dFromSF10 <- abs(exp(SF) - 0.1)\n    D10Ind <- which.min(dFromSF10)[1]\n    SF2Ind <- which.min(dFromD2)[1]\n\n    if (D10Ind == SF2Ind) {\n        dFromD2[SF2Ind] <- dFromD2[SF2Ind] + dFromD2[1]\n        SF2Ind <- which.min(dFromD2)[1]\n    }\n\n    DSF2 <- D[SF2Ind]\n    SF2 <- SF[SF2Ind]\n    D10 <- D[D10Ind]\n    SFD10 <- SF[D10Ind]\n\n    if(any(c(DSF2, D10, D[D10Ind] - D[SF2Ind])==0)){\n        return(c(0.25, 0.25))\n    }   \n    # Complete the gritty_guess calculation\n}",
        "complete": ".makeGrittyGuess <- function(lower_bounds, upper_bounds, D, SF) {\n    dFromD2 <- abs(D - 2)\n    dFromSF10 <- abs(exp(SF) - 0.1)\n    D10Ind <- which.min(dFromSF10)[1]\n    SF2Ind <- which.min(dFromD2)[1]\n\n    if (D10Ind == SF2Ind) {\n        dFromD2[SF2Ind] <- dFromD2[SF2Ind] + dFromD2[1]\n        SF2Ind <- which.min(dFromD2)[1]\n    }\n\n    DSF2 <- D[SF2Ind]\n    SF2 <- SF[SF2Ind]\n    D10 <- D[D10Ind]\n    SFD10 <- SF[D10Ind]\n\n    if(any(c(DSF2, D10, D[D10Ind] - D[SF2Ind])==0)){\n        return(c(0.25, 0.25))\n    }   \n    gritty_guess <- pmin(pmax(c((SF[D10Ind] * D[SF2Ind] ^ 2 - SF[SF2Ind] * D[D10Ind] ^ 2) / D[SF2Ind] / D[D10Ind] / (D[D10Ind] - D[SF2Ind]),\n                                (SF[D10Ind] * D[SF2Ind] - SF[SF2Ind] * D[D10Ind]) / D[SF2Ind] / D[D10Ind] / (D[SF2Ind] - D[D10Ind])), \n                                lower_bounds), \n                                upper_bounds)\n    return(gritty_guess)\n}"
      },
      {
        "partial": ".makeGrittyGuess <- function(lower_bounds, upper_bounds, D, SF) {\n    # Calculate dFromD2 and dFromSF10\n    # Find D10Ind and SF2Ind\n    # Handle the case when D10Ind equals SF2Ind\n    # Calculate DSF2, SF2, D10, and SFD10\n    # Handle the special case when certain values are zero\n    # Calculate and return gritty_guess\n}",
        "complete": ".makeGrittyGuess <- function(lower_bounds, upper_bounds, D, SF) {\n    dFromD2 <- abs(D - 2)\n    dFromSF10 <- abs(exp(SF) - 0.1)\n    D10Ind <- which.min(dFromSF10)[1]\n    SF2Ind <- which.min(dFromD2)[1]\n\n    if (D10Ind == SF2Ind) {\n        dFromD2[SF2Ind] <- dFromD2[SF2Ind] + dFromD2[1]\n        SF2Ind <- which.min(dFromD2)[1]\n    }\n\n    DSF2 <- D[SF2Ind]\n    SF2 <- SF[SF2Ind]\n    D10 <- D[D10Ind]\n    SFD10 <- SF[D10Ind]\n\n    if(any(c(DSF2, D10, D[D10Ind] - D[SF2Ind])==0)){\n        return(c(0.25, 0.25))\n    }   \n    gritty_guess <- pmin(pmax(c((SF[D10Ind] * D[SF2Ind] ^ 2 - SF[SF2Ind] * D[D10Ind] ^ 2) / D[SF2Ind] / D[D10Ind] / (D[D10Ind] - D[SF2Ind]),\n                                (SF[D10Ind] * D[SF2Ind] - SF[SF2Ind] * D[D10Ind]) / D[SF2Ind] / D[D10Ind] / (D[SF2Ind] - D[D10Ind])), \n                                lower_bounds), \n                                upper_bounds)\n    return(gritty_guess)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/utilities.R",
    "language": "R",
    "content": "## Utility function for the Gx suite packages ------------------------------\n## FIXME:: Put these functions in sections based on similar purposes\n\n# ExpressionSet to SummarizedExperiment -----------------------------------\n\n#' CSet molecularProfiles from ESets to SEs\n#'\n#' Converts all ExpressionSet objects within the molecularProfiles slot of a\n#'   CoreSet to SummarizedExperiments\n#'\n#' @param cSet \\code{S4} A CoreSet containing molecular data in ExpressionSets\n#'\n#' @return \\code{S4} A CoreSet containing molecular data in a\n#'   SummarizedExperiments\n#'\n#' @importFrom BiocParallel bplapply\n#' @importFrom SummarizedExperiment SummarizedExperiment Assays assay\n#'   assayNames assayNames<-\n#' @importFrom Biobase exprs fData pData annotation protocolData\n#'   assayDataElementNames\n#' @importFrom S4Vectors SimpleList DataFrame\n#' @importFrom stats setNames\n#' @keywords internal\n.convertCSetMolecularProfilesToSE <- function(cSet) {\n\n    eSets <- molecularProfilesSlot(cSet)  # Extract eSet data\n\n    molecularProfilesSlot(cSet) <- lapply(eSets, function(eSet) {\n\n        # Change rownames from probes to EnsemblGeneId for rna data type\n        if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n            rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n        }\n\n        # Build summarized experiment from eSet TODO:: Do we want to pass an environment for better memory efficiency?\n        SE <- SummarizedExperiment::SummarizedExperiment(assays = SimpleList(as.list(Biobase::assayData(eSet))), rowData = S4Vectors::DataFrame(Biobase::fData(eSet),\n            rownames = rownames(Biobase::fData(eSet))), colData = S4Vectors::DataFrame(Biobase::pData(eSet), rownames = rownames(Biobase::pData(eSet))),\n            metadata = list(experimentData = eSet@experimentData, annotation = Biobase::annotation(eSet), protocolData = Biobase::protocolData(eSet)))\n        ## TODO:: Determine if this can be done in the SE constructor?  Extract names from expression set\n        assayNames(SE) <- assayDataElementNames(eSet)\n        # Assign SE to cSet\n        mDataType <- Biobase::annotation(eSet)\n        molecularProfilesSlot(cSet)[[mDataType]] <- SE\n    })\n    setNames(cSet@molecularProfiles, names(eSets))\n    cSet\n}\n\n# sanityCheck -------------------------------------------------------------\n\n## TODO:: Add documentation!\n#' @export\n#' @noRd\n.sanitizeInput <- function(x, y, lower, upper, pars, x_as_log, y_as_log,\n        y_as_pct, trunc, verbose = FALSE) {\n    # Set to 2 to see debug printouts\n\n    if (!is.logical(x_as_log)) {\n        if (verbose == 2) {\n            message(\"x_as_log:\")\n            message(x_as_log)\n        }\n        stop(\"'x_as_log' is not a logical.\")\n    }\n\n    if (!is.logical(y_as_log)) {\n        if (verbose == 2) {\n            message(\"y_as_log:\")\n            message(y_as_log)\n        }\n        stop(\"'y_as_log' is not a logical.\")\n    }\n\n    if (!is.logical(y_as_pct)) {\n        if (verbose == 2) {\n            message(\"y_as_pct:\")\n            message(y_as_pct)\n        }\n        stop(\"'y_as_pct' is not a logical.\")\n    }\n\n    if (!is.logical(trunc)) {\n        if (verbose == 2) {\n            message(\"trunc:\")\n            message(trunc)\n        }\n        stop(\"'trunc' is not a logical.\")\n    }\n\n    if (y_as_pct && y_as_log) {\n        if (verbose == 2) {\n            message(\"y_as_pct:\")\n            message(y_as_pct)\n            message(\"y_as_log:\")\n            message(y_as_log)\n        }\n        warning(\"y_as_pct and y_as_log flags should almost certainly not both be TRUE.\")\n    }\n\n    if (!(verbose %in% c(0, 1, 2))) {\n        message(\"verbose:\")  #can't have the if(verbose == 2) statement here since verbose itself is the problem!\n        message(verbose)\n        stop(\"'verbose' flag is not set correctly.\")\n    }\n\n    if (!missing(x)) {\n        if (!all(is.finite(x) | is.na(x)) || (x_as_log && any(x == -Inf))) {\n            if (verbose == 2) {\n                message(\"x:\")\n                message(x)\n            }\n            stop(\"x must contain only real numbers, NA-values, and/or -Inf (if x_as_log flag is set to TRUE).\")\n        }\n\n        if (x_as_log == FALSE && min(x) < 0) {\n            if (verbose == 2) {\n                message(\"x:\")\n                message(x)\n                message(\"x_as_log:\")\n                message(x_as_log)\n            }\n            stop(\"Negative x-values encountered. Data may be inappropriate, or 'x_as_log' flag may be set incorrectly.\")\n        }\n        if (length(unique(x)) < 3) {\n            stop(\"Please pass in at least 3 unique dose points.\")\n        }\n    }\n\n    if (missing(y)) {\n        if (missing(pars)) {\n            stop(\"Both 'pars' and 'y' missing, please pass in some data!\")\n        } else {\n\n            if (pars[[1]] < 0 || pars[[2]] < 0) {\n                # HS or alpha\n                if (verbose == 2) {\n                  message(\"pars:\")\n                  message(pars)\n                }\n                warning(\"Curve parameters may be inappropriately set to negative values.\")\n            }\n\n            if (length(pars) == 3) {\n                # and thus we are in PharmacoGx\n                if (x_as_log == FALSE && pars[[3]] < 0) {\n                  message(\"pars:\")\n                  message(pars[[3]])\n                  message(\"x_as_log:\")\n                  message(x_as_log)\n                  stop(\"'x_as_log' flag may be set incorrectly, as the EC50 is negative when a positive value is expected.\")\n                }\n\n                if (y_as_pct == FALSE) {\n                  if (pars[[2]] > 1) {\n                    if (verbose == 2) {\n                      message(\"pars:\")\n                      message(pars[[2]])\n                      message(\"y_as_pct:\")\n                      message(y_as_pct)\n                    }\n                    warning(\"Warning: 'y_as_pct' flag may be set incorrectly.\")\n                  }\n                }\n            } else if (length(pars) == 2) {\n                if (pars[[1]] < pars[[2]]) {\n                  if (verbose) {\n                    warning(\"Alpha is greater than beta.\")\n                    if (verbose == 2) {\n                      message(\"pars:\")\n                      message(pars)\n                    }\n                  }\n                }\n            } else {\n                stop(\"Pars does not have the correct length.\")\n            }\n        }\n\n    } else {\n\n        if (!all(is.finite(y) | is.na(y)) || (y_as_log && any(y == -Inf))) {\n            if (verbose == 2) {\n                message(\"y:\")\n                message(y)\n            }\n            stop(\"y must contain only real numbers, NA-values, and/or -Inf (if y_as_log is set to TRUE).\")\n        }\n\n        if (min(y, na.rm=TRUE) < 0) {\n            if (verbose) {\n                warning(\"Warning: Negative y data.\")\n                if (verbose == 2) {\n                  message(\"y:\")\n                  message(y)\n                }\n            }\n        }\n\n        if (max(y, na.rm=TRUE) > (1 + 99 * y_as_pct)) {\n            if (verbose) {\n                warning(\"Warning: y data exceeds negative control.\")\n                if (verbose == 2) {\n                  message(\"y:\")\n                  message(y)\n                }\n            }\n        }\n\n        if (missing(pars)) {\n\n            if (y_as_log == FALSE && min(y, na.rm=TRUE) < 0) {\n                if (verbose) {\n                  warning(\"Negative y-values encountered. y data may be inappropriate, or 'y_as_log' flag may be set incorrectly.\")\n                  if (verbose == 2) {\n                    message(\"y:\")\n                    message(y)\n                    message(\"y_as_log:\")\n                    message(y_as_log)\n                  }\n                }\n            }\n\n            if (y_as_pct == TRUE && max(y, na.rm=TRUE) < 5) {\n                if (verbose) {\n                  warning(\"Warning: 'y_as_pct' flag may be set incorrectly.\")\n                  if (verbose == 2) {\n                    message(\"y:\")\n                    message(y)\n                    message(\"y_as_pct:\")\n                    message(y_as_pct)\n                  }\n                }\n            }\n\n            if (y_as_pct == FALSE && max(y, na.rm=TRUE) > 5) {\n                if (verbose) {\n                  warning(\"Warning: 'y_as_pct' flag may be set incorrectly.\")\n                  if (verbose == 2) {\n                    message(\"y:\")\n                    message(y)\n                    message(\"y_as_pct:\")\n                    message(y_as_pct)\n                  }\n                }\n            }\n\n            if (!missing(x) && length(x) != length(y)) {\n                if (verbose == 2) {\n                  message(\"x:\")\n                  message(x)\n                  message(\"y:\")\n                  message(y)\n                }\n                stop(\"Vector of x-values is not of same length as vector of y-values.\")\n            }\n\n        } else {\n            stop(\"Please pass in only one of 'pars' and 'y', as it is unclear which to use in the computation.\")\n        }\n    }\n\n    if (!missing(lower) && !missing(upper)) {\n        if (!(is.double(lower))) {\n            if (verbose == 2) {\n                message(\"lower:\")\n                message(lower)\n            }\n            stop(\"The lower bound must be a positive real number.\")\n        }\n\n        if (!(is.double(lower))) {\n            if (verbose == 2) {\n                message(\"upper:\")\n                message(upper)\n            }\n            stop(\"The upper bound must be a positive real number.\")\n        }\n\n        if (lower >= upper) {\n            if (verbose == 2) {\n                message(\"lower:\")\n                message(lower)\n                message(\"upper:\")\n                message(upper)\n            }\n            stop(\"The lower bound of the range of allowed x-values must be less than the upper bound.\")\n        }\n\n        if (lower < 0) {\n            if (verbose == 2) {\n                message(\"lower:\")\n                message(lower)\n            }\n            stop(\"The lower bound of the range of allowed x-values must be nonnegative.\")\n        }\n\n        if (upper < 0) {\n            if (verbose == 2) {\n                message(\"upper:\")\n                message(upper)\n            }\n            stop(\"The upper bound of the range of allowed x-values must be nonnegative.\")\n        }\n    }\n}\n\n\n# getSupportVec -----------------------------------------------------------\n\n## get vector of interpolated concentrations for graphing purposes\n#' .getSupportVec\n#'\n#' @param x An input vector of dosages\n#' @param output_length The length of the returned support vector\n#'\n#' @return \\code{numeric} A numeric vector of interpolated concentrations\n#'\n#' @export\n#' @noRd\n.getSupportVec <- function(x, output_length = 1001) {\n    return(seq(from = min(x), to = max(x), length.out = output_length))\n}\n\n#### reformatData ------------------------------------------------------------\n\n#' @export\n#' @noRd\n.reformatData <- function(x, y, pars, x_to_log, y_to_log, y_to_frac, trunc) {\n    if (!(is.logical(x_to_log))) {\n        stop(\"x_to_log must be a logical.\")\n    }\n\n    if (!(is.logical(y_to_log))) {\n        stop(\"y_to_log must be a logical.\")\n    }\n\n    if (!(is.logical(y_to_frac))) {\n        stop(\"y_to_frac must be a logical.\")\n    }\n\n    if(y_to_log && y_to_frac){\n        warning(\"Both y_to_log and y_as_frac set. Will first convert to fraction and then take the logarithm.\\n\n            If this is not what is intended, please reformat data prior to curve fitting. \")\n    }\n\n    if (x_to_log) {\n        x <- log10(x)\n    }\n    ### Note, if Y is passed in, it is sorted in this same order below. This is not obvious from the code right away.\n    if (is.unsorted(x, na.rm=TRUE)) {\n        InputUnsorted <- TRUE\n        warning(\"x-values passed in unsorted. Sorting x-values and corresponding y-values (if passed in).\")\n        xOrder <- order(x)\n        x <- x[xOrder]\n    } else {\n        InputUnsorted <- FALSE\n    }\n\n    if (!missing(y)) {\n\n        if (InputUnsorted) {\n            y <- y[xOrder]\n        }\n\n        if (any(is.na(x) & (!is.na(y)))) {\n            warning(\"Missing x-values with non-missing y-values encountered. Removed y-values correspoding to those x-values.\")\n            myx <- !is.na(x)\n            x <- as.numeric(x[myx])\n            y <- as.numeric(y[myx])\n        }\n\n        if (any((!is.na(x)) & is.na(y))) {\n            warning(\"Missing y-values with non-missing x-values encountered. Removed x values correspoding to those y-values.\")\n            myy <- !is.na(y)\n            x <- as.numeric(x[myy])\n            y <- as.numeric(y[myy])\n        }\n\n        myxy <- complete.cases(x,y)\n        x <- x[myxy]\n        y <- y[myxy]\n\n        if (y_to_frac) {\n            y <- y/100\n        }\n\n        if (trunc) {\n            y = pmin(as.numeric(y), 1)\n            y = pmax(as.numeric(y), 0)\n        }\n\n        if (x_to_log) {\n            x0s <- which(x == -Inf)\n            if (length(x0s) > 0) {\n                x <- x[-x0s]\n                y <- y[-x0s]\n            }\n        }\n\n        if (y_to_log) {\n            if (any(y <= 0)) {\n                warning(\"Transforming y to log with non-positive y values present, therefore removing.\")\n                x <- x[y > 0]\n                y <- y[y > 0]\n                if (!length(x)) {\n                  stop(\"No valid positive y values encountered, please pass in some data.\")\n                }\n            }\n            y <- log(y)\n        }\n\n\n\n         if (length(unique(x)) < 3) {\n            stop(\"Less than 3 unique dose points left after cleaning data, please pass in enough valid measurements.\")\n\n        }\n\n        return(list(x = x, y = y))\n    }\n\n    if (!missing(pars)) {\n\n        if (x_to_log && length(pars) == 3) {\n            pars[[3]] <- log10(pars[[3]])\n        }\n\n        if (y_to_frac && length(pars) == 3) {\n            pars[[2]] <- pars[[2]]/100\n        }\n\n        return(list(x = x, pars = pars))\n    }\n}\n\n\n\n\n# multinom ----------------------------------------------------------------\n\n#' @export\n#' @noRd\n.multinom <- function(x, y) {\n    coeff <- 1\n    for (i in seq_len(length(y))) {\n        coeff <- coeff * choose(x, y[i])\n        x <- x - y[i]\n    }\n    return(coeff)\n}\n\n# medncauchys -------------------------------------------------------------\n\n## TODO:: Add documentation to these functions\n\n#' A random sample distributed as the median of N Cauchy distributed variables\n#'\n#' Naming follows R conventions.\n#'\n#' @param N How many samples to sample\n#' @param n The number of Cauchy distributions to take the median of\n#' @param scale the scale of the Cauchy distribution.\n#'\n#' @importFrom stats rcauchy\n#' @export\n#' @keywords internal\n#' @noRd\n.rmedncauchys <- function(N, n, scale) {\n    x <- matrix(NA, nrow = 1, ncol = N)\n    for (i in seq_len(N)) {\n        x[i] <- median(rcauchy(n, scale = scale))\n    }\n    return(x)\n}\n\n#' PDF of the median of N Cauchy distributed variables\n#'\n#' This function calculates the PDF/density for a variable distributed as the median value of n IID Cauchy variables. Naming follows R conventions.\n#'\n#' @param x Where to evaluate the density function\n#' @param n The number of Cauchy distributions to take the median of\n#' @param scale the scale of the Cauchy distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats dcauchy pcauchy integrate\n#' @export\n#' @keywords internal\n#' @noRd\n.dmedncauchys = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- matrix(NA, nrow = 1, ncol = length(x))\n    for (g in seq_along(x)) {\n        if (n[g]%%2 == 0) {\n            y[g] <- 2 * .multinom(n[g], c(n[g]/2 - 1, n[g]/2 - 1)) * tryCatch(integrate(f = function(j) {\n                (pcauchy(x[g] - j/2, scale = scale[g]))^(n[g]/2 - 1) * (1 - pcauchy(x[g] + j/2, scale = scale[g]))^(n[g]/2 - 1) * dcauchy(x[g] -\n                  j/2, scale = scale[g]) * dcauchy(x[g] + j/2, scale = scale[g])\n            }, lower = 0, upper = Inf, subdivisions = divisions)[[1]], error = function(e) {\n                if (divisions == 1) {\n                  wseq <- c(1, 4, 1)\n                } else {\n                  wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n                }\n                aseq <- seq(from = 0, to = pi/2, length.out = 2 * divisions + 1)\n                tseq <- tan(aseq)/2\n                return(sum((pcauchy(x[g] + tseq, scale = scale[g]))^(n[g]/2 - 1) * (pcauchy(x[g] - tseq, scale = scale[g]))^(n[g]/2 - 1) *\n                  dcauchy(x[g] + tseq, scale = scale[g]) * dcauchy(x[g] - tseq, scale = scale[g])/(cos(aseq))^2 * wseq) * (aseq[2] - aseq[1])/6)\n            })\n        } else {\n            y[g] <- .multinom(n[g], c((n[g] - 1)/2, (n[g] - 1)/2)) * (pcauchy(x[g], scale = scale[g]))^((n[g] - 1)/2) * (1 - pcauchy(x[g],\n                scale = scale[g]))^((n[g] - 1)/2) * dcauchy(x[g], scale = scale[g])\n        }\n    }\n    return(y)\n}\n\n\n#' CDF of the median of N Cauchy distributed variables\n#'\n#' This function calculates the CDF/distribution for a variable distributed as the median value of n IID Cauchy variables. Naming follows R conventions.\n#'\n#' @param x Where to evaluate the distribution function\n#' @param n The number of Cauchy distributions to take the median of\n#' @param scale the scale of the Cauchy distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats pcauchy integrate\n#' @export\n#' @keywords internal\n#' @noRd\n.pmedncauchys = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- integer(length(x))\n    for (g in seq_along(x)) {\n        if (n[g] %% 2 == 0) {\n            y[g] <- tryCatch(integrate(f = function(k) {\n                .dmedncauchys(k, n[g], scale[g])\n            }, lower = -Inf, upper = x[g], subdivisions = divisions)[[1]], error = function(e) {\n                wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n                aseq <- seq(from = -pi/2, to = atan(x[g]), length.out = 2 * divisions + 1)\n                return(sum(.dmedncauchys(tan(aseq), n[g], scale[g]) * wseq/(cos(aseq))^2) * (aseq[3] - aseq[1])/6)\n            })\n        } else {\n            y[g] <- 0\n            Fx <- pcauchy(x[g], scale = scale[g])\n            for (i in 0:((n[g] - 1)/2)) {\n                y[g] <- y[g] + choose((n[g] - 1)/2, i) * (-1)^i * Fx^((n[g] + 1)/2 + i)/((n[g] + 1)/2 + i)\n            }\n            y[g] <- y[g] * .multinom(n[g], c((n[g] - 1)/2, (n[g] - 1)/2))\n        }\n    }\n    return(y)\n}\n\n#' Expectation of the likelihood of the median of N Cauchy distributions for\n#' truncated data\n#'\n#' This function calculates the expected value of the PDF of a median of N\n#' Cauchy with given scale parameter, calculated over the region from x to\n#' infinity if x>0, and -infinity to x otherwise.\n#'\n#' This is used in curve fitting when data has been truncated. Since for\n#' truncated data, we don't know what the \"real\" value was, the reasoning is\n#' we take the expected value.\n#'\n#' This increases robustness to extreme outliers while not completely ignoring\n#' the fact that points are truncated, and seems to work well in practice. The\n#' name of the function follows:\n#' e(xpectation)d(istribution)med(ian)ncauchys - following R conventions.\n#'\n#' @param x Where the truncation occurred\n#' @param n The number of Cauchy distributions to take the median of\n#' @param scale the scale of the Cauchy distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats integrate\n#' @keywords internal\n#' @export\n#' @noRd\n.edmedncauchys = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- numeric(length(x))\n    for (g in seq_along(y)) {\n        if (x[g] > 0) {\n            upper <- Inf\n            lower <- x[g]\n        } else {\n            upper <- x[g]\n            lower <- -Inf\n        }\n        y[g] <- tryCatch(integrate(f = function(k) {\n            (.dmedncauchys(k, n[g], scale[g]))^2\n        }, lower = lower, upper = upper, subdivisions = divisions)[[1]], error = function(e) {\n            wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n            aseq <- seq(from = atan(lower), to = atan(upper), length.out = 2 * divisions + 1)\n            return(sum((.dmedncauchys(tan(aseq), n[g], scale[g]))^2 * wseq/(cos(aseq))^2) * (aseq[3] - aseq[1])/6)\n        })\n    }\n    return(y)\n}\n\n#### mednnormals -------------------------------------------------------------\n\n#' A random sample distributed as the median of N Normally distributed variables\n#'\n#' Naming follows R conventions.\n#'\n#' @param N How many samples to sample\n#' @param n The number of normal distributions to take the median of\n#' @param scale the SD of the normal distribution.\n#'\n#' @export\n#' @keywords internal\n#' @noRd\n.rmednnormals = function(N, n, scale) {\n    x <- matrix(NA, nrow = 1, ncol = N)\n    for (i in seq_len(N)) {\n        x[i] <- median(rnorm(n, sd = scale))\n    }\n    return(x)\n}\n\n#' PDF of the median of N Normally distributed variables\n#'\n#' This function calculates the PDF/density for a variable distributed as the median value of n IID Normal variables. Naming follows R conventions.\n#'\n#' @param x where to evaluate the density\n#' @param n The number of normal distributions to take the median of\n#' @param scale the SD of the normal distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats rnorm  dnorm\n#' @export\n#' @keywords internal\n#' @noRd\n.dmednnormals = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- matrix(NA, nrow = 1, ncol = length(x))\n    for (g in seq_along(x)) {\n        if (n[g]%%2 == 0) {\n            y[g] <- 2 * .multinom(n[g], c(n[g]/2 - 1, n[g]/2 - 1)) * tryCatch(integrate(f = function(j) {\n                (pnorm(x[g] - j/2, sd = scale[g]))^(n[g]/2 - 1) * (1 - pnorm(x[g] + j/2, sd = scale[g]))^(n[g]/2 - 1) * dnorm(x[g] - j/2,\n                  sd = scale[g]) * dnorm(x[g] + j/2, sd = scale[g])\n            }, lower = 0, upper = Inf, subdivisions = divisions)[[1]], error = function(e) {\n                if (divisions == 1) {\n                  wseq <- c(1, 4, 1)\n                } else {\n                  wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n                }\n                aseq <- seq(from = 0, to = pi/2, length.out = 2 * divisions + 1)\n                tseq <- tan(aseq)/2\n                return(sum((pnorm(x[g] + tseq, sd = scale[g]))^(n[g]/2 - 1) * (pnorm(x[g] - tseq, sd = scale[g]))^(n[g]/2 - 1) * dnorm(x[g] +\n                  tseq, sd = scale[g]) * dnorm(x[g] - tseq, sd = scale[g])/(cos(aseq))^2 * wseq) * (aseq[2] - aseq[1])/6)\n            })\n        } else {\n            if(n[g]==1){\n                y[g] <- dnorm(x[g], sd = scale[g]) ## This reduces to the simple case for n equals 1 below, but we can save many calls to pnorm, which just get raised to a power of 0.\n            } else {\n                y[g] <- .multinom(n[g], c((n[g] - 1)/2, (n[g] - 1)/2)) * (pnorm(x[g], sd = scale[g]))^((n[g] - 1)/2) * (1 - pnorm(x[g], sd = scale[g]))^((n[g] -\n                                                                                                                                                              1)/2) * dnorm(x[g], sd = scale[g])\n            }\n\n        }\n    }\n    return(y)\n}\n\n\n#' CDF of the median of N Normally distributed variables\n#'\n#' This function calculates the CDF/distribution for a variable distributed as the median value of n IID Normal variables. Naming follows R conventions.\n#'\n#' @param x Where to evaluate the Distribution\n#' @param n The number of normal distributions to take the median of\n#' @param scale the SD of the normal distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats integrate\n#' @export\n#' @keywords internal\n#' @noRd\n.pmednnormals = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- numeric(length(x))\n    for (g in seq_along(x)) {\n        if (n[g]%%2 == 0) {\n            y[g] <- tryCatch(integrate(f = function(k) {\n                .dmednnormals(k, n[g], scale[g])\n            }, lower = -Inf, upper = x[g], subdivisions = divisions)[[1]], error = function(e) {\n                wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n                aseq <- seq(from = -pi/2, to = atan(x[g]), length.out = 2 * divisions + 1)\n                return(sum(.dmednnormals(tan(aseq), n[g], scale[g]) * wseq/(cos(aseq))^2) * (aseq[3] - aseq[1])/6)\n            })\n        } else {\n            y[g] <- 0\n            Fx <- pnorm(x[g], sd = scale[g])\n            for (i in 0:((n[g] - 1)/2)) {\n                y[g] <- y[g] + choose((n[g] - 1)/2, i) * (-1)^i * Fx^((n[g] + 1)/2 + i)/((n[g] + 1)/2 + i)\n            }\n            y[g] <- y[g] * .multinom(n[g], c((n[g] - 1)/2, (n[g] - 1)/2))\n        }\n    }\n    return(y)\n}\n\n#' Expectation of the likelihood of the median of N normal distributions for truncated data\n#'\n#' This function calculates the expected value of the PDF of a median of N normals with SD=scale, calculated over the region from x to infinity if x>0, and -infinity to x otherwise.\n#' This is used in curve fitting when data has been truncated. Since for truncated data, we don't know what the \"real\" value was, the reasoning is we take the expected value.\n#' This increases robustness to extreme outliers while not completely ignoring the fact that points are truncated, and seems to work well in practice. The name of the function follows:\n#' e(xpectation)d(istribution)med(ian)nnormals - following R conventions.\n#'\n#' @param x Where the truncation occurred\n#' @param n The number of normal distributions to take the median of\n#' @param scale the SD of the normal distribution.\n#' @param divisions How many maximum divisions to use in numerical integration\n#'\n#' @importFrom stats integrate\n#' @export\n#' @keywords internal\n#' @noRd\n.edmednnormals = function(x, n, scale, divisions = 100) {\n    n <- rep(n, times = length(x)/length(n))\n    scale <- rep(scale, times = length(x)/length(scale))\n    y <- numeric(length(x))\n    for (g in seq_along(y)) {\n        if(n[g]==1){ ## The n=1 case is called very often, and there are significant savings (20x) to not calling numerical integration.\n            if(x[g]>0){\n                pnorm(x[g], sd=scale[g]/sqrt(2), lower.tail = FALSE)/(scale*2*sqrt(pi))\n            } else {\n                pnorm(x[g], sd=scale[g]/sqrt(2), lower.tail = TRUE)/(scale*2*sqrt(pi))\n            }\n        } else {\n            if (x[g] > 0) {\n                upper <- Inf\n                lower <- x[g]\n            } else {\n                upper <- x[g]\n                lower <- -Inf\n            }\n            y[g] <- tryCatch(integrate(f = function(k) {\n                (.dmednnormals(k, n[g], scale[g]))^2\n            }, lower = lower, upper = upper, subdivisions = divisions)[[1]], error = function(e) {\n                wseq <- c(1, 4, rep(c(2, 4), times = divisions - 1), 1)\n                aseq <- seq(from = atan(lower), to = atan(upper), length.out = 2 * divisions + 1)\n                return(sum((.dmednnormals(tan(aseq), n[g], scale[g]))^2 * wseq/(cos(aseq))^2) * (aseq[3] - aseq[1])/6)\n            })\n        }\n\n    }\n    return(y)\n}\n\n\n\n\n# Set Operations ----------------------------------------------------------\n\n## TODO:: Can we implement this as an extension of the BiocGenerics::setdiff?\n#' Utility to find the symmetric set difference of a list of two or more\n#' vectors or lists\n#'\n#' The function finds the symmetric set differnces between all the arguments,\n#' defined as Union(args)-Intersection(args)\n#'\n#' @examples\n#' list1 <- list('a', 'b', 'c')\n#' list2 <- list('a', 'c')\n#' list3 <- list('a', 'c', 'd')\n#' listAll <- .symSetDiffList(list1, list2, list3)\n#' listAll\n#'\n#' @param ... A list of or any number of vector like objects of the same mode,\n#'   which could also be operated on by the native R set operations\n#'\n#' @return A vector like object of the same mode as the first argument,\n#'   containing only the symmetric set difference\n#'\n#' @export\n#' @keywords internal\n.symSetDiffList <- function(...) {\n    return(setdiff(.unionList(...), .intersectList(...)))\n}\n\n## FIXME:: This should be implemented as an extension of the intersect generic provided in the BiocGenerics package!\n#' Intersect A List of More Than Two Vectors\n#'\n#' Utility to find the intersection between a list of more than two vectors or\n#'   lists This function extends the native intersect function to work on two\n#'   or more arguments.\n#'\n#' @examples\n#' list1 <- list('a', 'b', 'c')\n#' list2 <- list('a', 'c')\n#' list3 <- list('a', 'c', 'd')\n#' listAll <- .intersectList(list1, list2, list3)\n#' listAll\n#'\n#' @param ... A list of or any number of vector like objects of the same mode,\n#'   which could also be operated on by the native R set operations\n#'\n#' @return A vector like object of the same mode as the first argument,\n#'   containing only the intersection common to all arguments to the function\n#'\n#' @export\n#' @keywords internal\n.intersectList <- function(...) {\n    args <- list(...)\n    nargs <- length(args)\n    if (nargs == 0) {\n        return(args)\n    }\n    if (nargs == 1) {\n        if (nargs == 1 && is.list(args[[1]])) {\n            do.call(\".intersectList\", args[[1]])\n        } else {\n            return(args[[1]])\n        }\n    } else if (nargs == 2) {\n        return(intersect(args[[1]], args[[2]]))\n    } else {\n        return(intersect(args[[1]], .intersectList(args[-1])))\n    }\n}\n\n\n## FIXME:: This should be implemented as an extension of the union generic from BiocGenerics\n#' Utility to find the union between a list of more than two vectors or\n#' lists\n#'\n#' This function extends the native union function to work on two or more\n#' arguments.\n#'\n#' @examples\n#' list1 <- list('a', 'b')\n#' list2 <- list('a', 'c')\n#' list3 <- list('c', 'd')\n#' listAll <- .unionList(list1, list2, list3)\n#' listAll\n#'\n#' @param ... A list of or any number of vector like objects of the same mode,\n#'   which could also be operated on by the native R set operations\n#'\n#' @return A vector like object of the same mode as the first argument,\n#'   containing all the elements of all arguments passed to the function\n#'\n#' @export\n#' @keywords internal\n.unionList <- function(...) {\n    args <- list(...)\n    nargs <- length(args)\n    return(unique(unlist(do.call(c, args))))\n}\n\n\n#' @param matInd array indices\n#' @param dimsizes array containing size of array of interest in each dimension\n#'\n#' @export\n#' @keywords internal\n#' @noRd\n.linInd <- function(matInd, dimsizes) {\n    y <- matInd[1]\n    if (length(dimsizes) > 1) {\n        for (i in seq(2, length(dimsizes))) {\n            y <- y + (matInd[i] - 1) * prod(dimsizes[seq_len(i - 1)])\n        }\n    }\n    return(y)\n}\n\n#' @export\n#' @keywords internal\n#' @noRd\n# @param linInd linear index @param dimsizes array containing size of array of interest in each dimension\n.matInd <- function(linInd, dimsizes) {\n    y <- matrix(0, nrow = length(dimsizes), ncol = 1)\n    if (NROW(y) > 1) {\n        for (i in seq(2, length(dimsizes))) {\n            y[i] <- ceiling(linInd/prod(dimsizes[seq_len(i - 1)]))\n            linInd <- linInd - (y[i] - 1) * prod(dimsizes[seq_len(i - 1)])\n        }\n    }\n    y[1] <- linInd\n    return(y)\n}\n\n\n# Not Used? ------------------------------------------------------------------\n\n### TODO:: Determine type of objects intended for this function\n#' Getter for attributes of an object\n#'\n#' @param pars The object for which attributes are to be returned\n#' @return A named vector where index `Rsquare` contains the attributes of the object\n#' @export\n#' @keywords internal\n#' @noRd\n.examineGOF <- function(pars) {\n    return(c(Rsquare = attr(pars, \"Rsquare\")))\n}\n\n\n# Different in PharmacoGx? ------------------------------------------------\n\n\n## FIXME:: This function already exists as base::trimws? Is there any reason we need to reimplement it?\n#' @export\n#' @keywords internal\n#' @noRd\n.stripWhiteSpace <- function(str, method = c(\"both\", \"head\", \"tail\")) {\n    method <- match.arg(method)\n    str2 <- NULL\n    if (length(str) == 1) {\n        switch(method, both = {\n            str2 <- gsub(\"^[ \\t]+\", \"\", str)\n            str2 <- gsub(\"[ \\t]+$\", \"\", str2)\n        }, head = {\n            str2 <- gsub(\"^[ \\t]+\", \"\", str)\n        }, tail = {\n            str2 <- gsub(\"[ \\t]+$\", \"\", str)\n        })\n        return(str2)\n    } else {\n        str2 <- vapply(str, .stripWhiteSpace, method = method, FUN.VALUE = character(1))\n        return(str2)\n    }\n}\n\n\n# ==== LongTable\n\n#' Convenience function for collapsing a character vector\n#'\n#' @examples\n#' .collapse(c(\"Vector\", \"of\", \"words\")\n#'\n#' @param ... `pairlist` One or more character vectors\n#' @param collapse `character` Argument to collapse of paste0, default is ' '.\n#'\n#' @return `character` A single character vector.\n#'\n#' @keywords internal\n#' @export\n#' @noRd\n.collapse <- function(..., collapse=' ')\n    paste0(..., collapse=collapse)\n\n#' Returns a colorized error message (magenta)\n#'\n#' @examples\n#' cat(.errorMsg('This ', 'is ', 'an ', 'error ', 'message', time = TRUE))\n#'\n#' @param ... `pairlist` One or more strings or character vectors, also\n#'   accepts any params to paste0.\n#' @param time `logical` Indicates whether to include timestamp or not. Default is FALSE.\n#'\n#' @return `character` Colorized string with results from paste0(...)\n#'\n#' @keywords internal\n#' @export\n#' @noRd\n.errorMsg <- function(..., time = FALSE, collapse=', ') {\n    msg <- paste0(..., collapse=collapse)\n    if (time) {\n        timestamp <- format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")\n        msg <- paste0(timestamp, \" \", msg)\n    }\n    magenta$bold(msg)\n}\n\n#' Returns a colorized warning message (cyan)\n#'\n#' @examples\n#' cat(.warnMsg('This ', 'is ', 'a ', 'warning ', 'message', time = TRUE))\n#'\n#' @param ... `pairlist` One or more strings or character vectors, also\n#'   accepts any params to paste0.\n#' @param time `logical` Indicates whether to include timestamp or not. Default is FALSE.\n#'\n#' @return `character` Colorized string with results from paste0(...)\n#'\n#' @keywords internal\n#' @export\n#' @noRd\n.warnMsg <- function(..., time = FALSE, collapse=', ') {\n    msg <- paste0(..., collapse=collapse)\n    if (time) {\n        timestamp <- format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")\n        msg <- paste0(timestamp, \" \", msg)\n    }\n    cyan$bold(msg)\n}\n\n#' Returns a colorized info message (green)\n#' @examples\n#' cat(.infoMsg('This ', 'is ', 'an ', 'info ', 'message', time = TRUE))\n#' @param ... `pairlist` One or more strings or character vectors, also\n#'  accepts any params to paste0.\n#' @param time `logical` Indicates whether to include timestamp or not. Default is FALSE.\n#' @return `character` Colorized string with results from paste0(...)\n#' @keywords internal\n#' @export\n#' @noRd\n#' @aliases .info\n.infoMsg <- function(..., time = FALSE, collapse=', ') {\n    msg <- paste0(..., collapse=collapse)\n    if (time) {\n        timestamp <- format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")\n        msg <- paste0(timestamp, \" \", msg)\n    }\n    green$bold(msg)\n}\n\n#' Get the types of all items in a list\n#'\n#' @examples\n#' list <- list(c(1,2,3), c('a','b','c'))\n#' is.items(list, 'character')\n#'\n#' @param list A `list` to get the types from\n#' @param ... `pairlist` Additional arguments to FUN\n#' @param FUN `function` or `character` Either a function, or the name\n#'   of a function which returns a single logical value. The default function\n#'   uses `is`, specify the desired type in `...`. You can also use other\n#'   type checking functions such as is.character, is.numeric, or is.data.frame.\n#'\n#' @return `logical` A vector indicating if the list item is the specified\n#'   type.\n#'\n#' @export\nis.items <- function(list, ..., FUN=is)\n    vapply(list, FUN=FUN, FUN.VALUE=logical(1), ...)\n\n#' @export\n.length_unique <- function(x) length(unique(x))\n\n#' @export\n.list_unique <- function(x) list(unique(x))\n\n#' @export\n.all_equals <- function(x, y) all(x == y)\n\n\n#' Return the name of the function and the name of the package that function\n#'   is in when called within an R function.\n#'\n#' For providing context in user messages, warnings and errors\n#'\n#' @param n `integer` How far up the call stack to look for context. Defaults to\n#'   2 since it is assumed this function will be used inside of `message`,\n#'   `warning` or `stop`.\n#'\n#' @return A `character` vector with the name of the function\n#'   `.getExecutionContext` was called from, as well as the package name,\n#'   if applicable.\n#'\n#' @md\n#' @keywords internal\n#' @importFrom rlang trace_back\n#' @importFrom utils packageName\n#' @noRd\n#' @aliases .context\n.getExecutionContext <- function(n=2) {\n\n    # name of function which called this function\n    callStack <- rlang::trace_back()$calls\n    context <- deparse(callStack[[length(callStack) - n]][1])\n\n    # remove function arguments\n    context <- gsub('\\\\(.*\\\\)', '', context)\n\n    # deal with getting function names from inside an lapply statement\n    ## TODO:: clean this up\n    if (grepl('.*lapply.*', context)) {\n        context <- deparse(callStack[[length(callStack) - (n + 1)]][3])\n        context <- gsub('\\\\(.*\\\\)', '', context)\n        # deal with S4 lapply calls (e.g., endoapply)\n        if (grepl('.*match.fun.*', context)) {\n            context <- deparse(callStack[[length(callStack) - (n + 5)]][3])\n            context <- gsub('\\\\(.*\\\\)', '', context)\n        }\n    } else if (grepl('.*mapply.*', context)) {\n        context <- deparse(callStack[[length(callStack) - (n + 1)]][1])\n        context <- gsub('\\\\(.*\\\\)', '', context)\n        if (grepl('.*match.fun.*', context)) {\n            context <- deparse(callStack[[length(callStack) - (n + 5)]][1])\n            context <- gsub('\\\\(.*\\\\)', '', context)\n        }\n    } else if (grepl('.*FUN.*', context)) {\n        context <- deparse(callStack[[length(callStack) - (n + 2)]][3])\n        context <- gsub('\\\\(.*\\\\)', '', context)\n        # deal with S4 lapply calls (e.g., endoapply)\n        if (grepl('.*match.fun.*', context)) {\n            context <- tryCatch({\n                deparse(callStack[[length(callStack) - (n + 6)]][3])\n            }, error=function(e) 'context_failed')\n            context <- gsub('\\\\(.*\\\\)', '', context)\n        }\n    }\n    if (!grepl('::', context)) context <- paste0(packageName(), '::', context)\n\n    return(paste0('\\n[', context, '] '))\n}\n#' @noRd\n.context <- .getExecutionContext\n\n\n#'\n#'\n#'\n#'\n#' @md\n#' @export\n.S4MethodContext <- function(generic, ...) {\n    dots <- list(...)\n    formals <- selectMethod(generic, signature=dots)\n    context <- paste0(\n        formals@target@package[1], '::`', # what package is the method from\n        formals@generic, ',',  # what is the name of the generic\n        paste0(formals@target@.Data, collapse=','), '-method`') # what is the method signature\n    return(context)\n}\n\n# Let it live here for now...\n\n#' Build an assay table with an `S4` object.\n#'\n#' @param object `S4` An S4 object a list-like slot containing assays for the\n#'   object.\n#' @param ... Allow new arguments to be defined for this generic.\n#'\n#' @return `data.table`.\n#'\n#' @examples\n#' \"This is a generic method!\"\n#'\n#' @exportMethod buildComboProfiles\nsetGeneric(\"buildComboProfiles\", function(object, ...) standardGeneric(\"buildComboProfiles\"))\n\n#' Build an assay table with selected assay profiles for drug combinations\n#'\n#' @examples\n#' \\dontrun{\n#' combo_profile_1 <- buildComboProfiles(tre, c(\"auc\", \"SCORE\"))\n#' combo_profile_2 <- buildComboProfiles(tre, c(\"HS\", \"EC50\", \"E_inf\", \"ZIP\"))\n#' }\n#'\n#' @param object `LongTable` or inheriting class containing curated drug combination data.\n#' @param profiles `character` a vector of profile names, i.e., column names of assays.\n#'\n#' @return A `data.table` containing fields\n#'   `treatment1id`, `treatment1dose`, `treatment2id`, `treatment2dose`, `sampleid`,\n#'   which are used as keys to keep track of profiles,\n#'   along with columns of selected profiles from their assays.\n#'   Each `*_1` is the monothearpy profile of treatment 1 in the combination,\n#'   and the same rule applies to treatment 2.\n#'\n#' @import data.table\n#' @importFrom methods is\n#' @export\n#' @docType methods\nsetMethod(\"buildComboProfiles\", signature(object = \"LongTable\"),\n          function(object, profiles) {\n    if (!is.character(profiles)) {\n        stop(\"argument `profiles` must be `character`\")\n    } else if (length(profiles) == 0) {\n        stop(\"argument `profiles` must not be empty\")\n    }\n\n    if (is.null(object[[\"sensitivity\"]])) {\n        stop(\"Assay sensitivity is missing\", call. = FALSE)\n    } else if (!\"treatment2id\" %in% idCols(object)) {\n        stop(\"This `TreatmentResponseExperiment` does not contain drug combination data.\",\n             call. = FALSE)\n    }\n\n    get_combo_viability <- (\"combo_viability\" %in% profiles)\n    #if (get_combo_viability) {\n    #    profiles <- profiles[!profiles %in% \"combo_viability\"]\n    #    # and enable option for including combo viability\n    #}\n\n    combo_keys <- c(\"treatment1id\", \"treatment2id\",\n                    \"treatment1dose\", \"treatment2dose\", \"sampleid\")\n    if (any(combo_keys %in% profiles)) {\n        profiles <- profiles[!profiles %in% combo_keys]\n        # and enable option for including dose here?\n    }\n\n    ## stop if none of the assays contain user selected profiles\n    which_profiles <- lapply(assayCols(object), function(x) {\n        if (any(x %in% profiles))\n            return(x %in% profiles)\n    })\n    which_profiles[sapply(which_profiles, is.null)] <- NULL\n    if (length(which_profiles) == 0)\n        stop(\"No profiles found in any assay!\")\n\n    ## check whether there are profiles not present in assays\n    profiles_exist <- vapply(profiles, function(x){\n        any(sapply(assayCols(object), function(y) x %in% y))\n    }, logical(1))\n    profiles_not_exist <- names(profiles_exist)[which(profiles_exist == FALSE)]\n    if (length(profiles_not_exist) > 0)\n        warning(\n            'No profiles named ',\n            paste(profiles_not_exist, collapse = \", \"),\n            ' in any of the assays, thus will not be included in the returned table.',\n            call. = FALSE\n        )\n\n    if (!is.null(object[[\"combo_viability\"]])) {\n        #if (get_combo_viability) {\n        #    combo_profiles <- object[[\"combo_viability\"]][,\n        #        c(combo_keys, \"combo_viability\"), with = FALSE\n        #    ]\n        #} else {\n        #    combo_profiles <- object[[\"combo_viability\"]][,\n        #        combo_keys, with = FALSE\n        #    ]\n        #}\n        combo_profiles <- object[[\"combo_viability\"]][,\n            combo_keys, with = FALSE\n        ]\n        ## we know replicates have been averaged in combo_viability\n    } else {\n        #if (get_combo_viability) {\n        #    object |>\n        #        subset(!is.na(treatment2dose)) |>\n        #        aggregate(\n        #            assay = \"sensitivity\",\n        #            combo_viability = (mean(viability) / 100),\n        #            by = combo_keys\n        #        ) -> combo_profiles\n        #} else {\n        #    combo_profiles <- unique(\n        #        object$sensitivity[\n        #            !is.na(treatment2dose),\n        #            combo_keys,\n        #            with = FALSE\n        #        ],\n        #        by = combo_keys\n        #    )\n        #}\n        combo_profiles <- unique(\n            object$sensitivity[\n                !is.na(treatment2dose),\n                combo_keys,\n                with = FALSE\n            ],\n            by = combo_keys\n        )\n    }\n    setkeyv(combo_profiles, combo_keys)\n\n    assay_to_query <- names(which_profiles)\n\n    ## how do we handle replicate rows?\n    for (i in seq_along(which_profiles)) {\n        assay_cols <- assayCols(object)[[assay_to_query[i]]]\n        query_profiles <- assay_cols[which_profiles[[i]]]\n        assay_ <- object[[assay_to_query[i]]]\n        if (!(\"treatment2id\" %in% assay_cols)) {\n            ## Assays for monotherapy data\n            ## Here I assume monotherapy assay tables have fewer keys\n            ## and less cardinality than treatment combo tables\n            ## might need extra condition check?\n            monotherapy_keys <- c(\"treatment1id\", \"sampleid\")\n            if (\"treatment1dose\" %in% assay_cols)\n                monotherapy_keys <- c(monotherapy_keys, \"treatment1dose\")\n            assay_ <- assay_[, c(monotherapy_keys, query_profiles), with = FALSE]\n            combo_profiles <- combo_profiles[assay_, ,\n                on = c(treatment1id = \"treatment1id\", sampleid = \"sampleid\")\n            ]\n            ## remove single agents not tested in drug combination screening\n            combo_profiles <- combo_profiles[!is.na(treatment2dose)]\n            combo_profiles <- merge(\n                combo_profiles,\n                assay_,\n                by.x = c(\"treatment2id\", \"sampleid\"),\n                by.y = c(\"treatment1id\", \"sampleid\"),\n                suffixes = c(\"_1\", \"_2\")\n            )\n            ## remove single agents not tested in drug combination screening\n            combo_profiles <- combo_profiles[!is.na(treatment1dose)]\n            ## Edge case: adding profiles in sensitivity first\n            ## then add monotherapy profiles\n            replicates <- c(\"tech_rep\", \"bio_rep\")\n            has_reps <- replicates %in% colnames(combo_profiles)\n            if (any(has_reps)) {\n                setkeyv(combo_profiles, c(combo_keys, replicates[has_reps]))\n            } else {\n                setkeyv(combo_profiles, combo_keys)\n            }\n        } else {\n            assay_keys <- key(assay_)\n            common_keys <- intersect(key(combo_profiles), assay_keys)\n            if (dim(combo_profiles)[1] >= dim(assay_)[1]) {\n                ## Here assume less cardinality implies no replicates\n                assay_ <- assay_[, c(common_keys, query_profiles), with = FALSE]\n                setkeyv(assay_, common_keys)\n                ## Left-join on combo_profiles\n                combo_profiles <- combo_profiles[assay_, ,\n                    on = common_keys\n                ]\n            } else { ## might have replicates\n                ## likely to happen for profiles in sensitivity assay\n                replicates <- c(\"tech_rep\", \"bio_rep\")\n                reps_in_common_keys <- replicates %in% common_keys\n                reps_in_assay_keys <- replicates %in% assay_keys\n                if (!all(reps_in_common_keys) & any(reps_in_assay_keys))\n                    miss_rep_key <- xor(reps_in_common_keys, reps_in_assay_keys)\n                if (any(miss_rep_key)) {\n                    ## treat it as a profile to add first\n                    add_rep_key <- replicates[which(reps_in_assay_keys)]\n                    query_profiles <- c(query_profiles, add_rep_key)\n                    setkeyv(assay_, c(common_keys, add_rep_key))\n                }\n                assay_ <- assay_[, c(common_keys, query_profiles), with = FALSE]\n                ## Left-join on assay_, replicate has become a key if present in assay_\n                combo_profiles <- assay_[combo_profiles, ,\n                    on = common_keys\n                ]\n            }\n        }\n    }\n    return(combo_profiles)\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.convertCSetMolecularProfilesToSE` function?",
        "answer": "The `.convertCSetMolecularProfilesToSE` function converts all ExpressionSet objects within the molecularProfiles slot of a CoreSet to SummarizedExperiments. It takes a CoreSet object as input and returns a modified CoreSet with molecular data stored as SummarizedExperiments instead of ExpressionSets."
      },
      {
        "question": "How does the function handle RNA data types when converting to SummarizedExperiments?",
        "answer": "For RNA data types (identified by the annotation 'rna'), the function changes the rownames from probes to EnsemblGeneId. This is done by assigning the 'EnsemblGeneId' column from the feature data (fData) of the ExpressionSet to the rownames of the ExpressionSet before conversion."
      },
      {
        "question": "What are the key steps in creating a SummarizedExperiment object from an ExpressionSet in this function?",
        "answer": "The key steps are: 1) Creating assays using the assayData from the ExpressionSet, 2) Setting rowData using the feature data (fData) from the ExpressionSet, 3) Setting colData using the phenotype data (pData) from the ExpressionSet, 4) Adding metadata including experimentData, annotation, and protocolData from the ExpressionSet, and 5) Assigning assay names using the assayDataElementNames from the ExpressionSet."
      }
    ],
    "completion_tasks": [
      {
        "partial": "# ExpressionSet to SummarizedExperiment -----------------------------------\n\n#' CSet molecularProfiles from ESets to SEs\n#'\n#' Converts all ExpressionSet objects within the molecularProfiles slot of a\n#'   CoreSet to SummarizedExperiments\n#'\n#' @param cSet \\code{S4} A CoreSet containing molecular data in ExpressionSets\n#'\n#' @return \\code{S4} A CoreSet containing molecular data in a\n#'   SummarizedExperiments\n#'\n#' @importFrom BiocParallel bplapply\n#' @importFrom SummarizedExperiment SummarizedExperiment Assays assay\n#'   assayNames assayNames<-\n#' @importFrom Biobase exprs fData pData annotation protocolData\n#'   assayDataElementNames\n#' @importFrom S4Vectors SimpleList DataFrame\n#' @importFrom stats setNames\n#' @keywords internal\n.convertCSetMolecularProfilesToSE <- function(cSet) {\n\n    eSets <- molecularProfilesSlot(cSet)  # Extract eSet data\n\n    molecularProfilesSlot(cSet) <- lapply(eSets, function(eSet) {\n\n        # Change rownames from probes to EnsemblGeneId for rna data type\n        if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n            rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n        }\n\n        # Build summarized experiment from eSet\n        SE <- SummarizedExperiment::SummarizedExperiment(\n            assays = SimpleList(as.list(Biobase::assayData(eSet))),\n            rowData = S4Vectors::DataFrame(Biobase::fData(eSet),\n                rownames = rownames(Biobase::fData(eSet))),\n            colData = S4Vectors::DataFrame(Biobase::pData(eSet),\n                rownames = rownames(Biobase::pData(eSet))),\n            metadata = list(\n                experimentData = eSet@experimentData,\n                annotation = Biobase::annotation(eSet),\n                protocolData = Biobase::protocolData(eSet)\n            )\n        )\n        # Extract names from expression set\n        assayNames(SE) <- assayDataElementNames(eSet)\n        # Assign SE to cSet\n        mDataType <- Biobase::annotation(eSet)\n        molecularProfilesSlot(cSet)[[mDataType]] <- SE\n    })\n    setNames(cSet@molecularProfiles, names(eSets))\n    cSet\n}",
        "complete": "# ExpressionSet to SummarizedExperiment -----------------------------------\n\n#' CSet molecularProfiles from ESets to SEs\n#'\n#' Converts all ExpressionSet objects within the molecularProfiles slot of a\n#'   CoreSet to SummarizedExperiments\n#'\n#' @param cSet \\code{S4} A CoreSet containing molecular data in ExpressionSets\n#'\n#' @return \\code{S4} A CoreSet containing molecular data in a\n#'   SummarizedExperiments\n#'\n#' @importFrom BiocParallel bplapply\n#' @importFrom SummarizedExperiment SummarizedExperiment Assays assay\n#'   assayNames assayNames<-\n#' @importFrom Biobase exprs fData pData annotation protocolData\n#'   assayDataElementNames\n#' @importFrom S4Vectors SimpleList DataFrame\n#' @importFrom stats setNames\n#' @keywords internal\n.convertCSetMolecularProfilesToSE <- function(cSet) {\n\n    eSets <- molecularProfilesSlot(cSet)  # Extract eSet data\n\n    molecularProfilesSlot(cSet) <- lapply(eSets, function(eSet) {\n\n        # Change rownames from probes to EnsemblGeneId for rna data type\n        if (grepl(\"^rna$\", Biobase::annotation(eSet))) {\n            rownames(eSet) <- Biobase::fData(eSet)$EnsemblGeneId\n        }\n\n        # Build summarized experiment from eSet\n        SE <- SummarizedExperiment::SummarizedExperiment(\n            assays = SimpleList(as.list(Biobase::assayData(eSet))),\n            rowData = S4Vectors::DataFrame(Biobase::fData(eSet),\n                rownames = rownames(Biobase::fData(eSet))),\n            colData = S4Vectors::DataFrame(Biobase::pData(eSet),\n                rownames = rownames(Biobase::pData(eSet))),\n            metadata = list(\n                experimentData = eSet@experimentData,\n                annotation = Biobase::annotation(eSet),\n                protocolData = Biobase::protocolData(eSet)\n            )\n        )\n        # Extract names from expression set\n        assayNames(SE) <- assayDataElementNames(eSet)\n        # Assign SE to cSet\n        mDataType <- Biobase::annotation(eSet)\n        molecularProfilesSlot(cSet)[[mDataType]] <- SE\n    })\n    setNames(cSet@molecularProfiles, names(eSets))\n    cSet\n}"
      },
      {
        "partial": "# sanityCheck -------------------------------------------------------------\n\n## TODO:: Add documentation!\n#' @export\n#' @noRd\n.sanitizeInput <- function(x, y, lower, upper, pars, x_as_log, y_as_log,\n        y_as_pct, trunc, verbose = FALSE) {\n    # Set to 2 to see debug printouts\n\n    if (!is.logical(x_as_log)) {\n        if (verbose == 2) {\n            message(\"x_as_log:\")\n            message(x_as_log)\n        }\n        stop(\"'x_as_log' is not a logical.\")\n    }\n\n    if (!is.logical(y_as_log)) {\n        if (verbose == 2) {\n            message(\"y_as_log:\")\n            message(y_as_log)\n        }\n        stop(\"'y_as_log' is not a logical.\")\n    }\n\n    if (!is.logical(y_as_pct)) {\n        if (verbose == 2) {\n            message(\"y_as_pct:\")\n            message(y_as_pct)\n        }\n        stop(\"'y_as_pct' is not a logical.\")\n    }\n\n    if (!is.logical(trunc)) {\n        if (verbose == 2) {\n            message(\"trunc:\")\n            message(trunc)\n        }\n        stop(\"'trunc' is not a logical.\")\n    }\n\n    if (y_as_pct && y_as_log) {\n        if (verbose == 2) {\n            message(\"y_as_pct:\")\n            message(y_as_pct)\n            message(\"y_as_log:\")\n            message(y_as_log)\n        }\n        warning(\"y_as_pct and y_as_log flags should almost certainly not both be TRUE.\")\n    }\n\n    if (!(verbose %in% c(0, 1, 2))) {\n        message(\"verbose:\")  #can't have the if(verbose == 2) statement here since verbose itself is the problem!\n        message(verbose)\n        stop(\"'verbose' flag is not set correctly.\")\n    }\n\n    if (!missing(x)) {\n        if (!all(is.finite(x) | is.na(x)) || (x_as_log && any(x == -Inf))) {\n            if (verbose == 2) {\n                message(\"x:\")\n                message(x)\n            }\n            stop(\"x must contain only real numbers, NA-values, and/or -Inf (if x_as_log flag is set to TRUE).\")\n        }\n\n        if (x_as_log == FALSE && min(x) < 0) {\n            if (verbose == 2) {\n                message(\"x:\")\n                message(x)\n                message(\"x_as_log:\")\n                message(x_as_log)\n            }\n            stop(\"Negative x-values encountered. Data may be inappropriate, or 'x_as_log' flag may be set incorrectly.\")\n        }\n        if (length(unique(x)) < 3) {\n            stop(\"Please pass in at least 3 unique dose points.\")\n        }\n    }\n\n    if (missing(y)) {\n        if (missing(pars)) {\n            stop(\"Both 'pars' and 'y' missing, please pass in some data!\")\n        } else {\n\n            if (pars[[1]] < 0 || pars[[2]] < 0) {\n                # HS or alpha\n                if (verbose == 2) {\n                  message(\"pars:\")\n                  message(pars)\n                }\n                warning(\"Curve parameters may be inappropriately set to negative values.\")\n            }\n\n            if (length(pars) == 3) {\n                # and thus we are in PharmacoGx\n                if (x_as_log == FALSE && pars[[3]] < 0) {\n                  message(\"pars:\")\n                  message(pars[[3]])\n                  message(\"x_as_log:\")\n                  message(x_as_log)\n                  stop(\"'x_as_log' flag may be set incorrectly, as the EC50 is negative when a positive value is expected.\")\n                }\n\n                if (y_as_pct == FALSE) {\n                  if (pars[[2]] > 1) {\n                    if (verbose == 2) {\n                      message(\"pars:\")\n                      message(pars[[2]])\n                      message(\"y_as_pct:\")\n                      message(y_as_pct)\n                    }\n                    warning(\"Warning: 'y_as_pct' flag may be set incorrectly.\")\n                  }\n                }\n            } else if (length(pars) == 2) {\n                if (pars[[1]] < pars[[2]]) {\n                  if (verbose) {\n                    warning(\"Alpha is greater than beta.\")\n                    if (verbose == 2) {\n                      message(\"pars:\")\n                      message(pars)\n                    }\n                  }\n                }\n            } else {\n                stop(\"Pars does not have the correct length.\")\n            }\n        }\n\n    } else {\n\n        if (!all(is.finite(y) | is.na(y)) || (y_as_log && any(y == -Inf))) {\n            if (verbose == 2) {\n                message(\"y:\")\n                message(y)\n            }\n            stop(\"y must contain only real numbers, NA-values, and/or -Inf (if y_as_log is set to TRUE).\")\n        }\n\n        if (min(y, na.rm=TRUE) < 0) {\n            if (verbose) {\n                warning(\"Warning: Negative y data.\")\n                if (verbose == 2) {\n                  message(\"y:\")\n                  message(y)\n                }\n            }\n        }\n\n        if (max(y, na.rm=TRUE) > (1 + 99 * y_as_pct)) {\n            if (verbose) {\n                warning(\"Warning: y data exceeds negative control.\")\n                if (verbose == 2) {\n                  message(\"y:\")\n                  message(y)\n                }\n            }\n        }\n\n        if (missing(pars)) {\n\n            if (y_as_log == FALSE && min(y, na.rm=TRUE) < 0) {\n                if (verbose) {\n                  warning(\"Negative y-values encountered. y data may be inappropriate, or 'y_as_log' flag may be set incorrectly.\")\n                  if (verbose == 2) {\n                    message(\"y:\")\n                    message(y)\n                    message(\"y_as_log:\")\n                    message(y_as_log)\n                  }\n                }\n            }\n\n            if (y_as_pct == TRUE && max(y, na.rm=TRUE) < 5) {\n                if (verbose) {\n                  warning(\"Warning: 'y_as_pct' flag may be set incorrectly.\")\n                  if (verbose == 2) {\n                    message(\"y:\")\n                    message(y)\n                    message(\"y_as_pct:\")\n                    message(y_as_pct)\n                  }\n                }\n            }\n\n            "
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/linearQuadraticModel.R",
    "language": "R",
    "content": "#' Fit linear-quadratic curves to dose-response data\n#'\n#' This function fits a linear-quadratic curve to dose-response data.\n#'\n#' @examples\n#' linearQuadraticModel(c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n#'  c(1.1, 0.8, 0.7, 0.45, 0.15, -0.1, -0.1, -0.4, -0.65, -0.75, -1.1))\n#'\n#' @param D vector of radiation doses\n#' @param SF vector of survival fractions corresponding to the doses\n#' @param lower_bounds vector of length 2 containing minimum allowed values of\n#'   fitted alpha and beta, respectively\n#' @param upper_bounds vector of length 2 containing maximum allowed values of\n#'   fitted alpha and beta, respectively\n#' @param scale parameter of the assumed error distribution of the data; see\n#'   sdetails\n#' @param family family of distributions of the error terms in the data;\n#'   currently supported options are \"normal\" and \"cauchy\"\n#' @param median_n see details\n#' @param trunc should survival fractions be truncated downward to 1? Defaults\n#'   to FALSE.\n#' @param verbose 'verbose' outputs warnings that are otherwised suppressed when\n#'   the function sanity-checks user inputs. 'median_n' denotes the number of\n#'   distributions from family 'family' that are medianned. (Note that setting\n#'   n = 1 (the default) is equivalent to using a simple normal or cauchy\n#'   distribution without taking any medians.)\n#'\n#' @return \\code{numeric} The estimated alpha and beta values\n#' @export\nlinearQuadraticModel <- function (D,\n                                  SF,\n                                  lower_bounds = c(0, 0),\n                                  upper_bounds = c(1, 1),\n                                  scale = 5,\n                                  family = c(\"normal\", \"Cauchy\"),\n                                  median_n = 1,\n                                  trunc = FALSE,\n                                  verbose = FALSE) {\n  family <- match.arg(family)\n\n  CoreGx::.sanitizeInput(x = D,\n                         y = SF,\n                         x_as_log = FALSE,\n                         y_as_log = FALSE,\n                         y_as_pct = FALSE,\n                         trunc = trunc,\n                         verbose = verbose)\n\n  DSF <- CoreGx::.reformatData(x = D,\n                               y = SF,\n                               x_to_log = FALSE,\n                               y_to_log = TRUE,\n                               y_to_frac = FALSE,\n                               trunc = trunc)\n  D <- DSF[[\"x\"]]\n  SF <- DSF[[\"y\"]]\n\n  if (!(all(lower_bounds < upper_bounds))) {\n    if (verbose == 2) {\n      message(\"lower_bounds:\")\n      message(lower_bounds)\n      message(\"upper_bounds:\")\n      message(upper_bounds)\n    }\n    stop (\"All lower bounds must be less than the corresponding upper_bounds.\")\n  }\n\n  if(!(0 %in% D) || SF[D==0] != 0) {\n    D <- c(0,D)\n    SF <- c(0,SF)\n  }\n\n  gritty_guess <- .makeGrittyGuess(lower_bounds = lower_bounds,\n                                   upper_bounds = upper_bounds,\n                                   D = D,\n                                   SF = SF)\n\n  guess <- CoreGx::.fitCurve(x = D,\n                              y = SF,\n                              f = .linearQuadratic,\n                              density = c(100, 100),\n                              step = c(0.005, 0.005),\n                              precision = 0.005,\n                              lower_bounds = lower_bounds,\n                              upper_bounds = upper_bounds,\n                              scale = scale,\n                              family = family,\n                              median_n = median_n,\n                              trunc = FALSE,\n                              verbose = verbose,\n                              gritty_guess = gritty_guess,\n                              span = 0.1)\n\n  names(guess) <- c(\"alpha\", \"beta\")\n\n  return(guess)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `linearQuadraticModel` function and what are its main input parameters?",
        "answer": "The `linearQuadraticModel` function fits a linear-quadratic curve to dose-response data. Its main input parameters are:\n1. `D`: vector of radiation doses\n2. `SF`: vector of survival fractions corresponding to the doses\n3. `lower_bounds` and `upper_bounds`: vectors containing minimum and maximum allowed values for fitted alpha and beta\n4. `scale`: parameter of the assumed error distribution\n5. `family`: family of distributions for error terms (normal or cauchy)\n6. `median_n`: number of distributions to be medianned\n7. `trunc`: boolean to determine if survival fractions should be truncated downward to 1\n8. `verbose`: controls output of warnings during input sanity checks"
      },
      {
        "question": "How does the function handle the case where the dose (D) vector doesn't include 0, or when the survival fraction (SF) at dose 0 is not 0?",
        "answer": "The function checks if 0 is in the dose vector (D) and if the survival fraction (SF) at dose 0 is 0. If either condition is not met, it adds a point (0, 0) to the beginning of both D and SF vectors. This is done with the following code:\n\n```R\nif(!(0 %in% D) || SF[D==0] != 0) {\n  D <- c(0,D)\n  SF <- c(0,SF)\n}\n```\n\nThis ensures that the model always includes the origin point, which is important for the linear-quadratic model's assumptions."
      },
      {
        "question": "What steps does the function take to sanitize and reformat the input data before fitting the model?",
        "answer": "The function takes several steps to sanitize and reformat the input data:\n\n1. It calls `CoreGx::.sanitizeInput()` to perform initial sanity checks on the input data (D and SF).\n2. It then uses `CoreGx::.reformatData()` to reformat the data. This function:\n   - Keeps D (dose) as is (x_to_log = FALSE)\n   - Converts SF (survival fraction) to log scale (y_to_log = TRUE)\n   - Does not convert SF to fraction if it's already in fraction form (y_to_frac = FALSE)\n   - Applies truncation if specified by the `trunc` parameter\n3. The reformatted data is stored back in D and SF variables.\n4. It checks if all lower bounds are less than the corresponding upper bounds, throwing an error if this condition is not met.\n5. It ensures that a (0,0) point exists in the data set, adding it if necessary.\n\nThese steps ensure that the data is in the correct format and meets the necessary conditions before the model fitting process begins."
      }
    ],
    "completion_tasks": [
      {
        "partial": "linearQuadraticModel <- function (D, SF, lower_bounds = c(0, 0), upper_bounds = c(1, 1), scale = 5, family = c(\"normal\", \"Cauchy\"), median_n = 1, trunc = FALSE, verbose = FALSE) {\n  family <- match.arg(family)\n\n  CoreGx::.sanitizeInput(x = D, y = SF, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = trunc, verbose = verbose)\n\n  DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = trunc)\n  D <- DSF[[\"x\"]]\n  SF <- DSF[[\"y\"]]\n\n  if (!(all(lower_bounds < upper_bounds))) {\n    if (verbose == 2) {\n      message(\"lower_bounds:\")\n      message(lower_bounds)\n      message(\"upper_bounds:\")\n      message(upper_bounds)\n    }\n    stop (\"All lower bounds must be less than the corresponding upper_bounds.\")\n  }\n\n  # Complete the function by adding the remaining code\n}",
        "complete": "linearQuadraticModel <- function (D, SF, lower_bounds = c(0, 0), upper_bounds = c(1, 1), scale = 5, family = c(\"normal\", \"Cauchy\"), median_n = 1, trunc = FALSE, verbose = FALSE) {\n  family <- match.arg(family)\n\n  CoreGx::.sanitizeInput(x = D, y = SF, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = trunc, verbose = verbose)\n\n  DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = trunc)\n  D <- DSF[[\"x\"]]\n  SF <- DSF[[\"y\"]]\n\n  if (!(all(lower_bounds < upper_bounds))) {\n    if (verbose == 2) {\n      message(\"lower_bounds:\")\n      message(lower_bounds)\n      message(\"upper_bounds:\")\n      message(upper_bounds)\n    }\n    stop (\"All lower bounds must be less than the corresponding upper_bounds.\")\n  }\n\n  if(!(0 %in% D) || SF[D==0] != 0) {\n    D <- c(0,D)\n    SF <- c(0,SF)\n  }\n\n  gritty_guess <- .makeGrittyGuess(lower_bounds = lower_bounds, upper_bounds = upper_bounds, D = D, SF = SF)\n\n  guess <- CoreGx::.fitCurve(x = D, y = SF, f = .linearQuadratic, density = c(100, 100), step = c(0.005, 0.005), precision = 0.005, lower_bounds = lower_bounds, upper_bounds = upper_bounds, scale = scale, family = family, median_n = median_n, trunc = FALSE, verbose = verbose, gritty_guess = gritty_guess, span = 0.1)\n\n  names(guess) <- c(\"alpha\", \"beta\")\n\n  return(guess)\n}"
      },
      {
        "partial": "linearQuadraticModel <- function (D, SF, lower_bounds = c(0, 0), upper_bounds = c(1, 1), scale = 5, family = c(\"normal\", \"Cauchy\"), median_n = 1, trunc = FALSE, verbose = FALSE) {\n  family <- match.arg(family)\n\n  CoreGx::.sanitizeInput(x = D, y = SF, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = trunc, verbose = verbose)\n\n  DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = trunc)\n  D <- DSF[[\"x\"]]\n  SF <- DSF[[\"y\"]]\n\n  # Add input validation and data preparation\n\n  # Fit the curve and return the result\n}",
        "complete": "linearQuadraticModel <- function (D, SF, lower_bounds = c(0, 0), upper_bounds = c(1, 1), scale = 5, family = c(\"normal\", \"Cauchy\"), median_n = 1, trunc = FALSE, verbose = FALSE) {\n  family <- match.arg(family)\n\n  CoreGx::.sanitizeInput(x = D, y = SF, x_as_log = FALSE, y_as_log = FALSE, y_as_pct = FALSE, trunc = trunc, verbose = verbose)\n\n  DSF <- CoreGx::.reformatData(x = D, y = SF, x_to_log = FALSE, y_to_log = TRUE, y_to_frac = FALSE, trunc = trunc)\n  D <- DSF[[\"x\"]]\n  SF <- DSF[[\"y\"]]\n\n  if (!(all(lower_bounds < upper_bounds))) {\n    if (verbose == 2) {\n      message(\"lower_bounds:\")\n      message(lower_bounds)\n      message(\"upper_bounds:\")\n      message(upper_bounds)\n    }\n    stop (\"All lower bounds must be less than the corresponding upper_bounds.\")\n  }\n\n  if(!(0 %in% D) || SF[D==0] != 0) {\n    D <- c(0,D)\n    SF <- c(0,SF)\n  }\n\n  gritty_guess <- .makeGrittyGuess(lower_bounds = lower_bounds, upper_bounds = upper_bounds, D = D, SF = SF)\n\n  guess <- CoreGx::.fitCurve(x = D, y = SF, f = .linearQuadratic, density = c(100, 100), step = c(0.005, 0.005), precision = 0.005, lower_bounds = lower_bounds, upper_bounds = upper_bounds, scale = scale, family = family, median_n = median_n, trunc = FALSE, verbose = verbose, gritty_guess = gritty_guess, span = 0.1)\n\n  names(guess) <- c(\"alpha\", \"beta\")\n\n  return(guess)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat.R",
    "language": "R",
    "content": "library(testthat)\nlibrary(CoreGx)\n\ntest_check(\"CoreGx\")\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `library()` function calls in this R code snippet?",
        "answer": "The `library()` function calls are used to load and attach the specified packages ('testthat' and 'CoreGx') to the current R session. This makes the functions and data from these packages available for use in the subsequent code."
      },
      {
        "question": "What does the `test_check()` function do in this context?",
        "answer": "The `test_check()` function is part of the 'testthat' package and is used to run all the tests for a specified package. In this case, it's running all the tests for the 'CoreGx' package. This function is typically used in the test file of an R package to execute all unit tests defined for that package."
      },
      {
        "question": "Why might a developer include this code snippet in their R package?",
        "answer": "A developer would include this code snippet in their R package to set up and run automated tests. This is a common practice in R package development to ensure the package's functions work as expected. The snippet loads necessary testing tools (testthat), the package being tested (CoreGx), and then runs all defined tests for the package. This helps maintain code quality and catch potential bugs during development or after changes to the package."
      }
    ],
    "completion_tasks": [
      {
        "partial": "library(testthat)\nlibrary(CoreGx)\n\ntest_",
        "complete": "library(testthat)\nlibrary(CoreGx)\n\ntest_check(\"CoreGx\")"
      },
      {
        "partial": "library(testthat)\n\ntest_check(",
        "complete": "library(testthat)\nlibrary(CoreGx)\n\ntest_check(\"CoreGx\")"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/downloadRSet.R",
    "language": "R",
    "content": "#' Return a table of RadioSets available for download\n#'\n#' The function fetches a table of all RadioSets available for download from\n#' the PharmacoGx server. The table includes the names of the PharamcoSet, the\n#' types of data available in the object, and the date of last update.\n#'\n#' @examples\n#' if (interactive()){\n#' availableRSets()\n#' }\n#'\n#' @param saveDir \\code{character} Directory to save the table of rSets\n#' @param fileName \\code{character} The filename for the table of rSets\n#' @param verbose \\code{bool} Should status messages be printed during download.\n#'\n#' @return A data.frame with details about the available RadioSet objects\n#'\n#' @export\n#' @import downloader\n#' @importFrom utils read.csv write.table\navailableRSets <- function(saveDir=tempdir(), fileName=\"availableRadioSets.csv\", verbose=TRUE) {\n\n    if (missing(saveDir) && verbose) {\n        message(\"Downloading to temporary folder... Use saveDir parameter to\n                save to a specific path\")\n        }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    downloader::download(\"https://zenodo.org/record/3899568/files/availableRadioSets.csv?download=1\",\n                         destfile = file.path(saveDir, fileName),\n                         quiet = !verbose)\n\n    rSetTable <- read.csv(file.path(saveDir, fileName), header = TRUE, stringsAsFactors = FALSE)\n    return(rSetTable)\n}\n\n#' Download a RadioSet object\n#'\n#' This function allows you to download a \\code{RadioSet} object for use with this\n#' package. The \\code{RadioSets} have been extensively curated and organized within\n#' a PharacoSet class, enabling use with all the analysis tools provided in\n#' \\code{PharmacoGx}.\n#'\n#' @examples\n#' if (interactive()) {\n#' cleveland <- downloadRSet(\"Cleveland\")\n#' }\n#'\n#' @param name \\code{Character} string, the name of the PhamracoSet to download.\n#' @param saveDir \\code{Character} string with the folder path where the\n#'     RadioSet should be saved. Defaults to \\code{'./rSets/'}. Will create\n#'     directory if it does not exist.\n#' @param rSetFileName \\code{character} string, the file name to save the dataset under\n#' @param verbose \\code{bool} Should status messages be printed during download.\n#'   Defaults to TRUE.\n#' @param timeout `numeric(1)` How long to wait before erroring due to timeout,\n#' in seconds. Default it 600s (10 minutes).\n#'\n#' @return A rSet object with the dataset, downloaded from our server\n#'\n#' @export\n#' @import downloader\ndownloadRSet <- function(name, saveDir=tempdir(), rSetFileName=NULL,\n        verbose=TRUE, timeout=600) {\n\n    # change the download timeout since the files are big\n    opts <- options()\n    options(timeout=timeout)\n    on.exit(options(opts))\n\n    if (missing(saveDir)) {message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")}\n    rSetTable <- availableRSets(saveDir = saveDir, verbose=FALSE)\n\n    whichx <- match(name, rSetTable[, 1])\n    if (is.na(whichx)) {\n        stop('Unknown Dataset. Please use the availableRSets() function for the\n            table of available RadicoSets.')\n    }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    if (is.null(rSetFileName)) {\n        rSetFileName <- paste0(rSetTable[whichx,\"RadioSet_name\"], \".rds\")\n    }\n    if (!file.exists(file.path(saveDir, rSetFileName))) {\n        downloader::download(url = as.character(rSetTable[whichx, \"URL\"]),\n            destfile = file.path(saveDir, rSetFileName), quiet = !verbose,\n            mode='wb')\n    }\n\n    rSet <- readRDS(file.path(saveDir, rSetFileName))\n    rSet <- updateObject(rSet)\n\n    return(rSet)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `availableRSets` function and what does it return?",
        "answer": "The `availableRSets` function fetches a table of all RadioSets available for download from the PharmacoGx server. It returns a data.frame containing details about the available RadioSet objects, including their names, types of data available, and the date of last update."
      },
      {
        "question": "How does the `downloadRSet` function handle timeout issues when downloading large files?",
        "answer": "The `downloadRSet` function sets a custom timeout value using `options(timeout=timeout)`, where `timeout` is a parameter with a default value of 600 seconds (10 minutes). This allows for longer download times for large files. The function also uses `on.exit(options(opts))` to restore the original options after the function execution."
      },
      {
        "question": "What happens if a user tries to download a RadioSet with an unknown name using the `downloadRSet` function?",
        "answer": "If a user tries to download a RadioSet with an unknown name, the function will throw an error. It does this by checking if the provided name exists in the table of available RadioSets. If the name is not found (i.e., `is.na(whichx)` is true), the function stops execution and displays an error message suggesting the user to use the `availableRSets()` function to see the table of available RadioSets."
      }
    ],
    "completion_tasks": [
      {
        "partial": "availableRSets <- function(saveDir=tempdir(), fileName=\"availableRadioSets.csv\", verbose=TRUE) {\n    if (missing(saveDir) && verbose) {\n        message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")\n    }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    downloader::download(\"https://zenodo.org/record/3899568/files/availableRadioSets.csv?download=1\",\n                         destfile = file.path(saveDir, fileName),\n                         quiet = !verbose)\n\n    # Complete the function by reading the CSV file and returning the result\n}",
        "complete": "availableRSets <- function(saveDir=tempdir(), fileName=\"availableRadioSets.csv\", verbose=TRUE) {\n    if (missing(saveDir) && verbose) {\n        message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")\n    }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    downloader::download(\"https://zenodo.org/record/3899568/files/availableRadioSets.csv?download=1\",\n                         destfile = file.path(saveDir, fileName),\n                         quiet = !verbose)\n\n    read.csv(file.path(saveDir, fileName), header = TRUE, stringsAsFactors = FALSE)\n}"
      },
      {
        "partial": "downloadRSet <- function(name, saveDir=tempdir(), rSetFileName=NULL, verbose=TRUE, timeout=600) {\n    opts <- options()\n    options(timeout=timeout)\n    on.exit(options(opts))\n\n    if (missing(saveDir)) {\n        message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")\n    }\n    rSetTable <- availableRSets(saveDir = saveDir, verbose=FALSE)\n\n    whichx <- match(name, rSetTable[, 1])\n    if (is.na(whichx)) {\n        stop('Unknown Dataset. Please use the availableRSets() function for the table of available RadicoSets.')\n    }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    if (is.null(rSetFileName)) {\n        rSetFileName <- paste0(rSetTable[whichx,\"RadioSet_name\"], \".rds\")\n    }\n    if (!file.exists(file.path(saveDir, rSetFileName))) {\n        downloader::download(url = as.character(rSetTable[whichx, \"URL\"]),\n            destfile = file.path(saveDir, rSetFileName), quiet = !verbose,\n            mode='wb')\n    }\n\n    # Complete the function by reading the RDS file, updating the object, and returning it\n}",
        "complete": "downloadRSet <- function(name, saveDir=tempdir(), rSetFileName=NULL, verbose=TRUE, timeout=600) {\n    opts <- options()\n    options(timeout=timeout)\n    on.exit(options(opts))\n\n    if (missing(saveDir)) {\n        message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")\n    }\n    rSetTable <- availableRSets(saveDir = saveDir, verbose=FALSE)\n\n    whichx <- match(name, rSetTable[, 1])\n    if (is.na(whichx)) {\n        stop('Unknown Dataset. Please use the availableRSets() function for the table of available RadicoSets.')\n    }\n\n    if (!file.exists(saveDir)) {\n        dir.create(saveDir, recursive = TRUE)\n    }\n\n    if (is.null(rSetFileName)) {\n        rSetFileName <- paste0(rSetTable[whichx,\"RadioSet_name\"], \".rds\")\n    }\n    if (!file.exists(file.path(saveDir, rSetFileName))) {\n        downloader::download(url = as.character(rSetTable[whichx, \"URL\"]),\n            destfile = file.path(saveDir, rSetFileName), quiet = !verbose,\n            mode='wb')\n    }\n\n    rSet <- readRDS(file.path(saveDir, rSetFileName))\n    updateObject(rSet)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/DataMapper-class.R",
    "language": "R",
    "content": "#' @importClassesFrom S4Vectors Annotated list_OR_List\n#' @importFrom data.table copy\nNULL\n\n#' An S4 Class For Mapping from Raw Experimental Data to a Specific S4 Object\n#'\n#' This object will be used as a way to abstract away data preprocessing.\n#'\n#' @section Slots:\n#' * rawdata: A list-like object containing one or more pieces of raw data\n#'   that will be processed and mapped to the slots of an `S4` object.\n#' * metadata: A `List` of object level metadata.\n#'\n#' @md\n#' @aliases DataMapper-class\n.DataMapper <- setClass('DataMapper',\n    contains=c('VIRTUAL', 'Annotated'),\n    slots=list(rawdata='list_OR_List')\n)\n\n.local_class_2 <- 'DataMapper'\n\n.docs_DataMapper_accessors <- function(...) .parseToRoxygen(\n    \"\n    @title Accessing and modifying data in a `{class_}` object.\n\n    @description\n    Documentation for the various setters and getters which allow manipulation\n    of data in the slots of a `{class_}` object.\n\n    @param object A `{class_}` object to get or set data from.\n    @param value A `list`-like object to assign to the rawdata slot. Should be\n        a `data.frame` or `data.table` with the current implementation.\n\n    @family DataMapper-accessors\n\n    @return Accessors: See details\n    @return Setters: An update `{class_}` object, returned invisibly.\n    \",\n    ...\n)\n\n\n# ==================================\n# DataMapper Accessors Documentation\n# ----------------------------------\n\n#' @name DataMapper-accessors\n#' @eval .docs_DataMapper_accessors(class_=.local_class_2)\nNULL\n\n#' @export\nsetGeneric('rawdata', function(object, ...) standardGeneric('rawdata'))\n\n.docs_DataMapper_get_rawdata <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __rawdata__: Get the raw data slot from a `{class_}` object. Returns\n    a list-like containing one or more raw data inputs to the\n    `{class_}` object.\n\n    @md\n    @aliases rawdata,{class_}-method\n    @exportMethod rawdata\n    \",\n    ...\n)\n\n#' @rdname DataMapper-accessors\n#' @aliases rawdata\n#' @eval .docs_DataMapper_get_rawdata(class_=.local_class_2)\nsetMethod('rawdata', signature(object='DataMapper'), function(object) {\n    rawdata_ <- object@rawdata\n    return(data.table::copy(rawdata_))\n})\n\n#' @export\nsetGeneric(\"rawdata<-\", function(object, ..., value)\n    standardgeneric(\"rawdata<-\"))\n\n.docs_DataMapper_set_rawdata <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __rawdata__: Set the raw data slot from a `{class_}` object.\n    __value__: The `list`-like object to set for the rawdata slot. Note: this\n        currently only supports `data.frame` or `data.table` objects.\n\n    @md\n    @aliases rawdata<-,{class_},{class1_}-method\n    @exportMethod rawdata<-\n    \",\n    ...\n)\n\n#' @rdname DataMapper-accessors\n#' @aliases rawdata<-\n#' @eval .docs_DataMapper_set_rawdata(class_=.local_class_2, class1_='ANY')\nsetReplaceMethod('rawdata', signature(object='DataMapper'),\n        function(object, value) {\n    object@rawdata <- value\n    object\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `.DataMapper` class in this code snippet?",
        "answer": "The `.DataMapper` class is an S4 class designed to abstract away data preprocessing. It serves as a mapping from raw experimental data to a specific S4 object. It contains two main slots: 'rawdata' for storing raw data to be processed, and 'metadata' for object-level metadata."
      },
      {
        "question": "How are the accessor methods for the `DataMapper` class implemented in this code?",
        "answer": "The accessor methods for the `DataMapper` class are implemented using S4 generics and methods. The code defines a generic 'rawdata' function and its corresponding method for getting the raw data. It also defines a generic 'rawdata<-' function and its method for setting the raw data. These methods use the '@' operator to access and modify the 'rawdata' slot of the object."
      },
      {
        "question": "What is the purpose of the `.docs_DataMapper_accessors` function in this code?",
        "answer": "The `.docs_DataMapper_accessors` function is used to generate documentation for the accessor methods of the `DataMapper` class. It creates a Roxygen2-compatible documentation string that describes the purpose of the accessors, their parameters, and return values. This function is likely called by other parts of the code to generate consistent documentation for different DataMapper-related functions."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' @importClassesFrom S4Vectors Annotated list_OR_List\n#' @importFrom data.table copy\nNULL\n\n#' An S4 Class For Mapping from Raw Experimental Data to a Specific S4 Object\n#'\n#' This object will be used as a way to abstract away data preprocessing.\n#'\n#' @section Slots:\n#' * rawdata: A list-like object containing one or more pieces of raw data\n#'   that will be processed and mapped to the slots of an `S4` object.\n#' * metadata: A `List` of object level metadata.\n#'\n#' @md\n#' @aliases DataMapper-class\n.DataMapper <- setClass('DataMapper',\n    contains=c('VIRTUAL', 'Annotated'),\n    slots=list(rawdata='list_OR_List')\n)\n\n.local_class_2 <- 'DataMapper'\n\n# Complete the following function\n.docs_DataMapper_accessors <- function(...) {\n    # Your code here\n}",
        "complete": "#' @importClassesFrom S4Vectors Annotated list_OR_List\n#' @importFrom data.table copy\nNULL\n\n#' An S4 Class For Mapping from Raw Experimental Data to a Specific S4 Object\n#'\n#' This object will be used as a way to abstract away data preprocessing.\n#'\n#' @section Slots:\n#' * rawdata: A list-like object containing one or more pieces of raw data\n#'   that will be processed and mapped to the slots of an `S4` object.\n#' * metadata: A `List` of object level metadata.\n#'\n#' @md\n#' @aliases DataMapper-class\n.DataMapper <- setClass('DataMapper',\n    contains=c('VIRTUAL', 'Annotated'),\n    slots=list(rawdata='list_OR_List')\n)\n\n.local_class_2 <- 'DataMapper'\n\n.docs_DataMapper_accessors <- function(...) .parseToRoxygen(\n    \"\n    @title Accessing and modifying data in a `{class_}` object.\n\n    @description\n    Documentation for the various setters and getters which allow manipulation\n    of data in the slots of a `{class_}` object.\n\n    @param object A `{class_}` object to get or set data from.\n    @param value A `list`-like object to assign to the rawdata slot. Should be\n        a `data.frame` or `data.table` with the current implementation.\n\n    @family DataMapper-accessors\n\n    @return Accessors: See details\n    @return Setters: An update `{class_}` object, returned invisibly.\n    \",\n    ...\n)"
      },
      {
        "partial": "#' @export\nsetGeneric('rawdata', function(object, ...) standardGeneric('rawdata'))\n\n.docs_DataMapper_get_rawdata <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __rawdata__: Get the raw data slot from a `{class_}` object. Returns\n    a list-like containing one or more raw data inputs to the\n    `{class_}` object.\n\n    @md\n    @aliases rawdata,{class_}-method\n    @exportMethod rawdata\n    \",\n    ...\n)\n\n#' @rdname DataMapper-accessors\n#' @aliases rawdata\n#' @eval .docs_DataMapper_get_rawdata(class_=.local_class_2)\n# Complete the following method\nsetMethod('rawdata', signature(object='DataMapper'), function(object) {\n    # Your code here\n})",
        "complete": "#' @export\nsetGeneric('rawdata', function(object, ...) standardGeneric('rawdata'))\n\n.docs_DataMapper_get_rawdata <- function(...) .parseToRoxygen(\n    \"\n    @details\n    __rawdata__: Get the raw data slot from a `{class_}` object. Returns\n    a list-like containing one or more raw data inputs to the\n    `{class_}` object.\n\n    @md\n    @aliases rawdata,{class_}-method\n    @exportMethod rawdata\n    \",\n    ...\n)\n\n#' @rdname DataMapper-accessors\n#' @aliases rawdata\n#' @eval .docs_DataMapper_get_rawdata(class_=.local_class_2)\nsetMethod('rawdata', signature(object='DataMapper'), function(object) {\n    rawdata_ <- object@rawdata\n    return(data.table::copy(rawdata_))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/computeSF2.R",
    "language": "R",
    "content": "#' Compute SF2\n#'\n#' This function computes the survival fraction after administering\n#'   2 units of radiation, given alpha and beta in the equation\n#'   SF = exp(-alpha * D - beta * D ^ 2).\n#'\n#' @examples computeSF2(c(0.2, 0.1))\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The survival fraction\n#'\n#' @export\ncomputeSF2 <- function(pars) {\n\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  SF <- .linearQuadratic(D = 2,\n                         pars = pars,\n                         SF_as_log = FALSE)\n\n  return(SF)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `computeSF2` function and what does SF stand for in this context?",
        "answer": "The `computeSF2` function computes the survival fraction (SF) after administering 2 units of radiation. It uses the linear-quadratic model equation SF = exp(-alpha * D - beta * D^2), where D is the radiation dose, and alpha and beta are parameters representing radiosensitivity."
      },
      {
        "question": "How does the function handle input sanitization and what external function does it use for this purpose?",
        "answer": "The function uses the `CoreGx::.sanitizeInput` function to sanitize the input parameters. This function is called with specific arguments: `pars` for the input parameters, `x_as_log = FALSE`, `y_as_log = FALSE`, `y_as_pct = FALSE`, `trunc = FALSE`, and `verbose = FALSE`. This ensures that the input is properly formatted and validated before further processing."
      },
      {
        "question": "What is the significance of the fixed value '2' in the `.linearQuadratic` function call, and how does it relate to the function's purpose?",
        "answer": "The fixed value '2' in the `.linearQuadratic` function call represents the radiation dose (D) of 2 units. This is consistent with the function's purpose of computing the survival fraction specifically for 2 units of radiation, as indicated in the function's description and name (`computeSF2`)."
      }
    ],
    "completion_tasks": [
      {
        "partial": "computeSF2 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  SF <- # Complete the function call to .linearQuadratic\n\n  return(SF)\n}",
        "complete": "computeSF2 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  SF <- .linearQuadratic(D = 2,\n                         pars = pars,\n                         SF_as_log = FALSE)\n\n  return(SF)\n}"
      },
      {
        "partial": "#' Compute SF2\n#'\n#' This function computes the survival fraction after administering\n#'   2 units of radiation, given alpha and beta in the equation\n#'   SF = exp(-alpha * D - beta * D ^ 2).\n#'\n#' @examples computeSF2(c(0.2, 0.1))\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The survival fraction\n#'\n#' @export\ncomputeSF2 <- function(pars) {\n  # Complete the function body\n}",
        "complete": "#' Compute SF2\n#'\n#' This function computes the survival fraction after administering\n#'   2 units of radiation, given alpha and beta in the equation\n#'   SF = exp(-alpha * D - beta * D ^ 2).\n#'\n#' @examples computeSF2(c(0.2, 0.1))\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The survival fraction\n#'\n#' @export\ncomputeSF2 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  SF <- .linearQuadratic(D = 2,\n                         pars = pars,\n                         SF_as_log = FALSE)\n\n  return(SF)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/geneDrugSensitivity.R",
    "language": "R",
    "content": "#' Calcualte the gene radiation sensitivity score\n#'\n#'\n#' @param x \\code{numeric} vector of gene expression values\n#' @param type \\code{factor} vector specifying the cell lines or type types\n#' @param batch \\code{factor} vector of factors specifying the batch\n#' @param drugpheno \\code{numeric} vector of drug sensitivity values (e.g.,\n#'   IC50 or AUC)\n#' @param model Should the full linear model be returned? Default set to FALSE\n#' @param standardize \\code{character} One of 'SD', 'rescale' or 'none'\n#' @param verbose \\code{logical} Should informative messages be written to\n#'   the console?\n#'\n#' @return A \\code{numeric} vector reporting the effect size (estimate of the\n#'   coefficient of drug concentration), standard error (se), sample size (n),\n#'   t statistic, and F statistics and its corresponding p-value\n#'\n#' @importFrom stats sd complete.cases lm glm anova pf formula var\n#' @importFrom scales rescale\n#'\n#' @noRd\ngeneRadSensitivity <- function(x,\n                               type,\n                               batch,\n                               drugpheno,\n                               model=FALSE,\n                               standardize=c(\"SD\", \"rescale\", \"none\"),\n                               verbose=FALSE)\n{\n  standardize <- match.arg(standardize)\n\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n\n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, list(1)), check.names=FALSE)\n\n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n\n  if(length(table(drugpheno)) > 2){\n     if(ncol(drugpheno)>1){\n      ##### FIX NAMES!!!\n      rest <- lapply(seq_len(ncol(drugpheno)), function(i){\n\n        est <- paste(\"estimate\", i, sep=\".\")\n        se <-  paste(\"se\", i, sep=\".\")\n        tstat <- paste(\"tstat\", i, sep=\".\")\n\n        rest <- rep(NA, 3)\n        names(rest) <- c(est, se, tstat)\n        return(rest)\n\n      })\n      rest <- do.call(c, rest)\n      rest <- c(rest, n=nn, \"fstat\"=NA, \"pvalue\"=NA)\n    } else {\n      rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"tstat\"=NA, \"fstat\"=NA, \"pvalue\"=NA, \"df\"=NA)\n    }\n  } else {\n    rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA)\n  }\n\n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    ## not enough samples with complete information or no variation in gene expression\n    return(rest)\n  }\n\n  ## standardized coefficient in linear model\n  if(length(table(drugpheno)) > 2 & standardize!= \"none\") {\n    switch(standardize,\n      \"SD\" = drugpheno <- apply(drugpheno, 2, function(x){\n      return(x[ccix]/sd(as.numeric(x[ccix])))}) ,\n      \"rescale\" = drugpheno <- apply(drugpheno, 2, function(x){\n      return(rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE))    })\n      )\n\n  }else{\n    drugpheno <- drugpheno[ccix,,drop=FALSE]\n  }\n  if(length(table(x)) > 2  & standardize!= \"none\"){\n    switch(standardize,\n      \"SD\" = xx <- x[ccix]/sd(as.numeric(x[ccix])) ,\n      \"rescale\" = xx <- rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE)\n      )\n  }else{\n    xx <- x[ccix]\n  }\n  if(ncol(drugpheno)>1){\n    ff0 <- paste(\"cbind(\", paste(paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\"), collapse=\",\"), \")\", sep=\"\")\n  } else {\n    ff0 <- sprintf(\"drugpheno.1\")\n  }\n\n  dd <- data.frame(drugpheno, \"x\"=xx)\n\n  ## control for tissue type\n  if(length(sort(unique(type))) > 1) {\n    dd <- cbind(dd, type=type[ccix])\n  }\n  ## control for batch\n  if(length(sort(unique(batch))) > 1) {\n        dd <- cbind(dd, batch=batch[ccix])\n  }\nif(any(unlist(lapply(drugpheno,is.factor)))){\n\nrr0 <- tryCatch(try(glm(formula(drugpheno.1 ~ . - x), data=dd, model=FALSE, x=FALSE, y=FALSE, family=\"binomial\")),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Null model did not convrge\"\n        message(ww)\n        if(\"type\" %in% colnames(dd)) {\n          tt <- table(dd[,\"type\"])\n          message(tt)\n        }\n      }\n    })\n  rr1 <- tryCatch(try(glm(formula(drugpheno.1 ~ .), data=dd, model=FALSE, x=FALSE, y=FALSE, family=\"binomial\")),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Model did not converge\"\n        tt <- table(dd[,\"drugpheno.1\"])\n        message(ww)\n        message(tt)\n      }\n      return(ww)\n    })\n\n\n} else{\n\nrr0 <- tryCatch(try(lm(formula(paste(ff0, \"~ . -x\", sep=\" \")), data=dd)),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Null model did not converge\"\n        message(ww)\n        if(\"type\" %in% colnames(dd)) {\n          tt <- table(dd[,\"type\"])\n          message(tt)\n        }\n      }\n    })\n  rr1 <- tryCatch(try(lm(formula(paste(ff0, \"~ . \", sep=\" \")), data=dd)),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Model did not converge\"\n        tt <- table(dd[,\"drugpheno.1\"])\n        message(ww)\n        message(tt)\n      }\n      return(ww)\n    })\n\n\n}\n\n\n  if (!is(rr0, \"try-error\") && !is(rr1, \"try-error\") & !is(rr0, \"character\") && !is(rr1, \"character\")) {\n    rr <- summary(rr1)\n\n    if(any(unlist(lapply(drugpheno,is.factor)))){\n      rrc <- stats::anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Estimate\"], \"se\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Std. Error\"], \"n\"=nn, \"pvalue\"=rrc$'Pr(>Chi)'[2])\n      names(rest) <- c(\"estimate\", \"se\", \"n\", \"pvalue\")\n\n    } else {\n      if(ncol(drugpheno)>1){\n        rrc <- summary(stats::manova(rr1))\n        rest <- lapply(seq_len(ncol(drugpheno)), function(i) {\n          est <- paste(\"estimate\", i, sep=\".\")\n          se <-  paste(\"se\", i, sep=\".\")\n          tstat <- paste(\"tstat\", i, sep=\".\")\n          rest <- c(rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"Estimate\"], rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"Std. Error\"], rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"t value\"])\n          names(rest) <- c(est, se, tstat)\n          return(rest)\n        })\n        rest <- do.call(c, rest)\n        rest <- c(rest,\"n\"=nn, \"fstat\"=rrc$stats[grep(\"^x\", rownames(rrc$stats)), \"approx F\"], \"pvalue\"=rrc$stats[grep(\"^x\", rownames(rrc$stats)), \"Pr(>F)\"])\n      } else {\n        rrc <- stats::anova(rr0, rr1, test = \"F\")\n        rest <- c(\"estimate\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Estimate\"], \"se\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Std. Error\"],\"n\"=nn, \"tstat\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"t value\"], \"fstat\"=rrc$F[2], \"pvalue\"=rrc$'Pr(>F)'[2], \"df\"=rr1$df.residual)\n        names(rest) <- c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\")\n      }\n    }\n\n    if(model) { rest <- list(\"stats\"=rest, \"model\"=rr1) }\n  }\n  return(rest)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `geneRadSensitivity` function and what are its main input parameters?",
        "answer": "The `geneRadSensitivity` function calculates the gene radiation sensitivity score. Its main input parameters are:\n- `x`: a numeric vector of gene expression values\n- `type`: a factor vector specifying cell lines or types\n- `batch`: a factor vector specifying the batch\n- `drugpheno`: a numeric vector of drug sensitivity values (e.g., IC50 or AUC)\n- `model`: a boolean indicating whether to return the full linear model (default is FALSE)\n- `standardize`: a character specifying the standardization method ('SD', 'rescale', or 'none')\n- `verbose`: a boolean indicating whether to write informative messages to the console"
      },
      {
        "question": "How does the function handle missing or infinite values in the input data?",
        "answer": "The function handles missing or infinite values in the following ways:\n1. It uses `complete.cases()` to identify rows with complete data across all input variables.\n2. For non-factor columns in `drugpheno`, it replaces infinite values with NA: `x[is.infinite(x)] <- NA`\n3. It checks if there are at least 3 samples with complete information and non-zero variance in gene expression. If not, it returns a vector of NA values for the results."
      },
      {
        "question": "What statistical models does the function use to calculate the gene radiation sensitivity score, and how does it handle different types of input data?",
        "answer": "The function uses different statistical models based on the input data:\n1. For binary outcomes (factor `drugpheno`), it uses a logistic regression model (glm with binomial family).\n2. For continuous outcomes (numeric `drugpheno`), it uses a linear regression model (lm).\n3. If there are multiple drug phenotypes (ncol(drugpheno) > 1), it uses a multivariate linear model and performs a MANOVA test.\n4. The function controls for tissue type and batch effects if multiple unique values are present in the `type` and `batch` inputs.\n5. It compares the full model (including gene expression) to a null model (without gene expression) using either a Chi-square test (for logistic regression) or an F-test (for linear regression) to assess the significance of the gene expression effect."
      }
    ],
    "completion_tasks": [
      {
        "partial": "geneRadSensitivity <- function(x, type, batch, drugpheno, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, list(1)), check.names=FALSE)\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  # Complete the function to handle different cases and return the appropriate result\n}",
        "complete": "geneRadSensitivity <- function(x, type, batch, drugpheno, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, list(1)), check.names=FALSE)\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA)\n    return(rest)\n  }\n  \n  if(standardize != \"none\") {\n    drugpheno <- apply(drugpheno, 2, function(x) {\n      if(standardize == \"SD\") {\n        return(x[ccix]/sd(as.numeric(x[ccix])))\n      } else {\n        return(rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE))\n      }\n    })\n    xx <- if(standardize == \"SD\") x[ccix]/sd(as.numeric(x[ccix])) else rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE)\n  } else {\n    drugpheno <- drugpheno[ccix,,drop=FALSE]\n    xx <- x[ccix]\n  }\n  \n  dd <- data.frame(drugpheno, \"x\"=xx)\n  if(length(unique(type)) > 1) dd$type <- type[ccix]\n  if(length(unique(batch)) > 1) dd$batch <- batch[ccix]\n  \n  ff0 <- if(ncol(drugpheno) > 1) paste(\"cbind(\", paste(paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\"), collapse=\",\"), \")\") else \"drugpheno.1\"\n  \n  model_func <- if(any(sapply(drugpheno, is.factor))) glm else lm\n  family <- if(any(sapply(drugpheno, is.factor))) \"binomial\" else NULL\n  \n  rr0 <- tryCatch(model_func(formula(paste(ff0, \"~ . -x\")), data=dd, family=family), warning=function(w) if(verbose) message(\"Null model did not converge\"))\n  rr1 <- tryCatch(model_func(formula(paste(ff0, \"~ .\")), data=dd, family=family), warning=function(w) if(verbose) message(\"Model did not converge\"))\n  \n  if (!inherits(rr0, \"try-error\") && !inherits(rr1, \"try-error\")) {\n    rr <- summary(rr1)\n    if(any(sapply(drugpheno, is.factor))) {\n      rrc <- anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"pvalue\"=rrc$'Pr(>Chi)'[2])\n    } else {\n      rrc <- anova(rr0, rr1, test=\"F\")\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"tstat\"=rr$coefficients[\"x\", \"t value\"], \"fstat\"=rrc$F[2], \"pvalue\"=rrc$'Pr(>F)'[2], \"df\"=rr1$df.residual)\n    }\n    if(model) rest <- list(\"stats\"=rest, \"model\"=rr1)\n  } else {\n    rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA)\n  }\n  \n  return(rest)\n}"
      },
      {
        "partial": "geneRadSensitivity <- function(x, type, batch, drugpheno, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, list(1)), check.names=FALSE)\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n  }\n  \n  # Complete the function to handle standardization, model fitting, and result calculation\n}",
        "complete": "geneRadSensitivity <- function(x, type, batch, drugpheno, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, list(1)), check.names=FALSE)\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n  }\n  \n  standardize_func <- function(x) {\n    if(standardize == \"SD\") x / sd(x, na.rm=TRUE)\n    else if(standardize == \"rescale\") rescale(x, q=0.05, na.rm=TRUE)\n    else x\n  }\n  \n  drugpheno <- as.data.frame(lapply(drugpheno[ccix,, drop=FALSE], standardize_func))\n  xx <- standardize_func(x[ccix])\n  \n  dd <- data.frame(drugpheno, x=xx, type=type[ccix], batch=batch[ccix])\n  dd <- dd[, sapply(dd, function(col) length(unique(col)) > 1), drop=FALSE]\n  \n  ff <- paste(paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\", collapse=\"+\"), \"~ .\", sep=\" \")\n  \n  model_func <- if(any(sapply(drugpheno, is.factor))) glm else lm\n  family <- if(any(sapply(drugpheno, is.factor))) binomial else NULL\n  \n  rr0 <- tryCatch(model_func(update(as.formula(ff), . ~ . - x), data=dd, family=family),\n                   warning=function(w) if(verbose) message(\"Null model did not converge\"))\n  rr1 <- tryCatch(model_func(as.formula(ff), data=dd, family=family),\n                   warning=function(w) if(verbose) message(\"Model did not converge\"))\n  \n  if (!inherits(rr0, \"try-error\") && !inherits(rr1, \"try-error\")) {\n    rr <- summary(rr1)\n    if(is.null(family)) {\n      rrc <- anova(rr0, rr1)\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"],\n                \"se\"=rr$coefficients[\"x\", \"Std. Error\"],\n                \"n\"=nn,\n                \"tstat\"=rr$coefficients[\"x\", \"t value\"],\n                \"fstat\"=rrc$F[2],\n                \"pvalue\"=rrc$`Pr(>F)`[2],\n                \"df\"=rr1$df.residual)\n    } else {\n      rrc <- anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"],\n                \"se\"=rr$coefficients[\"x\", \"Std. Error\"],\n                \"n\"=nn,\n                \"pvalue\"=rrc$`Pr(>Chi)`[2])\n    }\n    if(model) rest <- list(\"stats\"=rest, \"model\"=rr1)\n  } else {\n    rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA)\n  }\n  \n  return(rest)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/LongTableDataMapper-class.R",
    "language": "R",
    "content": "#' @include DataMapper-class.R\nNULL\n\n#' A Class for Mapping Between Raw Data and an `LongTable` Object\n#'\n#' @slot rawdata See Slots section.\n#' @slot rowDataMap See Slots section.\n#' @slot colDataMap See Slots section.\n#' @slot assayMap See Slots section.\n#' @slot metadataMap See Slots section.\n#'\n#' @inheritSection DataMapper-class Slots\n#'\n#' @section Slots:\n#' * rowDataMap: A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each row,\n#' the second is additional columns which map to rows, but are not required to\n#' uniquely identify them. Rows should be drugs.\n#' * colDataMap: A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each\n#' column, the second is additional columns which map to rows, but are not\n#' required to uniquely identify them. Columns should be samples.\n#' * assayMap A list-like where each item is a `list` with two elements\n#' specifying an assay, the first being the identifier columns in `rawdata`\n#' needed to uniquely identify each row an assay, and the second a list of\n#' `rawdata` columns to be mapped to that assay. The names of `assayMap`\n#' will be the names of the assays in the `LongTable` that is created when\n#' calling `metaConstruct` on this `DataMapper` object.\n#' * metadataMap: A list-like where each item is a `character` vector of\n#' `rawdata` column names to assign to the `@metadata` of the `LongTable`,\n#' where the name of that assay is the name of the list item. If names are\n#' omitted, assays will be numbered by their index in the list.\n#'\n#' @md\n#' @aliases LongTableDataMapper-class\n.LongTableDataMapper <- setClass('LongTableDataMapper',\n    contains=c('DataMapper'),\n    slots=list(\n        rowDataMap='list_OR_List',\n        colDataMap='list_OR_List',\n        assayMap='list_OR_List',\n        metadataMap='list_OR_List'\n    )\n)\n\n\n#' Constructor for the `LongTableDataMapper` class, which maps from one or\n#'   more raw experimental data files to the slots of a `LongTable` object.\n#'\n#' @details\n#' The `guessMapping` method can be used to test hypotheses about the\n#' cardinality of one or more sets of identifier columns. This is helpful\n#' to determine the id columns for `rowDataMap` and `colDataMap`, as well\n#' as identify columns mapping to `assays` or `metadata`.\n#'\n#' To attach metadata not associated with `rawdata`, please use the `metadata`\n#' assignment method on your `LongTableDataMapper`. This metadata will be\n#' merged with any metadata from `metadataMap` and added to the `LongTable`\n#' which this object ultimately constructs.\n#'\n#' @param rawdata A `data.frame` of raw data from a treatment response\n#' experiment. This will be coerced to a `data.table` internally. We recommend\n#' using joins to aggregate your raw data if it is not present in a single file.\n#' @param rowDataMap A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each row,\n#' the second is additional columns which map to rows, but are not required to\n#' uniquely identify them. Rows should be drugs.\n#' @param colDataMap A list-like object containing two `character` vectors.\n#' The first is column names in `rawdata` needed to uniquely identify each\n#' column, the second is additional columns which map to rows, but are not\n#' required to uniquely identify them. Columns should be samples.\n#' @param assayMap A list-like where each item is a `list` with two `character`\n#' vectors defining an assay, the first containing the identifier columns in\n#' `rawdata` needed to uniquely identify each row an assay, and the second the\n#' `rawdata` columns to be mapped to that assay. The names of `assayMap`\n#' will be the names of the assays in the `LongTable` that is created when\n#' calling `metaConstruct` on this `DataMapper` object. If the character vectors\n#' have names, the value columns will be renamed accordingly.\n#' @param metadataMap A list-like where each item is a `character` vector of\n#' `rawdata` column names to assign to the `@metadata` of the `LongTable`,\n#' where the name of that assay is the name of the list item. If names are\n#' omitted, assays will be numbered by their index in the list.\n#'\n#' @return A `LongTable` object, with columns mapped to it's slots according\n#' to the various maps in the `LongTableDataMapper` object.\n#'\n#' @seealso [`guessMapping`]\n#'\n#' @examples\n#' data(exampleDataMapper)\n#' exampleDataMapper\n#'\n#' @md\n#' @importFrom checkmate assertList assertDataTable\n#' @importFrom data.table setDT copy\n#' @export\nLongTableDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, 'data.frame') && !is(rawdata, 'data.table')) setDT(rawdata)\n    assertDataTable(rawdata)\n    assertList(rowDataMap, types=\"character\", len=2)\n    assertList(colDataMap, types=\"character\", len=2)\n    assertList(assayMap, types=\"list\", min.len=1)\n    for (i in seq_along(assayMap)) assertList(assayMap[[i]], types=\"character\",\n        len=2)\n    assertList(metadataMap)\n\n    .LongTableDataMapper(rawdata=copy(rawdata), rowDataMap=rowDataMap,\n        colDataMap=colDataMap, assayMap=assayMap, metadataMap=metadataMap)\n}\n\n## FIXME:: Modify rawdata setter to check that columns exist in maps for case\n##>when maps are assigned first, then rawdata\n\n# ======================\n# DataMapper Show Method\n# ----------------------\n\n\n#' @describeIn LongTableDataMapper-class Show method for LongTableDataMapper.\n#' Determines how the object is displayed in the console.\n#'\n#' @param object A `LongTableDataMapper` to display in the console.\n#'\n#' @examples\n#' show(exampleDataMapper)\n#'\n#' @return `invisible` Prints to console.\n#'\n#' @importFrom crayon %+% yellow red green blue cyan magenta\n#' @exportMethod show\nsetMethod('show', signature(object='LongTableDataMapper'), function(object) {\n\n    ## -- class\n    cat(yellow$bold$italic(paste0('<', class(object)[1], '>'), '\\n'))\n\n    missingVal <- ' NA'\n\n    ## -- rawdata\n    cat(yellow$bold('rawdata:'))\n    if (length(rawdata(object))) {\n        cat(paste0(' dim(', paste0(dim(rawdata(object)), collapse=', '), ')\\n'))\n        table_data <- capture.output(\n            print(head(rawdata(object), 3), trunc.cols=TRUE, class=TRUE)\n        )\n        table_data[1] <- paste0('  ', table_data[1])\n        rawdata_head <- paste0(\n            paste0(table_data[-length(table_data)], collapse='\\n  '),\n            paste0(\n                strwrap(table_data[length(table_data)], initial='\\n  ', exdent=4),\n                collapse='\\n'\n            ))\n        cat(rawdata_head, '\\n\\r')  # print the snapshot\n    } else {\n        red(cat(missingVal, '\\n'))\n    }\n\n    ## -- rowDataMap\n    cat(yellow$bold('rowDataMap:'))\n    rows <- rowDataMap(object)\n    if (length(rows)) {\n        cat('\\n ', green('rowIDs:'), paste0(rows[[1]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    if (length(rows) > 1) {\n        cat('\\n ', green('rowMeta:'), paste0(rows[[2]], collapse=', '))\n        cat('\\n')\n    } else {\n        cat('\\n')\n    }\n\n    ## -- colDataMap\n    cat(yellow$bold('colDataMap:'))\n    cols <- colDataMap(object)\n    if (length(cols)) {\n        cat('\\n ', green('colIDs:'), paste0(cols[[1]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    if (length(cols) > 1) {\n        cat('\\n ', green('colMeta:'), paste0(cols[[2]], collapse=', '))\n    }\n\n    ## -- assayMap\n    cat(yellow$bold('\\nassayMap:'))\n    assayM <- assayMap(object)\n    if (length(assayM)) {\n        for (aName in names(assayM)) {\n            cat('\\n ', red(paste0(aName, ':')))\n            cat('\\n    keys:',\n                paste0(strwrap(\n                    paste0(assayM[[aName]][[1]], collapse=', '), exdent=2),\n                collapse=\"\\n    \")\n            )\n            cat('\\n    values:',\n                paste0(strwrap(\n                    paste0(assayM[[aName]][[2]], collapse=', '), exdent=2),\n                collapse=\"\\n    \")\n            )\n        }\n    } else {\n        cat(green(missingVal))\n    }\n\n    ## -- metadataMap\n    cat(yellow$bold('\\nmetadataMap:'))\n    metadataM <- metadataMap(object)\n    if (length(metadataM)) {\n        for (mName in names(metadataM))\n            cat('\\n ', green(paste0(mName, ':')),\n                paste0(metadataM[[mName]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    cat('\\n')\n})\n\n## ===========================================\n## LongTableDataMapper Accessors Documentation\n## -------------------------------------------\n\n.local_class_3 <- 'LongTableDataMapper'\n.local_data_3 <- 'exampleDataMapper'\n\n#' @name LongTableDataMapper-accessors\n#'\n#' @eval .docs_DataMapper_accessors(class_=.local_class_3)\n#' @eval .docs_DataMapper_get_rawdata(class_=.local_class_3)\n#'\n#' @param value See details.\nNULL\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `LongTableDataMapper` class and what are its main components?",
        "answer": "The `LongTableDataMapper` class is designed to map raw experimental data to a `LongTable` object. Its main components are:\n1. `rawdata`: The raw data frame to be mapped.\n2. `rowDataMap`: Specifies columns for uniquely identifying rows (drugs) and additional row metadata.\n3. `colDataMap`: Specifies columns for uniquely identifying columns (samples) and additional column metadata.\n4. `assayMap`: Defines how to map raw data columns to different assays in the `LongTable`.\n5. `metadataMap`: Specifies which raw data columns should be assigned to the metadata of the `LongTable`."
      },
      {
        "question": "How does the `show` method for `LongTableDataMapper` display information about the object?",
        "answer": "The `show` method for `LongTableDataMapper` displays information in the following order:\n1. Class name in yellow, bold, and italic.\n2. `rawdata` dimensions and a snapshot of the first 3 rows.\n3. `rowDataMap` with rowIDs and rowMeta in green.\n4. `colDataMap` with colIDs and colMeta in green.\n5. `assayMap` with each assay name in red, followed by its keys and values.\n6. `metadataMap` with each metadata item in green.\n\nIt uses the `crayon` package for colored output and formats the information for better readability."
      },
      {
        "question": "What are the key differences between `rowDataMap`, `colDataMap`, `assayMap`, and `metadataMap` in the `LongTableDataMapper` constructor?",
        "answer": "The key differences are:\n1. `rowDataMap`: A list with two character vectors for row identifiers and additional row metadata.\n2. `colDataMap`: A list with two character vectors for column identifiers and additional column metadata.\n3. `assayMap`: A list of lists, where each inner list has two character vectors defining an assay's identifiers and value columns.\n4. `metadataMap`: A list where each item is a character vector of column names to be assigned to the `LongTable` metadata.\n\n`rowDataMap` and `colDataMap` are for identifying and describing rows and columns, `assayMap` is for mapping data to specific assays, and `metadataMap` is for additional metadata not tied to rows or columns."
      }
    ],
    "completion_tasks": [
      {
        "partial": "LongTableDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, 'data.frame') && !is(rawdata, 'data.table')) setDT(rawdata)\n    assertDataTable(rawdata)\n    assertList(rowDataMap, types=\"character\", len=2)\n    assertList(colDataMap, types=\"character\", len=2)\n    assertList(assayMap, types=\"list\", min.len=1)\n    for (i in seq_along(assayMap)) assertList(assayMap[[i]], types=\"character\",\n        len=2)\n    assertList(metadataMap)\n\n    # Complete the function by returning the appropriate object\n}",
        "complete": "LongTableDataMapper <- function(rawdata=data.frame(),\n        rowDataMap=list(character(), character()),\n        colDataMap=list(character(), character()),\n        assayMap=list(list(character(), character())),\n        metadataMap=list(character())) {\n\n    if (is(rawdata, 'data.frame') && !is(rawdata, 'data.table')) setDT(rawdata)\n    assertDataTable(rawdata)\n    assertList(rowDataMap, types=\"character\", len=2)\n    assertList(colDataMap, types=\"character\", len=2)\n    assertList(assayMap, types=\"list\", min.len=1)\n    for (i in seq_along(assayMap)) assertList(assayMap[[i]], types=\"character\",\n        len=2)\n    assertList(metadataMap)\n\n    .LongTableDataMapper(rawdata=copy(rawdata), rowDataMap=rowDataMap,\n        colDataMap=colDataMap, assayMap=assayMap, metadataMap=metadataMap)\n}"
      },
      {
        "partial": "setMethod('show', signature(object='LongTableDataMapper'), function(object) {\n\n    cat(yellow$bold$italic(paste0('<', class(object)[1], '>'), '\\n'))\n\n    missingVal <- ' NA'\n\n    cat(yellow$bold('rawdata:'))\n    if (length(rawdata(object))) {\n        cat(paste0(' dim(', paste0(dim(rawdata(object)), collapse=', '), ')\\n'))\n        table_data <- capture.output(\n            print(head(rawdata(object), 3), trunc.cols=TRUE, class=TRUE)\n        )\n        table_data[1] <- paste0('  ', table_data[1])\n        rawdata_head <- paste0(\n            paste0(table_data[-length(table_data)], collapse='\\n  '),\n            paste0(\n                strwrap(table_data[length(table_data)], initial='\\n  ', exdent=4),\n                collapse='\\n'\n            ))\n        cat(rawdata_head, '\\n\\r')\n    } else {\n        red(cat(missingVal, '\\n'))\n    }\n\n    # Complete the method by adding the remaining parts\n})",
        "complete": "setMethod('show', signature(object='LongTableDataMapper'), function(object) {\n\n    cat(yellow$bold$italic(paste0('<', class(object)[1], '>'), '\\n'))\n\n    missingVal <- ' NA'\n\n    cat(yellow$bold('rawdata:'))\n    if (length(rawdata(object))) {\n        cat(paste0(' dim(', paste0(dim(rawdata(object)), collapse=', '), ')\\n'))\n        table_data <- capture.output(\n            print(head(rawdata(object), 3), trunc.cols=TRUE, class=TRUE)\n        )\n        table_data[1] <- paste0('  ', table_data[1])\n        rawdata_head <- paste0(\n            paste0(table_data[-length(table_data)], collapse='\\n  '),\n            paste0(\n                strwrap(table_data[length(table_data)], initial='\\n  ', exdent=4),\n                collapse='\\n'\n            ))\n        cat(rawdata_head, '\\n\\r')\n    } else {\n        red(cat(missingVal, '\\n'))\n    }\n\n    cat(yellow$bold('rowDataMap:'))\n    rows <- rowDataMap(object)\n    if (length(rows)) {\n        cat('\\n ', green('rowIDs:'), paste0(rows[[1]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    if (length(rows) > 1) {\n        cat('\\n ', green('rowMeta:'), paste0(rows[[2]], collapse=', '))\n        cat('\\n')\n    } else {\n        cat('\\n')\n    }\n\n    cat(yellow$bold('colDataMap:'))\n    cols <- colDataMap(object)\n    if (length(cols)) {\n        cat('\\n ', green('colIDs:'), paste0(cols[[1]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    if (length(cols) > 1) {\n        cat('\\n ', green('colMeta:'), paste0(cols[[2]], collapse=', '))\n    }\n\n    cat(yellow$bold('\\nassayMap:'))\n    assayM <- assayMap(object)\n    if (length(assayM)) {\n        for (aName in names(assayM)) {\n            cat('\\n ', red(paste0(aName, ':')))\n            cat('\\n    keys:',\n                paste0(strwrap(\n                    paste0(assayM[[aName]][[1]], collapse=', '), exdent=2),\n                collapse=\"\\n    \")\n            )\n            cat('\\n    values:',\n                paste0(strwrap(\n                    paste0(assayM[[aName]][[2]], collapse=', '), exdent=2),\n                collapse=\"\\n    \")\n            )\n        }\n    } else {\n        cat(green(missingVal))\n    }\n\n    cat(yellow$bold('\\nmetadataMap:'))\n    metadataM <- metadataMap(object)\n    if (length(metadataM)) {\n        for (mName in names(metadataM))\n            cat('\\n ', green(paste0(mName, ':')),\n                paste0(metadataM[[mName]], collapse=', '))\n    } else {\n        cat(green(missingVal))\n    }\n    cat('\\n')\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/RadioSet-accessors.R",
    "language": "R",
    "content": "#' @include RadioSet-class.R\nNULL\n\n# Navigating this file:\n# - Slot section names start with ----\n# - Method section names start with ==\n#\n# As a result, you can use Ctrl + f to find the slot or method you are looking\n# for quickly, assuming you know its name.\n#\n# For example Ctrl + f '== molecularProfiles' would take you the molecularProfiles\n# method, while Ctrl + f '---- molecularProfiles' would take you to the slot\n# section.\n\n\n#### CoreGx dynamic documentation\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n\n# =======================================\n# Accessor Method Documentation Object\n# ---------------------------------------\n\n.local_class <- \"RadioSet\"\n.local_data <- \"clevelandSmall\"\n.local_sample <- \"cell\"\n\n#' @name RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_accessors(class_=.local_class)\n#' @eval CoreGx:::.parseToRoxygen(\"@examples data({data_})\", data_=.local_data)\nNULL\n\n\n\n# ======================================\n# Accessor Methods\n# --------------------------------------\n\n\n## ==============\n## ---- radiation slot\n## --------------\n\n\n##\n## == radiationInfo\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_treatmentInfo(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx treatmentInfo\n#' @aliases radiationInfo\n#' @export\nradiationInfo <- function(...) treatmentInfo(...)\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_treatmentInfo(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx treatmentInfo<-\n#' @aliases radiationInfo<-\n#' @export\n`radiationInfo<-` <- function(..., value) `radiationInfo<-`(..., value=value)\n\n\n\n##\n## == radiationNames\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_treatmentNames(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx treatmentNames\n#' @aliases radiationTypes\n#' @export\nradiationTypes <- function(...) treatmentNames(...)\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_treatmentNames(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx treatmentNames<-\n#' @aliases radiationTypes<-\n#' @export\n`radiationTypes<-` <- function(..., value) `treatmentNames<-`(..., value=value)\n\n\n## ====================\n## ---- annotation slot\n## --------------------\n\n\n##\n## == annotation\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_annotation(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx annotation\nsetMethod('annotation', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_annotation(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx annotation<-\nsetReplaceMethod(\"annotation\", signature(\"RadioSet\", \"list\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})\n\n\n##\n## == dateCreated\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_dateCreated(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx dateCreated\nsetMethod('dateCreated', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_dateCreated(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx dateCreated<-\nsetReplaceMethod('dateCreated', signature(object=\"RadioSet\", value=\"character\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n##\n## === name\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_name(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx name\nsetMethod('name', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_name(class_=.local_class, data_=.local_data)\n#' @importMethodsFrom CoreGx name<-\nsetReplaceMethod('name', signature(\"RadioSet\"), function(object, value) {\n    object <- callNextMethod(object, value=value)\n    return(invisible(object))\n})\n\n## ==============\n## ---- sample slot\n## --------------\n\n\n##\n## == sampleInfo\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sampleInfo(class_=.local_class,\n#' sample_=.local_sample)\n#' @importMethodsFrom CoreGx sampleInfo\n#' @importFrom CoreGx cellInfo\n#' @export\nsetMethod(\"sampleInfo\", \"RadioSet\", function(object) {\n    callNextMethod(object)\n})\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sampleInfo(class_=.local_class,\n#' data_=.local_data, sample_=\"cell\")\n#' @importMethodsFrom CoreGx sampleInfo<-\n#' @importFrom CoreGx cellInfo<-\n#' @export\nsetReplaceMethod(\"sampleInfo\", signature(object=\"RadioSet\",\n        value=\"data.frame\"), function(object, value) {\n    callNextMethod(object, value=value)\n})\n\n\n##\n## == sampleNames\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sampleNames(class_=.local_class,\n#' data_=.local_data, sample_=.local_sample)\n#' @importMethodsFrom CoreGx sampleNames\nsetMethod(\"sampleNames\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object)\n})\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sampleNames(class_=.local_class,\n#' data_=.local_data, sample_=.local_sample)\n#' @importMethodsFrom CoreGx sampleNames<-\nsetReplaceMethod(\"sampleNames\", signature(object=\"RadioSet\", value=\"character\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})\n\n\n\n## ------------------\n## ---- curation slot\n\n\n##\n## == curation\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_curation(class_=.local_class,\n#' data_=.local_data, details_=\"Contains three `data.frame`s, 'cell' with\n#' cell-line ids and 'tissue' with tissue ids and 'radiation' with radiation ids.\")\n#' @importMethodsFrom CoreGx curation\nsetMethod('curation', signature(object=\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_curation(class_=.local_class,\n#' data_=.local_data, details_=\"For a `RadioSet` object the slot should\n#' contain tissue, cell-line and radiation id `data.frame`s.\")\n#' @importMethodsFrom CoreGx curation<-\nsetReplaceMethod(\"curation\", signature(object=\"RadioSet\", value=\"list\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n## ----------------------\n## ---- datasetType slot\n\n\n#\n# == datasetType\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_datasetType(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx datasetType\nsetMethod(\"datasetType\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_datasetType(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx datasetType<-\nsetReplaceMethod(\"datasetType\", signature(object=\"RadioSet\",\n    value='character'), function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n## ---------------------------\n## ---- molecularProfiles slot\n\n\n##\n## == molecularProfiles\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_molecularProfiles(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx molecularProfiles\nsetMethod(molecularProfiles, \"RadioSet\", function(object, mDataType, assay)\n{\n    callNextMethod(object=object, mDataType=mDataType, assay=assay)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_molecularProfiles(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx molecularProfiles<-\nsetReplaceMethod(\"molecularProfiles\", signature(object=\"RadioSet\",\n    mDataType =\"character\", assay=\"character\", value=\"matrix\"),\n    function(object, mDataType, assay, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, assay=assay, value=value)\n})\nsetReplaceMethod(\"molecularProfiles\",\n    signature(object=\"RadioSet\", mDataType =\"character\", assay=\"missing\",\n        value=\"matrix\"), function(object, mDataType, assay, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, assay=assay, value=value)\n})\n\n\n##\n## == featureInfo\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_featureInfo(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx featureInfo\nsetMethod(featureInfo, \"RadioSet\", function(object, mDataType) {\n    callNextMethod(object=object, mDataType=mDataType)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_featureInfo(class_=.local_class,\n#' data_=.local_data, mDataType_='rna')\n#' @importMethodsFrom CoreGx featureInfo<-\nsetReplaceMethod(\"featureInfo\", signature(object=\"RadioSet\",\n    mDataType =\"character\",value=\"data.frame\"),\n    function(object, mDataType, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, value=value)\n})\nsetReplaceMethod(\"featureInfo\", signature(object=\"RadioSet\",\n    mDataType =\"character\",value=\"DataFrame\"),\n    function(object, mDataType, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, value=value)\n})\n\n\n\n##\n## == phenoInfo\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_phenoInfo(class_=.local_class,\n#' data_=.local_data, mDataType_='rna')\n#' @importMethodsFrom CoreGx phenoInfo\nsetMethod('phenoInfo', signature(object='RadioSet', mDataType='character'),\n    function(object, mDataType)\n{\n    callNextMethod(object=object, mDataType=mDataType)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_phenoInfo(class_=.local_class,\n#' data_=.local_data, mDataType_='rna')\n#' @importMethodsFrom CoreGx phenoInfo<-\nsetReplaceMethod(\"phenoInfo\", signature(object=\"RadioSet\",\n    mDataType =\"character\", value=\"data.frame\"),\n    function(object, mDataType, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, value=value)\n})\nsetReplaceMethod(\"phenoInfo\", signature(object=\"RadioSet\",\n    mDataType =\"character\", value=\"DataFrame\"),\n    function(object, mDataType, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, value=value)\n})\n\n\n##\n## == fNames\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_fNames(class_=.local_class,\n#' data_=.local_data, mDataType_='rna')\n#' @importMethodsFrom CoreGx fNames\nsetMethod('fNames', signature(object='RadioSet', mDataType='character'),\n    function(object, mDataType)\n{\n    callNextMethod(object=object, mDataType=mDataType)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_fNames(class_=.local_class,\n#' data_=.local_data, mDataType_='rna')\n#' @importMethodsFrom CoreGx fNames<-\nsetReplaceMethod('fNames', signature(object='RadioSet', mDataType='character',\n    value='character'), function(object, mDataType, value)\n{\n    callNextMethod(object=object, mDataType=mDataType, value=value)\n})\n\n\n##\n## == mDataNames\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_mDataNames(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx mDataNames\nsetMethod(\"mDataNames\", \"RadioSet\", function(object){\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_mDataNames(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx mDataNames<-\nsetReplaceMethod(\"mDataNames\", \"RadioSet\", function(object, value){\n    callNextMethod(object=object, value=value)\n})\n\n\n\n##\n## == molecularProfilesSlot\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_molecularProfilesSlot(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx molecularProfilesSlot\nsetMethod(\"molecularProfilesSlot\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_molecularProfilesSlot(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx molecularProfilesSlot<-\nsetReplaceMethod(\"molecularProfilesSlot\", signature(\"RadioSet\", \"list_OR_MAE\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n# ---------------------\n## ---- sensitivity slot\n\n\n##\n## == sensitivityInfo\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sensitivityInfo(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityInfo\nsetMethod('sensitivityInfo', signature(\"RadioSet\"),\n    function(object, dimension, ...)\n{\n    callNextMethod(object=object, dimension=dimension, ...)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sensitivityInfo(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityInfo<-\nsetReplaceMethod(\"sensitivityInfo\", signature(object=\"RadioSet\",\n    value=\"data.frame\"), function(object, dimension, ..., value)\n{\n    callNextMethod(object=object, dimension=dimension, ..., value=value)\n})\n\n\n##\n## == sensitvityMeasures\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sensitivityMeasures(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityMeasures\nsetMethod('sensitivityMeasures', signature(object=\"RadioSet\"),\n    function(object)\n{\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sensitityMeasures(class_=.local_class,\n#' data_=.local_data)\nsetReplaceMethod('sensitivityMeasures',\n    signature(object='RadioSet', value='character'), function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n##\n## == sensitivityProfiles\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sensitivityProfiles(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityProfiles\nsetMethod('sensitivityProfiles', signature(object=\"RadioSet\"), function(object)\n{\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sensitivityProfiles(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityProfiles<-\nsetReplaceMethod(\"sensitivityProfiles\",\n    signature(object=\"RadioSet\", value=\"data.frame\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n#\n# == sensitivityRaw\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sensitivityRaw(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityRaw\nsetMethod(\"sensitivityRaw\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sensitivityRaw(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensitivityRaw<-\nsetReplaceMethod('sensitivityRaw', signature(\"RadioSet\", \"array\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n#\n# == treatmentResponse\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_treatmentResponse(class_=.local_class,\n#'   data_=.local_data)\n#' @importMethodsFrom CoreGx treatmentResponse\nsetMethod(\"treatmentResponse\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\n\n\n#' @rdname RadioSet-accessors\n#' @importMethodsFrom CoreGx treatmentResponse<-\n#' @eval CoreGx:::.docs_CoreSet_set_treatmentResponse(class_=.local_class,\n#' data_=.local_data)\nsetReplaceMethod('treatmentResponse', signature(object='RadioSet',\n    value='list_OR_LongTable'), function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\n\n##\n## == sensNumber\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_sensNumber(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensNumber\nsetMethod('sensNumber', \"RadioSet\", function(object){\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_sensNumber(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx sensNumber<-\nsetReplaceMethod('sensNumber', signature(object=\"RadioSet\", value=\"matrix\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})\n\n\n## ======================\n## ---- perturbation slot\n\n\n##\n## == pertNumber\n\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_get_pertNumber(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx pertNumber\nsetMethod('pertNumber', signature(object='RadioSet'), function(object) {\n    callNextMethod(object=object)\n})\n\n#' @rdname RadioSet-accessors\n#' @eval CoreGx:::.docs_CoreSet_set_pertNumber(class_=.local_class,\n#' data_=.local_data)\n#' @importMethodsFrom CoreGx pertNumber<-\nsetReplaceMethod('pertNumber', signature(object='RadioSet', value=\"array\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `radiationInfo` method in the `RadioSet` class?",
        "answer": "The `radiationInfo` method is an accessor for the `treatmentInfo` slot in the `RadioSet` class. It retrieves information about the radiation treatments used in the dataset, such as dosage, type, or other relevant details."
      },
      {
        "question": "How does the `molecularProfiles` method differ from the `molecularProfilesSlot` method in the `RadioSet` class?",
        "answer": "The `molecularProfiles` method allows access to specific molecular profile data by specifying the molecular data type and assay, while `molecularProfilesSlot` returns the entire slot containing all molecular profiles. `molecularProfiles` is more granular and allows for targeted data retrieval, whereas `molecularProfilesSlot` provides access to the complete underlying data structure."
      },
      {
        "question": "What is the purpose of the `treatmentResponse` method in the `RadioSet` class, and what type of data does it return?",
        "answer": "The `treatmentResponse` method in the `RadioSet` class retrieves the treatment response data, which typically includes information about how samples (e.g., cell lines) respond to radiation treatments. It returns a list or a LongTable object containing the raw response data, which may include metrics like cell viability or growth inhibition at different radiation doses."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod('annotation', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\nsetReplaceMethod(\"annotation\", signature(\"RadioSet\", \"list\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})\n\nsetMethod('dateCreated', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object=object)\n})\n\nsetReplaceMethod('dateCreated', signature(object=\"RadioSet\", value=\"character\"),\n    function(object, value)\n{\n    callNextMethod(object=object, value=value)\n})\n\nsetMethod('name', signature(\"RadioSet\"), function(object) {\n    callNextMethod(object)\n})\n\nsetReplaceMethod('name', signature(\"RadioSet\"), function(object, value) {\n    object <- callNextMethod(object, value=value)\n    return(invisible(object))\n})",
        "complete": "setMethod('annotation', signature(\"RadioSet\"), function(object) callNextMethod(object=object))\n\nsetReplaceMethod(\"annotation\", signature(\"RadioSet\", \"list\"),\n        function(object, value) callNextMethod(object=object, value=value))\n\nsetMethod('dateCreated', signature(\"RadioSet\"), function(object) callNextMethod(object=object))\n\nsetReplaceMethod('dateCreated', signature(object=\"RadioSet\", value=\"character\"),\n    function(object, value) callNextMethod(object=object, value=value))\n\nsetMethod('name', signature(\"RadioSet\"), function(object) callNextMethod(object))\n\nsetReplaceMethod('name', signature(\"RadioSet\"), function(object, value) {\n    object <- callNextMethod(object, value=value)\n    invisible(object)\n})"
      },
      {
        "partial": "setMethod(\"sampleInfo\", \"RadioSet\", function(object) {\n    callNextMethod(object)\n})\n\nsetReplaceMethod(\"sampleInfo\", signature(object=\"RadioSet\",\n        value=\"data.frame\"), function(object, value) {\n    callNextMethod(object, value=value)\n})\n\nsetMethod(\"sampleNames\", signature(\"RadioSet\"), function(object) {\n    callNextMethod(object)\n})\n\nsetReplaceMethod(\"sampleNames\", signature(object=\"RadioSet\", value=\"character\"),\n        function(object, value) {\n    callNextMethod(object=object, value=value)\n})",
        "complete": "setMethod(\"sampleInfo\", \"RadioSet\", function(object) callNextMethod(object))\n\nsetReplaceMethod(\"sampleInfo\", signature(object=\"RadioSet\", value=\"data.frame\"),\n    function(object, value) callNextMethod(object, value=value))\n\nsetMethod(\"sampleNames\", signature(\"RadioSet\"), function(object) callNextMethod(object))\n\nsetReplaceMethod(\"sampleNames\", signature(object=\"RadioSet\", value=\"character\"),\n    function(object, value) callNextMethod(object=object, value=value))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/R/cosinePerm.R",
    "language": "R",
    "content": "#' Cosine Permutations\n#'\n#' Computes the cosine similarity and significance using permutation test. This\n#'   function uses random numbers, to ensure reproducibility please call \n#'   \\code{set.seed()} before running the function.\n#' \n#' @examples\n#' x <- factor(c(1,2,1,2,1))\n#' y <- factor(c(2,2,1,1,1))\n#' cosinePerm(x, y)\n#' \n#' @param x \\code{factor} is the factors for the first variable\n#' @param y \\code{factor} is the factors for the second variable\n#' @param nperm \\code{integer} is the number of permutations to compute the null\n#'   distribution of MCC estimates\n#' @param alternative \\code{string} indicates the alternative hypothesis and \n#'   must be one of \u2018'two.sided'\u2019, \u2018'greater'\u2019 or \u2018'less'\u2019.  You can specify \n#'   just the initial letter.  \u2018'greater'\u2019 corresponds to positive association, \n#'   \u2018'less'\u2019 to negative association. Options are 'two.sided', 'less', or \n#'   'greater'\n#' @param include.perm \\code{boolean} indicates whether the estimates for the \n#'   null distribution should be returned. Default set to 'FALSE'\n#' @param nthread \\code{integer} is the number of threads to be used to perform \n#'   the permutations in parallel\n#' @param ... A \\code{list} of fallthrough parameters \n#' \n#' @return A \\code{list} estimate of the cosine similarity, p-value and \n#'   estimates after random permutations (null distribution) in include.perm is \n#'   set to 'TRUE'\n#' \n#' @importFrom lsa cosine\n#' @importFrom BiocParallel bplapply\n#' \n#' @export\ncosinePerm <- function(x, y, nperm = 1000, alternative = c(\"two.sided\", \"less\", \"greater\"), include.perm = FALSE, nthread = 1, \n    ...) {\n    # PARAMETER CHANGE WARNING\n    if (!missing(...)) {\n        if (\"setseed\" %in% names(...)) {\n            warning(\"The setseed parameter has been removed in this release to conform\n              to Bioconductor coding standards. Please call set.seed in your\n              script before running this function.\")\n        }\n    }\n    \n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y))) {\n        stop(\"x and y must be vectors of the same length\")\n    }\n    res <- c(estimate = NA, p.value = NA)\n    x <- as.numeric(x)\n    y <- as.numeric(y)\n    ## compute cosine\n    res[\"estimate\"] <- drop(lsa::cosine(x = x, y = y))\n    ## compute significance of cosine using a permutation test\n    if (nperm > 0) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy) {\n            res <- vapply(x, function(x, xx, yy) {\n                xx <- sample(xx)\n                yy <- sample(yy)\n                return(drop(lsa::cosine(x = xx, y = yy)))\n            }, xx = xx, yy = yy, FUN.VALUE = numeric(1))\n            return(res)\n        }, xx = x, yy = y)\n        mcres <- unlist(mcres)\n        switch(alternative, two.sided = {\n            res[\"p.value\"] <- 2 * (min(sum(mcres < res[\"estimate\"]), sum(mcres > res[\"estimate\"]))/sum(!is.na(mcres)))\n        }, less = {\n            res[\"p.value\"] <- sum(mcres < res[\"estimate\"])/sum(!is.na(mcres))\n        }, greater = {\n            res[\"p.value\"] <- sum(mcres > res[\"estimate\"])/sum(!is.na(mcres))\n        })\n        if (res[\"p.value\"] == 0) {\n            res[\"p.value\"] <- 1/(nperm + 1)\n        }\n    }\n    res <- as.list(res)\n    if (include.perm) {\n        res <- c(res, list(estimate.random = mcres))\n    }\n    return(res)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `cosinePerm` function and what are its main input parameters?",
        "answer": "The `cosinePerm` function computes the cosine similarity between two factor variables and assesses its significance using a permutation test. The main input parameters are:\n- `x` and `y`: factor variables to compare\n- `nperm`: number of permutations for the null distribution (default 1000)\n- `alternative`: type of alternative hypothesis ('two.sided', 'less', or 'greater')\n- `include.perm`: whether to include null distribution estimates in the output\n- `nthread`: number of threads for parallel processing"
      },
      {
        "question": "How does the function handle the computation of p-values for different alternative hypotheses?",
        "answer": "The function uses a switch statement to compute p-values based on the specified alternative hypothesis:\n- For 'two.sided': p-value = 2 * min(sum(mcres < estimate), sum(mcres > estimate)) / sum(!is.na(mcres))\n- For 'less': p-value = sum(mcres < estimate) / sum(!is.na(mcres))\n- For 'greater': p-value = sum(mcres > estimate) / sum(!is.na(mcres))\nIf the computed p-value is 0, it's set to 1/(nperm + 1) to avoid reporting exact zero probabilities."
      },
      {
        "question": "How does the function implement parallel processing for permutations, and what libraries are used for this purpose?",
        "answer": "The function uses parallel processing to compute permutations efficiently:\n1. It splits the permutation indices using `parallel::splitIndices`\n2. It uses `BiocParallel::bplapply` to apply the permutation function across multiple threads\n3. The `lsa::cosine` function is used to compute cosine similarity for each permutation\n4. The number of threads is controlled by the `nthread` parameter\nThe function imports `lsa::cosine` for cosine similarity calculation and `BiocParallel::bplapply` for parallel processing."
      }
    ],
    "completion_tasks": [
      {
        "partial": "cosinePerm <- function(x, y, nperm = 1000, alternative = c(\"two.sided\", \"less\", \"greater\"), include.perm = FALSE, nthread = 1, ...) {\n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y))) {\n        stop(\"x and y must be vectors of the same length\")\n    }\n    res <- c(estimate = NA, p.value = NA)\n    x <- as.numeric(x)\n    y <- as.numeric(y)\n    res[\"estimate\"] <- drop(lsa::cosine(x = x, y = y))\n    \n    # Complete the function to compute the p-value using permutation test\n    # and return the result\n}",
        "complete": "cosinePerm <- function(x, y, nperm = 1000, alternative = c(\"two.sided\", \"less\", \"greater\"), include.perm = FALSE, nthread = 1, ...) {\n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y))) {\n        stop(\"x and y must be vectors of the same length\")\n    }\n    res <- c(estimate = NA, p.value = NA)\n    x <- as.numeric(x)\n    y <- as.numeric(y)\n    res[\"estimate\"] <- drop(lsa::cosine(x = x, y = y))\n    \n    if (nperm > 0) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy) {\n            vapply(x, function(x, xx, yy) {\n                drop(lsa::cosine(x = sample(xx), y = sample(yy)))\n            }, xx = xx, yy = yy, FUN.VALUE = numeric(1))\n        }, xx = x, yy = y)\n        mcres <- unlist(mcres)\n        res[\"p.value\"] <- switch(alternative,\n            two.sided = 2 * min(sum(mcres < res[\"estimate\"]), sum(mcres > res[\"estimate\"])),\n            less = sum(mcres < res[\"estimate\"]),\n            greater = sum(mcres > res[\"estimate\"])\n        ) / sum(!is.na(mcres))\n        if (res[\"p.value\"] == 0) res[\"p.value\"] <- 1/(nperm + 1)\n    }\n    \n    res <- as.list(res)\n    if (include.perm) res <- c(res, list(estimate.random = mcres))\n    return(res)\n}"
      },
      {
        "partial": "cosinePerm <- function(x, y, nperm = 1000, alternative = c(\"two.sided\", \"less\", \"greater\"), include.perm = FALSE, nthread = 1, ...) {\n    # Add parameter change warning\n    \n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y))) stop(\"x and y must be vectors of the same length\")\n    res <- c(estimate = NA, p.value = NA)\n    x <- as.numeric(x)\n    y <- as.numeric(y)\n    res[\"estimate\"] <- drop(lsa::cosine(x = x, y = y))\n    \n    # Complete the function to compute p-value and handle include.perm\n}",
        "complete": "cosinePerm <- function(x, y, nperm = 1000, alternative = c(\"two.sided\", \"less\", \"greater\"), include.perm = FALSE, nthread = 1, ...) {\n    if (!missing(...) && \"setseed\" %in% names(...)) {\n        warning(\"The setseed parameter has been removed in this release to conform to Bioconductor coding standards. Please call set.seed in your script before running this function.\")\n    }\n    \n    alternative <- match.arg(alternative)\n    if ((length(x) != length(y))) stop(\"x and y must be vectors of the same length\")\n    res <- c(estimate = NA, p.value = NA)\n    x <- as.numeric(x)\n    y <- as.numeric(y)\n    res[\"estimate\"] <- drop(lsa::cosine(x = x, y = y))\n    \n    if (nperm > 0) {\n        splitix <- parallel::splitIndices(nx = nperm, ncl = nthread)\n        splitix <- splitix[vapply(splitix, length, FUN.VALUE = numeric(1)) > 0]\n        mcres <- BiocParallel::bplapply(splitix, function(x, xx, yy) {\n            vapply(x, function(x, xx, yy) {\n                drop(lsa::cosine(x = sample(xx), y = sample(yy)))\n            }, xx = xx, yy = yy, FUN.VALUE = numeric(1))\n        }, xx = x, yy = y)\n        mcres <- unlist(mcres)\n        res[\"p.value\"] <- switch(alternative,\n            two.sided = 2 * min(sum(mcres < res[\"estimate\"]), sum(mcres > res[\"estimate\"])),\n            less = sum(mcres < res[\"estimate\"]),\n            greater = sum(mcres > res[\"estimate\"])\n        ) / sum(!is.na(mcres))\n        if (res[\"p.value\"] == 0) res[\"p.value\"] <- 1/(nperm + 1)\n    }\n    \n    res <- as.list(res)\n    if (include.perm) res <- c(res, list(estimate.random = mcres))\n    return(res)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/RadioGx.git",
    "file": "../../../../repos/RadioGx/R/computeD10.R",
    "language": "R",
    "content": "#' Compute D10\n#'\n#' @description This function computes the radiation dose at which only 10% of\n#'   cancer cells survive under the exponential model\n#'   SF = exp(-alpha * D - beta * D ^ 2) given alpha and beta, where D is the\n#'   radiation dose given and SF is the fraction of cells surviving\n#'\n#' @examples\n#' computeD10(c(0.2, 0.1))\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The D10 value\n#'\n#' @details The units of the returned dose are the inverses of the units of\n#'   the alpha and beta passed in.\n#' @export\ncomputeD10 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  return(.linearQuadraticInv(SF = 0.1,\n                             pars = pars,\n                             SF_as_log = FALSE))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `computeD10` function and what does it return?",
        "answer": "The `computeD10` function computes the radiation dose at which only 10% of cancer cells survive under the exponential model SF = exp(-alpha * D - beta * D ^ 2). It takes parameters alpha and beta as input and returns a numeric value representing the D10 dose. The units of the returned dose are the inverses of the units of the input alpha and beta parameters."
      },
      {
        "question": "How does the function handle input sanitization and what is the purpose of the `.sanitizeInput` call?",
        "answer": "The function uses `CoreGx::.sanitizeInput` to sanitize the input parameters. This call ensures that the input `pars` are properly formatted and validated. It sets various options like `x_as_log = FALSE`, `y_as_log = FALSE`, `y_as_pct = FALSE`, `trunc = FALSE`, and `verbose = FALSE` to specify how the input should be interpreted and processed."
      },
      {
        "question": "What is the significance of the `.linearQuadraticInv` function call in `computeD10`, and what are its arguments?",
        "answer": "The `.linearQuadraticInv` function is called to compute the inverse of the linear-quadratic model. It takes three arguments: `SF = 0.1` (representing the surviving fraction of 10%), `pars` (the input parameters alpha and beta), and `SF_as_log = FALSE` (indicating that the surviving fraction is not in logarithmic form). This function calculates the dose required to achieve the specified surviving fraction given the model parameters."
      }
    ],
    "completion_tasks": [
      {
        "partial": "computeD10 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  return()\n}",
        "complete": "computeD10 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  return(.linearQuadraticInv(SF = 0.1,\n                             pars = pars,\n                             SF_as_log = FALSE))\n}"
      },
      {
        "partial": "#' Compute D10\n#'\n#' @description This function computes the radiation dose at which only 10% of\n#'   cancer cells survive under the exponential model\n#'   SF = exp(-alpha * D - beta * D ^ 2) given alpha and beta, where D is the\n#'   radiation dose given and SF is the fraction of cells surviving\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The D10 value\n#'\n#' @export\ncomputeD10 <- function(pars) {\n  # Add code here\n}",
        "complete": "#' Compute D10\n#'\n#' @description This function computes the radiation dose at which only 10% of\n#'   cancer cells survive under the exponential model\n#'   SF = exp(-alpha * D - beta * D ^ 2) given alpha and beta, where D is the\n#'   radiation dose given and SF is the fraction of cells surviving\n#'\n#' @param pars parameters (alpha, beta) in equation\n#'   y = exp(-alpha * x - beta * x ^ 2)\n#'\n#' @return \\code{numeric} The D10 value\n#'\n#' @export\ncomputeD10 <- function(pars) {\n  CoreGx::.sanitizeInput(pars = pars,\n                          x_as_log = FALSE,\n                          y_as_log = FALSE,\n                          y_as_pct = FALSE,\n                          trunc = FALSE,\n                          verbose = FALSE)\n\n  return(.linearQuadraticInv(SF = 0.1,\n                             pars = pars,\n                             SF_as_log = FALSE))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/R/mRMRe.Network.R",
    "language": "R",
    "content": "## Definition\n\nsetClass(\"mRMRe.Network\", representation(topologies = \"list\", mi_matrix = \"matrix\", causality_list = \"list\",\n                sample_names = \"character\", feature_names = \"character\", target_indices = \"integer\"))\n\n## Wrappers\n`mRMR.network` <- function(...)\n{\n    return(new(\"mRMRe.Network\", ...)) \n}\n\n\n## FIXME: Add wrappers for network\n\n## initialize\n\nsetMethod(\"initialize\", signature(\"mRMRe.Network\"), function(.Object, data, prior_weight, target_indices, levels,\n                layers, ..., mi_threshold = -Inf, causality_threshold = Inf)\n{\n    if (missing(layers))\n        layers <- 1L\n    \n    \n    #.Object@causality_vector <- as.numeric(sapply(seq(featureCount(data)), function(i){ return(NA) }))\n\n    .Object@mi_matrix <- matrix(nrow = featureCount(data), ncol = featureCount(data), dimnames = list(featureNames(data), featureNames(data)))\n    .Object@sample_names <- sampleNames(data)\n    .Object@feature_names <- featureNames(data)\n    .Object@target_indices <- as.integer(target_indices)\n    .Object@topologies <- list()\n\t.Object@causality_list <- list()\n    \n    for (i in 1:layers)\n    {\n        filter <- new(\"mRMRe.Filter\", data = data, prior_weight = prior_weight, target_indices = target_indices,\n                levels = levels, ...)\n\n        solutions <- solutions(filter, mi_threshold = mi_threshold, causality_threshold = causality_threshold)\n       \tcausality <- causality(filter)\n\t\t\n        lapply(names(solutions), function(i) { \n\t\t\t\t\t.Object@topologies[[i]] <<- solutions[[i]]\n\t\t\t\t\t.Object@causality_list[[i]] <<- causality[[i]]\n\t\t\t\t})\n\t\tscreen <- which(!is.na(mim(filter, method=\"cor\")))\n        .Object@mi_matrix[screen] <- mim(filter, method=\"cor\")[screen]\n\n        new_target_indices <- unique(unlist(solutions))\n        new_target_indices <- new_target_indices[!is.na(new_target_indices)]\n        target_indices <- new_target_indices[!as.character(new_target_indices) %in% names(.Object@topologies)]\n        \n        if (length(target_indices) == 0)\n            break()\n    }\n\n    if (length(target_indices) == 0)\n        return(.Object)\n\n    ## Perform last-layer linking  \n\n    filter <- new(\"mRMRe.Filter\", data = data, prior_weight = prior_weight, target_indices = target_indices,\n            levels = levels, ...)\n    solutions <- solutions(filter, mi_threshold = mi_threshold, causality_threshold = causality_threshold)\n    \n    lapply(target_indices, function(target_index)\n    {\n        solution <- solutions[[as.character(target_index)]]\n        new_solutions <- apply(solution, c(1, 2), function(feature_index)\n                    ifelse(as.character(feature_index) %in% names(.Object@topologies), feature_index, NA))\n        \n        if (sum(is.na(new_solutions)) > 0)\n            .Object@topologies[[as.character(target_index)]] <<- new_solutions\n    })\n    \n    return(.Object)\n})\n\n## show\n\nsetMethod(\"show\", signature(\"mRMRe.Network\"), function(object)\n{\n    str(object)\n})\n\n## sampleNames\n\nsetMethod(\"sampleCount\", signature(\"mRMRe.Network\"), function(object)\n\t\t{\n\t\t\treturn(length(object@sample_names))\n\t\t})\n\n## sampleNames\n\nsetMethod(\"sampleNames\", signature(\"mRMRe.Network\"), function(object)\n{\n    return(object@sample_names)\n})\n\n## featureCount\n\nsetMethod(\"featureCount\", signature(\"mRMRe.Network\"), function(object)\n\t\t{\n\t\t\treturn(length(object@feature_names))\n\t\t})\n\n## featureNames\n\nsetMethod(\"featureNames\", signature(\"mRMRe.Network\"), function(object)\n{\n    return(object@feature_names)\n})\n\n## solutions\n\nsetMethod(\"solutions\", signature(\"mRMRe.Network\"), function(object)\n{\n    # filters[[target]][solution, ] is a vector of selected features\n    # in a solution for a target; missing values denote removed features\n            \n    return(object@topologies)\n})\n\n## mim\n\nsetMethod(\"mim\", signature(\"mRMRe.Network\"), function(object)\n{\n    # mi_matrix[i, j] contains the biased correlation between\n    # features i and j (i -> j directionality)\n            \n    return(object@mi_matrix)\n})\n\n## causality\n\nsetMethod(\"causality\", signature(\"mRMRe.Network\"), function(object)\n{\n    # causality_matrix[[target]][feature] contains the causality coefficient\n    # between feature and target (feature -> target directionality)\n            \n    return(object@causality_list)\n})\n\n## adjacencyMatrix\n\nsetMethod(\"adjacencyMatrix\", signature(\"mRMRe.Network\"), function(object)\n{\n    adjacency_matrix <- matrix(0, nrow = length(object@feature_names), ncol = length(object@feature_names), dimnames=list(object@feature_names, object@feature_names))\n    \n    lapply(names(object@topologies), function(target_index)\n    {\n        connected_indices <- as.vector(object@topologies[[target_index]])\n        connected_indices <- unique(connected_indices[!is.na(connected_indices)])\n        if(length(connected_indices) > 0) {\n            adjacency_matrix[connected_indices, as.integer(target_index)] <<- 1\n            if(length(causality(object)) == 0)\n                adjacency_matrix[as.integer(target_index), connected_indices] <<- 1\n        }\n    })\n\n    # adjacency matrix: parents (seletected features) in rows, children (target features) in columns\n    return(adjacency_matrix)\n})\n\n## adjacencyMatrixSum\n\nsetMethod(\"adjacencyMatrixSum\", signature(\"mRMRe.Network\"), function(object)\n{\n    adjacency_matrix <- matrix(0, nrow = length(object@feature_names), ncol = length(object@feature_names), dimnames=list(object@feature_names, object@feature_names))\n    \n    lapply(names(object@topologies), function(target_index)\n    {\n        connected_indices <- as.vector(object@topologies[[target_index]])\n        connected_indices <- sort(connected_indices[!is.na(connected_indices)])\n        connected_indices_count <- table(connected_indices)\n        connected_indices <- unique(connected_indices)\n        if(length(connected_indices) > 0) {\n            adjacency_matrix[connected_indices, as.integer(target_index)] <<- connected_indices_count\n            if(length(causality(object)) == 0)\n                adjacency_matrix[as.integer(target_index), connected_indices] <<- connected_indices_count\n        }\n    })\n\n    # adjacency matrix: parents (seletected features) in rows, children (target features) in columns\n    return(adjacency_matrix)\n})\n\n## visualize\n\nsetMethod(\"visualize\", signature(\"mRMRe.Network\"), function(object)\n{\n    ## FIXME : Cannot find a way to display vertex names...\n    \n    adjacency <- adjacencyMatrix(object)\n\tused_rows <- apply(adjacency, 1, sum) > 0\n\tused_cols <- apply(adjacency, 2, sum) > 0\n\tadjacency <- adjacency[used_rows | used_cols, used_cols | used_rows]\n    graph <- graph.adjacency(adjacency, mode = \"undirected\", add.rownames = 'label')\n\t\n    return(plot.igraph(graph))\n})\n\n## target\n\nsetMethod(\"target\", signature(\"mRMRe.Network\"), function(object)\n{\n\treturn(object@target_indices)\n})\n\nsetMethod(\"scores\", signature(\"mRMRe.Network\"), function(object)\n{\n\tmi_matrix <- mim(object)\n\ttargets <- names(solutions(object))\n\n\tscores <- lapply(targets, function(target) {\n\t\t\t\tapply(solutions(object)[[target]], 2, function(solution) {\n\t\t\t\t\t\t\tsapply(1:length(solution), function(i) {\n\n\t\t\t\t\t\t\t\t\t\tfeature_i <- solution[i]\n\t\t\t\t\t\t\t\t\t\tif(is.na(feature_i))\n\t\t\t\t\t\t\t\t\t\t\treturn(NA)\n\t\t\t\t\t\t\t\t\t\tif(i == 1)\n\t\t\t\t\t\t\t\t\t\t\treturn(mi_matrix[as.numeric(target), feature_i])\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tancestry_score <- mean(sapply((i-1):1, function(j) mi_matrix[feature_i, solution[j]]))\n\t\t\t\t\t\t\t\t\t\treturn(mi_matrix[as.numeric(target), feature_i] - ancestry_score)\n\t\t\t\t\t\t\t\t\t})\t\t\t\t\t\t\t\n\t\t\t\t\t\t})\n\t\t\t})\n\tnames(scores) <- targets\n\treturn(scores)\n})\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `mRMR.network` function in this code snippet?",
        "answer": "The `mRMR.network` function is a wrapper that creates and returns a new instance of the 'mRMRe.Network' class. It uses the `new()` function to instantiate the object with any provided arguments."
      },
      {
        "question": "How does the `initialize` method handle the creation of topologies and causality lists for the mRMRe.Network object?",
        "answer": "The `initialize` method creates topologies and causality lists by iterating through the specified number of layers. For each layer, it creates a new mRMRe.Filter object, computes solutions and causality, and stores them in the @topologies and @causality_list slots of the object. It continues this process until either all layers are processed or no new target indices are found."
      },
      {
        "question": "What is the purpose of the `adjacencyMatrix` method in the mRMRe.Network class?",
        "answer": "The `adjacencyMatrix` method generates and returns an adjacency matrix representing the network structure. It creates a matrix where rows represent parent features and columns represent child (target) features. It populates this matrix based on the topologies stored in the object, setting values to 1 where connections exist. If no causality information is available, it assumes bidirectional connections."
      }
    ],
    "completion_tasks": [
      {
        "partial": "setMethod(\"adjacencyMatrix\", signature(\"mRMRe.Network\"), function(object)\n{\n    adjacency_matrix <- matrix(0, nrow = length(object@feature_names), ncol = length(object@feature_names), dimnames=list(object@feature_names, object@feature_names))\n    \n    lapply(names(object@topologies), function(target_index)\n    {\n        connected_indices <- as.vector(object@topologies[[target_index]])\n        connected_indices <- unique(connected_indices[!is.na(connected_indices)])\n        if(length(connected_indices) > 0) {\n            # Complete the code here\n        }\n    })\n\n    return(adjacency_matrix)\n})",
        "complete": "setMethod(\"adjacencyMatrix\", signature(\"mRMRe.Network\"), function(object)\n{\n    adjacency_matrix <- matrix(0, nrow = length(object@feature_names), ncol = length(object@feature_names), dimnames=list(object@feature_names, object@feature_names))\n    \n    lapply(names(object@topologies), function(target_index)\n    {\n        connected_indices <- as.vector(object@topologies[[target_index]])\n        connected_indices <- unique(connected_indices[!is.na(connected_indices)])\n        if(length(connected_indices) > 0) {\n            adjacency_matrix[connected_indices, as.integer(target_index)] <<- 1\n            if(length(causality(object)) == 0)\n                adjacency_matrix[as.integer(target_index), connected_indices] <<- 1\n        }\n    })\n\n    return(adjacency_matrix)\n})"
      },
      {
        "partial": "setMethod(\"scores\", signature(\"mRMRe.Network\"), function(object)\n{\n    mi_matrix <- mim(object)\n    targets <- names(solutions(object))\n\n    scores <- lapply(targets, function(target) {\n        apply(solutions(object)[[target]], 2, function(solution) {\n            sapply(1:length(solution), function(i) {\n                feature_i <- solution[i]\n                if(is.na(feature_i))\n                    return(NA)\n                # Complete the code here\n            })\n        })\n    })\n    names(scores) <- targets\n    return(scores)\n})",
        "complete": "setMethod(\"scores\", signature(\"mRMRe.Network\"), function(object)\n{\n    mi_matrix <- mim(object)\n    targets <- names(solutions(object))\n\n    scores <- lapply(targets, function(target) {\n        apply(solutions(object)[[target]], 2, function(solution) {\n            sapply(1:length(solution), function(i) {\n                feature_i <- solution[i]\n                if(is.na(feature_i))\n                    return(NA)\n                if(i == 1)\n                    return(mi_matrix[as.numeric(target), feature_i])\n                ancestry_score <- mean(sapply((i-1):1, function(j) mi_matrix[feature_i, solution[j]]))\n                return(mi_matrix[as.numeric(target), feature_i] - ancestry_score)\n            })\n        })\n    })\n    names(scores) <- targets\n    return(scores)\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/CoreGx.git",
    "file": "../../../../repos/CoreGx/tests/testthat/test-aggregate-methods.R",
    "language": "R",
    "content": "library(testthat)\nlibrary(CoreGx)\nlibrary(BiocParallel)\nlibrary(data.table)\n\ndata(nci_TRE_small)\ntre <- copy(nci_TRE_small)\nby <- c(\"treatment1id\", \"treatment2id\", \"sampleid\")\nsens <- tre$sensitivity\n\n\n## -- Computing aggregations\n\n\ntestthat::test_that(\"`aggregate2` is equivalent to raw data.table aggregation\", {\n    ## Single threaded case\n    agg_res <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by\n        )\n    ## Mutlithreaded case (via bplapply)\n    agg_res_parallel <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by,\n            nthread=2\n        )\n    ## data.table default\n    dt_res <- sens[\n        treatment1id %in% unique(treatment1id)[1:3],\n        .(\n            mean_treatment1dose=mean(treatment1dose),\n            mean_treatment2dose=mean(treatment2dose),\n            mean_viability=mean(viability)\n        ),\n        by=by\n    ]\n    expect_true(all.equal(\n        agg_res,\n        dt_res,\n        check.attributes=FALSE  # to allow addition of aggregate call as attribute\n    ))\n    expect_true(all.equal(\n        agg_res_parallel,\n        dt_res,\n        check.attributes=FALSE\n    ))\n})\n\ntestthat::test_that(\"`aggregate,LongTable-method` is equivalent to aggregating the raw assay data.table\", {\n    agg_tre <- tre |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by\n        )\n    agg_tre_parallel <- tre |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by,\n            nthread=2\n        )\n    agg_dt <- tre$sensitivity[,\n        .(mean_viability=mean(viability)),\n        by=by\n    ]\n    agg_dt_small <- tre$sensitivity[\n        treatment1id %in% unique(treatment1id)[1:3],\n        .(mean_viability=mean(viability)),\n        by=by\n    ]\n    expect_true(all.equal(\n        agg_tre, agg_dt,\n        check.attributes=FALSE\n    ))\n    expect_true(all.equal(\n        agg_tre_parallel, agg_dt_small,\n        check.attributes=FALSE\n    ))\n})\n\ntestthat::test_that(\"`aggregate2` and `aggregate,LongTable-method` automatic naming works correctly\", {\n    ## aggregate2\n    agg2_named <- sens |>\n        aggregate2(\n            mean_viability=mean(viability), mean_treatment1dose=mean(treatment1dose),\n                mean_treatment2dose=mean(treatment2dose),\n            by=by\n        )\n    agg2_unnamed <- sens |>\n        aggregate2(\n            mean(viability), mean(treatment1dose), mean(treatment2dose),\n            by=by\n        )\n    testthat::expect_true(all.equal(\n        agg2_named, agg2_unnamed,\n        check.attributes=FALSE\n    ))\n    ## aggregate,LongTable-method\n    agg_named <- tre |>\n        aggregate(\n            \"sensitivity\",\n            mean_viability=mean(viability), mean_treatment1dose=mean(treatment1dose),\n                mean_treatment2dose=mean(treatment2dose),\n            by=by\n        )\n    agg_unnamed <- tre |>\n        aggregate(\n            \"sensitivity\",\n            mean(viability), mean(treatment1dose), mean(treatment2dose),\n            by=by\n        )\n    testthat::expect_true(all.equal(\n        agg_named, agg_unnamed,\n        check.attributes=FALSE\n    ))\n})\n\n\n## -- Assigning aggregated assays\n\ntestthat::test_that(\"`Assignment doesn't modify summarized assay data\", {\n    ntre <- copy(tre)\n    sens_summary <- tre |>\n        aggregate(\n            \"sensitivity\",\n            mean_viability=mean(viability, na.rm=TRUE),\n            mean_treatment1dose=mean(treatment1dose, na.rm=TRUE),\n            mean_treatment2dose=mean(treatment2dose, na.rm=TRUE),\n            by=by\n        )\n    ntre$sens_summary <- sens_summary\n    sens_summary2 <- unique(ntre$sens_summary[, .SD, .SDcols=colnames(sens_summary)])\n    setkeyv(sens_summary, by)\n    setkeyv(sens_summary2, by)\n    testthat::expect_true(all.equal(\n        sens_summary,\n        sens_summary2,\n        check.attributes=FALSE\n    ))\n})\n\ntestthat::test_that(\"`reindex,LongTable-method` doesn't corrupt referrential integrity of summarized assays\", {\n    ntre <- copy(tre)\n    sens_summary <- tre |>\n        aggregate(\n            \"sensitivity\",\n            mean_viability=mean(viability), mean_treatment1dose=mean(treatment1dose),\n                mean_treatment2dose=mean(treatment2dose),\n            by=by\n        )\n    ntre$sens_summary <- sens_summary\n    ntre2 <- reindex(ntre)\n    expect_true(all.equal(\n        ntre$sens_summary,\n        ntre2$sens_summary\n    ))\n})\n\ntestthat::test_that(\"`subset,LongTable-method` works correctly with summary assays\", {\n    ntre <- copy(tre)\n    sens_summary <- tre |>\n        aggregate(\n            \"sensitivity\",\n            mean_viability=mean(viability), mean_treatment1dose=mean(treatment1dose),\n                mean_treatment2dose=mean(treatment2dose),\n            by=by\n        )\n    ntre$sens_summary <- sens_summary\n    stre <- subset(ntre, treatment1id %in% treatment1id[1:5])\n    testthat::expect_true(CoreGx:::.table_is_subset(\n        stre$sens_summary,\n        ntre$sens_summary[treatment1id %in% treatment1id[1:5]]\n    ))\n})",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `aggregate2` function in this code, and how does it compare to the standard data.table aggregation?",
        "answer": "The `aggregate2` function is a custom aggregation function that is being tested for equivalence with raw data.table aggregation. It's used to compute mean values for 'treatment1dose', 'treatment2dose', and 'viability' grouped by 'treatment1id', 'treatment2id', and 'sampleid'. The test compares the results of `aggregate2` (both single-threaded and multi-threaded versions) with the standard data.table aggregation to ensure they produce the same output."
      },
      {
        "question": "How does the code handle parallel processing for aggregation, and what method is used to implement it?",
        "answer": "The code implements parallel processing for aggregation using the `nthread` parameter in the `aggregate2` function. It uses the `bplapply` function from the BiocParallel package to perform multi-threaded aggregation. The test case creates an `agg_res_parallel` object using `aggregate2` with `nthread=2`, which enables parallel processing with two threads. The results are then compared with the single-threaded version and the standard data.table aggregation to ensure consistency across different computation methods."
      },
      {
        "question": "What is the purpose of the `reindex` and `subset` operations on the LongTable object, and how does the code ensure data integrity after these operations?",
        "answer": "The `reindex` and `subset` operations are used to modify the LongTable object while preserving the integrity of summarized assays. The `reindex` function is tested to ensure it doesn't corrupt the referential integrity of summarized assays by comparing the 'sens_summary' before and after reindexing. The `subset` function is tested to verify that it correctly subsets both the main data and the summary assays. The code uses the `CoreGx:::.table_is_subset` function to check if the subsetted summary assay is a proper subset of the original summary assay. These tests ensure that data manipulation operations on the LongTable object maintain consistency and correctness of the summarized data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "testthat::test_that(\"`aggregate2` is equivalent to raw data.table aggregation\", {\n    ## Single threaded case\n    agg_res <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by\n        )\n    ## Mutlithreaded case (via bplapply)\n    agg_res_parallel <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by,\n            nthread=2\n        )\n    ## data.table default\n    dt_res <- sens[",
        "complete": "testthat::test_that(\"`aggregate2` is equivalent to raw data.table aggregation\", {\n    ## Single threaded case\n    agg_res <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by\n        )\n    ## Mutlithreaded case (via bplapply)\n    agg_res_parallel <- sens |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate2(\n            mean(treatment1dose), mean(treatment2dose), mean(viability),\n            by=by,\n            nthread=2\n        )\n    ## data.table default\n    dt_res <- sens[\n        treatment1id %in% unique(treatment1id)[1:3],\n        .(\n            mean_treatment1dose=mean(treatment1dose),\n            mean_treatment2dose=mean(treatment2dose),\n            mean_viability=mean(viability)\n        ),\n        by=by\n    ]\n    expect_true(all.equal(\n        agg_res,\n        dt_res,\n        check.attributes=FALSE  # to allow addition of aggregate call as attribute\n    ))\n    expect_true(all.equal(\n        agg_res_parallel,\n        dt_res,\n        check.attributes=FALSE\n    ))\n})"
      },
      {
        "partial": "testthat::test_that(\"`aggregate,LongTable-method` is equivalent to aggregating the raw assay data.table\", {\n    agg_tre <- tre |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by\n        )\n    agg_tre_parallel <- tre |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by,\n            nthread=2\n        )\n    agg_dt <- tre$sensitivity[,\n        .(mean_viability=mean(viability)),\n        by=by\n    ]\n    agg_dt_small <- tre$sensitivity[",
        "complete": "testthat::test_that(\"`aggregate,LongTable-method` is equivalent to aggregating the raw assay data.table\", {\n    agg_tre <- tre |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by\n        )\n    agg_tre_parallel <- tre |>\n        subset(treatment1id %in% unique(treatment1id)[1:3]) |>\n        aggregate(\n            assay=\"sensitivity\",\n            mean_viability=mean(viability),\n            by=by,\n            nthread=2\n        )\n    agg_dt <- tre$sensitivity[,\n        .(mean_viability=mean(viability)),\n        by=by\n    ]\n    agg_dt_small <- tre$sensitivity[\n        treatment1id %in% unique(treatment1id)[1:3],\n        .(mean_viability=mean(viability)),\n        by=by\n    ]\n    expect_true(all.equal(\n        agg_tre, agg_dt,\n        check.attributes=FALSE\n    ))\n    expect_true(all.equal(\n        agg_tre_parallel, agg_dt_small,\n        check.attributes=FALSE\n    ))\n})"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/mRMRe.git",
    "file": "../../../../repos/mRMRe/unitest/test_mpi.R",
    "language": "R",
    "content": "library(Rmpi)\n\nslave_function <- function()\n{\n    fate <- integer(1)\n    mpi.recv(x = fate, type = 1, source = 0, tag = 0)\n    print(paste(\"received fate \", fate, mpi.comm.rank() ))\n    if (as.logical(fate))\n        active_slave_function()\n    else\n        passive_slave_function()\n}\n\npassive_slave_function <- function()\n{\n    run <- TRUE\n    print(\"In passive\")\n    while (run)\n    {\n        Sys.sleep(1)\n        #mpi.irecv(x = junk, type = 1, source = 0, tag = 0, request = 0)\n        \n        #if (mpi.test(request = 0) && mpi.get.sourcetag()[2] == 0)\n        #    run <<- FALSE;\n    }\n    \n    #mpi.send(x = 1, type = 1, dest = 0, tag = 0)\n}\n\nactive_slave_function <- function()\n{\n    print(\"In active\")\n\t\n\tmpi.recv(x = task, type = 1, source = 0, tag = 0)\n\tif(task == 0)\n\t{\n\t\tnb_threads <- 1\n\t\tmpi.recv(x = nb_threads, type = 1, source = 0, tag = 0)\n\t\t\n\t\t\n\t\tdata_matrix <- mpi.recv.Robj(source = 0, tag = 0)\n\t\tsapply(1:ncol(data_matrix), function(i) {\n\t\t\t   sapply((i + 1):ncol(data_matrix), function(j) {\n\t\t\t\t\t  cor(data_matrix[ , i], data_matrix[ , j])\n\t\t\t\t\t  })\n\t\t\t   })\n\t\tcor_matrix <- cor(data_matrix)\n\t\tmpi.send.Robj(x = cor_matrix, dest = 0, tag = 0)\n\t}\n    Sys.sleep(5)\n    \n    mpi.send(x = 0, type = 1, dest = 0, tag = 0)\n    \n    mpi.send.Robj(obj = paste(\"active: \", mpi.comm.rank()), dest = 0, tag = 0)\n}\n\nmaster_function <- function()\n{\n    mpi.spawn.Rslaves(nslaves=8)\n    mpi.remote.exec(library(Rmpi))\n    all_slaves <- mpi.remote.exec(list(rank = mpi.comm.rank(), host = mpi.get.processor.name()))\n    mpi.remote.exec(source(\"~/mpi.R\"))\n    active_slaves <- list()\n    passive_slaves <- list()\n    \n    mpi.bcast.cmd(slave_function())\n    \n    lapply(all_slaves, function(slave)\n    {\n        if (length(active_slaves) > 0 &&\n                sum(sapply(active_slaves, function(i) slave$host == i$host)) > 1)\n        {\n\t    print(paste(\"changing \", slave$rank,\"to passive\"))\n            passive_slaves[[length(passive_slaves) + 1]] <<- slave\n            mpi.send(x = 0, type = 1, dest = slave$rank, tag = 0)\n        }\n        else\n        {\n\t    print(paste(\"changing \", slave$rank,\"to active\"))\n            active_slaves[[length(active_slaves) + 1]] <<- slave\n            mpi.send(x = 1, type = 1, dest = slave$rank, tag = 0)\n        }\n    })\n    \n    active_slaves_on_wait <- rep(TRUE, length(active_slaves))\n    first_run <- TRUE \n    while (sum(active_slaves_on_wait))\n    {\n        Sys.sleep(1)\n        \n        lapply(seq(length(active_slaves_on_wait)), function(active_slave_index)\n        {\n            slave_status <- integer(1)\n            \n            if (active_slaves_on_wait[[active_slave_index]])\n            {\n\t\t#browser()\n\t\tprint(paste(\"waiting for \", active_slaves[[active_slave_index]]$rank))\n                if(first_run)\n\t\t\tmpi.irecv(x = slave_status, type = 1, source = active_slaves[[active_slave_index]]$rank, tag = 0, request =active_slaves[[active_slave_index]]$rank)\n                if (mpi.test(request = active_slaves[[active_slave_index]]$rank))\n                {\n                    active_slaves_on_wait[[active_slave_index]] <<- FALSE\n                    print(paste(\"received aknowledgement from \", active_slave_index))\n                }\n                else\n                  print( \"Pas recu\")\n\t    }\n        })\n\tfirst_run <- FALSE\n    }\n\ttest_matrix <- matrix(runif(1000**2), 1000, 1000)\n    lapply(active_slaves, function(active_slave)\n    {\n\t\t   mpi.send(x = 0, type = 1, dest = active_slave$rank, tag = 0)\n\t\t   mpi.send(x = length(active_slaves), type = 1, dest = active_slave$rank, tag = 0)\n\t\t   mpi.send.Robj(test_matrix, active_slave$rank, tag = 0)\n    })\n\t\n\tlapply(active_slaves, function(active_slave)\n\t{\n\t     mpi.recv.Robj(source = active_slave$rank, tag = 0)\n\t\t\n\t})\n\n    #mpi.close.Rslaves()\n    #mpi.finalize()\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `slave_function` in this Rmpi code?",
        "answer": "The `slave_function` acts as a dispatcher for slave processes. It receives a 'fate' value from the master process and based on this value, it either calls `active_slave_function()` or `passive_slave_function()`. This allows the master to dynamically assign roles to slave processes."
      },
      {
        "question": "How does the `master_function` determine which slaves should be active or passive?",
        "answer": "The `master_function` assigns slaves to active or passive roles based on their host. It ensures that no more than two active slaves are on the same host. If a slave is from a host that already has two active slaves, it is assigned as passive. Otherwise, it's assigned as active. This logic helps in load balancing across different hosts."
      },
      {
        "question": "What is the main task performed by the `active_slave_function` in this code?",
        "answer": "The main task of the `active_slave_function` is to compute a correlation matrix. It receives a data matrix from the master, calculates the correlation matrix using the `cor()` function, and then sends the result back to the master. This demonstrates how Rmpi can be used for distributed computation of computationally intensive tasks."
      }
    ],
    "completion_tasks": [
      {
        "partial": "slave_function <- function() {\n    fate <- integer(1)\n    mpi.recv(x = fate, type = 1, source = 0, tag = 0)\n    print(paste(\"received fate \", fate, mpi.comm.rank()))\n    if (as.logical(fate))\n        active_slave_function()\n    else\n        passive_slave_function()\n}\n\npassive_slave_function <- function() {\n    run <- TRUE\n    print(\"In passive\")\n    while (run) {\n        Sys.sleep(1)\n    }\n}\n\nactive_slave_function <- function() {\n    print(\"In active\")\n    # Complete the function\n}",
        "complete": "slave_function <- function() {\n    fate <- integer(1)\n    mpi.recv(x = fate, type = 1, source = 0, tag = 0)\n    print(paste(\"received fate \", fate, mpi.comm.rank()))\n    if (as.logical(fate))\n        active_slave_function()\n    else\n        passive_slave_function()\n}\n\npassive_slave_function <- function() {\n    run <- TRUE\n    print(\"In passive\")\n    while (run) {\n        Sys.sleep(1)\n    }\n}\n\nactive_slave_function <- function() {\n    print(\"In active\")\n    mpi.recv(x = task, type = 1, source = 0, tag = 0)\n    if(task == 0) {\n        nb_threads <- 1\n        mpi.recv(x = nb_threads, type = 1, source = 0, tag = 0)\n        data_matrix <- mpi.recv.Robj(source = 0, tag = 0)\n        cor_matrix <- cor(data_matrix)\n        mpi.send.Robj(x = cor_matrix, dest = 0, tag = 0)\n    }\n    Sys.sleep(5)\n    mpi.send(x = 0, type = 1, dest = 0, tag = 0)\n    mpi.send.Robj(obj = paste(\"active: \", mpi.comm.rank()), dest = 0, tag = 0)\n}"
      },
      {
        "partial": "master_function <- function() {\n    mpi.spawn.Rslaves(nslaves=8)\n    mpi.remote.exec(library(Rmpi))\n    all_slaves <- mpi.remote.exec(list(rank = mpi.comm.rank(), host = mpi.get.processor.name()))\n    mpi.remote.exec(source(\"~/mpi.R\"))\n    active_slaves <- list()\n    passive_slaves <- list()\n    \n    mpi.bcast.cmd(slave_function())\n    \n    # Complete the function\n}",
        "complete": "master_function <- function() {\n    mpi.spawn.Rslaves(nslaves=8)\n    mpi.remote.exec(library(Rmpi))\n    all_slaves <- mpi.remote.exec(list(rank = mpi.comm.rank(), host = mpi.get.processor.name()))\n    mpi.remote.exec(source(\"~/mpi.R\"))\n    active_slaves <- list()\n    passive_slaves <- list()\n    \n    mpi.bcast.cmd(slave_function())\n    \n    lapply(all_slaves, function(slave) {\n        if (length(active_slaves) > 0 && sum(sapply(active_slaves, function(i) slave$host == i$host)) > 1) {\n            passive_slaves[[length(passive_slaves) + 1]] <<- slave\n            mpi.send(x = 0, type = 1, dest = slave$rank, tag = 0)\n        } else {\n            active_slaves[[length(active_slaves) + 1]] <<- slave\n            mpi.send(x = 1, type = 1, dest = slave$rank, tag = 0)\n        }\n    })\n    \n    active_slaves_on_wait <- rep(TRUE, length(active_slaves))\n    while (sum(active_slaves_on_wait)) {\n        Sys.sleep(1)\n        lapply(seq(length(active_slaves_on_wait)), function(active_slave_index) {\n            if (active_slaves_on_wait[[active_slave_index]]) {\n                if (mpi.iprobe(source = active_slaves[[active_slave_index]]$rank, tag = 0)) {\n                    mpi.recv(x = slave_status, type = 1, source = active_slaves[[active_slave_index]]$rank, tag = 0)\n                    active_slaves_on_wait[[active_slave_index]] <<- FALSE\n                }\n            }\n        })\n    }\n    \n    test_matrix <- matrix(runif(1000**2), 1000, 1000)\n    lapply(active_slaves, function(active_slave) {\n        mpi.send(x = 0, type = 1, dest = active_slave$rank, tag = 0)\n        mpi.send(x = length(active_slaves), type = 1, dest = active_slave$rank, tag = 0)\n        mpi.send.Robj(test_matrix, active_slave$rank, tag = 0)\n    })\n    \n    results <- lapply(active_slaves, function(active_slave) {\n        mpi.recv.Robj(source = active_slave$rank, tag = 0)\n    })\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  }
]