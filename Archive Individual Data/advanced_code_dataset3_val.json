[
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/fuzzy.ttest.R",
    "language": "R",
    "content": "#' @title Function to compute the fuzzy Student t test based on weighted\n#'   mean and weighted variance\n#'\n#' @description\n#' This function allows for computing the weighted mean and weighted variance\n#'   of a vector of continuous values.\n#'\n#' @usage\n#' fuzzy.ttest(x, w1, w2, alternative=c(\"two.sided\", \"less\", \"greater\"),\n#'   check.w = TRUE, na.rm = FALSE)\n#'\n#' @param x an object containing the observed values.\n#' @param w1 a numerical vector of weights of the same length as x giving the weights\n#'   to use for elements of x in the first class.\n#' @param w2 a numerical vector of weights of the same length as x giving the weights to\n#'   use for elements of x in the second class.\n#' @param alternative a character string specifying the alternative hypothesis, must be one\n#'   of \"two.sided\" (default), \"greater\" or \"less\". You can specify just the initial letter.\n#' @param check.w TRUE if weights should be checked such that `0 <= w <= 1` and `w1[i] + w2[i]) < 1`\n#'   for 1 <= i <= length(x), FALSE otherwise. Beware that weights greater than one\n#'   may inflate over-optimistically resulting p-values, use with caution.\n#' @param na.rm TRUE if missing values should be removed, FALSE otherwise.\n#'\n#' @details\n#' The weights w1 and w2 should represent the likelihood for each observation stored in\n#'   x to belong to the first and second class, respectively. Therefore the values contained\n#'   in w1 and w2 should lay in \\[0,1\\] and `0 <= (w1[i] + w2[i]) <= 1` for i in {0,1,...,n} where\n#'   n is the length of x.\n#' The Welch's version of the t test is implemented in this function, therefore assuming\n#'   unequal sample size and unequal variance. The sample size of the first and second class\n#'   are calculated as the sum(w1) and sum(w2), respectively.\n#'\n#' @return\n#' A numeric vector of six values that are the difference between the two weighted means,\n#'   the value of the t statistic, the sample size of class 1, the sample size of class 2,\n#'   the degree of freedom and the corresponding p-value.\n#'\n#' @references\n#' http://en.wikipedia.org/wiki/T_test\n#'\n#' @seealso\n#' [stats::weighted.mean]\n#'\n#'@examples\n#' set.seed(54321)\n#' # random generation of 50 normally distributed values for each of the two classes\n#' xx <- c(rnorm(50), rnorm(50)+1)\n#' # fuzzy membership to class 1\n#' ww1 <- runif(50) + 0.3\n#' ww1[ww1 > 1] <- 1\n#' ww1 <- c(ww1, 1 - ww1)\n#' # fuzzy membership to class 2\n#' ww2 <- 1 - ww1\n#' # Welch's t test weighted by fuzzy membership to class 1 and 2\n#' wt <- fuzzy.ttest(x=xx, w1=ww1, w2=ww2)\n#' print(wt)\n#' # Not run:\n#' # permutation test to compute the null distribution of the weighted t statistic\n#' wt <- wt[2]\n#' rands <- t(sapply(1:1000, function(x,y) { return(sample(1:y)) }, y=length(xx)))\n#' randst <- apply(rands, 1, function(x, xx, ww1, ww2)\n#' { return(fuzzy.ttest(x=xx, w1=ww1[x], w2=ww2[x])[2]) }, xx=xx, ww1=ww1, ww2=ww2)\n#' ifelse(wt < 0, sum(randst <= wt), sum(randst >= wt)) / length(randst)\n#' # End(Not run)\n#'\n#' @md\n#' @export\nfuzzy.ttest <-\nfunction(x, w1, w2, alternative=c(\"two.sided\", \"less\", \"greater\"), check.w=TRUE, na.rm=FALSE) {\n\talternative <- match.arg(alternative)\n\tii <- complete.cases(x, w1, w2)\n\tif(!na.rm && sum(!ii) > 0) { stop(\"missing values are present!\") } else {\n\t\tw1 <- w1[ii]\n\t\tw2 <- w2[ii]\n\t\tx <- x[ii]\n\t}\n\tif(check.w && (!all(w1 >= 0 & w1 <= 1) || !all(w2 >= 0 & w2 <= 1) || (!all((w1 + w2) >= 0) && !all((w1 + w2) <= 1)))) { stop(\"weights and their sum should lay in [0, 1]!\") }\n\ttt <- weighted.meanvar(x=x, w=w1, na.rm=na.rm)\n\tx1.w <- tt[1]\n\tvar1.w <- tt[2]\n\ttt <- weighted.meanvar(x=x, w=w2, na.rm=na.rm)\n\tx2.w <- tt[1]\n\tvar2.w <- tt[2]\n\tn1 <- sum(w1)\n\tn2 <- sum(w2)\n\tt.value <- (x1.w - x2.w) / sqrt((var1.w / n1) + (var2.w / n2))\n\tdf <- (((var1.w / n1) + (var2.w / n2))^2) / ((((var1.w / n1)^2) / (n1 - 1)) + (((var2.w / n2)^2) / (n2 - 1)))\n\tp.value <- pt(q=abs(t.value), df=df, lower.tail=FALSE)\n\tif(alternative == \"two.sided\")  { p.value <- p.value*2 }\n\tif(alternative == \"less\") { p.value <- 1-p.value }\n\tres <- c(x1.w - x2.w, t.value, n1, n2, df, p.value)\n\tnames(res) <- c(\"diff\", \"t.value\", \"n1\", \"n2\", \"df\", \"p.value\")\n\treturn(res)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `fuzzy.ttest` function and how does it differ from a standard t-test?",
        "answer": "The `fuzzy.ttest` function computes a fuzzy Student t-test based on weighted mean and weighted variance. It differs from a standard t-test by allowing for fuzzy membership of observations to two classes, represented by weight vectors w1 and w2. This function is useful when the class membership of observations is not binary but probabilistic. It implements Welch's version of the t-test, assuming unequal sample sizes and variances."
      },
      {
        "question": "How are the degrees of freedom (df) calculated in the `fuzzy.ttest` function, and why is this method used?",
        "answer": "The degrees of freedom (df) in the `fuzzy.ttest` function are calculated using the Welch\u2013Satterthwaite equation: df = (((var1.w / n1) + (var2.w / n2))^2) / ((((var1.w / n1)^2) / (n1 - 1)) + (((var2.w / n2)^2) / (n2 - 1))). This method is used because it accounts for potentially unequal variances and sample sizes between the two groups, which is appropriate for the Welch's t-test implemented in this function. It provides a more accurate approximation of the degrees of freedom when the assumptions of equal variances and sample sizes are not met."
      },
      {
        "question": "What are the constraints on the weight vectors w1 and w2 in the `fuzzy.ttest` function, and how are these constraints enforced?",
        "answer": "The weight vectors w1 and w2 should represent the likelihood of each observation belonging to the first and second class, respectively. The constraints are: 1) All values in w1 and w2 should be between 0 and 1 (inclusive). 2) The sum of corresponding elements in w1 and w2 should be between 0 and 1 (inclusive). These constraints are enforced by the `check.w` parameter. When `check.w` is TRUE (default), the function checks these conditions and throws an error if they are not met, using the condition: `if(check.w && (!all(w1 >= 0 & w1 <= 1) || !all(w2 >= 0 & w2 <= 1) || (!all((w1 + w2) >= 0) && !all((w1 + w2) <= 1))))`. Users are warned that weights greater than one may inflate p-values optimistically."
      }
    ],
    "completion_tasks": [
      {
        "partial": "fuzzy.ttest <- function(x, w1, w2, alternative=c(\"two.sided\", \"less\", \"greater\"), check.w=TRUE, na.rm=FALSE) {\n  alternative <- match.arg(alternative)\n  ii <- complete.cases(x, w1, w2)\n  if(!na.rm && sum(!ii) > 0) { stop(\"missing values are present!\") } else {\n    w1 <- w1[ii]\n    w2 <- w2[ii]\n    x <- x[ii]\n  }\n  if(check.w && (!all(w1 >= 0 & w1 <= 1) || !all(w2 >= 0 & w2 <= 1) || (!all((w1 + w2) >= 0) && !all((w1 + w2) <= 1)))) { stop(\"weights and their sum should lay in [0, 1]!\") }\n  # Complete the function by calculating weighted means, variances, t-value, degrees of freedom, and p-value\n  # Return the results as a named vector\n}",
        "complete": "fuzzy.ttest <- function(x, w1, w2, alternative=c(\"two.sided\", \"less\", \"greater\"), check.w=TRUE, na.rm=FALSE) {\n  alternative <- match.arg(alternative)\n  ii <- complete.cases(x, w1, w2)\n  if(!na.rm && sum(!ii) > 0) { stop(\"missing values are present!\") } else {\n    w1 <- w1[ii]\n    w2 <- w2[ii]\n    x <- x[ii]\n  }\n  if(check.w && (!all(w1 >= 0 & w1 <= 1) || !all(w2 >= 0 & w2 <= 1) || (!all((w1 + w2) >= 0) && !all((w1 + w2) <= 1)))) { stop(\"weights and their sum should lay in [0, 1]!\") }\n  tt <- weighted.meanvar(x=x, w=w1, na.rm=na.rm)\n  x1.w <- tt[1]\n  var1.w <- tt[2]\n  tt <- weighted.meanvar(x=x, w=w2, na.rm=na.rm)\n  x2.w <- tt[1]\n  var2.w <- tt[2]\n  n1 <- sum(w1)\n  n2 <- sum(w2)\n  t.value <- (x1.w - x2.w) / sqrt((var1.w / n1) + (var2.w / n2))\n  df <- (((var1.w / n1) + (var2.w / n2))^2) / ((((var1.w / n1)^2) / (n1 - 1)) + (((var2.w / n2)^2) / (n2 - 1)))\n  p.value <- pt(q=abs(t.value), df=df, lower.tail=FALSE)\n  if(alternative == \"two.sided\")  { p.value <- p.value*2 }\n  if(alternative == \"less\") { p.value <- 1-p.value }\n  res <- c(x1.w - x2.w, t.value, n1, n2, df, p.value)\n  names(res) <- c(\"diff\", \"t.value\", \"n1\", \"n2\", \"df\", \"p.value\")\n  return(res)\n}"
      },
      {
        "partial": "weighted.meanvar <- function(x, w, na.rm = FALSE) {\n  if (na.rm) {\n    i <- complete.cases(x, w)\n    x <- x[i]\n    w <- w[i]\n  }\n  # Complete the function by calculating the weighted mean and variance\n  # Return the results as a vector\n}",
        "complete": "weighted.meanvar <- function(x, w, na.rm = FALSE) {\n  if (na.rm) {\n    i <- complete.cases(x, w)\n    x <- x[i]\n    w <- w[i]\n  }\n  sum_w <- sum(w)\n  mean_w <- sum(w * x) / sum_w\n  var_w <- sum(w * (x - mean_w)^2) / (sum_w - sum(w^2) / sum_w)\n  return(c(mean_w, var_w))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/hr.comp.meta.R",
    "language": "R",
    "content": "`hr.comp.meta` <-\nfunction(list.hr1, list.hr2, hetero=FALSE) {\n\n\tif(length(list.hr1) != length(list.hr2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n\tn <- 0\n\tx1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n\tfor(i in 1:length(list.hr1)) {\n\t\tnn <- list.hr1[[i]]$n\n\t\tif(nn != list.hr2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n\t\tn <- n + nn\n\t\tx1 <- c(x1, list.hr1[[i]]$coef)\n\t\tx1.se <- c(x1.se, list.hr1[[i]]$se)\n\t\tx2 <- c(x2, list.hr2[[i]]$coef)\n\t\tx2.se <- c(x2.se, list.hr2[[i]]$se)\n\t\tcort <- cor(list.hr1[[i]]$data$x, list.hr2[[i]]$data$x, method=\"spearman\", use=\"complete.obs\")\n\t\t## since r is the spearman correlation coefficient and not the Pearson's one, we should apply a correction factor (see http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient for details)\n\t\tcorz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n\t\tif(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n\t}\n\tx1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n\tx2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n\tif(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n\t## same hazard ratios\n\t\treturn(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n\t}\n\trz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n\t## since r is the spearman correlation coefficient and not the Pearson's one, we should apply a correction factor (see http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient for details)\n\trz <- rz / (sqrt((n - 3) / 1.06))\n\tr <- fisherz(rz, inv=TRUE)\n\n\tif(abs(r) < 1) {\n\t\tt.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n\t\tdiff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n\t} else { diff.ci.p <- 1 }\n\treturn(list(\"p.value\"=diff.ci.p, \"hr1\"=exp(x1.meta$estimate), \"hr2\"=exp(x2.meta$estimate)))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `hr.comp.meta` function and what are its main inputs?",
        "answer": "The `hr.comp.meta` function is designed to compare two sets of hazard ratios (HR) or concordance indices. It takes three main inputs: `list.hr1` and `list.hr2`, which are lists containing HR data for two different models or conditions, and an optional `hetero` parameter to indicate if heterogeneity should be considered in the meta-analysis. The function performs a meta-analysis on the input data and compares the results, returning a p-value for the difference between the two sets of HRs and the combined estimates for each set."
      },
      {
        "question": "How does the function handle the correlation between the two sets of hazard ratios, and why is a correction factor applied?",
        "answer": "The function calculates the Spearman correlation coefficient between the two sets of hazard ratios for each sample. It then applies a correction factor to this correlation when converting it to Fisher's z-score. The correction factor is sqrt((nn - 3) / 1.06), where nn is the sample size. This correction is applied because the function uses Spearman's rank correlation coefficient instead of Pearson's correlation coefficient. The correction helps to adjust for the difference between these two types of correlations, making the Fisher's z-transformation more accurate for the Spearman correlation."
      },
      {
        "question": "What statistical test is used to compare the two sets of hazard ratios, and under what condition is this test not performed?",
        "answer": "The function uses a t-test to compare the two sets of hazard ratios. It calculates a t-statistic using the difference between the meta-analyzed estimates, their standard errors, and the correlation between the sets. The p-value is then computed using the t-distribution with n-1 degrees of freedom. However, this test is not performed if the absolute value of the correlation coefficient (r) is equal to or greater than 1. In such cases, the function returns a p-value of 1, indicating no significant difference between the sets of hazard ratios."
      }
    ],
    "completion_tasks": [
      {
        "partial": "hr.comp.meta <- function(list.hr1, list.hr2, hetero=FALSE) {\n  if(length(list.hr1) != length(list.hr2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.hr1)) {\n    nn <- list.hr1[[i]]$n\n    if(nn != list.hr2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.hr1[[i]]$coef)\n    x1.se <- c(x1.se, list.hr1[[i]]$se)\n    x2 <- c(x2, list.hr2[[i]]$coef)\n    x2.se <- c(x2.se, list.hr2[[i]]$se)\n    cort <- cor(list.hr1[[i]]$data$x, list.hr2[[i]]$data$x, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    if(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  # Complete the function\n}",
        "complete": "hr.comp.meta <- function(list.hr1, list.hr2, hetero=FALSE) {\n  if(length(list.hr1) != length(list.hr2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.hr1)) {\n    nn <- list.hr1[[i]]$n\n    if(nn != list.hr2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.hr1[[i]]$coef)\n    x1.se <- c(x1.se, list.hr1[[i]]$se)\n    x2 <- c(x2, list.hr2[[i]]$coef)\n    x2.se <- c(x2.se, list.hr2[[i]]$se)\n    cort <- cor(list.hr1[[i]]$data$x, list.hr2[[i]]$data$x, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    if(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  rz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n  rz <- rz / (sqrt((n - 3) / 1.06))\n  r <- fisherz(rz, inv=TRUE)\n\n  if(abs(r) < 1) {\n    t.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"hr1\"=exp(x1.meta$estimate), \"hr2\"=exp(x2.meta$estimate)))\n}"
      },
      {
        "partial": "hr.comp.meta <- function(list.hr1, list.hr2, hetero=FALSE) {\n  if(length(list.hr1) != length(list.hr2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.hr1)) {\n    nn <- list.hr1[[i]]$n\n    if(nn != list.hr2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.hr1[[i]]$coef)\n    x1.se <- c(x1.se, list.hr1[[i]]$se)\n    x2 <- c(x2, list.hr2[[i]]$coef)\n    x2.se <- c(x2.se, list.hr2[[i]]$se)\n    cort <- cor(list.hr1[[i]]$data$x, list.hr2[[i]]$data$x, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    if(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n  }\n  # Complete the function\n}",
        "complete": "hr.comp.meta <- function(list.hr1, list.hr2, hetero=FALSE) {\n  if(length(list.hr1) != length(list.hr2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.hr1)) {\n    nn <- list.hr1[[i]]$n\n    if(nn != list.hr2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.hr1[[i]]$coef)\n    x1.se <- c(x1.se, list.hr1[[i]]$se)\n    x2 <- c(x2, list.hr2[[i]]$coef)\n    x2.se <- c(x2.se, list.hr2[[i]]$se)\n    cort <- cor(list.hr1[[i]]$data$x, list.hr2[[i]]$data$x, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    if(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  rz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n  rz <- rz / (sqrt((n - 3) / 1.06))\n  r <- fisherz(rz, inv=TRUE)\n\n  if(abs(r) < 1) {\n    t.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"hr1\"=exp(x1.meta$estimate), \"hr2\"=exp(x2.meta$estimate)))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/dataset.R",
    "language": "R",
    "content": "#' TGGATESsmall dataset\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the example\n#' usage in the roxygen2 documentation for ToxicoGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name TGGATESsmall\n#' @usage data(TGGATESsmall)\n#' @keywords datasets\n#' @format ToxicoSet object\n#'\nNULL\n\n#' HCC_sig dataset\n#'\n#' A dataset cotaining the gene names associated with the HCC geneset signature\n#'\n#' @docType data\n#' @name HCC_sig\n#' @usage data(HCC_sig)\n#' @keywords datasets\n#' @format character\nNULL\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `@docType data` tag in the provided R code snippet?",
        "answer": "The `@docType data` tag is used in roxygen2 documentation to indicate that the object being documented is a dataset. It helps in generating the correct documentation format for datasets in R packages."
      },
      {
        "question": "Why is the `NULL` statement used at the end of each dataset documentation block?",
        "answer": "The `NULL` statement is used as a placeholder to ensure that the roxygen2 comments are associated with an object in the R code. Since these are dataset documentations, there's no actual R code to attach the comments to, so `NULL` is used to create a binding point for the documentation."
      },
      {
        "question": "What is the difference between the `@format` tags for the TGGATESsmall and HCC_sig datasets?",
        "answer": "The `@format` tag specifies the structure of the dataset. For TGGATESsmall, the format is given as 'ToxicoSet object', indicating it's a complex object specific to toxicogenomics analysis. For HCC_sig, the format is 'character', suggesting it's a simpler dataset, likely a vector of character strings containing gene names."
      }
    ],
    "completion_tasks": [
      {
        "partial": "#' TGGATESsmall dataset\n#'\n#' Documentation for this dataset will be added at a later date.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name TGGATESsmall\n#' @usage data(TGGATESsmall)\n#' @keywords datasets\n#' @format ToxicoSet object\n#'\nNULL",
        "complete": "#' TGGATESsmall dataset\n#'\n#' Documentation for this dataset will be added at a later date. For now I just\n#' need this package to pass the CRAN checks! This dataset powers the example\n#' usage in the roxygen2 documentation for ToxicoGx.\n#'\n#' @references\n#' Lamb et al. The Connectivity Map: using gene-expression signatures to connect\n#'   small molecules, genes, and disease. Science, 2006.\n#'\n#' @docType data\n#' @name TGGATESsmall\n#' @usage data(TGGATESsmall)\n#' @keywords datasets\n#' @format ToxicoSet object\n#'\nNULL"
      },
      {
        "partial": "#' HCC_sig dataset\n#'\n#' A dataset cotaining the gene names associated with the HCC geneset signature\n#'\n#' @docType data\n#' @name HCC_sig\n#' @usage data(HCC_sig)\n#' @keywords datasets\n#' @format",
        "complete": "#' HCC_sig dataset\n#'\n#' A dataset cotaining the gene names associated with the HCC geneset signature\n#'\n#' @docType data\n#' @name HCC_sig\n#' @usage data(HCC_sig)\n#' @keywords datasets\n#' @format character\nNULL"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/ToxicoSet-class.R",
    "language": "R",
    "content": "#' @include allGenerics.R\nNULL\n\n#' Class to contain Toxico-genomic Data\n#'\n#' The ToxicoSet (tSet) class was development to contain and organise large\n#' ToxicGenomic datasets as well as provide useful tools for interacting with\n#' this data. Functions are included for exploring the relationship between\n#' survival fraction and gene expression in cultured human and rat tissues\n#' during exposure to a wide ranges of compounds. Features include plotting dose\n#' and exposure time curves, calculating AUC, fitting linear models and\n#' computing sensitivity signatures.\n#'\n#' @slot annotation A \\code{list} of annotation data about the ToxicoSet,\n#'    including the \\code{$name} and the session information for how the object\n#'    was creating, detailing the exact versions of R and all the packages used\n#' @slot molecularProfiles A \\code{list} containing \\code{SummarizedExperiment}\n#'   type object for holding data for RNA, DNA, SNP and CNV\n#'   measurements, with associated \\code{fData} and \\code{pData}\n#'   containing the row and column metadata\n#' @slot sample A \\code{data.frame} containing the annotations for all the cell\n#'   lines profiled in the data set, across all data types\n#' @slot treatment A \\code{data.frame} containg the annotations for all the drugs\n#'   profiled in the data set, across all data types\n#' @slot treatmentResponse A \\code{list} containing all the data for the sensitivity\n#'   experiments, including \\code{$info}, a \\code{data.frame} containing the\n#'   experimental info,\\code{$raw} a 3D \\code{array} containing raw data,\n#'   \\code{$profiles}, a \\code{data.frame} containing sensitivity profiles\n#'   statistics, and \\code{$n}, a \\code{data.frame} detailing the number of\n#'   experiments for each cell-drug pair\n#' @slot perturbation A \\code{list} containting \\code{$n}, a \\code{data.frame}\n#'   summarizing the available perturbation data,\n#' @slot curation A \\code{list} containing mappings for \\code{$treatment},\n#'   \\code{sample}, \\code{tissue} names  used in the data set to universal\n#'   identifiers used between different ToxicoSet objects\n#' @slot datasetType A \\code{character} string of 'sensitivity',\n#'   'perturbation', or both detailing what type of data can be found in the\n#'   ToxicoSet, for proper processing of the data\n#'\n#' @return An object of the ToxicoSet class\n#'\n#' @importClassesFrom CoreGx CoreSet\n.ToxicoSet <- setClass(\"ToxicoSet\", contains=\"CoreSet\")\n\n## TODO:: implement .intern slot to hold arbitrary metadata about a tSet\n\n## Variables for dynamic inheritted roxygen2 docs\n\n.local_class=\"ToxicoSet\"\n.local_data=\"TGGATESsmall\"\n.local_sample=\"cell\"\n\n#### CoreGx inherited methods\n####\n#### Note: The raw documentation lives in CoreGx, see the functions called\n#### in @eval tags for the content of the metaprogrammed roxygen2 docs.\n####\n#### See .parseToRoxygen method in utils-messages.R file of CoreGx to\n#### create similar metaprogrammed docs.\n####\n#### Warning: for dynamic docs to work, you must set\n#### Roxygen: list(markdown = TRUE, r6=FALSE)\n#### in the DESCRPTION file!\n\n\n### -------------------------------------------------------------------------\n### Constructor -------------------------------------------------------------\n### -------------------------------------------------------------------------\n\n# The default constructor above does a poor job of explaining the required\n# structure of a ToxicoSet. The constructor function defined below guides the\n# user into providing the required components of the curation and senstivity\n# lists and hides the annotation slot which the user does not need to manually\n# fill. This also follows the design of the Expression Set class.\n\n#' ToxicoSet constructor\n#'\n#' A constructor that simplifies the process of creating ToxicoSets, as well\n#' as creates empty objects for data not provided to the constructor. Only\n#' objects returned by this constructor are expected to work with the ToxicoSet\n#' methods. For a much more detailed instruction on creating ToxicoSets, please\n#' see the \"CreatingToxicoSet\" vignette.\n#'\n#' @inheritParams CoreGx::CoreSet\n#'\n#' @return An object of class \\code{ToxicoSet}\n#'\n#' @import methods\n#' @importFrom utils sessionInfo\n#' @importFrom stats na.omit\n#' @importFrom SummarizedExperiment rowData colData assay assays\n#'   assayNames Assays rowData<- colData<-\n#' @importFrom S4Vectors DataFrame SimpleList metadata\n#' @importFrom CoreGx CoreSet\n#' @export\nToxicoSet <-  function(name,\n                       molecularProfiles=list(),\n                       sample=data.frame(),\n                       treatment=data.frame(),\n                       sensitivityInfo=data.frame(),\n                       sensitivityRaw=array(dim = c(0,0,0)),\n                       sensitivityProfiles=matrix(),\n                       sensitivityN=matrix(nrow = 0, ncol=0),\n                       perturbationN=array(NA, dim = c(0,0,0)),\n                       curationTreatment=data.frame(),\n                       curationSample = data.frame(),\n                       curationTissue = data.frame(),\n                       datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                       #sharedControls=FALSE,\n                       verify = TRUE)\n{\n    # .Deprecated(\"ToxicoSet2\", package=packageName(), msg=\"The ToxicoSet class is\n    #     being redesigned. Please use the new constructor to ensure forwards\n    #     compatibility with future releases! Old objects can be updated with\n    #     the updateObject method.\", old=\"ToxicoSet\")\n\n    cSet <- CoreGx::CoreSet(\n        name=name,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        sensitivityInfo=sensitivityInfo,\n        sensitivityRaw=sensitivityRaw,\n        sensitivityProfiles=sensitivityProfiles,\n        sensitivityN=sensitivityN,\n        perturbationN=perturbationN,\n        curationTreatment=curationTreatment,\n        curationSample=curationSample,\n        curationTissue=curationTissue,\n        datasetType=datasetType,\n        verify=verify\n    )\n\n    tSet  <- .ToxicoSet(\n        annotation=cSet@annotation,\n        molecularProfiles=cSet@molecularProfiles,\n        sample=cSet@sample,\n        treatment=cSet@treatment,\n        datasetType=cSet@datasetType,\n        treatmentResponse=cSet@treatmentResponse,\n        perturbation=cSet@perturbation,\n        curation=cSet@curation\n    )\n    if (verify) { checkTSetStructure(tSet)}\n    if (length(sensitivityN) == 0 && datasetType %in% c(\"sensitivity\", \"both\")) {\n        sensNumber(tSet) <- .summarizeSensitivityNumbers(tSet)\n    }\n    if (length(perturbationN) == 0  && datasetType %in% c(\"perturbation\", \"both\")) {\n        pertNumber(tSet) <- .summarizePerturbationNumbers(tSet)\n    }\n    return(tSet)\n}\n\n# Helper Functions --------------------------------------------------------\n\n.summarizeSensitivityNumbers <- function(tSet) {\n\n  if (datasetType(tSet) != \"sensitivity\" && datasetType(tSet) != \"both\") {\n    stop (\"Data type must be either sensitivity or both\")\n  }\n\n  ## consider all drugs\n  drugn <- treatmentNames(tSet)\n\n  ## consider all cell lines\n  celln <- rownames(sampleInfo(tSet))\n\n  sensitivity.info <- matrix(0, nrow=length(celln), ncol=length(drugn),\n                             dimnames=list(celln, drugn))\n  drugids <- sensitivityInfo(tSet)[, \"treatmentid\"]\n  cellids <- sensitivityInfo(tSet)[, \"sampleid\"]\n  cellids <- cellids[grep(\"///\", drugids, invert=TRUE)]\n  drugids <- drugids[grep(\"///\", drugids, invert=TRUE)]\n\n\n  tt <- table(cellids, drugids)\n  sensitivity.info[rownames(tt), colnames(tt)] <- tt\n\n  return(sensitivity.info)\n}\n\n.summarizePerturbationNumbers <- function(tSet) {\n\n  if (datasetType(tSet) != \"perturbation\" && datasetType(tSet) != \"both\") {\n    stop (\"Data type must be either perturbation or both\")\n  }\n\n  ## consider all drugs\n  drugn <- treatmentNames(tSet)\n\n  ## consider all cell lines\n  celln <- rownames(sampleInfo(tSet))\n\n  perturbation.info <- array(0, dim=c(length(celln), length(drugn), length(molecularProfilesSlot(tSet))), dimnames=list(celln, drugn, names((molecularProfilesSlot(tSet)))))\n\n  for (i in seq_along(molecularProfilesSlot(tSet))) {\n    if (nrow(SummarizedExperiment::colData(molecularProfilesSlot(tSet)[[i]])) > 0 &&\n        all(\n          is.element(c(\"sampleid\", \"treatmentid\"),\n                     colnames(SummarizedExperiment::colData(molecularProfilesSlot(tSet)[[i]]))))) {\n      tt <- table(SummarizedExperiment::colData(molecularProfilesSlot(tSet)[[i]])[ , \"sampleid\"], SummarizedExperiment::colData(molecularProfilesSlot(tSet)[[i]])[ , \"treatmentid\"])\n      perturbation.info[rownames(tt), colnames(tt), names(molecularProfilesSlot(tSet))[i]] <- tt\n    }\n  }\n\n  return(perturbation.info)\n}\n\n\n#' A function to verify the structure of a ToxicoSet\n#'\n#' This function checks the structure of a ToxicoSet, ensuring that the\n#' correct annotations are in place and all the required slots are filled so\n#' that matching of cells and drugs can be properly done across different types\n#' of data and with other studies.\n#'\n#' @examples\n#' checkTSetStructure(TGGATESsmall)\n#'\n#' @param tSet A \\code{ToxicoSet} object\n#' @param plotDist Should the function also plot the distribution of molecular data?\n#' @param result.dir The path to the directory for saving the plots as a string, defaults to `tempdir()`\n#'\n#' @return Prints out messages whenever describing the errors found in the structure of the pset object passed in.\n#'\n#' @importFrom graphics hist\n#' @importFrom grDevices dev.off pdf\n#' @importFrom S4Vectors metadata\n#' @importFrom CoreGx .message .warning .error\n#'\n#' @export\ncheckTSetStructure <- function(tSet, plotDist=FALSE, result.dir=\".\") {\n\n    if(!file.exists(result.dir) && plotDist)\n        dir.create(result.dir, showWarnings=FALSE, recursive=TRUE)\n\n    for( i in seq_along(molecularProfilesSlot(tSet))) {\n        profile <- molecularProfilesSlot(tSet)[[i]]\n        if (is.null(names(metadata(profile))))\n            .error(paste0(\"Please ensure all items in the metadata slot of\n                 SummarizedExperiments are named. Item \", i, \" of molecualrProfiles\n                 does not have metadata names.\"))\n        if (!(\"annotation\" %in% names(metadata(profile))))\n            .error(paste0(\"At minimum the SummarizedExperiments in molecularProfiles must contain\n                    a metadata item names 'annotation' specifying the molecular datatype\n                   the SummarizedExperiment contains! Item \", i, \" of\n                   molecularProfilesis missing annotation metadata.\"))\n        nn <- names(molecularProfilesSlot(tSet))[i]\n\n        if(plotDist) {\n            if (S4Vectors::metadata(profile)$annotation == \"rna\" ||\n                S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n            {\n                pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n                hist(SummarizedExperiment::assay(profile, 1), breaks = 100)\n                dev.off()\n            }\n        }\n        if (nrow(SummarizedExperiment::rowData(profile)) !=\n            nrow(SummarizedExperiment::assay(profile, 1)))\n        {\n            .warning(sprintf(\"%s: number of features in fData is different from expression slots\", nn))\n        } else {\n            .message(sprintf(\"%s: fData dimension is OK\", nn))\n        }\n        if (nrow(SummarizedExperiment::colData(profile)) != ncol(SummarizedExperiment::assay(profile, 1)))\n        {\n            .warning(sprintf(\"%s: number of cell lines in pData is different from expression slots\", nn))\n        } else {\n            .message(sprintf(\"%s: pData dimension is OK\", nn))\n        }\n\n        if (\"sampleid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            .message(\"sampleid OK!\")\n        } else {\n            .warning(sprintf(\"%s: sampleid does not exist in pData columns\", nn))\n        }\n        if (\"batchid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            .message(\"batchid OK!\")\n        } else {\n            .warning(sprintf(\"%s: batchid does not exist in pData columns\", nn))\n        }\n        if (S4Vectors::metadata(profile)$annotation == \"rna\" ||\n            S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n        {\n            if (\"BEST\" %in% colnames(SummarizedExperiment::rowData(profile))) {\n                .message(\"BEST is OK\")\n            } else {\n                .warning(sprintf(\"%s: BEST does not exist in fData columns\", nn))\n            }\n\n            if (\"Symbol\" %in% colnames(SummarizedExperiment::rowData(profile))) {\n                .message(\"Symbol is OK\")\n            } else {\n                .warning(sprintf(\"%s: Symbol does not exist in fData columns\", nn))\n            }\n        }\n        if (\"sampleid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            if (!all(SummarizedExperiment::colData(profile)[, \"sampleid\"] %in% rownames(sampleInfo(tSet)))) {\n                .warning(sprintf(\"%s: not all the cell lines in this profile are in cell lines slot\", nn))\n            }\n        } else {\n            .warning(sprintf(\"%s: sampleid does not exist in pData\", nn))\n        }\n    }\n    if (\"tissueid\" %in% colnames(sampleInfo(tSet))) {\n        if (\"unique.tissueid\" %in% colnames(curation(tSet)$tissue)) {\n        if (length(intersect(rownames(curation(tSet)$tissue), rownames(sampleInfo(tSet)))) != nrow(sampleInfo(tSet))) {\n            .message(\"rownames of curation tissue slot should be the same as cell slot (curated cell ids)\")\n        } else {\n            if(length(intersect(sampleInfo(tSet)$tissueid, curation(tSet)$tissue$unique.tissueid)) !=\n                length(table(sampleInfo(tSet)$tissueid)))\n            {\n                .message(\"tissueid should be the same as unique tissue id from tissue curation slot\")\n            }\n        }\n        } else {\n            .message(\"unique.tissueid which is curated tissue id across data set should be a column of tissue curation slot\")\n        }\n        if(any(is.na(sampleInfo(tSet)[,\"tissueid\"]) | sampleInfo(tSet)[,\"tissueid\"] == \"\", na.rm = TRUE)) {\n            .message(sprintf(\"There is no tissue type for this cell line(s): %s\", paste(rownames(sampleInfo(tSet))[which(is.na(sampleInfo(tSet)[,\"tissueid\"]) | sampleInfo(tSet)[,\"tissueid\"] == \"\")], collapse = \" \")))\n        }\n    } else {\n        .warning(\"tissueid does not exist in cell slot\")\n    }\n\n    if (\"unique.sampleid\" %in% colnames(curation(tSet)$cell)) {\n        if(length(intersect(curation(tSet)$cell$unique.sampleid, rownames(sampleInfo(tSet)))) != nrow(sampleInfo(tSet))) {\n            .message(\"rownames of cell slot should be curated cell ids\")\n        }\n    } else {\n        .message(\"unique.sampleid which is curated cell id across data set should be a column of cell curation slot\")\n    }\n\n    if (length(intersect(rownames(curation(tSet)$cell), rownames(sampleInfo(tSet)))) != nrow(sampleInfo(tSet))) {\n        .message(\"rownames of curation cell slot should be the same as cell slot (curated cell ids)\")\n    }\n\n    if (\"unique.treatmentid\" %in% colnames(curation(tSet)$treatment)) {\n        if(length(intersect(curation(tSet)$treatment$unique.treatmentid, treatmentNames(tSet))) != nrow(treatmentInfo(tSet))) {\n            .message(\"rownames of drug slot should be curated drug ids\")\n        }\n    } else {\n        .message(\"unique.treatmentid which is curated drug id across data set should be a column of drug curation slot\")\n    }\n\n    if (length(intersect(rownames(curation(tSet)$cell), rownames(sampleInfo(tSet)))) != nrow(sampleInfo(tSet))) {\n        .message(\"rownames of curation drug slot should be the same as drug slot (curated drug ids)\")\n    }\n\n    if (!is(sampleInfo(tSet), \"data.frame\")) {\n        .warning(\"cell slot class type should be dataframe\")\n    }\n    if (!is(treatmentInfo(tSet), \"data.frame\")) {\n        .warning(\"drug slot class type should be dataframe\")\n    }\n    if (datasetType(tSet) %in% c(\"sensitivity\", \"both\"))\n    {\n        if(!is(sensitivityInfo(tSet), \"data.frame\")) {\n            .warning(\"sensitivity info slot class type should be dataframe\")\n        }\n        if(\"sampleid\" %in% colnames(sensitivityInfo(tSet))) {\n            if(!all(sensitivityInfo(tSet)[,\"sampleid\"] %in% rownames(sampleInfo(tSet)))) {\n                .warning(\"not all the cell lines in sensitivity data are in cell slot\")\n            }\n        } else {\n            .warning(\"sampleid does not exist in sensitivity info\")\n        }\n        if (\"treatmentid\" %in% colnames(sensitivityInfo(tSet))) {\n            drug.ids <- unique(sensitivityInfo(tSet)[, \"treatmentid\"])\n            drug.ids <- drug.ids[grep(\"///\",drug.ids, invert=TRUE)]\n            if (!all(drug.ids %in% treatmentNames(tSet))) {\n                .message(\"not all the drugs in sensitivity data are in drug slot\")\n            }\n        } else {\n            .warning(\"treatmentid does not exist in sensitivity info\")\n        }\n\n        if (any(!is.na(sensitivityRaw(tSet)))) {\n            if(!all(dimnames(sensitivityRaw(tSet))[[1]] %in% rownames(sensitivityInfo(tSet)))) {\n                .warning(\"For some experiments there is raw sensitivity data but no experimet information in sensitivity info\")\n            }\n        }\n        if (!all(rownames(sensitivityProfiles(tSet)) %in% rownames(sensitivityInfo(tSet)))) {\n            .warning(\"For some experiments there is sensitivity profiles but no experimet information in sensitivity info\")\n        }\n    }\n}\n\n\n\n# -------------------------------------------------------------------------\n# Method Definitions ------------------------------------------------------\n# -------------------------------------------------------------------------\n\n\n##  here\n#' Show a ToxicoSet\n#'\n#' @param object A \\code{ToxicoSet} object to print a summary for\n#'\n#' @examples\n#' TGGATESsmall\n#'\n#' @return Prints the ToxicoSet object to the output stream, and returns\n#'   invisible NULL.\n#'\n#' @importMethodsFrom CoreGx show\n#' @export\nsetMethod(\"show\", signature=signature(object=\"ToxicoSet\"), function(object) {\n    callNextMethod(object)\n})\n\n\n#' Get the dimensions of a ToxicoSet\n#'\n#' @examples\n#' data(TGGATESsmall)\n#' dim(TGGATESsmall)\n#'\n#' @param x ToxicoSet\n#' @return A named vector with the number of Cells and Drugs in the ToxicoSet\n#' @export\nsetMethod(\"dim\", signature(\"ToxicoSet\"), function(x) {\n    return(c(Cells=length(sampleNames(x)), Drugs=length(treatmentNames(x))))\n})\n\n\n#' @importFrom CoreGx updateSampleId\n#' @aliases updateCellId\nupdateSampleId <- updateCellId <- function(object, new.ids=vector('character')) {\n    CoreGx:::updateSampleId(object, new.ids)\n}\n\n#' @importFrom CoreGx updateTreatmentId\n#' @aliases updateDrugId\nupdateTreatmentId <- updateDrugId <- function(object, new.ids=vector('character')) {\n    CoreGx:::updateTreamentId(object, new.ids)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the ToxicoSet class in this code snippet?",
        "answer": "The ToxicoSet class is designed to contain and organize large toxicogenomic datasets. It provides useful tools for interacting with this data, including functions for exploring the relationship between survival fraction and gene expression in cultured human and rat tissues during exposure to a wide range of compounds. Features include plotting dose and exposure time curves, calculating AUC, fitting linear models, and computing sensitivity signatures."
      },
      {
        "question": "What are the main slots defined in the ToxicoSet class?",
        "answer": "The main slots defined in the ToxicoSet class are: annotation, molecularProfiles, sample, treatment, treatmentResponse, perturbation, curation, and datasetType. Each slot contains specific types of data or metadata related to the toxicogenomic experiments, such as sample annotations, molecular profiles, treatment information, and sensitivity data."
      },
      {
        "question": "What is the purpose of the `checkTSetStructure` function in this code?",
        "answer": "The `checkTSetStructure` function is used to verify the structure of a ToxicoSet object. It checks that the correct annotations are in place and all required slots are filled, ensuring that matching of cells and drugs can be properly done across different types of data and with other studies. The function prints out messages describing any errors found in the structure of the ToxicoSet object passed to it."
      }
    ],
    "completion_tasks": [
      {
        "partial": "ToxicoSet <- function(name,\n                       molecularProfiles=list(),\n                       sample=data.frame(),\n                       treatment=data.frame(),\n                       sensitivityInfo=data.frame(),\n                       sensitivityRaw=array(dim = c(0,0,0)),\n                       sensitivityProfiles=matrix(),\n                       sensitivityN=matrix(nrow = 0, ncol=0),\n                       perturbationN=array(NA, dim = c(0,0,0)),\n                       curationTreatment=data.frame(),\n                       curationSample = data.frame(),\n                       curationTissue = data.frame(),\n                       datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                       verify = TRUE)\n{\n    # Constructor body\n}",
        "complete": "ToxicoSet <- function(name,\n                       molecularProfiles=list(),\n                       sample=data.frame(),\n                       treatment=data.frame(),\n                       sensitivityInfo=data.frame(),\n                       sensitivityRaw=array(dim = c(0,0,0)),\n                       sensitivityProfiles=matrix(),\n                       sensitivityN=matrix(nrow = 0, ncol=0),\n                       perturbationN=array(NA, dim = c(0,0,0)),\n                       curationTreatment=data.frame(),\n                       curationSample = data.frame(),\n                       curationTissue = data.frame(),\n                       datasetType=c(\"sensitivity\", \"perturbation\", \"both\"),\n                       verify = TRUE)\n{\n    cSet <- CoreGx::CoreSet(\n        name=name,\n        sample=sample,\n        treatment=treatment,\n        molecularProfiles=molecularProfiles,\n        sensitivityInfo=sensitivityInfo,\n        sensitivityRaw=sensitivityRaw,\n        sensitivityProfiles=sensitivityProfiles,\n        sensitivityN=sensitivityN,\n        perturbationN=perturbationN,\n        curationTreatment=curationTreatment,\n        curationSample=curationSample,\n        curationTissue=curationTissue,\n        datasetType=datasetType,\n        verify=verify\n    )\n\n    tSet  <- .ToxicoSet(\n        annotation=cSet@annotation,\n        molecularProfiles=cSet@molecularProfiles,\n        sample=cSet@sample,\n        treatment=cSet@treatment,\n        datasetType=cSet@datasetType,\n        treatmentResponse=cSet@treatmentResponse,\n        perturbation=cSet@perturbation,\n        curation=cSet@curation\n    )\n    if (verify) { checkTSetStructure(tSet) }\n    if (length(sensitivityN) == 0 && datasetType %in% c(\"sensitivity\", \"both\")) {\n        sensNumber(tSet) <- .summarizeSensitivityNumbers(tSet)\n    }\n    if (length(perturbationN) == 0  && datasetType %in% c(\"perturbation\", \"both\")) {\n        pertNumber(tSet) <- .summarizePerturbationNumbers(tSet)\n    }\n    return(tSet)\n}"
      },
      {
        "partial": "checkTSetStructure <- function(tSet, plotDist=FALSE, result.dir=\".\") {\n    # Function body\n}",
        "complete": "checkTSetStructure <- function(tSet, plotDist=FALSE, result.dir=\".\") {\n    if(!file.exists(result.dir) && plotDist)\n        dir.create(result.dir, showWarnings=FALSE, recursive=TRUE)\n\n    for(i in seq_along(molecularProfilesSlot(tSet))) {\n        profile <- molecularProfilesSlot(tSet)[[i]]\n        if (is.null(names(metadata(profile))))\n            .error(paste0(\"Please ensure all items in the metadata slot of\n                 SummarizedExperiments are named. Item \", i, \" of molecualrProfiles\n                 does not have metadata names.\"))\n        if (!(\"annotation\" %in% names(metadata(profile))))\n            .error(paste0(\"At minimum the SummarizedExperiments in molecularProfiles must contain\n                    a metadata item names 'annotation' specifying the molecular datatype\n                   the SummarizedExperiment contains! Item \", i, \" of\n                   molecularProfilesis missing annotation metadata.\"))\n        nn <- names(molecularProfilesSlot(tSet))[i]\n\n        if(plotDist) {\n            if (S4Vectors::metadata(profile)$annotation == \"rna\" ||\n                S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n            {\n                pdf(file=file.path(result.dir, sprintf(\"%s.pdf\", nn)))\n                hist(SummarizedExperiment::assay(profile, 1), breaks = 100)\n                dev.off()\n            }\n        }\n        if (nrow(SummarizedExperiment::rowData(profile)) !=\n            nrow(SummarizedExperiment::assay(profile, 1)))\n        {\n            .warning(sprintf(\"%s: number of features in fData is different from expression slots\", nn))\n        } else {\n            .message(sprintf(\"%s: fData dimension is OK\", nn))\n        }\n        if (nrow(SummarizedExperiment::colData(profile)) != ncol(SummarizedExperiment::assay(profile, 1)))\n        {\n            .warning(sprintf(\"%s: number of cell lines in pData is different from expression slots\", nn))\n        } else {\n            .message(sprintf(\"%s: pData dimension is OK\", nn))\n        }\n\n        if (\"sampleid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            .message(\"sampleid OK!\")\n        } else {\n            .warning(sprintf(\"%s: sampleid does not exist in pData columns\", nn))\n        }\n        if (\"batchid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            .message(\"batchid OK!\")\n        } else {\n            .warning(sprintf(\"%s: batchid does not exist in pData columns\", nn))\n        }\n        if (S4Vectors::metadata(profile)$annotation == \"rna\" ||\n            S4Vectors::metadata(profile)$annotation == \"rnaseq\")\n        {\n            if (\"BEST\" %in% colnames(SummarizedExperiment::rowData(profile))) {\n                .message(\"BEST is OK\")\n            } else {\n                .warning(sprintf(\"%s: BEST does not exist in fData columns\", nn))\n            }\n\n            if (\"Symbol\" %in% colnames(SummarizedExperiment::rowData(profile))) {\n                .message(\"Symbol is OK\")\n            } else {\n                .warning(sprintf(\"%s: Symbol does not exist in fData columns\", nn))\n            }\n        }\n        if (\"sampleid\" %in% colnames(SummarizedExperiment::colData(profile))) {\n            if (!all(SummarizedExperiment::colData(profile)[, \"sampleid\"] %in% rownames(sampleInfo(tSet)))) {\n                .warning(sprintf(\"%s: not all the cell lines in this profile are in cell lines slot\", nn))\n            }\n        } else {\n            .warning(sprintf(\"%s: sampleid does not exist in pData\", nn))\n        }\n    }\n    # Additional checks...\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/collapseIDs.R",
    "language": "R",
    "content": "#' @title Utility function to collapse IDs\n#'\n#' @description\n#' Utility function called within the claudinLow classifier\n#'\n#' @usage\n#' collapseIDs(x,allids=row.names(x),method=\"mean\")\n#'\n#' @param x Matrix of numbers.\n#' @param allids Defaults to rownames of matrix.\n#' @param method Default method is \"mean\".\n#'\n#'\n#' @return\n#' A matrix\n#'\n#' @references\n#' citation(\"claudinLow\")\n#'\n#' @seealso\n#' [genefu::claudinLow]\n#'\n#' @md\n#' @export\ncollapseIDs <- function(x,allids=row.names(x),method=\"mean\"){\n\n  allids<-as.vector(allids)\n  ids<- levels(as.factor(allids))\n  x.col<- matrix(nrow=length(ids), ncol=dim(x)[2])\n\n  if(length(ids)==dim(x)[1]){\n    dimnames(x)[[1]]<-allids\n    return(x)\n  }\n\n  for(i in 1:length(ids)){\n    if(sum(allids==ids[i])>1){\n      indices <- allids==ids[i]\n      if(method==\"mean\"){\n        vals<-apply(x[indices,],2,mean,na.rm=TRUE)\n      }\n      if(method==\"median\"){\n        vals<-apply(x[indices,],2,median,na.rm=TRUE)\n      }\n      if(method==\"stdev\"){\n        temp<- x[indices,]\n        stdevs<- apply(temp,1,sd,na.rm=TRUE)\n        vals<- temp[match(max(stdevs),stdevs),]\n      }\n      if(method==\"sum\"){\n        vals<-apply(x[indices,],2,sum,na.rm=TRUE)\n      }\n      if(method==\"iqr\"){\n        temp<- x[indices,]\n        iqrs<- apply(temp,1,function(x){quantile(x,.75,na.rm=TRUE) -\n            quantile(x,.25,na.rm=TRUE)})\n        vals<- temp[match(max(iqrs),iqrs),]\n      }\n      x.col[i,] <- vals\n    }else{\n      x.col[i,] <- t(as.vector(x[allids==ids[i],]))\n    }\n  }\n\n  dimnames(x.col)<- list(ids,dimnames(x)[[2]])\n  return(x.col)\n\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `collapseIDs` function in the given R code snippet?",
        "answer": "The `collapseIDs` function is a utility function used within the claudinLow classifier. Its purpose is to collapse multiple rows in a matrix that share the same ID into a single row, using a specified method (e.g., mean, median, standard deviation, sum, or interquartile range) to aggregate the values."
      },
      {
        "question": "How does the function handle cases where there are multiple rows with the same ID?",
        "answer": "When multiple rows share the same ID, the function applies the specified aggregation method (default is 'mean') to combine these rows. It uses the `apply` function with the chosen method (e.g., `mean`, `median`, `sd`, `sum`) to calculate the aggregated values across the columns for the rows with the same ID."
      },
      {
        "question": "What is the significance of the 'stdev' and 'iqr' methods in the `collapseIDs` function?",
        "answer": "The 'stdev' and 'iqr' methods are special cases in the function. Instead of aggregating values, they select a single row based on a criterion. For 'stdev', it chooses the row with the highest standard deviation across its values. For 'iqr', it selects the row with the largest interquartile range. These methods are useful when you want to retain the most variable or spread-out row among those sharing the same ID."
      }
    ],
    "completion_tasks": [
      {
        "partial": "collapseIDs <- function(x, allids = row.names(x), method = \"mean\") {\n  allids <- as.vector(allids)\n  ids <- levels(as.factor(allids))\n  x.col <- matrix(nrow = length(ids), ncol = dim(x)[2])\n\n  if (length(ids) == dim(x)[1]) {\n    dimnames(x)[[1]] <- allids\n    return(x)\n  }\n\n  for (i in 1:length(ids)) {\n    if (sum(allids == ids[i]) > 1) {\n      indices <- allids == ids[i]\n      # Complete the code here\n    } else {\n      x.col[i,] <- t(as.vector(x[allids == ids[i],]))\n    }\n  }\n\n  dimnames(x.col) <- list(ids, dimnames(x)[[2]])\n  return(x.col)\n}",
        "complete": "collapseIDs <- function(x, allids = row.names(x), method = \"mean\") {\n  allids <- as.vector(allids)\n  ids <- levels(as.factor(allids))\n  x.col <- matrix(nrow = length(ids), ncol = dim(x)[2])\n\n  if (length(ids) == dim(x)[1]) {\n    dimnames(x)[[1]] <- allids\n    return(x)\n  }\n\n  for (i in 1:length(ids)) {\n    if (sum(allids == ids[i]) > 1) {\n      indices <- allids == ids[i]\n      vals <- switch(method,\n        mean = apply(x[indices,], 2, mean, na.rm = TRUE),\n        median = apply(x[indices,], 2, median, na.rm = TRUE),\n        stdev = {\n          temp <- x[indices,]\n          stdevs <- apply(temp, 1, sd, na.rm = TRUE)\n          temp[which.max(stdevs),]\n        },\n        sum = apply(x[indices,], 2, sum, na.rm = TRUE),\n        iqr = {\n          temp <- x[indices,]\n          iqrs <- apply(temp, 1, function(x) diff(quantile(x, c(0.25, 0.75), na.rm = TRUE)))\n          temp[which.max(iqrs),]\n        }\n      )\n      x.col[i,] <- vals\n    } else {\n      x.col[i,] <- t(as.vector(x[allids == ids[i],]))\n    }\n  }\n\n  dimnames(x.col) <- list(ids, dimnames(x)[[2]])\n  return(x.col)\n}"
      },
      {
        "partial": "#' @title Utility function to collapse IDs\n#'\n#' @param x Matrix of numbers.\n#' @param allids Defaults to rownames of matrix.\n#' @param method Default method is \"mean\".\n#'\n#' @return A matrix\n#'\n#' @export\ncollapseIDs <- function(x, allids = row.names(x), method = \"mean\") {\n  # Complete the function body here\n}",
        "complete": "#' @title Utility function to collapse IDs\n#'\n#' @param x Matrix of numbers.\n#' @param allids Defaults to rownames of matrix.\n#' @param method Default method is \"mean\".\n#'\n#' @return A matrix\n#'\n#' @export\ncollapseIDs <- function(x, allids = row.names(x), method = \"mean\") {\n  allids <- as.vector(allids)\n  ids <- levels(as.factor(allids))\n  x.col <- matrix(nrow = length(ids), ncol = ncol(x))\n\n  if (length(ids) == nrow(x)) {\n    rownames(x) <- allids\n    return(x)\n  }\n\n  for (i in seq_along(ids)) {\n    indices <- allids == ids[i]\n    if (sum(indices) > 1) {\n      x.col[i,] <- switch(method,\n        mean = colMeans(x[indices,], na.rm = TRUE),\n        median = apply(x[indices,], 2, median, na.rm = TRUE),\n        stdev = x[indices,][which.max(apply(x[indices,], 1, sd, na.rm = TRUE)),],\n        sum = colSums(x[indices,], na.rm = TRUE),\n        iqr = x[indices,][which.max(apply(x[indices,], 1, function(x) diff(quantile(x, c(0.25, 0.75), na.rm = TRUE)))),]\n      )\n    } else {\n      x.col[i,] <- x[indices,]\n    }\n  }\n\n  dimnames(x.col) <- list(ids, colnames(x))\n  return(x.col)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/compare.proto.cor.R",
    "language": "R",
    "content": "#' @title Function to statistically compare correlation to prototypes\n#'\n#' @description\n#' This function performs a statistical comparison of the correlation \n#'  coefficients as computed between each probe and prototype.\n#'\n#' @usage\n#' compareProtoCor(gene.cor, proto.cor, nn,\n#'  p.adjust.m = c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\"))\n#'\n#' @param gene.cor Correlation coefficients between the probes and each of the prototypes.\n#' @param proto.cor Pairwise correlation coefficients of the prototypes.\n#' @param nn Number of samples used to compute the correlation coefficients between\n#'   the probes and each of the prototypes.\n#' @param p.adjust.m Correction method as defined in p.adjust.\n#'\n#'\n#' @return\n#' Data frame with probes in rows and with three columns: \n#'  \"proto\" is the prototype to which the probe is the most correlated,  \n#'  \"cor\" is the actual correlation, and \"signif\" is the (corrected) p-value\n#'  for the superiority of the correlation to this prototype compared to the \n#'  second highest correlation.\n#'\n#' @seealso\n#' [genefu::compute.proto.cor.meta], [genefu::compute.pairw.cor.meta]\n#'\n#' @examples\n#' # load VDX dataset\n#' data(vdxs)\n#' # load NKI dataset\n#' data(nkis)\n#' # reduce datasets\n#' ginter <- intersect(annot.vdxs[ ,\"EntrezGene.ID\"], annot.nkis[ ,\"EntrezGene.ID\"])\n#' ginter <- ginter[!is.na(ginter)][1:30]\n#' myx <- unique(c(match(ginter, annot.vdxs[ ,\"EntrezGene.ID\"]),\n#'   sample(x=1:nrow(annot.vdxs), size=20)))\n#' data2.vdxs <- data.vdxs[ ,myx]\n#' annot2.vdxs <- annot.vdxs[myx, ]\n#' myx <- unique(c(match(ginter, annot.nkis[ ,\"EntrezGene.ID\"]),\n#' sample(x=1:nrow(annot.nkis), size=20)))\n#' data2.nkis <- data.nkis[ ,myx]\n#' annot2.nkis <- annot.nkis[myx, ]\n#' # mapping of datasets\n#' datas <- list(\"VDX\"=data2.vdxs,\"NKI\"=data2.nkis)\n#' annots <- list(\"VDX\"=annot2.vdxs, \"NKI\"=annot2.nkis)\n#' datas.mapped <- map.datasets(datas=datas, annots=annots, do.mapping=TRUE)\n#' # define some prototypes\n#' protos <- paste(\"geneid\", ginter[1:3], sep=\".\")\n#' # compute meta-estimate of correlation coefficients to the three prototype genes\n#' probecor <- compute.proto.cor.meta(datas=datas.mapped$datas, proto=protos,\n#'   method=\"pearson\")\n#' # compute meta-estimate of pairwise correlation coefficients between prototypes\n#' datas.proto <- lapply(X=datas.mapped$datas, FUN=function(x, p) {\n#'   return(x[ ,p,drop=FALSE]) }, p=protos)\n#' protocor <- compute.pairw.cor.meta(datas=datas.proto, method=\"pearson\")\n#' # compare correlation coefficients to each prototype\n#' res <- compareProtoCor(gene.cor=probecor$cor, proto.cor=protocor$cor,\n#' nn=probecor$cor.n, p.adjust.m=\"fdr\")\n#' head(res)\n#'\n#' @md\n#' @export\ncompareProtoCor <-\nfunction(gene.cor, proto.cor, nn, p.adjust.m=c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\")) {\n\tp.adjust.m <- match.arg(p.adjust.m)\n\tproto <- dimnames(proto.cor)[[1]]\n\t## select the best two absolute correlations\n\tbest2corix <- t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(order(abs(x), decreasing=TRUE)[1:2]) }))\n\tbest2corn <- apply(X=t(apply(X=nn, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), MARGIN=1, FUN=min) ## not perfect since we are not sure that the samples were paired\n\tbest2cor <- cbind(t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), proto.cor[best2corix], best2corn)\n\tdimnames(best2cor) <- list(dimnames(gene.cor)[[1]], c(\"r.x1y\", \"r.x2y\", \"r.x1x2\", \"nn\"))\n\t\n\trr <- apply(X=best2cor, MARGIN=1, FUN=function(x) { return(cordiff.dep(r.x1y=abs(x[1]), r.x2y=abs(x[2]), r.x1x2=abs(x[3]), n=x[4], alternative=\"greater\")) })\n\trr <- rr[\"p.value\",  , drop=TRUE]\n\trr <- p.adjust(rr, method=p.adjust.m)\n\tnames(rr) <- dimnames(best2cor)[[1]]\n\tif(!is.null(names(proto))) {\n\t\trr2 <- data.frame(\"proto\"=names(proto)[best2corix[ ,1]], \"cor\"=best2cor[ , 1], \"signif\"=rr, row.names=dimnames(best2cor)[[1]], stringsAsFactors=FALSE)\n\t} else {\n\t\trr2 <- data.frame(\"proto\"=proto[best2corix[ ,1]], \"cor\"=best2cor[ , 1], \"signif\"=rr,  row.names=dimnames(best2cor)[[1]], stringsAsFactors=FALSE)\n\t}\n\n\treturn(rr2)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `compareProtoCor` function and what are its main input parameters?",
        "answer": "The `compareProtoCor` function performs a statistical comparison of correlation coefficients between probes and prototypes. Its main input parameters are: `gene.cor` (correlation coefficients between probes and prototypes), `proto.cor` (pairwise correlation coefficients of prototypes), `nn` (number of samples used for correlation computation), and `p.adjust.m` (method for p-value adjustment)."
      },
      {
        "question": "How does the function handle the selection of the best two absolute correlations for each probe?",
        "answer": "The function selects the best two absolute correlations for each probe using the `order` function with `decreasing=TRUE`. It applies this to both the correlation values (`gene.cor`) and the sample sizes (`nn`). The results are stored in `best2corix` for indices, `best2corn` for sample sizes, and `best2cor` for the actual correlation values and related information."
      },
      {
        "question": "What does the function return, and how is the statistical significance of the correlations determined?",
        "answer": "The function returns a data frame with three columns: 'proto' (the prototype with the highest correlation), 'cor' (the actual correlation value), and 'signif' (the adjusted p-value). The statistical significance is determined using the `cordiff.dep` function to compare the highest correlation to the second highest, and then adjusting the resulting p-values using the method specified in `p.adjust.m`."
      }
    ],
    "completion_tasks": [
      {
        "partial": "compareProtoCor <- function(gene.cor, proto.cor, nn, p.adjust.m=c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\")) {\n  p.adjust.m <- match.arg(p.adjust.m)\n  proto <- dimnames(proto.cor)[[1]]\n  best2corix <- t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(order(abs(x), decreasing=TRUE)[1:2]) }))\n  best2corn <- apply(X=t(apply(X=nn, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), MARGIN=1, FUN=min)\n  best2cor <- cbind(t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), proto.cor[best2corix], best2corn)\n  dimnames(best2cor) <- list(dimnames(gene.cor)[[1]], c(\"r.x1y\", \"r.x2y\", \"r.x1x2\", \"nn\"))\n  \n  # Complete the function by adding the code to calculate rr and rr2\n  \n}",
        "complete": "compareProtoCor <- function(gene.cor, proto.cor, nn, p.adjust.m=c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\")) {\n  p.adjust.m <- match.arg(p.adjust.m)\n  proto <- dimnames(proto.cor)[[1]]\n  best2corix <- t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(order(abs(x), decreasing=TRUE)[1:2]) }))\n  best2corn <- apply(X=t(apply(X=nn, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), MARGIN=1, FUN=min)\n  best2cor <- cbind(t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), proto.cor[best2corix], best2corn)\n  dimnames(best2cor) <- list(dimnames(gene.cor)[[1]], c(\"r.x1y\", \"r.x2y\", \"r.x1x2\", \"nn\"))\n  \n  rr <- apply(X=best2cor, MARGIN=1, FUN=function(x) { return(cordiff.dep(r.x1y=abs(x[1]), r.x2y=abs(x[2]), r.x1x2=abs(x[3]), n=x[4], alternative=\"greater\")) })\n  rr <- rr[\"p.value\", , drop=TRUE]\n  rr <- p.adjust(rr, method=p.adjust.m)\n  names(rr) <- dimnames(best2cor)[[1]]\n  rr2 <- data.frame(\"proto\"=if(!is.null(names(proto))) names(proto)[best2corix[,1]] else proto[best2corix[,1]], \"cor\"=best2cor[,1], \"signif\"=rr, row.names=dimnames(best2cor)[[1]], stringsAsFactors=FALSE)\n  \n  return(rr2)\n}"
      },
      {
        "partial": "compareProtoCor <- function(gene.cor, proto.cor, nn, p.adjust.m=c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\")) {\n  p.adjust.m <- match.arg(p.adjust.m)\n  proto <- dimnames(proto.cor)[[1]]\n  # Add code to calculate best2corix, best2corn, and best2cor\n  \n  rr <- apply(X=best2cor, MARGIN=1, FUN=function(x) { return(cordiff.dep(r.x1y=abs(x[1]), r.x2y=abs(x[2]), r.x1x2=abs(x[3]), n=x[4], alternative=\"greater\")) })\n  rr <- rr[\"p.value\", , drop=TRUE]\n  rr <- p.adjust(rr, method=p.adjust.m)\n  names(rr) <- dimnames(best2cor)[[1]]\n  # Complete the function by adding the code to calculate rr2 and return the result\n  \n}",
        "complete": "compareProtoCor <- function(gene.cor, proto.cor, nn, p.adjust.m=c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\")) {\n  p.adjust.m <- match.arg(p.adjust.m)\n  proto <- dimnames(proto.cor)[[1]]\n  best2corix <- t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(order(abs(x), decreasing=TRUE)[1:2]) }))\n  best2corn <- apply(X=t(apply(X=nn, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), MARGIN=1, FUN=min)\n  best2cor <- cbind(t(apply(X=gene.cor, MARGIN=1, FUN=function(x) { return(x[order(abs(x), decreasing=TRUE)[1:2]]) })), proto.cor[best2corix], best2corn)\n  dimnames(best2cor) <- list(dimnames(gene.cor)[[1]], c(\"r.x1y\", \"r.x2y\", \"r.x1x2\", \"nn\"))\n  \n  rr <- apply(X=best2cor, MARGIN=1, FUN=function(x) { return(cordiff.dep(r.x1y=abs(x[1]), r.x2y=abs(x[2]), r.x1x2=abs(x[3]), n=x[4], alternative=\"greater\")) })\n  rr <- rr[\"p.value\", , drop=TRUE]\n  rr <- p.adjust(rr, method=p.adjust.m)\n  names(rr) <- dimnames(best2cor)[[1]]\n  rr2 <- data.frame(\"proto\"=if(!is.null(names(proto))) names(proto)[best2corix[,1]] else proto[best2corix[,1]], \"cor\"=best2cor[,1], \"signif\"=rr, row.names=dimnames(best2cor)[[1]], stringsAsFactors=FALSE)\n  \n  return(rr2)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/paramMissingHandlerTests.R",
    "language": "R",
    "content": "# A Handler to Assign Default Values for Missing Parameters\n#\n# This function will take in the params of a function as well as its name.\n#   Missing values will then be assigned to a list, which will be used to\n#   populate the parent functions scope with the correct default argument for\n#   each missing parameter\n#\n# @param funName \\code{character} A string of the function name. This argument is\n#   used to match the correct parameter checking conditions with each functionss\n# @param ... \\code{pairlist} A list of all parameters passed as arguements to the\n#   function \"funName\".\n#\n# @return \\code{list} A list of all missing parameter argument values, named\n#    with the respective missing parameters,\n#\n#' @keywords internal\nparamMissingHandlerTests <- function(funName, tSet, mDataType, ...) {\n\n  ## Errors if tSet parameter not passed an argument\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  } else if (missing(mDataType)) {\n    stop(paste0(funName, \" requires an mDataType argument!\"))\n  }\n\n  ## Interection of missing values for similar functions\n  intersectMissingChecks <- c(\n    \"cell_lines\", \"drugs\", \"features\", \"duration\"\n  )\n\n  missingChecks <-\n    switch(funName,\n           \"summarizeMolecularProfiles\" =\n             intersectMissingChecks\n    )\n\n  # Assigns values for missing parameters and throws messages\n  .checkParamsForMissingTests(\n    funName = funName, tSet = tSet, mDataType = mDataType,\n    missingChecks = missingChecks, ...\n    )\n}\n\n#' @keywords internal\n.checkParamsForMissingTests <- function(\n  funName = funName, tSet = tSet, missingChecks, mDataType, ...) {\n  # Initialize variable names in the local environment\n  cell_lines <- duration <- drugs <- features <- NULL\n  # Extract named arguments into local environment\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) { ## TODO:: Make this work with seq_along()\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n\n  message(paste(\"Testing paramMissingHandler returns correct messages for \"))\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {\n      message(paste0(missing, \" parameter not specified, defaults to all cell lines in the given tSet!\"))\n      },\n      \"drugs\" = {if (is.null(drugs)) { missingParamValues[[missing]] <- unique(treatmentNames(tSet));\n      message(paste0(missing, \" parameter not specified, defaults to all drugs in the given tSet!\"))}\n      },\n      \"features\" = {if (is.null(features)) {missingParamValues[[missing]] <- unique(fNames(tSet, mDataType));\n      message(paste0(missing, \" parameter not specified, defaults to all features in the given tSet for the specified mDataType!\"))}\n      },\n      \"duration\" = {if (is.null(duration)) {missingParamValues[[missing]] <- unique(as.character(ToxicoGx::sensitivityInfo(tSet)$duration_h));\n      message(paste0(missing, \" parameter not specified, defaults to all experimental durations in given tSet!\"))}\n      }\n    )\n  }\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `paramMissingHandlerTests` function in this code snippet?",
        "answer": "The `paramMissingHandlerTests` function is designed to handle missing parameters for a given function. It checks for required arguments, defines a set of parameters to check for missing values, and then calls `.checkParamsForMissingTests` to assign default values and display messages for missing parameters."
      },
      {
        "question": "How does the code handle the case when the 'tSet' or 'mDataType' arguments are missing?",
        "answer": "If the 'tSet' or 'mDataType' arguments are missing, the function stops execution and throws an error message. It uses the `missing()` function to check if these arguments are provided, and if not, it calls `stop()` with a custom error message indicating which argument is required."
      },
      {
        "question": "What is the purpose of the `switch` statement in the `.checkParamsForMissingTests` function?",
        "answer": "The `switch` statement in `.checkParamsForMissingTests` is used to handle different missing parameters. For each missing parameter (cell_lines, drugs, features, duration), it performs specific actions such as displaying a message or assigning default values. This allows for flexible handling of various missing parameters based on their names."
      }
    ],
    "completion_tasks": [
      {
        "partial": "paramMissingHandlerTests <- function(funName, tSet, mDataType, ...) {\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  } else if (missing(mDataType)) {\n    stop(paste0(funName, \" requires an mDataType argument!\"))\n  }\n\n  intersectMissingChecks <- c(\n    \"cell_lines\", \"drugs\", \"features\", \"duration\"\n  )\n\n  missingChecks <-\n    switch(funName,\n           \"summarizeMolecularProfiles\" =\n             intersectMissingChecks\n    )\n\n  # Complete the function by calling .checkParamsForMissingTests\n  # with the appropriate arguments\n}",
        "complete": "paramMissingHandlerTests <- function(funName, tSet, mDataType, ...) {\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  } else if (missing(mDataType)) {\n    stop(paste0(funName, \" requires an mDataType argument!\"))\n  }\n\n  intersectMissingChecks <- c(\n    \"cell_lines\", \"drugs\", \"features\", \"duration\"\n  )\n\n  missingChecks <-\n    switch(funName,\n           \"summarizeMolecularProfiles\" =\n             intersectMissingChecks\n    )\n\n  .checkParamsForMissingTests(\n    funName = funName, tSet = tSet, mDataType = mDataType,\n    missingChecks = missingChecks, ...\n  )\n}"
      },
      {
        "partial": ".checkParamsForMissingTests <- function(funName, tSet, missingChecks, mDataType, ...) {\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) {\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n  message(\"Testing paramMissingHandler returns correct messages for \")\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {\n        message(paste0(missing, \" parameter not specified, defaults to all cell lines in the given tSet!\"))\n      },\n      # Complete the function by adding cases for \"drugs\", \"features\", and \"duration\"\n    )\n  }\n}",
        "complete": ".checkParamsForMissingTests <- function(funName, tSet, missingChecks, mDataType, ...) {\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) {\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n  message(\"Testing paramMissingHandler returns correct messages for \")\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {\n        message(paste0(missing, \" parameter not specified, defaults to all cell lines in the given tSet!\"))\n      },\n      \"drugs\" = {\n        if (is.null(drugs)) {\n          message(paste0(missing, \" parameter not specified, defaults to all drugs in the given tSet!\"))\n        }\n      },\n      \"features\" = {\n        if (is.null(features)) {\n          message(paste0(missing, \" parameter not specified, defaults to all features in the given tSet for the specified mDataType!\"))\n        }\n      },\n      \"duration\" = {\n        if (is.null(duration)) {\n          message(paste0(missing, \" parameter not specified, defaults to all experimental durations in given tSet!\"))\n        }\n      }\n    )\n  }\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/concordance.index.R",
    "language": "R",
    "content": "`concordance.index` <-\nfunction(x, surv.time, surv.event, cl, weights, comppairs=10, strat, alpha=0.05, outx=TRUE, method=c(\"conservative\", \"noether\", \"nam\"), alternative=c(\"two.sided\", \"less\", \"greater\"), na.rm=FALSE) {\n\tmethod <- match.arg(method)\n\talternative <- match.arg(alternative)\n\tif(!missing(weights)) {\n\t\tif(length(weights) != length(x)) { stop(\"bad length for parameter weights!\") }\n\t\tif(min(weights, na.rm=TRUE) < 0 && max(weights, na.rm=TRUE) > 1) { stop(\"weights must be a number between 0 and 1!\") }\n\t} else { weights <- rep(1, length(x)) }\n\tif(!missing(strat)) {\n\t\tif(length(strat) != length(x)) { stop(\"bad length for parameter strat!\") }\n\t} else { strat <- rep(1, length(x)) }\n\n\tif(missing(cl) && (missing(surv.time) || missing(surv.event))) { stop(\"binary classes and survival data are missing!\") }\n\tif(!missing(cl) && (!missing(surv.time) || !missing(surv.event))) { stop(\"choose binary classes or survival data but not both!\") }\n\tmsurv <- FALSE\n\tif(missing(cl)) { ## survival data\n\t\tmsurv <- TRUE\n\t\tcl <- rep(0, length(x))\n\t} else { surv.time <- surv.event <- rep(0, length(x)) } ## binary classes\n\n\tcc.ix <- complete.cases(x, surv.time, surv.event, cl, weights, strat)\n\tif(sum(cc.ix) < 3) {\n\t## not enough observations\n\t\tif(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n\t\treturn(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=sum(cc.ix), \"data\"=data, \"comppairs\"=NA))\n\t}\n\tif(any(!cc.ix) & !na.rm) { stop(\"NA values are present!\") }\n  ## remove samples whose the weight is equal to 0 to speed up the computation of the concordance index\n\tcc.ix <- cc.ix & weights != 0\n\tx2 <- x[cc.ix]\n\tcl2 <- cl[cc.ix]\n\tst <- surv.time[cc.ix]\n\tse <- surv.event[cc.ix]\n\tif(msurv && sum(se) == 0) {\n\t\twarning(\"\\nno events, the concordance index cannot be computed!\")\n\t\tdata <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event)\n\t\treturn(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n\t}\n\tif(!msurv && length(unique(cl2)) == 1) {\n\t\twarning(\"\\nonly one class, the concordance index cannot be computed!\")\n\t\tdata  <- list(\"x\"=x, \"cl\"=cl)\n\t\treturn(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n\t}\n\tweights <- weights[cc.ix]\n\tstrat <- strat[cc.ix]\n\tstrat <- as.numeric(as.factor(strat))\n\tustrat <- sort(unique(strat)) ## to check later\n\tN <- sum(weights) ##length(x2)\n\tif(N <= 1) {\n    warning(\"\\nweights of observations are too small (sum should be > 1), the concordance index cannot be computed!\")\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=NA))\n  }\n\n\tch <- dh <- uh <- rph <- rep(0, times=length(strat))\n\tlenS <- length(strat)\n\tlenU <- length(ustrat)\n\tout <- .C(.C_concordanceIndexC, as.integer(as.logical(msurv)), as.integer(ustrat), as.double(x2),\n\t\t\tas.integer(cl2), as.double(st), as.integer(se), as.double(weights), as.integer(strat),\n\t\t\tas.integer(N), as.integer(as.logical(outx)), ch = as.numeric(ch), dh = as.numeric(dh),\n\t\t\tuh = as.numeric(uh), rph = as.numeric(rph), as.integer(lenS), as.integer(lenU), PACKAGE=\"survcomp\")\n  ch <- out$ch\n  dh <- out$dh\n  uh <- out$uh\n  rph <- out$rph\n  cscount <- sum(ch + dh) ## comparable pairs\n  if(sum(ch)==0 || sum(dh)==0 || sum(ch * (ch - 1))==0 || sum(dh * (dh - 1))==0 || sum(ch * dh)==0 || cscount < comppairs){\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=cscount))\n  }\n\n\tpc <- (1 / (N * (N - 1))) * sum(ch)\n\tpd  <- (1 / (N * (N - 1))) * sum(dh)\n\tcindex <- pc / (pc + pd)\n\n\tswitch(method,\n\t\"noether\"={\n    pcc <- (1 / (N * (N - 1) * (N - 2))) * sum(ch * (ch - 1))\n    pdd <- (1 / (N * (N - 1) * (N - 2))) * sum(dh * (dh - 1))\n    pcd <- (1 / (N * (N - 1) * (N - 2))) * sum(ch * dh)\n    varp <- (4 / (pc + pd)^4) * (pd^2 * pcc - 2 * pc * pd * pcd + pc^2 * pdd)\n    if((varp / N) > 0) {\n      ci <- qnorm(p=alpha / 2, lower.tail=FALSE) * sqrt(varp / N)\n      lower <- cindex - ci\n      upper <- cindex + ci\n      switch(alternative,\n\t\t   \"two.sided\"={ p <- pnorm((cindex - 0.5) / sqrt(varp / N), lower.tail=cindex < 0.5) * 2 },\n\t\t   \"less\"={ p <- pnorm((cindex - 0.5) / sqrt(varp / N), lower.tail=TRUE) },\n\t\t   \"greater\"={  p <- pnorm((cindex - 0.5) / sqrt(varp / N), lower.tail=FALSE) }\n\t    )\n    } else { ci <- lower <- upper <- p <- NA }\n  },\n\t\"conservative\"={\n    C <- cindex\n    ## pc and pd have been computed previously\n    w <- (2 * qnorm(p=alpha / 2, lower.tail=FALSE)^2) / (N * (pc + pd))\n    ci <- sqrt(w^2 + 4 * w * C * (1 - C)) / (2 * (1 + w))\n    point <- (w + 2 * C) / (2 * (1 + w))\n    lower <- point - ci\n    upper <- point + ci\n    cindex <- C\n    p <- NA\n    varp <- NA\n  },\n  \"name\"={\n    stop(\"method not implemented!\")\n  })\n  #bound the confidence interval\n  lower <- ifelse(lower < 0, 0, lower)\n  lower <- ifelse(lower > 1, 1, lower)\n  upper <- ifelse(upper < 0, 0, upper)\n  upper <- ifelse(upper > 1, 1, upper)\n  if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n  if(!is.na(varp) && (varp / N) > 0) { se <- sqrt(varp / N) } else { se <- NA }\n  return(list(\"c.index\"=cindex, \"se\"=se, \"lower\"=lower, \"upper\"=upper, \"p.value\"=p, \"n\"=length(x2), \"data\"=data, \"comppairs\"=cscount))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `concordance.index` function and what are its main input parameters?",
        "answer": "The `concordance.index` function calculates the concordance index (C-index) for survival analysis or binary classification. Its main input parameters are:\n- `x`: predictor variable\n- `surv.time` and `surv.event`: survival time and event indicator for survival analysis\n- `cl`: binary class labels for classification\n- `weights`: optional observation weights\n- `strat`: optional stratification variable\n- `method`: method for calculating confidence intervals ('conservative', 'noether', or 'nam')\n- `alternative`: type of alternative hypothesis for p-value calculation"
      },
      {
        "question": "How does the function handle missing data and what options are available for dealing with it?",
        "answer": "The function handles missing data in the following ways:\n1. It checks for complete cases using `complete.cases()` function.\n2. If there are fewer than 3 complete observations, it returns NA for all results.\n3. The `na.rm` parameter controls whether to stop execution if NA values are present (default) or remove them.\n4. Observations with zero weight are removed to speed up computation.\n5. If all events are censored in survival data or only one class is present in classification data, it returns NA with a warning."
      },
      {
        "question": "What are the different methods available for calculating the confidence interval of the C-index, and how are they implemented in the function?",
        "answer": "The function offers three methods for calculating the confidence interval of the C-index:\n1. 'noether': Uses Noether's method to estimate variance and calculate CI using normal approximation.\n2. 'conservative': Applies a conservative method using a quadratic equation to compute CI.\n3. 'nam': This method is not implemented and will raise an error if selected.\n\nThe method is chosen using the `method` parameter. The function uses a switch statement to select the appropriate calculation based on the chosen method. For 'noether' and 'conservative' methods, it calculates lower and upper bounds of the CI, while for 'nam' it raises an error."
      }
    ],
    "completion_tasks": [
      {
        "partial": "concordance.index <- function(x, surv.time, surv.event, cl, weights, comppairs=10, strat, alpha=0.05, outx=TRUE, method=c(\"conservative\", \"noether\", \"nam\"), alternative=c(\"two.sided\", \"less\", \"greater\"), na.rm=FALSE) {\n  method <- match.arg(method)\n  alternative <- match.arg(alternative)\n  if(!missing(weights)) {\n    if(length(weights) != length(x)) { stop(\"bad length for parameter weights!\") }\n    if(min(weights, na.rm=TRUE) < 0 && max(weights, na.rm=TRUE) > 1) { stop(\"weights must be a number between 0 and 1!\") }\n  } else { weights <- rep(1, length(x)) }\n  if(!missing(strat)) {\n    if(length(strat) != length(x)) { stop(\"bad length for parameter strat!\") }\n  } else { strat <- rep(1, length(x)) }\n\n  if(missing(cl) && (missing(surv.time) || missing(surv.event))) { stop(\"binary classes and survival data are missing!\") }\n  if(!missing(cl) && (!missing(surv.time) || !missing(surv.event))) { stop(\"choose binary classes or survival data but not both!\") }\n  msurv <- FALSE\n  if(missing(cl)) { ## survival data\n    msurv <- TRUE\n    cl <- rep(0, length(x))\n  } else { surv.time <- surv.event <- rep(0, length(x)) } ## binary classes\n\n  cc.ix <- complete.cases(x, surv.time, surv.event, cl, weights, strat)\n  if(sum(cc.ix) < 3) {\n    ## not enough observations\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=sum(cc.ix), \"data\"=data, \"comppairs\"=NA))\n  }\n  if(any(!cc.ix) & !na.rm) { stop(\"NA values are present!\") }\n  ## remove samples whose the weight is equal to 0 to speed up the computation of the concordance index\n  cc.ix <- cc.ix & weights != 0\n  x2 <- x[cc.ix]\n  cl2 <- cl[cc.ix]\n  st <- surv.time[cc.ix]\n  se <- surv.event[cc.ix]\n  if(msurv && sum(se) == 0) {\n    warning(\"\\nno events, the concordance index cannot be computed!\")\n    data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event)\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n  }\n  if(!msurv && length(unique(cl2)) == 1) {\n    warning(\"\\nonly one class, the concordance index cannot be computed!\")\n    data  <- list(\"x\"=x, \"cl\"=cl)\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n  }\n  weights <- weights[cc.ix]\n  strat <- strat[cc.ix]\n  strat <- as.numeric(as.factor(strat))\n  ustrat <- sort(unique(strat)) ## to check later\n  N <- sum(weights) ##length(x2)\n  if(N <= 1) {\n    warning(\"\\nweights of observations are too small (sum should be > 1), the concordance index cannot be computed!\")\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=NA))\n  }\n\n  ch <- dh <- uh <- rph <- rep(0, times=length(strat))\n  lenS <- length(strat)\n  lenU <- length(ustrat)\n  out <- .C(.C_concordanceIndexC, as.integer(as.logical(msurv)), as.integer(ustrat), as.double(x2),\n            as.integer(cl2), as.double(st), as.integer(se), as.double(weights), as.integer(strat),\n            as.integer(N), as.integer(as.logical(outx)), ch = as.numeric(ch), dh = as.numeric(dh),\n            uh = as.numeric(uh), rph = as.numeric(rph), as.integer(lenS), as.integer(lenU), PACKAGE=\"survcomp\")\n  ch <- out$ch\n  dh <- out$dh\n  uh <- out$uh\n  rph <- out$rph\n  cscount <- sum(ch + dh) ## comparable pairs\n  if(sum(ch)==0 || sum(dh)==0 || sum(ch * (ch - 1))==0 || sum(dh * (dh - 1))==0 || sum(ch * dh)==0 || cscount < comppairs){\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=cscount))\n  }\n\n  pc <- (1 / (N * (N - 1))) * sum(ch)\n  pd  <- (1 / (N * (N - 1))) * sum(dh)\n  cindex <- pc / (pc + pd)\n\n  # Complete the function by implementing the switch statement for different methods\n  # and returning the final result\n}",
        "complete": "concordance.index <- function(x, surv.time, surv.event, cl, weights, comppairs=10, strat, alpha=0.05, outx=TRUE, method=c(\"conservative\", \"noether\", \"nam\"), alternative=c(\"two.sided\", \"less\", \"greater\"), na.rm=FALSE) {\n  method <- match.arg(method)\n  alternative <- match.arg(alternative)\n  if(!missing(weights)) {\n    if(length(weights) != length(x)) { stop(\"bad length for parameter weights!\") }\n    if(min(weights, na.rm=TRUE) < 0 && max(weights, na.rm=TRUE) > 1) { stop(\"weights must be a number between 0 and 1!\") }\n  } else { weights <- rep(1, length(x)) }\n  if(!missing(strat)) {\n    if(length(strat) != length(x)) { stop(\"bad length for parameter strat!\") }\n  } else { strat <- rep(1, length(x)) }\n\n  if(missing(cl) && (missing(surv.time) || missing(surv.event))) { stop(\"binary classes and survival data are missing!\") }\n  if(!missing(cl) && (!missing(surv.time) || !missing(surv.event))) { stop(\"choose binary classes or survival data but not both!\") }\n  msurv <- FALSE\n  if(missing(cl)) { ## survival data\n    msurv <- TRUE\n    cl <- rep(0, length(x))\n  } else { surv.time <- surv.event <- rep(0, length(x)) } ## binary classes\n\n  cc.ix <- complete.cases(x, surv.time, surv.event, cl, weights, strat)\n  if(sum(cc.ix) < 3) {\n    ## not enough observations\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=sum(cc.ix), \"data\"=data, \"comppairs\"=NA))\n  }\n  if(any(!cc.ix) & !na.rm) { stop(\"NA values are present!\") }\n  ## remove samples whose the weight is equal to 0 to speed up the computation of the concordance index\n  cc.ix <- cc.ix & weights != 0\n  x2 <- x[cc.ix]\n  cl2 <- cl[cc.ix]\n  st <- surv.time[cc.ix]\n  se <- surv.event[cc.ix]\n  if(msurv && sum(se) == 0) {\n    warning(\"\\nno events, the concordance index cannot be computed!\")\n    data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event)\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n  }\n  if(!msurv && length(unique(cl2)) == 1) {\n    warning(\"\\nonly one class, the concordance index cannot be computed!\")\n    data  <- list(\"x\"=x, \"cl\"=cl)\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=0, \"data\"=data, \"comppairs\"=NA))\n  }\n  weights <- weights[cc.ix]\n  strat <- strat[cc.ix]\n  strat <- as.numeric(as.factor(strat))\n  ustrat <- sort(unique(strat)) ## to check later\n  N <- sum(weights) ##length(x2)\n  if(N <= 1) {\n    warning(\"\\nweights of observations are too small (sum should be > 1), the concordance index cannot be computed!\")\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=NA))\n  }\n\n  ch <- dh <- uh <- rph <- rep(0, times=length(strat))\n  lenS <- length(strat)\n  lenU <- length(ustrat)\n  out <- .C(.C_concordanceIndexC, as.integer(as.logical(msurv)), as.integer(ustrat), as.double(x2),\n            as.integer(cl2), as.double(st), as.integer(se), as.double(weights), as.integer(strat),\n            as.integer(N), as.integer(as.logical(outx)), ch = as.numeric(ch), dh = as.numeric(dh),\n            uh = as.numeric(uh), rph = as.numeric(rph), as.integer(lenS), as.integer(lenU), PACKAGE=\"survcomp\")\n  ch <- out$ch\n  dh <- out$dh\n  uh <- out$uh\n  rph <- out$rph\n  cscount <- sum(ch + dh) ## comparable pairs\n  if(sum(ch)==0 || sum(dh)==0 || sum(ch * (ch - 1))==0 || sum(dh * (dh - 1))==0 || sum(ch * dh)==0 || cscount < comppairs){\n    if(msurv) { data <- list(\"x\"=x, \"surv.time\"=surv.time, \"surv.event\"=surv.event) } else { data  <- list(\"x\"=x, \"cl\"=cl) }\n    return(list(\"c.index\"=NA, \"se\"=NA, \"lower\"=NA, \"upper\"=NA, \"p.value\"=NA, \"n\"=length(x2), \"data\"=data, \"comppairs\"=cs"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/overlapSets.R",
    "language": "R",
    "content": "#' @title Overlap two datasets\n#'\n#' @description\n#' Utility function called within the claudinLow classifien.\n#'\n#' @usage\n#' overlapSets(x,y)\n#'\n#' @param x\tMatrix1\n#' @param y\tMatrix2\n#'\n#' @return\n#' A list of overlapped dataset\n#'\n#' @references\n#' citation(\"claudinLow\")\n#'\n#' @seealso\n#' [genefu::claudinLow]\n#'\n#' @md\n#' @export\noverlapSets<-function(x,y){\n  \n  # subset the two lists to have a commonly ordered gene list\n  x<-x[dimnames(x)[[1]] %in% dimnames(y)[[1]],]\n  y<-y[dimnames(y)[[1]] %in% dimnames(x)[[1]],]\n  \n  #and sort such that thing are in the correct order\n  x<-x[sort.list(row.names(x)),]\n  y<-y[sort.list(row.names(y)),]\n  \n  return(list(x=x,y=y))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `overlapSets` function in the given R code snippet?",
        "answer": "The `overlapSets` function is a utility function used within the claudinLow classifier. Its purpose is to overlap two datasets (matrices) by finding common rows based on their row names, subsetting both matrices to include only these common rows, and then sorting the rows in both matrices to ensure they are in the same order."
      },
      {
        "question": "How does the function handle the case where the input matrices have different row names?",
        "answer": "The function handles matrices with different row names by using the `%in%` operator to subset both matrices. It keeps only the rows from each matrix that have corresponding row names in the other matrix. This effectively creates an intersection of the row names, ensuring that the resulting matrices contain only the common rows."
      },
      {
        "question": "What is the significance of the `sort.list(row.names(x))` and `sort.list(row.names(y))` operations in the function?",
        "answer": "These operations are used to sort the rows of both matrices based on their row names. The `sort.list` function returns the indices that would sort the row names alphabetically. By applying these sorted indices to both matrices, the function ensures that the rows in both resulting matrices are in the same order, which is crucial for maintaining consistency when comparing or analyzing the overlapped datasets."
      }
    ],
    "completion_tasks": [
      {
        "partial": "overlapSets <- function(x, y) {\n  x <- x[dimnames(x)[[1]] %in% dimnames(y)[[1]], ]\n  y <- y[dimnames(y)[[1]] %in% dimnames(x)[[1]], ]\n  \n  # Complete the function by sorting and returning the result\n}",
        "complete": "overlapSets <- function(x, y) {\n  x <- x[dimnames(x)[[1]] %in% dimnames(y)[[1]], ]\n  y <- y[dimnames(y)[[1]] %in% dimnames(x)[[1]], ]\n  \n  x <- x[order(rownames(x)), ]\n  y <- y[order(rownames(y)), ]\n  \n  list(x = x, y = y)\n}"
      },
      {
        "partial": "overlapSets <- function(x, y) {\n  common_genes <- intersect(rownames(x), rownames(y))\n  \n  # Complete the function by subsetting and returning the result\n}",
        "complete": "overlapSets <- function(x, y) {\n  common_genes <- intersect(rownames(x), rownames(y))\n  \n  x <- x[common_genes, ]\n  y <- y[common_genes, ]\n  \n  list(x = x, y = y)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/strescR.R",
    "language": "R",
    "content": "#' @title Utility function to escape LaTeX special characters \n#'   present in a string\n#'\n#' @description\n#' This function returns a vector of strings in which LaTeX special \n#'   characters are escaped, this was useful in conjunction with xtable.\n#'\n#' @usage\n#' strescR(strings)\n#'\n#' @param strings\tA vector of strings to deal with.\n#'\n#' @return\n#' A vector of strings with escaped characters within each string.\n#'\n#' @references\n#' citation(\"seqinr\")\n#'\n#' @seealso\n#' stresc\n#' \n#' @examples\n#' strescR(\"MISC_RNA\")\n#' strescR(c(\"BB_0001\",\"BB_0002\"))\n#'\n#' @md\n#' @export\nstrescR <-\nfunction (strings) {\n\n\tc2s <- function (chars = c(\"m\", \"e\", \"r\", \"g\", \"e\", \"d\")) {\n\t\treturn(paste(chars, collapse = \"\"))\n\t}\n\t\n\ts2c <- function (string) {\n\t\tif (is.character(string) && length(string) == 1) {\n\t\t\treturn(unlist(strsplit(string, split = \"\")))\n\t\t} else {\n\t\t\twarning(\"Wrong argument type in s2c(), NA returned\")\n\t\t\treturn(NA)\n\t\t}\n\t}\n\n\tfromchar <- s2c(\"\\\\{}$^_%#&~[]\")\n\ttochar <- c(\"$\\\\backslash$\", \"\\\\{\", \"\\\\}\", \"\\\\$\", \"\\\\^{}\", \n\t\"\\\\_\", \"\\\\%\", \"\\\\#\", \"\\\\&\", \"\\\\~{}\", \"\\\\[\", \"\\\\]\")\n\tf <- function(string) {\n\t\tc2s(sapply(s2c(string), function(x) ifelse(x %in% fromchar, tochar[which(x == fromchar)], x)))\n\t}\n\t\n\treturn(sapply(strings, f, USE.NAMES = FALSE))\n}",
    "qa_pairs": [
      {
        "question": "What is the primary purpose of the `strescR` function in this code snippet?",
        "answer": "The primary purpose of the `strescR` function is to escape LaTeX special characters present in a string or vector of strings. It takes a vector of strings as input and returns a vector of strings with LaTeX special characters properly escaped, which is useful when working with tools like xtable that generate LaTeX output."
      },
      {
        "question": "How does the function handle multiple input strings, and what data structure does it return?",
        "answer": "The function can handle multiple input strings by accepting a vector of strings as its input parameter. It processes each string in the vector using the `sapply` function, which applies the escaping logic to each element. The function returns a vector of strings, where each element is the escaped version of the corresponding input string. The `USE.NAMES = FALSE` argument in the `sapply` call ensures that the output is a simple vector without names."
      },
      {
        "question": "What are the helper functions `c2s` and `s2c` used for within the `strescR` function, and why are they important?",
        "answer": "The `c2s` (characters to string) and `s2c` (string to characters) are helper functions used within `strescR`. `c2s` concatenates a vector of characters into a single string, while `s2c` splits a string into a vector of individual characters. These functions are important because they allow the main escaping logic to work on individual characters of each input string, making it easier to identify and replace LaTeX special characters. The `s2c` function also includes error checking to ensure the input is a single string, improving the robustness of the code."
      }
    ],
    "completion_tasks": [
      {
        "partial": "strescR <- function(strings) {\n  fromchar <- s2c(\"\\\\{}$^_%#&~[]\")\n  tochar <- c(\"$\\\\backslash$\", \"\\\\{\", \"\\\\}\", \"\\\\$\", \"\\\\^{}\", \n  \"\\\\_\", \"\\\\%\", \"\\\\#\", \"\\\\&\", \"\\\\~{}\", \"\\\\[\", \"\\\\]\")\n  f <- function(string) {\n    # Complete the function body\n  }\n  return(sapply(strings, f, USE.NAMES = FALSE))\n}",
        "complete": "strescR <- function(strings) {\n  fromchar <- s2c(\"\\\\{}$^_%#&~[]\")\n  tochar <- c(\"$\\\\backslash$\", \"\\\\{\", \"\\\\}\", \"\\\\$\", \"\\\\^{}\", \n  \"\\\\_\", \"\\\\%\", \"\\\\#\", \"\\\\&\", \"\\\\~{}\", \"\\\\[\", \"\\\\]\")\n  f <- function(string) {\n    c2s(sapply(s2c(string), function(x) ifelse(x %in% fromchar, tochar[which(x == fromchar)], x)))\n  }\n  return(sapply(strings, f, USE.NAMES = FALSE))\n}"
      },
      {
        "partial": "c2s <- function(chars) {\n  # Complete the function body\n}\n\ns2c <- function(string) {\n  if (is.character(string) && length(string) == 1) {\n    # Complete the function body\n  } else {\n    warning(\"Wrong argument type in s2c(), NA returned\")\n    return(NA)\n  }\n}",
        "complete": "c2s <- function(chars) {\n  paste(chars, collapse = \"\")\n}\n\ns2c <- function(string) {\n  if (is.character(string) && length(string) == 1) {\n    unlist(strsplit(string, split = \"\"))\n  } else {\n    warning(\"Wrong argument type in s2c(), NA returned\")\n    return(NA)\n  }\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/globals.R",
    "language": "R",
    "content": "utils::globalVariables(c(\"sig.gene70\", \"sig.ggi\", \"sig.gene76\",\n    \"sigOvcAngiogenic\",\"modelOvcAngiogenic\", \"sig.genius\",\"scmod1.robust\",\n    \"sigOvcCrijns\", \"sigOvcCrijn\", \"sigOvcTCGA\", \"sigOvcYoshihara\",\n    \"sig.pik3cags\", \"pam50\", \"sig.tamr13\", \"sig.oncotypedx\"))",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `utils::globalVariables()` function in this code snippet?",
        "answer": "The `utils::globalVariables()` function is used to declare global variables in R to avoid CRAN check notes about undefined global variables. It informs R that these variables will be available at runtime, even if they're not explicitly defined in the current scope. This is often used in package development to suppress warnings about variables that will be available when the package is loaded or used in a specific context."
      },
      {
        "question": "How many variables are being declared as global in this code snippet?",
        "answer": "There are 15 variables being declared as global in this code snippet. They are passed as a character vector to the `utils::globalVariables()` function."
      },
      {
        "question": "What naming convention is used for most of the variables in this code snippet?",
        "answer": "Most of the variables in this code snippet use a naming convention that starts with 'sig.' followed by a descriptive name, such as 'sig.gene70', 'sig.ggi', 'sig.gene76', etc. This suggests that these variables might represent different gene signatures or signaling pathways in a bioinformatics or genomics context."
      }
    ],
    "completion_tasks": [
      {
        "partial": "utils::globalVariables(c(\"sig.gene70\", \"sig.ggi\", \"sig.gene76\",\n\"sigOvcAngiogenic\",\"modelOvcAngiogenic\", \"sig.genius\",\"scmod1.robust\",\n\"sigOvcCrijns\", \"sigOvcCrijn\", \"sigOvcTCGA\", \"sigOvcYoshihara\",\n\"sig.pik3cags\", \"pam50\", \"sig.tamr13\", ...))",
        "complete": "utils::globalVariables(c(\"sig.gene70\", \"sig.ggi\", \"sig.gene76\",\n\"sigOvcAngiogenic\",\"modelOvcAngiogenic\", \"sig.genius\",\"scmod1.robust\",\n\"sigOvcCrijns\", \"sigOvcCrijn\", \"sigOvcTCGA\", \"sigOvcYoshihara\",\n\"sig.pik3cags\", \"pam50\", \"sig.tamr13\", \"sig.oncotypedx\"))"
      },
      {
        "partial": "utils::globalVariables(c(...))",
        "complete": "utils::globalVariables(c(\"sig.gene70\", \"sig.ggi\", \"sig.gene76\",\n\"sigOvcAngiogenic\",\"modelOvcAngiogenic\", \"sig.genius\",\"scmod1.robust\",\n\"sigOvcCrijns\", \"sigOvcCrijn\", \"sigOvcTCGA\", \"sigOvcYoshihara\",\n\"sig.pik3cags\", \"pam50\", \"sig.tamr13\", \"sig.oncotypedx\"))"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/rescale.R",
    "language": "R",
    "content": "#' @title Function to rescale values based on quantiles\n#'\n#' @description\n#' This function rescales values x based on quantiles specified by the user\n#'   such that x' = (x - q1) / (q2 - q1) where q is the specified quantile,\n#'   q1 = q / 2, q2 = 1 - q/2) and x' are the new rescaled values.\n#'\n#' @usage\n#' rescale(x, na.rm = FALSE, q = 0)\n#'\n#' @param x\tThe `matrix` or `vector` to rescale.\n#' @param na.rm\tTRUE if missing values should be removed, FALSE otherwise.\n#' @param q\tQuantile (must lie in \\[0,1\\]]).\n#'\n#' @details\n#' In order to rescale gene expressions, q = 0.05 yielded comparable scales in\n#'   numerous breast cancer microarray datasets (data not shown).The rational\n#'   behind this is that, in general, 'extreme cases' (e.g. low and high\n#'   proliferation, high and low expression of ESR1, ...) are often present\n#'   in microarray datasets, making the estimation of 'extreme' quantiles\n#'   quite stable. This is specially true for genes exhibiting some\n#'   multi-modality like ESR1 or ERBB2.\n#'\n#' @return\n#' A vector of rescaled values with two attributes q1 and q1 containing\n#'   the values of the lower and the upper quantiles respectively.\n#'\n#' @seealso\n#' [base::scale()]\n#'\n#' @examples\n#' # load VDX dataset\n#' data(vdxs)\n#' # load NKI dataset\n#' data(nkis)\n#' # example of rescaling for ESR1 expression\n#' par(mfrow=c(2,2))\n#' hist(data.vdxs[ ,\"205225_at\"], xlab=\"205225_at\", breaks=20,\n#'   main=\"ESR1 in VDX\")\n#' hist(data.nkis[ ,\"NM_000125\"], xlab=\"NM_000125\", breaks=20,\n#'   main=\"ESR1 in NKI\")\n#' hist((rescale(x=data.vdxs[ ,\"205225_at\"], q=0.05) - 0.5) * 2,\n#'   xlab=\"205225_at\", breaks=20, main=\"ESR1 in VDX\\nrescaled\")\n#' hist((rescale(x=data.nkis[ ,\"NM_000125\"], q=0.05) - 0.5) * 2,\n#'   xlab=\"NM_000125\", breaks=20, main=\"ESR1 in NKI\\nrescaled\")\n#'\n#' @md\n#' @export\nrescale <-\nfunction(x, na.rm=FALSE, q=0) {\n\tif(q == 0) {\n\t\tma <- max(x, na.rm=na.rm)\n\t\tmi <- min(x, na.rm=na.rm)\n\t} else {\n\t\tma <- quantile(x, probs=1-(q/2), na.rm=na.rm)\n\t\tmi <- quantile(x, probs=q/2, na.rm=na.rm)\n\t}\n\txx <- (x - mi) / (ma - mi)\n\tattributes(xx) <- list(\"names\"=names(x), \"q1\"=mi,\"q2\"=ma)\n\treturn(xx)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'rescale' function and how does it handle different values of the 'q' parameter?",
        "answer": "The 'rescale' function is designed to rescale values based on quantiles. When q=0, it uses the minimum and maximum values of x for rescaling. When q>0, it uses quantiles (q/2 and 1-q/2) instead. This allows for more robust scaling, especially useful in datasets with extreme values or multi-modal distributions, such as gene expression data in microarray datasets."
      },
      {
        "question": "How does the function handle missing values (NA) in the input data?",
        "answer": "The function has an 'na.rm' parameter that determines how missing values are handled. If na.rm=TRUE, missing values are removed before calculating quantiles or min/max values. If na.rm=FALSE (default), missing values are included in the calculations, which may affect the results or potentially cause errors if not handled properly in the calling code."
      },
      {
        "question": "What attributes are added to the returned vector, and why might these be useful?",
        "answer": "The function adds three attributes to the returned vector: 'names', 'q1', and 'q2'. 'names' preserves the original names of the input vector. 'q1' and 'q2' store the lower and upper quantile values (or min and max when q=0) used for rescaling. These attributes can be useful for understanding the scale of the original data and potentially for reversing the rescaling process if needed."
      }
    ],
    "completion_tasks": [
      {
        "partial": "rescale <- function(x, na.rm=FALSE, q=0) {\n  if(q == 0) {\n    ma <- max(x, na.rm=na.rm)\n    mi <- min(x, na.rm=na.rm)\n  } else {\n    # Calculate quantiles here\n  }\n  # Rescale and set attributes here\n}",
        "complete": "rescale <- function(x, na.rm=FALSE, q=0) {\n  if(q == 0) {\n    ma <- max(x, na.rm=na.rm)\n    mi <- min(x, na.rm=na.rm)\n  } else {\n    ma <- quantile(x, probs=1-(q/2), na.rm=na.rm)\n    mi <- quantile(x, probs=q/2, na.rm=na.rm)\n  }\n  xx <- (x - mi) / (ma - mi)\n  attributes(xx) <- list(\"names\"=names(x), \"q1\"=mi, \"q2\"=ma)\n  xx\n}"
      },
      {
        "partial": "rescale <- function(x, na.rm=FALSE, q=0) {\n  # Calculate ma and mi based on q\n  # Rescale x\n  # Set attributes\n  # Return result\n}",
        "complete": "rescale <- function(x, na.rm=FALSE, q=0) {\n  ma <- if(q == 0) max(x, na.rm=na.rm) else quantile(x, probs=1-(q/2), na.rm=na.rm)\n  mi <- if(q == 0) min(x, na.rm=na.rm) else quantile(x, probs=q/2, na.rm=na.rm)\n  xx <- (x - mi) / (ma - mi)\n  attributes(xx) <- list(\"names\"=names(x), \"q1\"=mi, \"q2\"=ma)\n  xx\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/st.gallen.R",
    "language": "R",
    "content": "#' @title Function to compute the St Gallen consensus criterion for \n#'   prognostication\n#'\n#' @description\n#' This function computes the updated St Gallen consensus criterions as \n#'   published by Goldhirsh et al 2003.\n#'\n#' @usage\n#' st.gallen(size, grade, node, her2.neu, age, vascular.inv, na.rm = FALSE)\n#' \n#' @param size tumor size in cm.\n#' @param grade Histological grade, i.e. low (1), intermediate (2) and \n#'   high (3) grade.\n#' @param node Nodal status (0 or 1 for no lymph node invasion a,d at \n#'   least 1 invaded lymph ode respectively).\n#' @param her2.neu Her2/neu status (0 or 1).\n#' @param age Age at diagnosis (in years).\n#' @param vascular.inv Peritumoral vascular invasion (0 or 1).\n#' @param na.rm\tTRUE if missing values should be removed, FALSE otherwise.\n#'\n#' @return\n#' Vector of risk predictions: \"Good\", \"Intermediate\", and \"Poor\".\n#'\n#' @references\n#' Goldhirsh A, Wood WC, Gelber RD, Coates AS, Thurlimann B, and Senn HJ \n#'   (2003) \"Meeting highlights: Updated international expert \n#'   consensus on the primary therapy of early breast cancer\", Journal of \n#'   Clinical Oncology, 21(17):3357-3365.\n#'\n#' @seealso\n#' [genefu::npi]\n#' \n#' @examples\n#' # load nkis dataset\n#' data(nkis)\n#'\n#' # compute St Gallen predictions\n#' st.gallen(size=demo.nkis[ ,\"size\"], grade=demo.nkis[ ,\"grade\"],\n#'   node=demo.nkis[ ,\"node\"], her2.neu=sample(x=0:1, size=nrow(demo.nkis),\n#'   replace=TRUE), age=demo.nkis[ ,\"age\"], vascular.inv=sample(x=0:1,                                                                                                           \n#'   size=nrow(demo.nkis), replace=TRUE), na.rm=TRUE)\n#'\n#' @md\n#' @export\nst.gallen <-\nfunction(size, grade, node, her2.neu, age, vascular.inv, na.rm=FALSE) {\n\n\tnn <- names(size)\n\tif(is.null(nn)) { nn <- paste(\"PATIENT\",  1:length(size),  sep=\".\") }\n\tnames(size) <- names(grade) <- names(node) <- names(her2.neu) <- names(age) <- names(vascular.inv) <- nn\n\t\n\t## remove missing values\n\tcc.ix <- complete.cases(size, grade, node, her2.neu, age, vascular.inv)\n\tsize <- size[cc.ix]\n\tgrade <- grade[cc.ix]\n\tnode <- node[cc.ix]\n\ther2.neu <- her2.neu[cc.ix]\n\tage <- age[cc.ix]\n\tvascular.inv <- vascular.inv[cc.ix]\n\t\n\tif(length(size) + length(grade) + length(node) + length(her2.neu) + length(age) + length(vascular.inv) != (6 * length(size))) {\n\t\tstop(\"size, grade, lymph node stage, her2/neu expression, age and peritumoral vascular invasion must have the same length!\")\n\t}\n\tif(!all(cc.ix) & !na.rm)  { stop(\"NA values are present!\") }\n\tif(!all(is.element(grade, c(\"1\", \"2\", \"3\")))) {\n\t\tstop(\"grade must be 1, 2 or 3!\")\n\t}\n\tif(!all(is.element(node, c(\"0\", \"1\")))) {\n\t\tstop(\"lymph node stage must be 0 or 1!\")\n\t}\n\tif(!is.numeric(size)) {\n\t\tstop(\"tumor size (cm) must be numeric!\")\n\t}\n\tif(!is.numeric(age)) {\n\t\tstop(\"age (years) must be numeric!\")\n\t}\n\tif(!all(is.element(her2.neu, c(\"0\", \"1\")))) {\n\t\tstop(\"her2/neu expression must be 0 or 1!\")\n\t}\n\tif(!all(is.element(vascular.inv, c(\"0\", \"1\")))) {\n\t\tstop(\"peritumoral vascular invasion must be 0 or 1!\")\n\t}\n\t\n\tlowr <- node == 0 & (size <= 2 & grade == 1 & vascular.inv == 0 & her2.neu == 0 & age >= 35)\n\tnames(lowr) <- nn[cc.ix]\n\tintermediater <- (node == 0 & (size > 2 | grade != 1 | vascular.inv == 1 | her2.neu == 1 | age < 35)) | (node == 1 & her2.neu == 0)\n\tnames(intermediater) <- nn[cc.ix]\n\thighr <- (node == 1 & (her2.neu == 1)) # | (node.stage == 3)\n\tnames(highr) <- nn[cc.ix]\n\t\n\t#if(sum(lowr) + sum(highr) + sum(intermediater) != (3 * sum(cc.ix))) {\n\t#\tstop(\"the classification is not unique!\")\n\t#}\n\t\n\tstgr <- rep(NA, length(cc.ix))\n\tnames(stgr) <- nn\n\tstgr[names(lowr)][lowr] <- \"Good\"\n\tstgr[names(intermediater)][intermediater] <- \"Intermediate\"\n\tstgr[names(highr)][highr] <- \"Poor\"\n\t\n\treturn(stgr)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `st.gallen` function and what are its main input parameters?",
        "answer": "The `st.gallen` function computes the updated St Gallen consensus criterions for breast cancer prognostication. Its main input parameters are: tumor size (cm), histological grade (1, 2, or 3), nodal status (0 or 1), Her2/neu status (0 or 1), age at diagnosis (years), and peritumoral vascular invasion (0 or 1)."
      },
      {
        "question": "How does the function handle missing values and what input validation does it perform?",
        "answer": "The function handles missing values by removing them if `na.rm=TRUE`, otherwise it stops with an error if NA values are present. It performs input validation by checking that: all parameters have the same length, grade is 1, 2, or 3, nodal status and Her2/neu status are 0 or 1, tumor size and age are numeric, and vascular invasion is 0 or 1. If any of these conditions are not met, it stops with an appropriate error message."
      },
      {
        "question": "How does the function classify patients into risk categories and what are these categories?",
        "answer": "The function classifies patients into three risk categories: 'Good', 'Intermediate', and 'Poor'. It uses logical conditions based on the input parameters to determine the risk category. For example, a patient is classified as 'Good' if they have no nodal involvement, tumor size <= 2cm, grade 1, no vascular invasion, Her2/neu negative, and age >= 35. The function returns a vector of these risk predictions for each patient."
      }
    ],
    "completion_tasks": [
      {
        "partial": "st.gallen <- function(size, grade, node, her2.neu, age, vascular.inv, na.rm=FALSE) {\n  nn <- names(size)\n  if(is.null(nn)) { nn <- paste(\"PATIENT\", 1:length(size), sep=\".\") }\n  names(size) <- names(grade) <- names(node) <- names(her2.neu) <- names(age) <- names(vascular.inv) <- nn\n  \n  cc.ix <- complete.cases(size, grade, node, her2.neu, age, vascular.inv)\n  size <- size[cc.ix]\n  grade <- grade[cc.ix]\n  node <- node[cc.ix]\n  her2.neu <- her2.neu[cc.ix]\n  age <- age[cc.ix]\n  vascular.inv <- vascular.inv[cc.ix]\n  \n  # Add input validation here\n  \n  # Calculate risk categories\n  lowr <- node == 0 & (size <= 2 & grade == 1 & vascular.inv == 0 & her2.neu == 0 & age >= 35)\n  intermediater <- (node == 0 & (size > 2 | grade != 1 | vascular.inv == 1 | her2.neu == 1 | age < 35)) | (node == 1 & her2.neu == 0)\n  highr <- (node == 1 & (her2.neu == 1))\n  \n  # Assign risk categories\n  stgr <- rep(NA, length(cc.ix))\n  names(stgr) <- nn\n  # Complete the assignment of risk categories\n  \n  return(stgr)\n}",
        "complete": "st.gallen <- function(size, grade, node, her2.neu, age, vascular.inv, na.rm=FALSE) {\n  nn <- names(size)\n  if(is.null(nn)) { nn <- paste(\"PATIENT\", 1:length(size), sep=\".\") }\n  names(size) <- names(grade) <- names(node) <- names(her2.neu) <- names(age) <- names(vascular.inv) <- nn\n  \n  cc.ix <- complete.cases(size, grade, node, her2.neu, age, vascular.inv)\n  size <- size[cc.ix]\n  grade <- grade[cc.ix]\n  node <- node[cc.ix]\n  her2.neu <- her2.neu[cc.ix]\n  age <- age[cc.ix]\n  vascular.inv <- vascular.inv[cc.ix]\n  \n  if(length(size) + length(grade) + length(node) + length(her2.neu) + length(age) + length(vascular.inv) != (6 * length(size))) {\n    stop(\"size, grade, lymph node stage, her2/neu expression, age and peritumoral vascular invasion must have the same length!\")\n  }\n  if(!all(cc.ix) & !na.rm) { stop(\"NA values are present!\") }\n  if(!all(is.element(grade, c(\"1\", \"2\", \"3\")))) { stop(\"grade must be 1, 2 or 3!\") }\n  if(!all(is.element(node, c(\"0\", \"1\")))) { stop(\"lymph node stage must be 0 or 1!\") }\n  if(!is.numeric(size)) { stop(\"tumor size (cm) must be numeric!\") }\n  if(!is.numeric(age)) { stop(\"age (years) must be numeric!\") }\n  if(!all(is.element(her2.neu, c(\"0\", \"1\")))) { stop(\"her2/neu expression must be 0 or 1!\") }\n  if(!all(is.element(vascular.inv, c(\"0\", \"1\")))) { stop(\"peritumoral vascular invasion must be 0 or 1!\") }\n  \n  lowr <- node == 0 & (size <= 2 & grade == 1 & vascular.inv == 0 & her2.neu == 0 & age >= 35)\n  intermediater <- (node == 0 & (size > 2 | grade != 1 | vascular.inv == 1 | her2.neu == 1 | age < 35)) | (node == 1 & her2.neu == 0)\n  highr <- (node == 1 & (her2.neu == 1))\n  \n  stgr <- rep(NA, length(cc.ix))\n  names(stgr) <- nn\n  stgr[names(lowr)][lowr] <- \"Good\"\n  stgr[names(intermediater)][intermediater] <- \"Intermediate\"\n  stgr[names(highr)][highr] <- \"Poor\"\n  \n  return(stgr)\n}"
      },
      {
        "partial": "st.gallen <- function(size, grade, node, her2.neu, age, vascular.inv, na.rm=FALSE) {\n  nn <- names(size)\n  if(is.null(nn)) { nn <- paste(\"PATIENT\", 1:length(size), sep=\".\") }\n  names(size) <- names(grade) <- names(node) <- names(her2.neu) <- names(age) <- names(vascular.inv) <- nn\n  \n  cc.ix <- complete.cases(size, grade, node, her2.neu, age, vascular.inv)\n  # Remove missing values\n  \n  # Add input validation here\n  \n  # Calculate risk categories\n  lowr <- node == 0 & (size <= 2 & grade == 1 & vascular.inv == 0 & her2.neu == 0 & age >= 35)\n  names(lowr) <- nn[cc.ix]\n  intermediater <- (node == 0 & (size > 2 | grade != 1 | vascular.inv == 1 | her2.neu == 1 | age < 35)) | (node == 1 & her2.neu == 0)\n  names(intermediater) <- nn[cc.ix]\n  highr <- (node == 1 & (her2.neu == 1))\n  names(highr) <- nn[cc.ix]\n  \n  # Assign risk categories\n  stgr <- rep(NA, length(cc.ix))\n  names(stgr) <- nn\n  # Complete the assignment of risk categories\n  \n  return(stgr)\n}",
        "complete": "st.gallen <- function(size, grade, node, her2.neu, age, vascular.inv, na.rm=FALSE) {\n  nn <- names(size)\n  if(is.null(nn)) { nn <- paste(\"PATIENT\", 1:length(size), sep=\".\") }\n  names(size) <- names(grade) <- names(node) <- names(her2.neu) <- names(age) <- names(vascular.inv) <- nn\n  \n  cc.ix <- complete.cases(size, grade, node, her2.neu, age, vascular.inv)\n  size <- size[cc.ix]\n  grade <- grade[cc.ix]\n  node <- node[cc.ix]\n  her2.neu <- her2.neu[cc.ix]\n  age <- age[cc.ix]\n  vascular.inv <- vascular.inv[cc.ix]\n  \n  if(length(size) + length(grade) + length(node) + length(her2.neu) + length(age) + length(vascular.inv) != (6 * length(size))) {\n    stop(\"size, grade, lymph node stage, her2/neu expression, age and peritumoral vascular invasion must have the same length!\")\n  }\n  if(!all(cc.ix) & !na.rm) { stop(\"NA values are present!\") }\n  if(!all(is.element(grade, c(\"1\", \"2\", \"3\")))) { stop(\"grade must be 1, 2 or 3!\") }\n  if(!all(is.element(node, c(\"0\", \"1\")))) { stop(\"lymph node stage must be 0 or 1!\") }\n  if(!is.numeric(size)) { stop(\"tumor size (cm) must be numeric!\") }\n  if(!is.numeric(age)) { stop(\"age (years) must be numeric!\") }\n  if(!all(is.element(her2.neu, c(\"0\", \"1\")))) { stop(\"her2/neu expression must be 0 or 1!\") }\n  if(!all(is.element(vascular.inv, c(\"0\", \"1\")))) { stop(\"peritumoral vascular invasion must be 0 or 1!\") }\n  \n  lowr <- node == 0 & (size <= 2 & grade == 1 & vascular.inv == 0 & her2.neu == 0 & age >= 35)\n  names(lowr) <- nn[cc.ix]\n  intermediater <- (node == 0 & (size > 2 | grade != 1 | vascular.inv == 1 | her2.neu == 1 | age < 35)) | (node == 1 & her2.neu == 0)\n  names(intermediater) <- nn[cc.ix]\n  highr <- (node == 1 & (her2.neu == 1))\n  names(highr) <- nn[cc.ix]\n  \n  stgr <- rep(NA, length(cc.ix))\n  names(stgr) <- nn\n  stgr[names(lowr)][lowr] <- \"Good\"\n  stgr[names(intermediater)][intermediater] <- \"Intermediate\"\n  stgr[names(highr)][highr] <- \"Poor\"\n  \n  return(stgr)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/metaplot.surv.R",
    "language": "R",
    "content": "metaplot.surv <- function( mn, se=NULL, lower=NULL, upper=NULL, nn=NULL,\n    labels=NULL, conf.level = .95, xlab = \"\", ylab = \"\", xlim = NULL,\n    summn = NULL, sumse = NULL, sumlower = NULL, sumupper = NULL,\n    sumnn = NULL, summlabel = \"Summary\", logeffect = FALSE,\n    lwd = 2, boxsize = 1, zero = as.numeric(logeffect),\n    colors, xaxt=\"s\", logticks=TRUE, ... ) {\n  nth<-function(x,i){\n      x[ (i-1) %% length(x) +1]\n  }\n\tif(missing(colors)) { colors <- rmeta::meta.colors() }\n  ci.value <- -qnorm( ( 1 - conf.level ) / 2 )\n  ok <- is.finite( mn + se )\n  if ( is.null( xlim ) ) \n    xlim <- c( min( mn[ok] - ci.value * se[ok], na.rm = TRUE ),\n      max( mn[ok] + ci.value * se[ok], na.rm = TRUE ) )\n  ##par( pty=\"s\" )\n  n <- length( mn )\n  if ( logeffect ) {\n    xlog <- \"x\"\n    nxlim <- exp( xlim )\n  }\n  else {\n    xlog <- \"\"\n    nxlim <- xlim\n  }\n  leftedge<-nxlim[1]\n\n  if ( !is.null( labels ) ) {\n      if ( logeffect )  \n          nxlim[1] <- nxlim[1] / sqrt( nxlim[2] / nxlim[1] )\n      else\n        nxlim[1] <- nxlim[1] - 0.5 * ( nxlim[2] - nxlim[1] )\n      labels<-as.character(labels)\n  }\n  par( xaxt = \"n\",yaxt = \"n\", bg=colors$background )\n  plot( nxlim,c( 1,-n-2-3 * !is.null( summn ) ),\n        type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\",\n        log = xlog, xlab=xlab, ylab=ylab,..., col.lab=colors$axes )\n\n  par( xaxt = \"s\" )\n  if (xaxt==\"s\"){\n      if (logeffect) {\n          if (logticks){\n              ats<-round( 10 ^ pretty( log( exp( xlim ),10), 8,min.n=6  ), 2 )\n              ats<-ats[ats> exp(xlim[1]) & ats< 10^(par(\"usr\")[2])]\n              axis( 1, at = ats, col= colors$axes, col.axis= colors$axes)\n          } else {\n              ats<-pretty(exp(xlim),8, min.n=6)\n              ats<-ats[ats> exp(xlim[1]) & ats <10^(par(\"usr\")[2])]\n              axis( 1, at=ats, col= colors$axes, col.axis= colors$axes)\n          }\n      }  else {\n          ats<-pretty(xlim, 6)\n          ##ats<-ats[ats> xlim[1] & ats <xlim[2]]\n          axis( 1, at=ats, col= colors$axes, col.axis= colors$axes)\n      }\n  }\n  \n  if ( !is.null( zero )&& zero>leftedge )\n      abline( v = zero, lty = 2, lwd = 2 ,col=colors$zero)\n\n  if(is.null(lower) || is.null(upper)){\n    ci.value <- -qnorm( ( 1 - conf.level ) / 2 )\n    lower <- mn - ci.value * se\n    upper <- mn + ci.value * se\n    if ( logeffect ){\n        lower <- exp( lower )\n        upper <- exp( upper )\n    }\n  }\n  for ( i in 1:n ){\n      if ( is.na( lower[i]+upper[i] ) ) \n          next\n      lines( c( lower[i], upper[i] ), c( -i, -i ), lwd = lwd, col=nth(colors$lines,i),... )\n  }\n\n  if ( !is.null( labels ) )\n      text( rep( nxlim[1], n ), -( 1:n ), labels,..., col=rep(colors$text,length.out=n),adj=0 )\n\n  if (is.null(nn) && !is.null(se)){\n    nn <- se ^ -2\n  } else {\n    nn <- 1\n  }\n  yscale <- 0.3 * boxsize / max( sqrt( nn ), na.rm = TRUE )\n\n  if ( logeffect ) { \n      scale <- ( nxlim[2] / nxlim[1] ) ^ ( yscale / ( 4 + n ) )\n      xl <- exp( mn ) * ( scale ^ -sqrt( nn ) )\n      xr <- exp( mn ) * ( scale ^ sqrt( nn ) )\n  }\n  else {\n      scale <- yscale * ( nxlim[2] - nxlim[1] ) / ( 4 + n )\n      xl <- mn - scale * sqrt( nn )\n      xr <- mn + scale * sqrt( nn )\n  }\n  yb <- ( 1:n ) - yscale * sqrt( nn )\n  yt <- ( 1:n ) + yscale * sqrt( nn )\n  for ( i in 1:n ) {\n      if ( !is.finite( mn[i] ) ) \n          next  \n      rect( xl[i], -yb[i], xr[i], -yt[i], col = nth(colors$box,i),border=nth(colors$box,i))\n  }\n  if ( !is.null( summn ) ) {\n      if ( logeffect ) {\n          x0 <- exp( summn )\n          if(is.null(lower) || is.null(upper)){\n            xl <- exp( summn - ci.value * sumse )\n            xr <- exp( summn + ci.value * sumse )\n          } else {\n            xl <- exp(sumlower)\n            xr <- exp(sumupper)\n          }\n      }\n      else{\n          x0 <- summn\n          if(is.null(lower) || is.null(upper)){\n            xl <- summn - ci.value * sumse\n            xr <- summn + ci.value * sumse\n          } else {\n            xl <- sumlower\n            xr <- sumupper\n          }\n      }\n      y0 <- n + 3\n      yb <- n + 3 - sqrt( sumnn ) * yscale\n      yt <- n + 3 + sqrt( sumnn ) * yscale\n      polygon( c( xl, x0, xr, x0 ), -c( y0, yt, y0, yb ),\n  \t         col = colors$summary, border = colors$summary )\n      text( nxlim[1], -y0, labels = summlabel, adj = 0,col=colors$text )\n  }\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `nth` function defined at the beginning of the `metaplot.surv` function?",
        "answer": "The `nth` function is a helper function used for cycling through colors. It takes a vector `x` and an index `i`, and returns the `i`th element of `x`, wrapping around to the beginning if `i` is larger than the length of `x`. This allows for repeating color patterns when there are more data points than available colors."
      },
      {
        "question": "How does the function handle logarithmic effects, and what parameters control this behavior?",
        "answer": "The function handles logarithmic effects through the `logeffect` parameter. When `logeffect` is `TRUE`, the x-axis is plotted on a logarithmic scale. This affects various calculations throughout the function, including the transformation of `mn`, `lower`, and `upper` values using `exp()`, the calculation of `xlim`, and the plotting of axis ticks. The `logticks` parameter further controls whether logarithmic ticks are used when `logeffect` is `TRUE`."
      },
      {
        "question": "What is the purpose of the `boxsize` parameter, and how is it used in the function?",
        "answer": "The `boxsize` parameter controls the size of the boxes in the forest plot. It is used to calculate the `yscale` variable, which determines the height of the boxes relative to the plot area. A larger `boxsize` value will result in taller boxes. The `yscale` is calculated as `0.3 * boxsize / max(sqrt(nn), na.rm = TRUE)`, where `nn` represents the sample sizes or inverse variances of the studies."
      }
    ],
    "completion_tasks": [
      {
        "partial": "metaplot.surv <- function(mn, se=NULL, lower=NULL, upper=NULL, nn=NULL, labels=NULL, conf.level=.95, xlab=\"\", ylab=\"\", xlim=NULL, summn=NULL, sumse=NULL, sumlower=NULL, sumupper=NULL, sumnn=NULL, summlabel=\"Summary\", logeffect=FALSE, lwd=2, boxsize=1, zero=as.numeric(logeffect), colors, xaxt=\"s\", logticks=TRUE, ...) {\n  nth <- function(x,i) {\n    x[(i-1) %% length(x) + 1]\n  }\n  if(missing(colors)) { colors <- rmeta::meta.colors() }\n  ci.value <- -qnorm((1 - conf.level) / 2)\n  ok <- is.finite(mn + se)\n  if(is.null(xlim)) \n    xlim <- c(min(mn[ok] - ci.value * se[ok], na.rm=TRUE),\n              max(mn[ok] + ci.value * se[ok], na.rm=TRUE))\n  n <- length(mn)\n  if(logeffect) {\n    xlog <- \"x\"\n    nxlim <- exp(xlim)\n  } else {\n    xlog <- \"\"\n    nxlim <- xlim\n  }\n  leftedge <- nxlim[1]\n\n  # Complete the function implementation\n}",
        "complete": "metaplot.surv <- function(mn, se=NULL, lower=NULL, upper=NULL, nn=NULL, labels=NULL, conf.level=.95, xlab=\"\", ylab=\"\", xlim=NULL, summn=NULL, sumse=NULL, sumlower=NULL, sumupper=NULL, sumnn=NULL, summlabel=\"Summary\", logeffect=FALSE, lwd=2, boxsize=1, zero=as.numeric(logeffect), colors, xaxt=\"s\", logticks=TRUE, ...) {\n  nth <- function(x,i) {\n    x[(i-1) %% length(x) + 1]\n  }\n  if(missing(colors)) { colors <- rmeta::meta.colors() }\n  ci.value <- -qnorm((1 - conf.level) / 2)\n  ok <- is.finite(mn + se)\n  if(is.null(xlim)) \n    xlim <- c(min(mn[ok] - ci.value * se[ok], na.rm=TRUE),\n              max(mn[ok] + ci.value * se[ok], na.rm=TRUE))\n  n <- length(mn)\n  if(logeffect) {\n    xlog <- \"x\"\n    nxlim <- exp(xlim)\n  } else {\n    xlog <- \"\"\n    nxlim <- xlim\n  }\n  leftedge <- nxlim[1]\n\n  if(!is.null(labels)) {\n    if(logeffect)  \n      nxlim[1] <- nxlim[1] / sqrt(nxlim[2] / nxlim[1])\n    else\n      nxlim[1] <- nxlim[1] - 0.5 * (nxlim[2] - nxlim[1])\n    labels <- as.character(labels)\n  }\n  par(xaxt=\"n\", yaxt=\"n\", bg=colors$background)\n  plot(nxlim, c(1,-n-2-3 * !is.null(summn)),\n       type=\"n\", bty=\"n\", xaxt=\"n\", yaxt=\"n\",\n       log=xlog, xlab=xlab, ylab=ylab, ..., col.lab=colors$axes)\n\n  par(xaxt=\"s\")\n  if(xaxt==\"s\") {\n    if(logeffect) {\n      if(logticks) {\n        ats <- round(10 ^ pretty(log(exp(xlim), 10), 8, min.n=6), 2)\n        ats <- ats[ats > exp(xlim[1]) & ats < 10^(par(\"usr\")[2])]\n      } else {\n        ats <- pretty(exp(xlim), 8, min.n=6)\n        ats <- ats[ats > exp(xlim[1]) & ats < 10^(par(\"usr\")[2])]\n      }\n    } else {\n      ats <- pretty(xlim, 6)\n    }\n    axis(1, at=ats, col=colors$axes, col.axis=colors$axes)\n  }\n  \n  if(!is.null(zero) && zero > leftedge)\n    abline(v=zero, lty=2, lwd=2, col=colors$zero)\n\n  if(is.null(lower) || is.null(upper)) {\n    lower <- mn - ci.value * se\n    upper <- mn + ci.value * se\n    if(logeffect) {\n      lower <- exp(lower)\n      upper <- exp(upper)\n    }\n  }\n  for(i in 1:n) {\n    if(is.na(lower[i] + upper[i])) next\n    lines(c(lower[i], upper[i]), c(-i, -i), lwd=lwd, col=nth(colors$lines, i), ...)\n  }\n\n  if(!is.null(labels))\n    text(rep(nxlim[1], n), -(1:n), labels, ..., col=rep(colors$text, length.out=n), adj=0)\n\n  nn <- if(is.null(nn) && !is.null(se)) se^-2 else 1\n  yscale <- 0.3 * boxsize / max(sqrt(nn), na.rm=TRUE)\n\n  if(logeffect) { \n    scale <- (nxlim[2] / nxlim[1]) ^ (yscale / (4 + n))\n    xl <- exp(mn) * (scale ^ -sqrt(nn))\n    xr <- exp(mn) * (scale ^ sqrt(nn))\n  } else {\n    scale <- yscale * (nxlim[2] - nxlim[1]) / (4 + n)\n    xl <- mn - scale * sqrt(nn)\n    xr <- mn + scale * sqrt(nn)\n  }\n  yb <- (1:n) - yscale * sqrt(nn)\n  yt <- (1:n) + yscale * sqrt(nn)\n  for(i in 1:n) {\n    if(!is.finite(mn[i])) next  \n    rect(xl[i], -yb[i], xr[i], -yt[i], col=nth(colors$box, i), border=nth(colors$box, i))\n  }\n  if(!is.null(summn)) {\n    if(logeffect) {\n      x0 <- exp(summn)\n      xl <- if(is.null(lower) || is.null(upper)) exp(summn - ci.value * sumse) else exp(sumlower)\n      xr <- if(is.null(lower) || is.null(upper)) exp(summn + ci.value * sumse) else exp(sumupper)\n    } else {\n      x0 <- summn\n      xl <- if(is.null(lower) || is.null(upper)) summn - ci.value * sumse else sumlower\n      xr <- if(is.null(lower) || is.null(upper)) summn + ci.value * sumse else sumupper\n    }\n    y0 <- n + 3\n    yb <- n + 3 - sqrt(sumnn) * yscale\n    yt <- n + 3 + sqrt(sumnn) * yscale\n    polygon(c(xl, x0, xr, x0), -c(y0, yt, y0, yb),\n            col=colors$summary, border=colors$summary)\n    text(nxlim[1], -y0, labels=summlabel, adj=0, col=colors$text)\n  }\n}"
      },
      {
        "partial": "metaplot.surv <- function(mn, se=NULL, lower=NULL, upper=NULL, nn=NULL, labels=NULL, conf.level=.95, xlab=\"\", ylab=\"\", xlim=NULL, summn=NULL, sumse=NULL, sumlower=NULL, sumupper=NULL, sumnn=NULL, summlabel=\"Summary\", logeffect=FALSE, lwd=2, boxsize=1, zero=as.numeric(logeffect), colors, xaxt=\"s\", logticks=TRUE, ...) {\n  # Implement the helper function nth\n  # Set up initial variables and calculations\n  # Implement the main plotting logic\n  # Add error bars\n  # Add labels\n  # Draw boxes\n  # Add summary polygon if summn is provided\n}",
        "complete": "metaplot.surv <- function(mn, se=NULL, lower=NULL, upper=NULL, nn=NULL, labels=NULL, conf.level=.95, xlab=\"\", ylab=\"\", xlim=NULL, summn=NULL, sumse=NULL, sumlower=NULL, sumupper=NULL, sumnn=NULL, summlabel=\"Summary\", logeffect=FALSE, lwd=2, boxsize=1, zero=as.numeric(logeffect), colors, xaxt=\"s\", logticks=TRUE, ...) {\n  nth <- function(x,i) x[(i-1) %% length(x) + 1]\n  if(missing(colors)) colors <- rmeta::meta.colors()\n  ci.value <- -qnorm((1 - conf.level) / 2)\n  ok <- is.finite(mn + se)\n  if(is.null(xlim)) xlim <- c(min(mn[ok] - ci.value * se[ok], na.rm=TRUE), max(mn[ok] + ci.value * se[ok], na.rm=TRUE))\n  n <- length(mn)\n  nxlim <- if(logeffect) exp(xlim) else xlim\n  leftedge <- nxlim[1]\n\n  if(!is.null(labels)) {\n    nxlim[1] <- if(logeffect) nxlim[1] / sqrt(nxlim[2] / nxlim[1]) else nxlim[1] - 0.5 * (nxlim[2] - nxlim[1])\n    labels <- as.character(labels)\n  }\n\n  par(xaxt=\"n\", yaxt=\"n\", bg=colors$background)\n  plot(nxlim, c(1,-n-2-3 * !is.null(summn)), type=\"n\", bty=\"n\", xaxt=\"n\", yaxt=\"n\", log=if(logeffect) \"x\" else \"\", xlab=xlab, ylab=ylab, ..., col.lab=colors$axes)\n\n  if(xaxt==\"s\") {\n    ats <- if(logeffect) {\n      if(logticks) round(10 ^ pretty(log(exp(xlim),10), 8, min.n=6), 2)\n      else pretty(exp(xlim), 8, min.n=6)\n    } else pretty(xlim, 6)\n    ats <- ats[ats > (if(logeffect) exp(xlim[1]) else xlim[1]) & ats < 10^(par(\"usr\")[2])]\n    axis(1, at=ats, col=colors$axes, col.axis=colors$axes)\n  }\n\n  if(!is.null(zero) && zero > leftedge) abline(v=zero, lty=2, lwd=2, col=colors$zero)\n\n  if(is.null(lower) || is.null(upper)) {\n    lower <- mn - ci.value * se\n    upper <- mn + ci.value * se\n    if(logeffect) { lower <- exp(lower); upper <- exp(upper) }\n  }\n  for(i in 1:n) if(!is.na(lower[i] + upper[i])) lines(c(lower[i], upper[i]), c(-i, -i), lwd=lwd, col=nth(colors$lines, i), ...)\n\n  if(!is.null(labels)) text(rep(nxlim[1], n), -(1:n), labels, ..., col=rep(colors$text, length.out=n), adj=0)\n\n  nn <- if(is.null(nn) && !is.null(se)) se^-2 else 1\n  yscale <- 0.3 * boxsize / max(sqrt(nn), na.rm=TRUE)\n  scale <- if(logeffect) (nxlim[2] / nxlim[1]) ^ (yscale / (4 + n)) else yscale * (nxlim[2] - nxlim[1]) / (4 + n)\n  xl <- if(logeffect) exp(mn) * (scale ^ -sqrt(nn)) else mn - scale * sqrt(nn)\n  xr <- if(logeffect) exp(mn) * (scale ^ sqrt(nn)) else mn + scale * sqrt(nn)\n  yb <- (1:n) - yscale * sqrt(nn)\n  yt <- (1:n) + yscale * sqrt"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/dindex.comp.meta.R",
    "language": "R",
    "content": "`dindex.comp.meta` <-\nfunction(list.dindex1, list.dindex2, hetero=FALSE) {\n\n\tif(length(list.dindex1) != length(list.dindex2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n\tn <- 0\n\tx1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n\tfor(i in 1:length(list.dindex1)) {\n\t\tnn <- list.dindex1[[i]]$n\n\t\tif(nn != list.dindex2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n\t\tn <- n + nn\n\t\tx1 <- c(x1, list.dindex1[[i]]$coef)\n\t\tx1.se <- c(x1.se, list.dindex1[[i]]$se)\n\t\tx2 <- c(x2, list.dindex2[[i]]$coef)\n\t\tx2.se <- c(x2.se, list.dindex2[[i]]$se)\n\t\tcort <- cor(list.dindex1[[i]]$data$z, list.dindex2[[i]]$data$z, method=\"spearman\", use=\"complete.obs\")\n\t\t## since r is the spearman correlation coefficient and not the Pearson's one, we should apply a correction factor (see http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient for details)\n\t\tcorz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n\t\tif(nn > 3) { corz.se <- c(corz.se, 1 / sqrt(nn - 3)) } else { corz.se <- c(corz.se, NA) }\n\t}\n\tx1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n\tx2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n\tif(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n\t## same D indices\t\n\t\treturn(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n\t}\n\trz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n\t## since r is the spearman correlation coefficient and not the Pearson's one, we should apply a correction factor (see http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient for details)\n\trz <- rz / (sqrt((n - 3) / 1.06))\n\tr <- fisherz(rz, inv=TRUE)\n\n\tif(abs(r) < 1) {\n\t\tt.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n\t\tdiff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n\t} else { diff.ci.p <- 1 }\n\treturn(list(\"p.value\"=diff.ci.p, \"dindex1\"=exp(x1.meta$estimate), \"dindex2\"=exp(x2.meta$estimate)))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `dindex.comp.meta` function and what are its main inputs?",
        "answer": "The `dindex.comp.meta` function is designed to compare two lists of concordance indices (D-indices) and perform a meta-analysis. Its main inputs are `list.dindex1` and `list.dindex2`, which are lists containing concordance index data, and an optional `hetero` parameter to specify whether heterogeneity should be considered in the analysis."
      },
      {
        "question": "How does the function handle the correlation between the two sets of concordance indices?",
        "answer": "The function calculates the Spearman correlation coefficient between the 'z' values of the two concordance index lists. It then applies a correction factor to the Fisher's z-transformed correlation, which is sqrt((nn - 3) / 1.06), to account for the use of Spearman's rank correlation instead of Pearson's correlation. This corrected correlation is used in the final calculation of the test statistic."
      },
      {
        "question": "What statistical test is performed to compare the two concordance indices, and under what condition is this test not applied?",
        "answer": "The function performs a t-test to compare the two concordance indices. It calculates a t-statistic using the difference between the meta-analyzed estimates, their standard errors, and the correlation between them. However, if the absolute value of the correlation coefficient (r) is equal to 1, the t-test is not applied, and the function returns a p-value of 1, indicating no significant difference between the indices."
      }
    ],
    "completion_tasks": [
      {
        "partial": "dindex.comp.meta <- function(list.dindex1, list.dindex2, hetero=FALSE) {\n  if(length(list.dindex1) != length(list.dindex2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.dindex1)) {\n    nn <- list.dindex1[[i]]$n\n    if(nn != list.dindex2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.dindex1[[i]]$coef)\n    x1.se <- c(x1.se, list.dindex1[[i]]$se)\n    x2 <- c(x2, list.dindex2[[i]]$coef)\n    x2.se <- c(x2.se, list.dindex2[[i]]$se)\n    cort <- cor(list.dindex1[[i]]$data$z, list.dindex2[[i]]$data$z, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    corz.se <- c(corz.se, if(nn > 3) 1 / sqrt(nn - 3) else NA)\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  # Complete the function\n}",
        "complete": "dindex.comp.meta <- function(list.dindex1, list.dindex2, hetero=FALSE) {\n  if(length(list.dindex1) != length(list.dindex2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.dindex1)) {\n    nn <- list.dindex1[[i]]$n\n    if(nn != list.dindex2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.dindex1[[i]]$coef)\n    x1.se <- c(x1.se, list.dindex1[[i]]$se)\n    x2 <- c(x2, list.dindex2[[i]]$coef)\n    x2.se <- c(x2.se, list.dindex2[[i]]$se)\n    cort <- cor(list.dindex1[[i]]$data$z, list.dindex2[[i]]$data$z, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    corz.se <- c(corz.se, if(nn > 3) 1 / sqrt(nn - 3) else NA)\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  rz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n  rz <- rz / (sqrt((n - 3) / 1.06))\n  r <- fisherz(rz, inv=TRUE)\n\n  if(abs(r) < 1) {\n    t.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"dindex1\"=exp(x1.meta$estimate), \"dindex2\"=exp(x2.meta$estimate)))\n}"
      },
      {
        "partial": "dindex.comp.meta <- function(list.dindex1, list.dindex2, hetero=FALSE) {\n  if(length(list.dindex1) != length(list.dindex2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.dindex1)) {\n    nn <- list.dindex1[[i]]$n\n    if(nn != list.dindex2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.dindex1[[i]]$coef)\n    x1.se <- c(x1.se, list.dindex1[[i]]$se)\n    x2 <- c(x2, list.dindex2[[i]]$coef)\n    x2.se <- c(x2.se, list.dindex2[[i]]$se)\n    # Complete the loop body\n  }\n  # Complete the function\n}",
        "complete": "dindex.comp.meta <- function(list.dindex1, list.dindex2, hetero=FALSE) {\n  if(length(list.dindex1) != length(list.dindex2)) { stop(\"the concordance indices are computed from different number of samples!\") }\n\n  n <- 0\n  x1 <- x1.se <- x2 <- x2.se <- corz <- corz.se <- NULL\n  for(i in 1:length(list.dindex1)) {\n    nn <- list.dindex1[[i]]$n\n    if(nn != list.dindex2[[i]]$n) { stop(\"the number of samples to compute the concordance indices is not the same!\") }\n    n <- n + nn\n    x1 <- c(x1, list.dindex1[[i]]$coef)\n    x1.se <- c(x1.se, list.dindex1[[i]]$se)\n    x2 <- c(x2, list.dindex2[[i]]$coef)\n    x2.se <- c(x2.se, list.dindex2[[i]]$se)\n    cort <- cor(list.dindex1[[i]]$data$z, list.dindex2[[i]]$data$z, method=\"spearman\", use=\"complete.obs\")\n    corz <- c(corz, sqrt((nn - 3) / 1.06) * fisherz(cort, inv=FALSE))\n    corz.se <- c(corz.se, if(nn > 3) 1 / sqrt(nn - 3) else NA)\n  }\n  x1.meta <- combine.est(x=x1, x.se=x1.se, hetero=hetero, na.rm=TRUE)\n  x2.meta <- combine.est(x=x2, x.se=x2.se, hetero=hetero, na.rm=TRUE) \n  if(x1.meta$estimate == x2.meta$estimate && x1.meta$se == x2.meta$se) {\n    return(list(\"p.value\"=1, \"cindex1\"=x1.meta$estimate, \"cindex2\"=x2.meta$estimate))\n  }\n  rz <- combine.est(x=corz, x.se=corz.se, na.rm=TRUE, hetero=hetero)$estimate\n  rz <- rz / (sqrt((n - 3) / 1.06))\n  r <- fisherz(rz, inv=TRUE)\n\n  if(abs(r) < 1) {\n    t.stat <- (x1.meta$estimate - x2.meta$estimate) / sqrt(x1.meta$se^2 + x2.meta$se^2 - 2 * r * x1.meta$se * x2.meta$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"dindex1\"=exp(x1.meta$estimate), \"dindex2\"=exp(x2.meta$estimate)))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/combine.est.R",
    "language": "R",
    "content": "'combine.est' <-\nfunction(x, x.se, hetero=FALSE, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se)\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\") }\n\tif(all(!cc.ix)) { return(list(\"estimate\"=NA, \"se\"=NA)) } ## all estimates/standard errors are missing\n\tx <- x[cc.ix]\n\tx.se <- x.se[cc.ix]\n\tk <- length(x)\n\tif(any(x.se == 0)) {\n\t\twarning(\"standard deviation of zero is present!\")\n\t\tx.se[x.se == 0] <- 10^-16\t\n\t}\n\tif(k == 1) { return(list(\"estimate\"=x, \"se\"=x.se)) }\n\twi <- x.se^-2\n\tif(hetero) {\n\t\tw.bar <- sum(wi / k)\n\t\ts2w <- (sum(wi^2) - k * w.bar^2) / (k - 1)\n\t\tU <- (k - 1) * (w.bar - s2w / (k * w.bar))\n\t\tQ <- test.hetero.est(x=x, x.se=x.se)$Q\n\t\ttau2 <- ifelse(Q <= (k - 1), 0, (Q - (k - 1)) / U)\n\t\twi <- 1 / ((1 / wi) + tau2)\n\t}\n\tce <- c(sum(wi * x) / sum(wi), sqrt(1/sum(wi)))\n\treturn(list(\"estimate\"=ce[1], \"se\"=ce[2]))\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'combine.est' function in R, and how does it handle missing values?",
        "answer": "The 'combine.est' function in R is designed to combine estimates and their standard errors. It handles missing values in two ways: 1) If 'na.rm' is set to FALSE (default) and there are missing values, it stops execution with an error message. 2) If 'na.rm' is TRUE, it removes any rows with missing values before proceeding with the calculation. If all values are missing, it returns NA for both estimate and standard error."
      },
      {
        "question": "How does the function handle heterogeneity in the estimates, and what is the significance of the 'hetero' parameter?",
        "answer": "The function handles heterogeneity when the 'hetero' parameter is set to TRUE. In this case, it calculates a measure of between-study variance (tau^2) using the DerSimonian and Laird method. This involves computing Q (a measure of heterogeneity), and if Q exceeds its expected value under homogeneity, tau^2 is estimated. The weights for combining estimates are then adjusted to account for this between-study variance, resulting in a random-effects model instead of a fixed-effect model."
      },
      {
        "question": "What is the purpose of the code block that checks for and modifies standard errors of zero, and why is this important?",
        "answer": "The code block that checks for standard errors of zero is important for preventing division by zero errors in subsequent calculations. If any standard error is exactly zero, the function issues a warning and replaces these zero values with a very small number (10^-16). This is crucial because the function uses inverse variance weighting (1/SE^2) to combine estimates, and a zero standard error would lead to infinite weight and potential numerical instability or errors in the calculations."
      }
    ],
    "completion_tasks": [
      {
        "partial": "combine.est <- function(x, x.se, hetero=FALSE, na.rm=FALSE) {\n  cc.ix <- complete.cases(x, x.se)\n  if(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\") }\n  if(all(!cc.ix)) { return(list(\"estimate\"=NA, \"se\"=NA)) }\n  x <- x[cc.ix]\n  x.se <- x.se[cc.ix]\n  k <- length(x)\n  if(any(x.se == 0)) {\n    warning(\"standard deviation of zero is present!\")\n    x.se[x.se == 0] <- 10^-16\n  }\n  if(k == 1) { return(list(\"estimate\"=x, \"se\"=x.se)) }\n  wi <- x.se^-2\n  if(hetero) {\n    # Complete the heterogeneous case\n  }\n  # Complete the final calculation and return\n}",
        "complete": "combine.est <- function(x, x.se, hetero=FALSE, na.rm=FALSE) {\n  cc.ix <- complete.cases(x, x.se)\n  if(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\") }\n  if(all(!cc.ix)) { return(list(\"estimate\"=NA, \"se\"=NA)) }\n  x <- x[cc.ix]\n  x.se <- x.se[cc.ix]\n  k <- length(x)\n  if(any(x.se == 0)) {\n    warning(\"standard deviation of zero is present!\")\n    x.se[x.se == 0] <- 10^-16\n  }\n  if(k == 1) { return(list(\"estimate\"=x, \"se\"=x.se)) }\n  wi <- x.se^-2\n  if(hetero) {\n    w.bar <- sum(wi) / k\n    s2w <- (sum(wi^2) - k * w.bar^2) / (k - 1)\n    U <- (k - 1) * (w.bar - s2w / (k * w.bar))\n    Q <- test.hetero.est(x=x, x.se=x.se)$Q\n    tau2 <- max(0, (Q - (k - 1)) / U)\n    wi <- 1 / ((1 / wi) + tau2)\n  }\n  ce <- c(sum(wi * x) / sum(wi), sqrt(1/sum(wi)))\n  return(list(\"estimate\"=ce[1], \"se\"=ce[2]))\n}"
      },
      {
        "partial": "combine.est <- function(x, x.se, hetero=FALSE, na.rm=FALSE) {\n  cc.ix <- complete.cases(x, x.se)\n  if(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\") }\n  if(all(!cc.ix)) { return(list(\"estimate\"=NA, \"se\"=NA)) }\n  x <- x[cc.ix]\n  x.se <- x.se[cc.ix]\n  k <- length(x)\n  # Handle zero standard deviations\n  # Calculate weights\n  # Complete the function\n}",
        "complete": "combine.est <- function(x, x.se, hetero=FALSE, na.rm=FALSE) {\n  cc.ix <- complete.cases(x, x.se)\n  if(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\") }\n  if(all(!cc.ix)) { return(list(\"estimate\"=NA, \"se\"=NA)) }\n  x <- x[cc.ix]\n  x.se <- x.se[cc.ix]\n  k <- length(x)\n  if(any(x.se == 0)) {\n    warning(\"standard deviation of zero is present!\")\n    x.se[x.se == 0] <- 10^-16\n  }\n  if(k == 1) { return(list(\"estimate\"=x, \"se\"=x.se)) }\n  wi <- x.se^-2\n  if(hetero) {\n    w.bar <- sum(wi) / k\n    s2w <- (sum(wi^2) - k * w.bar^2) / (k - 1)\n    U <- (k - 1) * (w.bar - s2w / (k * w.bar))\n    Q <- test.hetero.est(x=x, x.se=x.se)$Q\n    tau2 <- max(0, (Q - (k - 1)) / U)\n    wi <- 1 / ((1 / wi) + tau2)\n  }\n  ce <- c(sum(wi * x) / sum(wi), sqrt(1/sum(wi)))\n  return(list(\"estimate\"=ce[1], \"se\"=ce[2]))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/summarizeMolecularProfiles.R",
    "language": "R",
    "content": "#' Takes molecular data from a ToxicoSet, and summarises them\n#' into one entry per drug and experimental condition.\n#'\n#' Given a ToxicoSet with molecular data, this function will summarize\n#' the data into one profile per experimental condition (duration, dose level)\n#' using the chosen summary.stat and return a SummarizedExperiment object, with\n#' one Assay corresponding to a requested drug.\n#'\n#' @examples\n#' data(TGGATESsmall)\n#' summMP <- ToxicoGx::summarizeMolecularProfiles(\n#'   tSet = TGGATESsmall, mDataType = \"rna\",\n#'   cell_lines=sampleNames(TGGATESsmall), drugs = head(treatmentNames(TGGATESsmall)),\n#'   features = fNames(TGGATESsmall,\"rna\")[seq_len(100)], duration = \"8\",\n#'   dose = c(\"Control\", \"High\"), summary.stat = \"median\",\n#'   fill.missing = TRUE, verbose=TRUE\n#'   )\n#'\n#' #subset into expression matrix for a requested drug\n#' assays <- SummarizedExperiment::assays(summMP)[[treatmentNames(TGGATESsmall)[1]]]\n#' #summarization of phenoData for requested experiments\n#' phenoData <- SummarizedExperiment::colData(summMP)\n#' #summarization of phenoData for requested experiments\n#' featureData <- SummarizedExperiment::rowData(summMP) #featureData for requested experiments\n#'\n#' @param tSet \\code{ToxicoSet} The ToxicoSet to summarize\n#' @param mDataType \\code{character} which one of the molecular data types\n#' to use in the analysis, out of all the molecular data types available for the tSet\n#' for example: rna\n#' @param cell_lines \\code{character} The cell lines to be summarized.\n#'   If any cell.line has no data, missing values will be created\n#' @param drugs \\code{character} The drugs to be summarized\n#' @param features \\code{character} A vector of the feature names to include in the summary\n#' @param duration \\code{character} A vector of durations to summarize across\n#' @param dose \\code{character} The dose level to summarize replicates across\n#' @param summary.stat \\code{character} which summary method to use if there are repeated\n#'   cell_lines? Choices are \"mean\", \"median\", \"first\", or \"last\"\n#' @param fill.missing \\code{boolean} should the missing cell lines not in the\n#'   molecular data object be filled in with missing values?\n#' @param summarize A flag which when set to FALSE (defaults to TRUE) disables summarizing and\n#'   returns the data unchanged as a ExpressionSet\n#' @param verbose \\code{boolean} should messages be printed\n#' @return \\code{SummarizedExperiment} A SummarizedExperiment object with the molecular data summarized\n#'   per cell line.\n#' @importFrom utils setTxtProgressBar txtProgressBar\n#' @importFrom Biobase ExpressionSet exprs pData AnnotatedDataFrame assayDataElement assayDataElement<- fData<-\n#' @importFrom SummarizedExperiment SummarizedExperiment\n#'\n#' @export\n#'\n# Output is of SummarizedExperiment class\n## TODO:: Rewrite this using apply functions instead of for loops\nsummarizeMolecularProfiles <-\n  function(tSet,\n           mDataType,\n           cell_lines = NULL, # Defaults get set in paramMissingHandler call\n           drugs = NULL,\n           features = NULL,\n           duration = NULL,\n           dose = c(\"Control\", \"Low\", \"Middle\", \"High\"),\n           summary.stat = c(\"mean\", \"median\", \"first\", \"last\"),\n           fill.missing = TRUE,\n           summarize = TRUE,\n           verbose = TRUE\n  ) {\n\n    ##### CHECKING INPUT VALIDITY #####\n\n    ## MISSING VALUE HANDLING FOR PARAMETERS\n    # Get named list of defualt values for missing parameters\n    argDefaultList <-\n      paramMissingHandler(\n        funName = \"summarizeMolecularProfiles\", tSet = tSet,\n        mDataType = mDataType, cell_lines = cell_lines, drugs = drugs,\n        features = features, duration = duration\n      )\n\n    # Assign any missing parameter default values to function environment\n    if (length(argDefaultList) > 0) {\n      for (idx in seq_along(argDefaultList)) {\n        assign(names(argDefaultList)[idx], argDefaultList[[idx]])\n      }\n    }\n\n    ## TODO:: Standardized parameter names across all function\n    ## ERROR HANDLING FOR PARAMETERS\n    paramErrorChecker(\n      \"summarizeMolecularProfiles\", tSet = tSet,\n      mDataType = mDataType, cell_lines = cell_lines, drugs = drugs,\n      features = features, duration = duration, dose = dose,\n      summary.stat = summary.stat\n    )\n\n    ##### FUNCTION LOGIC BEGINS #####\n\n    dd <- ToxicoGx::molecularProfiles(tSet, mDataType)[features, , drop = FALSE] #expression matrix of the tSet\n    pp <- ToxicoGx::phenoInfo(tSet, mDataType) #phenoData of the tSet\n    ff <- ToxicoGx::featureInfo(tSet, mDataType)[features,,drop = FALSE]\n\n    unique.cells <- unique(cell_lines) #unique cell types (row names of the result)\n    #subset phenoData to include only the experiments requested\n    pp2 <- pp[(pp[,\"sampleid\"] %in% unique.cells & pp[,\"treatmentid\"] %in% drugs\n               & pp[,\"duration\"] %in% duration & pp[,\"dose_level\"] %in% dose), , drop = FALSE] #only the phenoData that is relevant to the request input\n    dd2 <- dd[features,rownames(pp2), drop = FALSE] #only the gene expression data that is relevant to the request input\n\n    #vector of experimental conditions requested for each drug\n    a <- paste(expand.grid(dose,duration)[,1], expand.grid(dose, duration)[,2], sep = \";\")\n\n    ##TODO:: Do we really need this c() wrapper around seq_along()?\n    ddt <- dd[,NA][,c(seq_along(a)), drop = FALSE]\n    ppt <- pp[FALSE,]\n\n    exp.list <- list()\n    cnt <- 0\n    blank <- ddt[,1,drop = FALSE]\n\n    for (drug in drugs) {\n      cnt <- cnt + 1\n      for (i in a) {\n        if (verbose == TRUE) {\n          message(i)\n        }\n        ## TODO:: Is the print error occuring here?\n        curr_dose <- sub(';.*$','', i)\n        curr_dur <- sub('.*;','', i)\n\n        pp3 <- pp2[(pp2[,\"dose_level\"] == curr_dose\n                    & pp2[,\"duration\"] == curr_dur\n                    & pp2[,\"treatmentid\"] == drug), , drop = FALSE]\n        dd3 <- dd2[features,rownames(pp3), drop = FALSE]\n\n        if (ncol(dd3) > 1){ #if there are replicates\n          switch(summary.stat, #ddr, ppr contains gene expression data, phenoData, for replicates\n                 \"mean\" = { ddr <- apply(dd3, 1, mean) },\n                 \"median\"= { ddr <- apply(dd3, 1, median) },\n                 \"first\"= { ddr <- dd3[ ,1 , drop=FALSE] },\n                 \"last\" = { ddr <- dd3[ , ncol(dd3), drop=FALSE] },\n          )\n          ppr <- apply(pp3[, , drop=FALSE], 2, function (x) {\n            x <- paste(unique(as.character(x[!is.na(x)])), collapse=\"/\")\n            return(x)\n          })\n          ppr <- as.data.frame(t(ppr))\n          ppr[!is.na(ppr) & ppr == \"\"] <- NA\n\n          ddt <- cbind(ddt,ddr)\n          ppt <- rbind(ppt,ppr)\n        } else if (ncol(dd3) == 0){ #experiment does not exist\n          ddt <- cbind(ddt,blank)\n        }\n        else{#no replicates\n          ddt <- cbind(ddt,dd3)\n          ppt <- rbind(ppt,pp3)\n        }\n      }\n      ddt <- ddt[,-(seq_len(length(a))), drop = FALSE] #ddt contains the final expression matrix for a single drug\n      colnames(ddt) <- a\n\n      exp.list[[cnt]] <- ddt\n    }\n    names(exp.list) <- drugs\n    ppf <- pp2[FALSE,]\n    for (i in unique(ppt[,\"dose_level\"])) {\n      if (verbose == TRUE ) {\n        message(i)\n      }\n      for (j in unique(ppt[,\"duration\"])) {\n        if (verbose == TRUE) {\n          message(j)\n        }\n        pp4 <- apply(ppt[ppt[,\"dose_level\"] == i & ppt[,\"duration\"] == j,,drop = FALSE], 2, function(x) {\n          x <- paste(unique(as.character(x[!is.na(x)])), collapse = \"///\")\n          return(x)\n        })\n        pp4 <- as.data.frame(t(pp4))\n        pp4[!is.na(pp4) & pp4 == \"\"] <- NA\n        ppf <- rbind(ppf,pp4)\n      }\n    }\n    ppf <- as.data.frame(ppf,stringsAsFactors=FALSE)\n    rownames(ppf) <- paste(ppf[,\"dose_level\"],\";\",ppf[,\"duration\"], sep = \"\")\n    vec <- as.vector(colnames(exp.list[[1]]))\n    ppf <- ppf[vec,]\n\n    res <- SummarizedExperiment(assays = exp.list, rowData = ff, colData = ppf)\n\n    return(res)\n  }\n",
    "qa_pairs": [
      {
        "question": "What is the main purpose of the `summarizeMolecularProfiles` function in this code snippet?",
        "answer": "The main purpose of the `summarizeMolecularProfiles` function is to take molecular data from a ToxicoSet and summarize it into one entry per drug and experimental condition. It processes the data based on specified parameters such as cell lines, drugs, features, duration, and dose levels, and returns a SummarizedExperiment object containing the summarized molecular profiles."
      },
      {
        "question": "How does the function handle missing data or experiments that do not exist?",
        "answer": "The function handles missing data or non-existent experiments in two ways: 1) If `fill.missing` is set to TRUE, it fills in missing cell lines not present in the molecular data object with missing values. 2) When processing the data, if an experiment does not exist (i.e., `ncol(dd3) == 0`), it adds a blank column to the `ddt` matrix, effectively representing the missing experiment with NA values."
      },
      {
        "question": "What are the options for the `summary.stat` parameter, and how does each option affect the summarization of replicate data?",
        "answer": "The `summary.stat` parameter has four options: 'mean', 'median', 'first', and 'last'. When there are replicates (i.e., `ncol(dd3) > 1`), these options affect the summarization as follows: 'mean' calculates the average of replicates, 'median' takes the median value, 'first' selects the first replicate, and 'last' selects the last replicate. This summarization is applied to each feature across the replicates for a given experimental condition."
      }
    ],
    "completion_tasks": null,
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/tbrm.R",
    "language": "R",
    "content": "#' @title Function to compute Tukey's Biweight Robust Mean\n#'\n#' @description\n#' Computation of Tukey's Biweight Robust Mean, a robust average that is \n#'   unaffected by outliers.\n#'\n#' @usage\n#' tbrm(x, C = 9)\n#'\n#' @param x\ta numeric vector\n#' @param C\ta constant. C is preassigned a value of 9 according to the Cook \n#'   reference below but other values are possible.\n#'\n#' @details\n#' This is a one step computation that follows the Affy whitepaper below see \n#'   page 22. This function is called by chron to calculate a robust mean. C \n#'   determines the point at which outliers are given a weight of 0 and \n#'   therefore do not contribute to the calculation of the mean. C=9 sets \n#'   values roughly +/-6 standard deviations to 0. C=6 is also used in \n#'   tree-ring chronology development. Cook and Kairiukstis (1990) have \n#'   further details.\n#' Retrieved from tbrm.\n#'\n#' @return\n#' A numeric mean.\n#' \n#' @references\n#' Statistical Algorithms Description Document, 2002, Affymetrix. p22.\n#' Cook, E. R. and Kairiukstis, L.A. (1990) Methods of Dendrochronology: \n#'   Applications in the Environmental Sciences. ISBN-13: 978-0792305866.\n#' Mosteller, F. and Tukey, J. W. (1977) Data Analysis and Regression: \n#'   a second course in statistics. Addison-Wesley. ISBN-13: 978-0201048544.\n#'\n#' @seealso\n#' chron\n#'\n#' @examples\n#' tbrm(rnorm(100))\n#'\n#' @md\n#' @export\ntbrm <-\nfunction(x,C=9)\n{\n    x=x[!is.na(x)]\n    wt=rep(0, length(x))\n    x.med=median(x)\n    S.star=median(abs(x - x.med))\n    w0=(x - x.med)/(C * S.star + 1e-06)\n    lt0.flag=abs(w0) <= 1\n    wt[lt0.flag]=((1 - w0^2)^2)[lt0.flag]\n    t.bi.m=sum(wt * x)/sum(wt)\n    t.bi.m\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'tbrm' function and what does it calculate?",
        "answer": "The 'tbrm' function computes Tukey's Biweight Robust Mean, which is a robust average that is unaffected by outliers. It calculates a weighted mean of the input vector, where the weights are determined based on how far each value is from the median, effectively reducing the influence of outliers on the final result."
      },
      {
        "question": "How does the function handle outliers, and what is the significance of the parameter 'C'?",
        "answer": "The function handles outliers by assigning weights to each value based on its distance from the median. The parameter 'C' determines the point at which outliers are given a weight of 0, effectively removing them from the calculation. By default, C=9, which sets values roughly \u00b16 standard deviations from the median to have zero weight. A smaller value of C (e.g., C=6) would be more aggressive in identifying outliers."
      },
      {
        "question": "Explain the calculation of 'w0' in the function and its role in determining the weights.",
        "answer": "The calculation of 'w0' is: w0 = (x - x.med) / (C * S.star + 1e-06), where x.med is the median of x, and S.star is the median absolute deviation. 'w0' represents a standardized distance of each point from the median. The weights (wt) are then calculated as (1 - w0^2)^2 for values where |w0| <= 1, and 0 otherwise. This assigns higher weights to values closer to the median and progressively lower weights to values farther away, with a cutoff determined by C."
      }
    ],
    "completion_tasks": [
      {
        "partial": "tbrm <- function(x, C=9) {\n    x = x[!is.na(x)]\n    x.med = median(x)\n    S.star = median(abs(x - x.med))\n    w0 = (x - x.med) / (C * S.star + 1e-06)\n    lt0.flag = abs(w0) <= 1\n    # Complete the function to calculate and return Tukey's Biweight Robust Mean\n}",
        "complete": "tbrm <- function(x, C=9) {\n    x = x[!is.na(x)]\n    x.med = median(x)\n    S.star = median(abs(x - x.med))\n    w0 = (x - x.med) / (C * S.star + 1e-06)\n    lt0.flag = abs(w0) <= 1\n    wt = rep(0, length(x))\n    wt[lt0.flag] = ((1 - w0^2)^2)[lt0.flag]\n    sum(wt * x) / sum(wt)\n}"
      },
      {
        "partial": "tbrm <- function(x, C=9) {\n    # Remove NA values and calculate median\n    x = x[!is.na(x)]\n    x.med = median(x)\n    \n    # Calculate S.star and w0\n    S.star = median(abs(x - x.med))\n    w0 = (x - x.med) / (C * S.star + 1e-06)\n    \n    # Complete the function to calculate weights and return the robust mean\n}",
        "complete": "tbrm <- function(x, C=9) {\n    x = x[!is.na(x)]\n    x.med = median(x)\n    S.star = median(abs(x - x.med))\n    w0 = (x - x.med) / (C * S.star + 1e-06)\n    wt = ifelse(abs(w0) <= 1, (1 - w0^2)^2, 0)\n    sum(wt * x) / sum(wt)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/rankGeneDrugSensitivity.R",
    "language": "R",
    "content": "\n#' @importFrom stats complete.cases\n#' @importFrom stats p.adjust\n\n##TODO:: Convert this to roxygen2 format\n#################################################\n## Rank genes based on drug effect in the Connectivity Map\n##\n## inputs:\n##      - data: gene expression data matrix\n##            - drugpheno: sensititivity values fo thr drug of interest\n##            - type: cell or tissue type for each experiment\n##            - duration: experiment duration in hours\n##      - batch: experiment batches\n##            - single.type: Should the statitsics be computed for each cell/tissue type separately?\n##      - nthread: number of parallel threads (bound to the maximum number of cores available)\n##\n## outputs:\n## list of datafraes with the statistics for each gene, for each type\n##\n## Notes:    duration is not taken into account as only 4 perturbations lasted 12h, the other 6096 lasted 6h\n#################################################\n\nrankGeneDrugSensitivity <- function (data, drugpheno, type, batch,\n                                     single.type=FALSE, standardize = \"SD\",\n                                     nthread=1, verbose=FALSE) {\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n\n    drugpheno <- data.frame(drugpheno)\n\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  res <- NULL\n  utype <- sort(unique(as.character(type)))\n  ltype <- list(\"all\"=utype)\n  if (single.type) {\n    ltype <- c(ltype, as.list(utype))\n    names(ltype)[-1] <- utype\n  }\n  res <- NULL\n  ccix <- complete.cases(data, type, batch, drugpheno)\n  nn <- sum(ccix)\n  if(!any(unlist(lapply(drugpheno,is.factor)))){\n     if(ncol(drugpheno)>1){\n      ##FIXME:: NAMES!\n      nc <- lapply(seq_len(ncol(drugpheno)), function(i){\n\n        est <- paste(\"estimate\", i, sep=\".\")\n        se <-  paste(\"se\", i, sep=\".\")\n        tstat <- paste(\"tstat\", i, sep=\".\")\n\n        nc <- c(est, se, tstat)\n        return(nc)\n\n      })\n      nc  <- c(nc, n=nn, \"fstat\"=NA, \"pvalue\"=NA, \"fdr\")\n    } else {\n      nc  <- c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\", \"fdr\")\n    }\n  } else {\n    nc  <- c(\"estimate\", \"se\", \"n\", \"pvalue\", \"fdr\")\n  }\n\n\n\n  for (ll in seq_along(ltype)) {\n    iix <- !is.na(type) & is.element(type, ltype[[ll]])\n\n    data.not.all.na <- apply(data[iix,,drop=FALSE], 1, function(x) {\n      any(!is.na(x))\n    })\n    drugpheno.not.all.na <- apply(drugpheno[iix,,drop=FALSE], 1, function(x) {\n      any(!is.na(x))\n    })\n    type.not.all.na <- vapply(type[iix], function(x) {\n      !is.na(x)\n    }, FUN.VALUE=logical(1))\n    batch.not.all.na <- vapply(batch[iix], function(x) {\n      !is.na(x)\n    }, FUN.VALUE=logical(1))\n\n    ccix <- data.not.all.na & drugpheno.not.all.na & type.not.all.na & batch.not.all.na\n\n\n\n    if (sum(ccix) < 3) {\n      ## not enough experiments\n      rest <- list(matrix(NA, nrow=ncol(data), ncol=length(nc), dimnames=list(colnames(data), nc)))\n      res <- c(res, rest)\n    } else {\n      splitix <- parallel::splitIndices(nx=ncol(data), ncl=nthread)\n      ##TODO:: Can we reimpement this without length?\n      splitix <- splitix[vapply(splitix, length, FUN.VALUE=numeric(1)) > 0]\n      mcres <- BiocParallel::bplapply(splitix, function(x, data, type, batch, drugpheno, standardize) {\n        res <- t(apply(data[ , x, drop=FALSE], 2, geneDrugSensitivity, type=type, batch=batch, drugpheno=drugpheno, verbose=verbose, standardize=standardize))\n        return(res)\n      }, data=data[iix, , drop=FALSE], type=type[iix], batch=batch[iix], drugpheno=drugpheno[iix,,drop=FALSE], standardize=standardize)\n      rest <- do.call(rbind, mcres)\n      rest <- cbind(rest, \"fdr\"=p.adjust(rest[ , \"pvalue\"], method=\"fdr\"))\n      res <- c(res, list(rest))\n    }\n  }\n  names(res) <- names(ltype)\n  return(res)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `rankGeneDrugSensitivity` function, and what are its main inputs?",
        "answer": "The `rankGeneDrugSensitivity` function is designed to rank genes based on drug effect in the Connectivity Map. Its main inputs are: 'data' (gene expression data matrix), 'drugpheno' (sensitivity values for the drug of interest), 'type' (cell or tissue type for each experiment), 'batch' (experiment batches), 'single.type' (boolean to compute statistics for each cell/tissue type separately), and 'nthread' (number of parallel threads)."
      },
      {
        "question": "How does the function handle parallel processing, and what precautions are taken?",
        "answer": "The function uses parallel processing through the 'nthread' parameter. It detects available cores using `parallel::detectCores()` and sets the number of threads accordingly. It also uses `options(mc.cores=nthread)` to set multicore options. As a precaution, it uses `on.exit(options(op))` to restore the original options when the function exits, ensuring that global settings are not permanently altered."
      },
      {
        "question": "What is the purpose of the `ccix` variable in the function, and how is it used?",
        "answer": "The `ccix` variable is used to identify complete cases in the input data. It's created using `complete.cases()` function to check for non-NA values across data, type, batch, and drugpheno. Later in the function, it's redefined for each tissue type to ensure there are enough valid experiments (at least 3) before performing calculations. This helps in filtering out incomplete or invalid data points before analysis."
      }
    ],
    "completion_tasks": [
      {
        "partial": "rankGeneDrugSensitivity <- function (data, drugpheno, type, batch,\n                                     single.type=FALSE, standardize = \"SD\",\n                                     nthread=1, verbose=FALSE) {\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n    drugpheno <- data.frame(drugpheno)\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  res <- NULL\n  utype <- sort(unique(as.character(type)))\n  ltype <- list(\"all\"=utype)\n  if (single.type) {\n    ltype <- c(ltype, as.list(utype))\n    names(ltype)[-1] <- utype\n  }\n  res <- NULL\n  ccix <- complete.cases(data, type, batch, drugpheno)\n  nn <- sum(ccix)\n\n  # TODO: Complete the function by implementing the logic for processing the data\n  # and calculating the statistics for each gene and type\n\n  return(res)\n}",
        "complete": "rankGeneDrugSensitivity <- function (data, drugpheno, type, batch,\n                                     single.type=FALSE, standardize = \"SD\",\n                                     nthread=1, verbose=FALSE) {\n  if (nthread != 1) {\n    availcore <- parallel::detectCores()\n    if (missing(nthread) || nthread < 1 || nthread > availcore) {\n      nthread <- availcore\n    }\n  }\n  # Set multicore options\n  op <- options()\n  options(mc.cores=nthread)\n  on.exit(options(op))\n\n  if(is.null(dim(drugpheno))){\n    drugpheno <- data.frame(drugpheno)\n  } else if(!is(drugpheno, \"data.frame\")) {\n    drugpheno <- as.data.frame(drugpheno)\n  }\n\n  if (missing(type) || all(is.na(type))) {\n    type <- array(\"other\", dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (missing(batch) || all(is.na(batch))) {\n    batch <- array(1, dim=nrow(data), dimnames=list(rownames(data)))\n  }\n  if (any(c(nrow(drugpheno), length(type), length(batch)) != nrow(data))) {\n    stop(\"length of drugpheno, type, duration, and batch should be equal to the number of rows of data!\")\n  }\n  rownames(drugpheno) <- names(type) <- names(batch) <- rownames(data)\n\n  res <- NULL\n  utype <- sort(unique(as.character(type)))\n  ltype <- list(\"all\"=utype)\n  if (single.type) {\n    ltype <- c(ltype, as.list(utype))\n    names(ltype)[-1] <- utype\n  }\n  res <- NULL\n  ccix <- complete.cases(data, type, batch, drugpheno)\n  nn <- sum(ccix)\n\n  nc <- if(!any(unlist(lapply(drugpheno,is.factor)))) {\n    if(ncol(drugpheno) > 1) {\n      c(unlist(lapply(seq_len(ncol(drugpheno)), function(i) {\n        c(paste0(c(\"estimate\", \"se\", \"tstat\"), \".\", i))\n      })), \"n\", \"fstat\", \"pvalue\", \"fdr\")\n    } else {\n      c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\", \"fdr\")\n    }\n  } else {\n    c(\"estimate\", \"se\", \"n\", \"pvalue\", \"fdr\")\n  }\n\n  for (ll in seq_along(ltype)) {\n    iix <- !is.na(type) & is.element(type, ltype[[ll]])\n    ccix <- complete.cases(data[iix,], type[iix], batch[iix], drugpheno[iix,])\n\n    if (sum(ccix) < 3) {\n      rest <- list(matrix(NA, nrow=ncol(data), ncol=length(nc), dimnames=list(colnames(data), nc)))\n    } else {\n      splitix <- parallel::splitIndices(nx=ncol(data), ncl=nthread)\n      splitix <- splitix[lengths(splitix) > 0]\n      mcres <- BiocParallel::bplapply(splitix, function(x, data, type, batch, drugpheno, standardize) {\n        t(apply(data[, x, drop=FALSE], 2, geneDrugSensitivity, type=type, batch=batch, drugpheno=drugpheno, verbose=verbose, standardize=standardize))\n      }, data=data[iix, , drop=FALSE], type=type[iix], batch=batch[iix], drugpheno=drugpheno[iix,, drop=FALSE], standardize=standardize)\n      rest <- do.call(rbind, mcres)\n      rest <- cbind(rest, \"fdr\"=p.adjust(rest[, \"pvalue\"], method=\"fdr\"))\n    }\n    res <- c(res, list(rest))\n  }\n  names(res) <- names(ltype)\n  return(res)\n}"
      },
      {
        "partial": "geneDrugSensitivity <- function(x, type, batch, drugpheno, verbose=FALSE, standardize=\"SD\") {\n  # TODO: Implement the function to calculate drug sensitivity for a single gene\n  # This function should handle the statistical analysis for one gene across all samples\n  # It should return a vector of statistics (estimate, se, n, tstat, etc.)\n\n  # Placeholder return statement\n  return(c(estimate=NA, se=NA, n=NA, tstat=NA, fstat=NA, pvalue=NA, df=NA))\n}",
        "complete": "geneDrugSensitivity <- function(x, type, batch, drugpheno, verbose=FALSE, standardize=\"SD\") {\n  ccix <- complete.cases(x, type, batch, drugpheno)\n  x <- x[ccix]\n  type <- type[ccix]\n  batch <- batch[ccix]\n  drugpheno <- drugpheno[ccix, , drop=FALSE]\n\n  n <- length(x)\n  if (n < 3) return(c(estimate=NA, se=NA, n=n, tstat=NA, fstat=NA, pvalue=NA, df=NA))\n\n  if (standardize == \"SD\") {\n    x <- scale(x)\n  } else if (standardize == \"rescale\") {\n    x <- (x - min(x)) / (max(x) - min(x))\n  }\n\n  if (is.factor(drugpheno)) {\n    mod <- try(lm(x ~ drugpheno + type + batch), silent=TRUE)\n    if (inherits(mod, \"try-error\")) {\n      return(c(estimate=NA, se=NA, n=n, tstat=NA, fstat=NA, pvalue=NA, df=NA))\n    }\n    sum <- summary(mod)\n    coef <- sum$coefficients[\"drugpheno\", ]\n    return(c(estimate=coef[\"Estimate\"], se=coef[\"Std. Error\"], n=n, \n             tstat=coef[\"t value\"], fstat=sum$fstatistic[1], \n             pvalue=coef[\"Pr(>|t|)\"], df=sum$df[2]))\n  } else {\n    mod <- try(lm(x ~ drugpheno + type + batch), silent=TRUE)\n    if (inherits(mod, \"try-error\")) {\n      return(c(estimate=NA, se=NA, n=n, tstat=NA, fstat=NA, pvalue=NA, df=NA))\n    }\n    sum <- summary(mod)\n    coef <- sum$coefficients[\"drugpheno\", ]\n    return(c(estimate=coef[\"Estimate\"], se=coef[\"Std. Error\"], n=n, \n             tstat=coef[\"t value\"], fstat=sum$fstatistic[1], \n             pvalue=coef[\"Pr(>|t|)\"], df=sum$df[2]))\n  }\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/bhr.comp.R",
    "language": "R",
    "content": "`bhr.comp` <-\nfunction(bhr1, bhr2) {\n\tif(bhr1$n != bhr2$n) { stop(\"the balanced hazard ratios are computed from different number of samples!\") }\n\tn <- bhr1$n\n\tx1 <- bhr1$data$x\n\tx2 <- bhr2$data$x\n\tbeta1 <- bhr1$coef\n\tbeta2 <- bhr2$coef\n\tse1 <- bhr1$se\n\tse2 <- bhr2$se\n\tr <- cor(x1, x2, method=\"spearman\", use=\"complete.obs\")\n\tif(abs(r) < 1) {\n\t\tt.stat <- (beta1 - beta2) / sqrt(se1^2 + se2^2 - 2 * r * se1 * se2)\n\t\tdiff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n\t} else { diff.ci.p <- 1 }\n\treturn(list(\"p.value\"=diff.ci.p, \"bhr1\"=exp(beta1), \"bhr2\"=exp(beta2)))\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `bhr.comp` function in the given R code snippet?",
        "answer": "The `bhr.comp` function compares two balanced hazard ratios (BHR). It calculates the statistical significance of the difference between two BHRs, considering their correlation. The function returns a list containing the p-value for the difference and the exponentiated coefficients of both BHRs."
      },
      {
        "question": "How does the function handle the case when the correlation between x1 and x2 is perfect (1 or -1)?",
        "answer": "When the absolute value of the correlation (r) between x1 and x2 is 1 (perfect correlation), the function sets the p-value (diff.ci.p) to 1. This is because in cases of perfect correlation, the standard statistical comparison is not applicable, so a p-value of 1 indicates no significant difference can be determined."
      },
      {
        "question": "What statistical test is used to compute the p-value when the correlation is not perfect, and how is it implemented?",
        "answer": "When the correlation is not perfect, the function uses a t-test to compute the p-value. It calculates a t-statistic using the difference in coefficients (beta1 - beta2) divided by the square root of the sum of squared standard errors minus twice the product of the correlation and standard errors. The p-value is then computed using the t-distribution with n-1 degrees of freedom, where n is the number of samples."
      }
    ],
    "completion_tasks": [
      {
        "partial": "bhr.comp <- function(bhr1, bhr2) {\n  if(bhr1$n != bhr2$n) { stop(\"the balanced hazard ratios are computed from different number of samples!\") }\n  n <- bhr1$n\n  x1 <- bhr1$data$x\n  x2 <- bhr2$data$x\n  beta1 <- bhr1$coef\n  beta2 <- bhr2$coef\n  se1 <- bhr1$se\n  se2 <- bhr2$se\n  r <- cor(x1, x2, method=\"spearman\", use=\"complete.obs\")\n  if(abs(r) < 1) {\n    t.stat <- (beta1 - beta2) / sqrt(se1^2 + se2^2 - 2 * r * se1 * se2)\n    # Complete the code to calculate diff.ci.p\n  } else { diff.ci.p <- 1 }\n  # Complete the return statement\n}",
        "complete": "bhr.comp <- function(bhr1, bhr2) {\n  if(bhr1$n != bhr2$n) { stop(\"the balanced hazard ratios are computed from different number of samples!\") }\n  n <- bhr1$n\n  x1 <- bhr1$data$x\n  x2 <- bhr2$data$x\n  beta1 <- bhr1$coef\n  beta2 <- bhr2$coef\n  se1 <- bhr1$se\n  se2 <- bhr2$se\n  r <- cor(x1, x2, method=\"spearman\", use=\"complete.obs\")\n  if(abs(r) < 1) {\n    t.stat <- (beta1 - beta2) / sqrt(se1^2 + se2^2 - 2 * r * se1 * se2)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"bhr1\"=exp(beta1), \"bhr2\"=exp(beta2)))\n}"
      },
      {
        "partial": "bhr.comp <- function(bhr1, bhr2) {\n  # Add input validation\n  n <- bhr1$n\n  x1 <- bhr1$data$x\n  x2 <- bhr2$data$x\n  beta1 <- bhr1$coef\n  beta2 <- bhr2$coef\n  se1 <- bhr1$se\n  se2 <- bhr2$se\n  # Calculate correlation\n  # Add logic for t-statistic and p-value calculation\n  # Return the result\n}",
        "complete": "bhr.comp <- function(bhr1, bhr2) {\n  if(bhr1$n != bhr2$n) { stop(\"the balanced hazard ratios are computed from different number of samples!\") }\n  n <- bhr1$n\n  x1 <- bhr1$data$x\n  x2 <- bhr2$data$x\n  beta1 <- bhr1$coef\n  beta2 <- bhr2$coef\n  se1 <- bhr1$se\n  se2 <- bhr2$se\n  r <- cor(x1, x2, method=\"spearman\", use=\"complete.obs\")\n  diff.ci.p <- if(abs(r) < 1) {\n    t.stat <- (beta1 - beta2) / sqrt(se1^2 + se2^2 - 2 * r * se1 * se2)\n    pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { 1 }\n  return(list(\"p.value\"=diff.ci.p, \"bhr1\"=exp(beta1), \"bhr2\"=exp(beta2)))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/genefu.git",
    "file": "../../../../repos/genefu/R/boxplotplus2.R",
    "language": "R",
    "content": "#' @title Box plot of group of values with corresponding jittered points\n#'\n#' @description\n#' This function allows for display a boxplot with jittered points.\n#'\n#' @usage\n#' boxplotplus2(x, .jit = 0.25, .las = 1, .ylim, box.col = \"lightgrey\",\n#'  pt.col = \"blue\", pt.cex = 0.5, pt.pch = 16, med.line = FALSE,\n#'  med.col = \"goldenrod\", ...)\n#'\n#' @param x could be a list of group values or a matrix (each group is a row).\n#' @param .jit Amount of jittering noise.\n#' @param .las Numeric in 0,1,2,3; the style of axis labels.\n#' @param .ylim Range for y axis.\n#' @param box.col Color for boxes.\n#' @param pt.col Color for groups (jittered points).\n#' @param pt.cex A numerical value giving the amount by which plotting jittered points\n#'   should be magnified relative to the default.\n#' @param pt.pch Either an integer specifying a symbol or a single character to be used\n#'   as the default in plotting jittered points. See points for possible values and\n#'   their interpretation.\n#' @param med.line TRUE if a line should link the median of each group, FALSE otherwise.\n#' @param med.col Color of med.line.\n#' @param ... Additional parameters for boxplot function.\n#'\n#' @return\n#' Number of samples in each group.\n#'\n#' @note\n#' 2.21.2006 - Christos Hatzis, Nuvera Biosciences\n#'\n#' @seealso\n#' [graphics::boxplot], [base::jitter]\n#'\n#' @examples\n#' dd <- list(\"G1\"=runif(20), \"G2\"=rexp(30) * -1.1, \"G3\"=rnorm(15) * 1.3)\n#' boxplotplus2(x=dd, .las=3, .jit=0.75, .ylim=c(-3,3), pt.cex=0.75,\n#'   pt.col=c(rep(\"darkred\", 20), rep(\"darkgreen\", 30), rep(\"darkblue\", 15)),\n#'   pt.pch=c(0, 9, 17))\n#'\n#' @md\n#' @importFrom survcomp fisherz\n#' @importFrom graphics points\n#' @export\nboxplotplus2 <- function(x, .jit = 0.25, .las = 1, .ylim,\n    box.col=\"lightgrey\", pt.col=\"blue\", pt.cex=0.5, pt.pch=16,\n    med.line = FALSE, med.col = \"goldenrod\", ...)\n{\n\n    isMAT <- is.matrix(x)\n    y <- x\n    if (isMAT) {\n\t\ty <- data.frame(t(x))\n\t\tif(missing(.ylim)) { myrange <- range(y, na.rm=TRUE) } else { myrange <- .ylim }\n\t} else { if(missing(.ylim)) { myrange <- range(unlist(x), na.rm=TRUE) } else { myrange <- .ylim } }\n\n    bp <- boxplot(y, las = .las, cex.axis = 0.85, border=\"grey\", col=box.col, boxwex=0.5, ylim=myrange, range=0, ...)\n    if (isMAT) {\n        xp <- rep(1:nrow(x), times=ncol(x))\n        yp <- as.vector(x)\n    } else {\n        reps <- sapply(x, FUN=function(x) length(x) )\n        xp <- rep(1:length(y), times=reps)\n        yp <- unlist(y)\n    }\n    points(jitter(xp, .jit), yp, cex=pt.cex, pch=pt.pch, col=pt.col)\n    if (med.line) points(1:length(bp$n), bp$stats[3, ], type=\"b\", col=\"goldenrod\", lwd=3, pch=19)\n    n <- bp$n\n    names(n) <- bp$names\n    n\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'boxplotplus2' function and how does it enhance the standard boxplot?",
        "answer": "The 'boxplotplus2' function creates an enhanced boxplot by combining a standard boxplot with jittered points. It allows for better visualization of data distribution within each group. The function adds individual data points on top of the boxplot, uses customizable colors and styles, and optionally includes a line connecting the medians of each group. This enhancement helps in identifying outliers, assessing data spread, and comparing distributions across groups more effectively than a standard boxplot alone."
      },
      {
        "question": "How does the function handle different input types for the 'x' parameter?",
        "answer": "The function is designed to handle two types of inputs for the 'x' parameter:\n1. A list of group values: In this case, each element of the list represents a group, and the function processes it directly.\n2. A matrix: If 'x' is a matrix, the function transposes it and converts it to a data frame, where each row of the original matrix becomes a group.\nThe function uses the 'isMAT' variable to check if the input is a matrix and processes it accordingly. This flexibility allows users to input data in different formats, making the function more versatile."
      },
      {
        "question": "What is the significance of the '.jit' parameter in the function, and how does it affect the visualization?",
        "answer": "The '.jit' parameter controls the amount of jittering applied to the individual data points in the plot. Jittering adds a small amount of random noise to the x-coordinates of the points, which helps to separate overlapping points in the visualization. This is particularly useful when dealing with discrete or categorical data on the x-axis.\n\nBy default, '.jit' is set to 0.25, but users can adjust this value. A larger value will spread the points more horizontally, potentially reducing overlap but also increasing the width of each group's representation. This parameter is crucial for improving the readability of the plot, especially when there are many data points in each group that might otherwise overlap and obscure the true distribution of the data."
      }
    ],
    "completion_tasks": [
      {
        "partial": "boxplotplus2 <- function(x, .jit = 0.25, .las = 1, .ylim,\n    box.col=\"lightgrey\", pt.col=\"blue\", pt.cex=0.5, pt.pch=16,\n    med.line = FALSE, med.col = \"goldenrod\", ...)\n{\n    isMAT <- is.matrix(x)\n    y <- x\n    if (isMAT) {\n        y <- data.frame(t(x))\n        if(missing(.ylim)) { myrange <- range(y, na.rm=TRUE) } else { myrange <- .ylim }\n    } else { if(missing(.ylim)) { myrange <- range(unlist(x), na.rm=TRUE) } else { myrange <- .ylim } }\n\n    bp <- boxplot(y, las = .las, cex.axis = 0.85, border=\"grey\", col=box.col, boxwex=0.5, ylim=myrange, range=0, ...)\n    # Add code here to handle plotting points and median line\n\n    n <- bp$n\n    names(n) <- bp$names\n    n\n}",
        "complete": "boxplotplus2 <- function(x, .jit = 0.25, .las = 1, .ylim,\n    box.col=\"lightgrey\", pt.col=\"blue\", pt.cex=0.5, pt.pch=16,\n    med.line = FALSE, med.col = \"goldenrod\", ...)\n{\n    isMAT <- is.matrix(x)\n    y <- x\n    if (isMAT) {\n        y <- data.frame(t(x))\n        if(missing(.ylim)) { myrange <- range(y, na.rm=TRUE) } else { myrange <- .ylim }\n    } else { if(missing(.ylim)) { myrange <- range(unlist(x), na.rm=TRUE) } else { myrange <- .ylim } }\n\n    bp <- boxplot(y, las = .las, cex.axis = 0.85, border=\"grey\", col=box.col, boxwex=0.5, ylim=myrange, range=0, ...)\n    if (isMAT) {\n        xp <- rep(1:nrow(x), times=ncol(x))\n        yp <- as.vector(x)\n    } else {\n        reps <- sapply(x, FUN=function(x) length(x) )\n        xp <- rep(1:length(y), times=reps)\n        yp <- unlist(y)\n    }\n    points(jitter(xp, .jit), yp, cex=pt.cex, pch=pt.pch, col=pt.col)\n    if (med.line) points(1:length(bp$n), bp$stats[3, ], type=\"b\", col=med.col, lwd=3, pch=19)\n    n <- bp$n\n    names(n) <- bp$names\n    n\n}"
      },
      {
        "partial": "boxplotplus2 <- function(x, .jit = 0.25, .las = 1, .ylim,\n    box.col=\"lightgrey\", pt.col=\"blue\", pt.cex=0.5, pt.pch=16,\n    med.line = FALSE, med.col = \"goldenrod\", ...)\n{\n    # Add code here to handle input data and prepare for plotting\n\n    bp <- boxplot(y, las = .las, cex.axis = 0.85, border=\"grey\", col=box.col, boxwex=0.5, ylim=myrange, range=0, ...)\n    if (isMAT) {\n        xp <- rep(1:nrow(x), times=ncol(x))\n        yp <- as.vector(x)\n    } else {\n        reps <- sapply(x, FUN=function(x) length(x) )\n        xp <- rep(1:length(y), times=reps)\n        yp <- unlist(y)\n    }\n    points(jitter(xp, .jit), yp, cex=pt.cex, pch=pt.pch, col=pt.col)\n    if (med.line) points(1:length(bp$n), bp$stats[3, ], type=\"b\", col=med.col, lwd=3, pch=19)\n    n <- bp$n\n    names(n) <- bp$names\n    n\n}",
        "complete": "boxplotplus2 <- function(x, .jit = 0.25, .las = 1, .ylim,\n    box.col=\"lightgrey\", pt.col=\"blue\", pt.cex=0.5, pt.pch=16,\n    med.line = FALSE, med.col = \"goldenrod\", ...)\n{\n    isMAT <- is.matrix(x)\n    y <- x\n    if (isMAT) {\n        y <- data.frame(t(x))\n        if(missing(.ylim)) { myrange <- range(y, na.rm=TRUE) } else { myrange <- .ylim }\n    } else { if(missing(.ylim)) { myrange <- range(unlist(x), na.rm=TRUE) } else { myrange <- .ylim } }\n\n    bp <- boxplot(y, las = .las, cex.axis = 0.85, border=\"grey\", col=box.col, boxwex=0.5, ylim=myrange, range=0, ...)\n    if (isMAT) {\n        xp <- rep(1:nrow(x), times=ncol(x))\n        yp <- as.vector(x)\n    } else {\n        reps <- sapply(x, FUN=function(x) length(x) )\n        xp <- rep(1:length(y), times=reps)\n        yp <- unlist(y)\n    }\n    points(jitter(xp, .jit), yp, cex=pt.cex, pch=pt.pch, col=pt.col)\n    if (med.line) points(1:length(bp$n), bp$stats[3, ], type=\"b\", col=med.col, lwd=3, pch=19)\n    n <- bp$n\n    names(n) <- bp$names\n    n\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/downloadTSet.R",
    "language": "R",
    "content": "#' Return a table of ToxicoSets available for download\n#'\n#' The function fetches a table of all ToxicoSets available for download from\n#' the ToxicoGx server. The table includes the names of the ToxicoSet, the\n#' types of data available in the object, and the date of last update.\n#'\n#' Much more information on the processing of the data and data provenance can be found at:\n#' www.orcestra.ca\n#'\n#' @examples\n#' if (interactive()){\n#' availableTSets()\n#' }\n#'\n#' @param canonical [`logical`] Should available TSets show only official TSets, or should\n#'   user generated TSets be included?\n#'\n#' @return A data.frame with details about the available ToxicoSet objects\n#' @export\n#' @import jsonlite\navailableTSets <- function(canonical=TRUE){\n  if (canonical) {\n    avail.tsets <- fromJSON(\"https://www.orcestra.ca/api/toxicosets/canonical\")\n  } else {\n    return(\"Only canonical TSets are available at the moment\")\n  }\n\n  tSetTable <- data.frame(\"ToxicoSet.Name\" = avail.tsets$dataset$name,\n                          \"Date.Created\" = avail.tsets$dateCreated,\n                          \"URL\" = avail.tsets$downloadLink,\n                          stringsAsFactors = FALSE,\n                          check.names = FALSE\n  )\n  return(tSetTable)\n}\n\n#' Download a ToxicoSet object\n#'\n#' This function allows you to download a \\code{ToxicoSet} object for use with this\n#' package. The \\code{ToxicoSets} have been extensively curated and organised within\n#' a ToxicoSet class, enabling use with all the analysis tools provided in\n#' \\code{ToxicoGx}.\n#'\n#' @examples\n#' if (interactive()) {\n#' drugMatrix_rat <- downloadTSet(\"DrugMatrix Rat\")\n#' }\n#'\n#' @param name \\code{Character} string, the name of the PhamracoSet to download.\n#' @param saveDir \\code{Character} string with the folder path where the\n#'     ToxicoSet should be saved. Defaults to \\code{'./tSets/'}. Will create\n#'     directory if it does not exist.\n#' @param tSetFileName \\code{character} string, the file name to save the dataset under\n#' @param verbose \\code{bool} Should status messages be printed during download.\n#'   Defaults to TRUE.\n#' @param timeout `numeric(1)` How long to wait before the download times out,\n#' in seconds. Default is 600 seconds (10 minutes).\n#'\n#' @return A tSet object with the dataset, downloaded from our server\n#'\n#' @importFrom downloader download\n#' @export\ndownloadTSet <- function(name, saveDir = tempdir(), tSetFileName = NULL, verbose = TRUE, timeout=600) {\n\n  # change the download timeout since the files are big\n  opts <- options()\n  options(timeout=timeout)\n  on.exit(options(opts))\n\n  if (missing(saveDir)) {message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")}\n  tSetTable <- availableTSets(canonical=TRUE)\n\n  whichx <- match(name, tSetTable[, 1])\n  if (is.na(whichx)) {\n    stop('Unknown Dataset. Please use the availableTSets() function for the\n         table of available ToxicoSets.')\n  }\n\n  if (!file.exists(saveDir)) {\n    dir.create(saveDir, recursive = TRUE)\n  }\n\n  if (is.null(tSetFileName)) {\n    tSetFileName <- paste0(tSetTable[whichx,\"ToxicoSet.Name\"], \".rds\")\n  }\n  if (!file.exists(file.path(saveDir, tSetFileName))) {\n    downloader::download(url = as.character(tSetTable[whichx, \"URL\"]),\n                         destfile = file.path(saveDir, tSetFileName),\n                         quiet = !verbose, mode='wb')\n  }\n\n  print(file.path(saveDir, tSetFileName))\n  tSet <- readRDS(file.path(saveDir, tSetFileName))\n  tSet <- updateObject(tSet)\n\n  return(tSet)\n}\n\n#' @importFrom utils read.table write.table\n.createtSetEntry <- function(tSet, outfn) {\n\n  if (file.exists(outfn)) {\n    tSetTable <- read.table(outfn, as.is = TRUE)\n    newrow <- c(name(tSet), datasetType(tSet), paste(names(molecularProfilesSlot(tSet)), collapse = \"/\"), annotation(tSet)$dateCreated, NA)\n    tSetTable <- rbind(tSetTable, newrow)\n    rownames(tSetTable) <- tSetTable[, 1]\n    write.table(tSetTable, file = outfn)\n  } else {\n    newrow <- c(name(tSet), datasetType(tSet), paste(names(molecularProfilesSlot(tSet)), collapse = \"/\"), annotation(tSet)$dateCreated, NA)\n    tSetTable <- t(matrix(newrow))\n    colnames(tSetTable) <- c(\"ToxicoSet.Name\",\"Data.Source\",\"Date.Updated\",\"URL\")\n    rownames(tSetTable) <- tSetTable[,1]\n    write.table(tSetTable, file = outfn)\n  }\n}\n",
    "qa_pairs": null,
    "completion_tasks": [
      {
        "partial": "availableTSets <- function(canonical=TRUE){\n  if (canonical) {\n    avail.tsets <- fromJSON(\"https://www.orcestra.ca/api/toxicosets/canonical\")\n  } else {\n    return(\"Only canonical TSets are available at the moment\")\n  }\n\n  tSetTable <- data.frame(\n    \"ToxicoSet.Name\" = avail.tsets$dataset$name,\n    \"Date.Created\" = avail.tsets$dateCreated,\n    \"URL\" = avail.tsets$downloadLink,\n    stringsAsFactors = FALSE,\n    check.names = FALSE\n  )\n  return(tSetTable)\n}",
        "complete": "availableTSets <- function(canonical=TRUE){\n  if (canonical) {\n    avail.tsets <- fromJSON(\"https://www.orcestra.ca/api/toxicosets/canonical\")\n    tSetTable <- data.frame(\n      \"ToxicoSet.Name\" = avail.tsets$dataset$name,\n      \"Date.Created\" = avail.tsets$dateCreated,\n      \"URL\" = avail.tsets$downloadLink,\n      stringsAsFactors = FALSE,\n      check.names = FALSE\n    )\n    return(tSetTable)\n  }\n  return(\"Only canonical TSets are available at the moment\")\n}"
      },
      {
        "partial": "downloadTSet <- function(name, saveDir = tempdir(), tSetFileName = NULL, verbose = TRUE, timeout=600) {\n  opts <- options()\n  options(timeout=timeout)\n  on.exit(options(opts))\n\n  if (missing(saveDir)) {message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")}\n  tSetTable <- availableTSets(canonical=TRUE)\n\n  whichx <- match(name, tSetTable[, 1])\n  if (is.na(whichx)) {\n    stop('Unknown Dataset. Please use the availableTSets() function for the table of available ToxicoSets.')\n  }\n\n  if (!file.exists(saveDir)) {\n    dir.create(saveDir, recursive = TRUE)\n  }\n\n  if (is.null(tSetFileName)) {\n    tSetFileName <- paste0(tSetTable[whichx,\"ToxicoSet.Name\"], \".rds\")\n  }\n  if (!file.exists(file.path(saveDir, tSetFileName))) {\n    downloader::download(url = as.character(tSetTable[whichx, \"URL\"]),\n                         destfile = file.path(saveDir, tSetFileName),\n                         quiet = !verbose, mode='wb')\n  }\n\n  print(file.path(saveDir, tSetFileName))\n  tSet <- readRDS(file.path(saveDir, tSetFileName))\n  tSet <- updateObject(tSet)\n\n  return(tSet)\n}",
        "complete": "downloadTSet <- function(name, saveDir = tempdir(), tSetFileName = NULL, verbose = TRUE, timeout=600) {\n  options(timeout=timeout)\n  on.exit(options(timeout=opts$timeout))\n\n  if (missing(saveDir)) message(\"Downloading to temporary folder... Use saveDir parameter to save to a specific path\")\n  tSetTable <- availableTSets(canonical=TRUE)\n\n  whichx <- match(name, tSetTable[, 1])\n  if (is.na(whichx)) stop('Unknown Dataset. Please use the availableTSets() function for the table of available ToxicoSets.')\n\n  if (!dir.exists(saveDir)) dir.create(saveDir, recursive = TRUE)\n\n  tSetFileName <- tSetFileName %||% paste0(tSetTable[whichx,\"ToxicoSet.Name\"], \".rds\")\n  filePath <- file.path(saveDir, tSetFileName)\n  \n  if (!file.exists(filePath)) {\n    downloader::download(url = as.character(tSetTable[whichx, \"URL\"]),\n                         destfile = filePath,\n                         quiet = !verbose, mode='wb')\n  }\n\n  if (verbose) print(filePath)\n  updateObject(readRDS(filePath))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/test.hetero.est.R",
    "language": "R",
    "content": "'test.hetero.est' <-\nfunction(x, x.se, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se);\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\"); }\n\tx <- x[cc.ix];\n\tk <- length(x);\n\tif(k == 1) {\n\t\tQ <- NA;\n\t\tqpv <- NA;\t\n\t}\n\telse {\n\t\tx.se <- x.se[cc.ix];\n\t\twi <- x.se^-2;\n\t\tQ <- sum(wi * x^2) - (sum(wi * x))^2 / sum(wi);\n\t\tqpv <- pchisq(Q, df=k-1, lower.tail=FALSE);\n\t}\n\treturn(list(\"Q\"=Q, \"p.value\"=qpv));\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the 'test.hetero.est' function in R, and what are its main inputs?",
        "answer": "The 'test.hetero.est' function is designed to perform a heterogeneity test on a set of estimates. It takes three main inputs: 'x' (a vector of estimates), 'x.se' (a vector of standard errors for the estimates), and 'na.rm' (a boolean flag to determine whether to remove NA values). The function calculates a Q statistic and its corresponding p-value to assess the heterogeneity of the estimates."
      },
      {
        "question": "How does the function handle missing values, and what happens if missing values are present when 'na.rm' is set to FALSE?",
        "answer": "The function uses 'complete.cases()' to identify non-missing values in both 'x' and 'x.se'. If any missing values are present and 'na.rm' is set to FALSE, the function will stop execution and raise an error message: 'missing values are present!'. If 'na.rm' is TRUE, the function will proceed with calculations using only the complete cases."
      },
      {
        "question": "What statistical calculations are performed when there is more than one estimate, and what do the returned values represent?",
        "answer": "When there is more than one estimate (k > 1), the function calculates a Q statistic and its p-value. The Q statistic is computed as Q = sum(wi * x^2) - (sum(wi * x))^2 / sum(wi), where wi are the inverse squared standard errors (weights). The p-value is calculated using the chi-square distribution with k-1 degrees of freedom. These values are returned as a list with keys 'Q' and 'p.value', representing the heterogeneity statistic and its significance level, respectively."
      }
    ],
    "completion_tasks": [
      {
        "partial": "function(x, x.se, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se);\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\"); }\n\tx <- x[cc.ix];\n\tk <- length(x);\n\tif(k == 1) {\n\t\tQ <- NA;\n\t\tqpv <- NA;\t\n\t}\n\telse {\n\t\tx.se <- x.se[cc.ix];\n\t\twi <- x.se^-2;\n\t\t# Calculate Q and qpv here\n\t}\n\treturn(list(\"Q\"=Q, \"p.value\"=qpv));\n}",
        "complete": "function(x, x.se, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se);\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\"); }\n\tx <- x[cc.ix];\n\tk <- length(x);\n\tif(k == 1) {\n\t\tQ <- NA;\n\t\tqpv <- NA;\t\n\t}\n\telse {\n\t\tx.se <- x.se[cc.ix];\n\t\twi <- x.se^-2;\n\t\tQ <- sum(wi * x^2) - (sum(wi * x))^2 / sum(wi);\n\t\tqpv <- pchisq(Q, df=k-1, lower.tail=FALSE);\n\t}\n\treturn(list(\"Q\"=Q, \"p.value\"=qpv));\n}"
      },
      {
        "partial": "'test.hetero.est' <-\nfunction(x, x.se, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se);\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\"); }\n\tx <- x[cc.ix];\n\tk <- length(x);\n\tif(k == 1) {\n\t\t# Handle case when k is 1\n\t}\n\telse {\n\t\tx.se <- x.se[cc.ix];\n\t\twi <- x.se^-2;\n\t\tQ <- sum(wi * x^2) - (sum(wi * x))^2 / sum(wi);\n\t\tqpv <- pchisq(Q, df=k-1, lower.tail=FALSE);\n\t}\n\treturn(list(\"Q\"=Q, \"p.value\"=qpv));\n}",
        "complete": "'test.hetero.est' <-\nfunction(x, x.se, na.rm=FALSE) {\n\tcc.ix <- complete.cases(x, x.se);\n\tif(!all(cc.ix) && !na.rm) { stop(\"missing values are present!\"); }\n\tx <- x[cc.ix];\n\tk <- length(x);\n\tif(k == 1) {\n\t\tQ <- NA;\n\t\tqpv <- NA;\n\t}\n\telse {\n\t\tx.se <- x.se[cc.ix];\n\t\twi <- x.se^-2;\n\t\tQ <- sum(wi * x^2) - (sum(wi * x))^2 / sum(wi);\n\t\tqpv <- pchisq(Q, df=k-1, lower.tail=FALSE);\n\t}\n\treturn(list(\"Q\"=Q, \"p.value\"=qpv));\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/geneDrugSensitivity.R",
    "language": "R",
    "content": "########################\n## Benjamin Haibe-Kains & Petr Smirnov\n## October 23, 2013\n########################\n\n#' @importFrom stats sd\n#' @importFrom stats complete.cases\n#' @importFrom stats lm\n#' @importFrom stats glm\n#' @importFrom stats anova\n#' @importFrom stats pf\n#' @importFrom stats formula\n#' @importFrom stats var\n#' @importFrom scales rescale\n\ngeneDrugSensitivity <- function(x, type, batch, drugpheno, interaction.typexgene=FALSE, model=FALSE,  standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n## input:\n##  x: numeric vector of gene expression values\n##  type: vector of factors specifying the cell lines or type types\n##  batch: vector of factors specifying the batch\n##  drugpheno: numeric vector of drug sensitivity values (e.g., IC50 or AUC)\n##  duration: numeric vector of experiment duration in hours\n##  interaction.typexgene: Should interaction between gene expression and cell/type type be computed? Default set to FALSE\n##  model: Should the full linear model be returned? Default set to FALSE\n##\n## output:\n##  vector reporting the effect size (estimateof the coefficient of drug concentration), standard error (se), sample size (n), t statistic, and F statistics and its corresponding p-value\n\n  standardize <- match.arg(standardize)\n\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n\n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, USE.NAMES=FALSE), check.names=FALSE,\n  FUN.VALUE=list(1))\n\n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n\n  if(length(table(drugpheno)) > 2){\n     if(ncol(drugpheno)>1){\n      ##### FIX NAMES!!!\n      rest <- lapply(seq_len(ncol(drugpheno)), function(i){\n\n        est <- paste(\"estimate\", i, sep=\".\")\n        se <-  paste(\"se\", i, sep=\".\")\n        tstat <- paste(\"tstat\", i, sep=\".\")\n\n        rest <- rep(NA, 3)\n        names(rest) <- c(est, se, tstat)\n        return(rest)\n\n      })\n      rest <- do.call(c, rest)\n      rest <- c(rest, n=nn, \"fstat\"=NA, \"pvalue\"=NA)\n    } else {\n      rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"tstat\"=NA, \"fstat\"=NA, \"pvalue\"=NA, \"df\"=NA)\n    }\n  } else {\n    rest <- c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA)\n  }\n\n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    ## not enough samples with complete information or no variation in gene expression\n    return(rest)\n  }\n\n  ## standardized coefficient in linear model\n  if(length(table(drugpheno)) > 2 & standardize!= \"none\") {\n    switch(standardize,\n      \"SD\" = drugpheno <- apply(drugpheno, 2, function(x){\n      return(x[ccix]/sd(as.numeric(x[ccix])))}) ,\n      \"rescale\" = drugpheno <- apply(drugpheno, 2, function(x){\n      return(rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE))    })\n      )\n\n  }else{\n    drugpheno <- drugpheno[ccix,,drop=FALSE]\n  }\n  if(length(table(x)) > 2  & standardize!= \"none\"){\n    switch(standardize,\n      \"SD\" = xx <- x[ccix]/sd(as.numeric(x[ccix])) ,\n      \"rescale\" = xx <- rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE)\n      )\n  }else{\n    xx <- x[ccix]\n  }\n  if(ncol(drugpheno)>1){\n    ff0 <- paste(\"cbind(\", paste(paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\"), collapse=\",\"), \")\", sep=\"\")\n  } else {\n    ff0 <- sprintf(\"drugpheno.1\")\n  }\n\n  dd <- data.frame(drugpheno, \"x\"=xx)\n\n  ## control for tissue type\n  if(length(sort(unique(type))) > 1) {\n    dd <- cbind(dd, type=type[ccix])\n  }\n  ## control for batch\n  if(length(sort(unique(batch))) > 1) {\n        dd <- cbind(dd, batch=batch[ccix])\n  }\n\n  if(any(unlist(lapply(drugpheno,is.factor)))){\n\nrr0 <- tryCatch(try(glm(formula(drugpheno.1 ~ . - x), data=dd, model=FALSE, x=FALSE, y=FALSE, family=\"binomial\")),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Null model did not convrge\"\n        message(ww)\n        if(\"type\" %in% colnames(dd)) {\n          tt <- table(dd[,\"type\"])\n          message(tt)\n        }\n      }\n    })\n  rr1 <- tryCatch(try(glm(formula(drugpheno.1 ~ .), data=dd, model=FALSE, x=FALSE, y=FALSE, family=\"binomial\")),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Model did not converge\"\n        tt <- table(dd[,\"drugpheno.1\"])\n        message(ww)\n        message(tt)\n      }\n      return(ww)\n    })\n\n\n} else{\n\nrr0 <- tryCatch(try(lm(formula(paste(ff0, \"~ . -x\", sep=\" \")), data=dd)),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Null model did not converge\"\n        message(ww)\n        if(\"type\" %in% colnames(dd)) {\n          tt <- table(dd[,\"type\"])\n          message(tt)\n        }\n      }\n    })\n  rr1 <- tryCatch(try(lm(formula(paste(ff0, \"~ . \", sep=\" \")), data=dd)),\n    warning=function(w) {\n      if(verbose) {\n        ww <- \"Model did not converge\"\n        tt <- table(dd[,\"drugpheno.1\"])\n        message(ww)\n        message(tt)\n      }\n      return(ww)\n    })\n\n\n}\n\n  ## FIXME:: Do we really want a vectorized and here?\n  if (!is(rr0, \"try-error\") && !is(rr1, \"try-error\") &\n      !is(rr0, \"character\") && !is(rr1, \"character\")) {\n    rr <- summary(rr1)\n\n    if(any(unlist(lapply(drugpheno,is.factor)))){\n      rrc <- stats::anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Estimate\"], \"se\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Std. Error\"], \"n\"=nn, \"pvalue\"=rrc$'Pr(>Chi)'[2])\n      names(rest) <- c(\"estimate\", \"se\", \"n\", \"pvalue\")\n\n    } else {\n      if(ncol(drugpheno)>1){\n        rrc <- summary(stats::manova(rr1))\n        rest <- lapply(seq_len(ncol(drugpheno)), function(i) {\n          est <- paste(\"estimate\", i, sep=\".\")\n          se <-  paste(\"se\", i, sep=\".\")\n          tstat <- paste(\"tstat\", i, sep=\".\")\n          rest <- c(rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"Estimate\"], rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"Std. Error\"], rr[[i]]$coefficients[grep(\"^x\", rownames(rr[[i]]$coefficients)), \"t value\"])\n          names(rest) <- c(est, se, tstat)\n          return(rest)\n        })\n        rest <- do.call(c, rest)\n        rest <- c(rest,\"n\"=nn, \"fstat\"=rrc$stats[grep(\"^x\", rownames(rrc$stats)), \"approx F\"], \"pvalue\"=rrc$stats[grep(\"^x\", rownames(rrc$stats)), \"Pr(>F)\"])\n      } else {\n        rrc <- stats::anova(rr0, rr1, test = \"F\")\n        rest <- c(\"estimate\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Estimate\"], \"se\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"Std. Error\"],\"n\"=nn, \"tstat\"=rr$coefficients[grep(\"^x\", rownames(rr$coefficients)), \"t value\"], \"fstat\"=rrc$F[2], \"pvalue\"=rrc$'Pr(>F)'[2], \"df\"=rr1$df.residual)\n        names(rest) <- c(\"estimate\", \"se\", \"n\", \"tstat\", \"fstat\", \"pvalue\", \"df\")\n      }\n    }\n\n    if(model) { rest <- list(\"stats\"=rest, \"model\"=rr1) }\n  }\n  return(rest)\n}",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `geneDrugSensitivity` function and what are its main input parameters?",
        "answer": "The `geneDrugSensitivity` function is designed to analyze the relationship between gene expression and drug sensitivity in cell lines. Its main input parameters are:\n- `x`: A numeric vector of gene expression values\n- `type`: A vector of factors specifying the cell lines or types\n- `batch`: A vector of factors specifying the batch\n- `drugpheno`: A numeric vector or matrix of drug sensitivity values (e.g., IC50 or AUC)\n- `interaction.typexgene`: A boolean indicating whether to compute interaction between gene expression and cell/type type\n- `model`: A boolean indicating whether to return the full linear model\n- `standardize`: A string specifying the standardization method ('SD', 'rescale', or 'none')"
      },
      {
        "question": "How does the function handle missing or infinite values in the input data?",
        "answer": "The function handles missing or infinite values in the following ways:\n1. It uses `complete.cases()` to identify rows with complete data across all input variables.\n2. Infinite values in the `drugpheno` data are replaced with NA: `x[is.infinite(x)] <- NA`\n3. The function checks if there are at least 3 samples with complete information and if there's variation in gene expression. If not, it returns a vector of NA values for the statistical results.\n4. The standardization step (if applied) is performed only on the complete cases."
      },
      {
        "question": "What statistical models does the function use, and how does it handle different types of drug phenotype data?",
        "answer": "The function uses different statistical models depending on the type of drug phenotype data:\n1. For continuous drug phenotype data, it uses linear models (`lm()`):\n   - A null model without the gene expression variable\n   - A full model including the gene expression variable\n2. For binary drug phenotype data, it uses generalized linear models with a binomial family (`glm(..., family=\"binomial\")`):\n   - A null model without the gene expression variable\n   - A full model including the gene expression variable\n3. For multiple drug phenotypes, it uses multivariate analysis of variance (MANOVA)\n\nThe function compares the null and full models using ANOVA (for continuous data) or Chi-square test (for binary data) to assess the significance of the gene expression variable. It returns various statistics including estimate, standard error, sample size, t-statistic (for single continuous phenotype), F-statistic (for continuous data), and p-value."
      }
    ],
    "completion_tasks": [
      {
        "partial": "geneDrugSensitivity <- function(x, type, batch, drugpheno, interaction.typexgene=FALSE, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, USE.NAMES=FALSE), check.names=FALSE,\n  FUN.VALUE=list(1))\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  # ... (rest of the function implementation)\n}",
        "complete": "geneDrugSensitivity <- function(x, type, batch, drugpheno, interaction.typexgene=FALSE, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) {\n      x[is.infinite(x)] <- NA\n    }\n    return(list(x))\n  }, USE.NAMES=FALSE), check.names=FALSE,\n  FUN.VALUE=list(1))\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n  }\n  \n  if(standardize != \"none\") {\n    drugpheno <- switch(standardize,\n      \"SD\" = apply(drugpheno, 2, function(x) x[ccix]/sd(as.numeric(x[ccix]))),\n      \"rescale\" = apply(drugpheno, 2, function(x) rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE))\n    )\n    xx <- switch(standardize,\n      \"SD\" = x[ccix]/sd(as.numeric(x[ccix])),\n      \"rescale\" = rescale(as.numeric(x[ccix]), q=0.05, na.rm=TRUE)\n    )\n  } else {\n    drugpheno <- drugpheno[ccix,,drop=FALSE]\n    xx <- x[ccix]\n  }\n  \n  dd <- data.frame(drugpheno, \"x\"=xx)\n  if(length(unique(type)) > 1) dd$type <- type[ccix]\n  if(length(unique(batch)) > 1) dd$batch <- batch[ccix]\n  \n  ff0 <- if(ncol(drugpheno) > 1) paste(\"cbind(\", paste(colnames(drugpheno), collapse=\",\"), \")\") else \"drugpheno.1\"\n  \n  model_func <- if(any(sapply(drugpheno, is.factor))) glm else lm\n  family <- if(any(sapply(drugpheno, is.factor))) \"binomial\" else NULL\n  \n  rr0 <- tryCatch(model_func(formula(paste(ff0, \"~ . -x\")), data=dd, family=family), error=function(e) e)\n  rr1 <- tryCatch(model_func(formula(paste(ff0, \"~ .\")), data=dd, family=family), error=function(e) e)\n  \n  if(!inherits(rr0, \"error\") && !inherits(rr1, \"error\")) {\n    rr <- summary(rr1)\n    if(any(sapply(drugpheno, is.factor))) {\n      rrc <- anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"pvalue\"=rrc$'Pr(>Chi)'[2])\n    } else {\n      if(ncol(drugpheno) > 1) {\n        rrc <- summary(manova(rr1))\n        rest <- c(sapply(rr, function(r) c(r$coefficients[\"x\", c(\"Estimate\", \"Std. Error\", \"t value\")])), \"n\"=nn, \"fstat\"=rrc$stats[\"x\", \"approx F\"], \"pvalue\"=rrc$stats[\"x\", \"Pr(>F)\"])\n      } else {\n        rrc <- anova(rr0, rr1, test=\"F\")\n        rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"tstat\"=rr$coefficients[\"x\", \"t value\"], \"fstat\"=rrc$F[2], \"pvalue\"=rrc$'Pr(>F)'[2], \"df\"=rr1$df.residual)\n      }\n    }\n    if(model) rest <- list(\"stats\"=rest, \"model\"=rr1)\n    return(rest)\n  }\n  return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n}"
      },
      {
        "partial": "geneDrugSensitivity <- function(x, type, batch, drugpheno, interaction.typexgene=FALSE, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  # Function implementation\n  \n  # ... (previous code)\n  \n  if(standardize != \"none\") {\n    # Standardize drugpheno and x\n  }\n  \n  dd <- data.frame(drugpheno, \"x\"=xx)\n  if(length(unique(type)) > 1) dd$type <- type[ccix]\n  if(length(unique(batch)) > 1) dd$batch <- batch[ccix]\n  \n  # ... (rest of the function implementation)\n}",
        "complete": "geneDrugSensitivity <- function(x, type, batch, drugpheno, interaction.typexgene=FALSE, model=FALSE, standardize=c(\"SD\", \"rescale\", \"none\"), verbose=FALSE) {\n  standardize <- match.arg(standardize)\n  colnames(drugpheno) <- paste(\"drugpheno\", seq_len(ncol(drugpheno)), sep=\".\")\n  \n  drugpheno <- data.frame(vapply(drugpheno, function(x) {\n    if (!is.factor(x)) x[is.infinite(x)] <- NA\n    list(x)\n  }, USE.NAMES=FALSE), check.names=FALSE, FUN.VALUE=list(1))\n  \n  ccix <- complete.cases(x, type, batch, drugpheno)\n  nn <- sum(ccix)\n  \n  if(nn < 3 || var(x[ccix], na.rm=TRUE) == 0) {\n    return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n  }\n  \n  if(standardize != \"none\") {\n    standardize_func <- switch(standardize,\n      \"SD\" = function(x) x / sd(as.numeric(x), na.rm=TRUE),\n      \"rescale\" = function(x) rescale(as.numeric(x), q=0.05, na.rm=TRUE)\n    )\n    drugpheno <- as.data.frame(lapply(drugpheno[ccix,], standardize_func))\n    xx <- standardize_func(x[ccix])\n  } else {\n    drugpheno <- drugpheno[ccix,, drop=FALSE]\n    xx <- x[ccix]\n  }\n  \n  dd <- data.frame(drugpheno, \"x\"=xx)\n  if(length(unique(type)) > 1) dd$type <- type[ccix]\n  if(length(unique(batch)) > 1) dd$batch <- batch[ccix]\n  \n  ff0 <- if(ncol(drugpheno) > 1) paste(\"cbind(\", paste(colnames(drugpheno), collapse=\",\"), \")\") else \"drugpheno.1\"\n  \n  model_func <- if(any(sapply(drugpheno, is.factor))) glm else lm\n  family <- if(any(sapply(drugpheno, is.factor))) \"binomial\" else NULL\n  \n  rr0 <- tryCatch(model_func(formula(paste(ff0, \"~ . -x\")), data=dd, family=family), error=function(e) e)\n  rr1 <- tryCatch(model_func(formula(paste(ff0, \"~ .\")), data=dd, family=family), error=function(e) e)\n  \n  if(!inherits(rr0, \"error\") && !inherits(rr1, \"error\")) {\n    rr <- summary(rr1)\n    if(any(sapply(drugpheno, is.factor))) {\n      rrc <- anova(rr0, rr1, test=\"Chisq\")\n      rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"pvalue\"=rrc$'Pr(>Chi)'[2])\n    } else {\n      if(ncol(drugpheno) > 1) {\n        rrc <- summary(manova(rr1))\n        rest <- c(sapply(rr, function(r) c(r$coefficients[\"x\", c(\"Estimate\", \"Std. Error\", \"t value\")])), \"n\"=nn, \"fstat\"=rrc$stats[\"x\", \"approx F\"], \"pvalue\"=rrc$stats[\"x\", \"Pr(>F)\"])\n      } else {\n        rrc <- anova(rr0, rr1, test=\"F\")\n        rest <- c(\"estimate\"=rr$coefficients[\"x\", \"Estimate\"], \"se\"=rr$coefficients[\"x\", \"Std. Error\"], \"n\"=nn, \"tstat\"=rr$coefficients[\"x\", \"t value\"], \"fstat\"=rrc$F[2], \"pvalue\"=rrc$'Pr(>F)'[2], \"df\"=rr1$df.residual)\n      }\n    }\n    if(model) rest <- list(\"stats\"=rest, \"model\"=rr1)\n    return(rest)\n  }\n  return(c(\"estimate\"=NA, \"se\"=NA, \"n\"=nn, \"pvalue\"=NA))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/survcomp.git",
    "file": "../../../../repos/survcomp/R/cindex.comp.R",
    "language": "R",
    "content": "`cindex.comp` <-\nfunction(cindex1, cindex2) {\n\n\tif(cindex1$n != cindex2$n) { stop(\"the concordance indices are computed from different number of samples!\") }\n\tif(is.na(cindex1$se) || is.na(cindex2$se)){stop(\"the concordance indices must be computed using method noether!\")}\n\teps <- 1E-15\n\t\n\tn <- cindex1$n\n\tr <- cor(cindex1$data$x, cindex2$data$x, use=\"complete.obs\", method=\"spearman\")\n\tif((1 - abs(r)) > eps) {\n\t\tt.stat <- (cindex1$c.index - cindex2$c.index) / sqrt(cindex1$se^2 + cindex2$se^2 - 2 * r * cindex1$se * cindex2$se)\n\t\tdiff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n\t} else { diff.ci.p <- 1 }\n\treturn(list(\"p.value\"=diff.ci.p, \"cindex1\"=cindex1$c.index, \"cindex2\"=cindex2$c.index))\n}\n\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `cindex.comp` function and what are its main inputs?",
        "answer": "The `cindex.comp` function is designed to compare two concordance indices. It takes two main inputs: `cindex1` and `cindex2`, which are expected to be objects containing concordance index information, including the number of samples (n), standard error (se), and the actual concordance index value (c.index)."
      },
      {
        "question": "How does the function handle potential errors or invalid inputs?",
        "answer": "The function includes error checking at the beginning. It stops execution with an error message if: 1) The number of samples (n) in cindex1 and cindex2 are not equal, or 2) If either of the standard errors (se) for cindex1 or cindex2 is NA. This ensures that the inputs are valid and comparable before proceeding with the calculations."
      },
      {
        "question": "What statistical method is used to compare the two concordance indices, and what does the function return?",
        "answer": "The function uses a t-statistic to compare the two concordance indices. It calculates the Spearman correlation between the data of the two indices and uses this in the t-statistic calculation if the correlation is not too close to 1 or -1. The function returns a list containing three elements: the p-value of the difference between the indices, and the individual c.index values from cindex1 and cindex2."
      }
    ],
    "completion_tasks": [
      {
        "partial": "cindex.comp <- function(cindex1, cindex2) {\n  if(cindex1$n != cindex2$n) { stop(\"the concordance indices are computed from different number of samples!\") }\n  if(is.na(cindex1$se) || is.na(cindex2$se)) { stop(\"the concordance indices must be computed using method noether!\") }\n  eps <- 1E-15\n  n <- cindex1$n\n  r <- cor(cindex1$data$x, cindex2$data$x, use=\"complete.obs\", method=\"spearman\")\n  if((1 - abs(r)) > eps) {\n    t.stat <- (cindex1$c.index - cindex2$c.index) / sqrt(cindex1$se^2 + cindex2$se^2 - 2 * r * cindex1$se * cindex2$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  # Complete the return statement\n}",
        "complete": "cindex.comp <- function(cindex1, cindex2) {\n  if(cindex1$n != cindex2$n) { stop(\"the concordance indices are computed from different number of samples!\") }\n  if(is.na(cindex1$se) || is.na(cindex2$se)) { stop(\"the concordance indices must be computed using method noether!\") }\n  eps <- 1E-15\n  n <- cindex1$n\n  r <- cor(cindex1$data$x, cindex2$data$x, use=\"complete.obs\", method=\"spearman\")\n  if((1 - abs(r)) > eps) {\n    t.stat <- (cindex1$c.index - cindex2$c.index) / sqrt(cindex1$se^2 + cindex2$se^2 - 2 * r * cindex1$se * cindex2$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"cindex1\"=cindex1$c.index, \"cindex2\"=cindex2$c.index))\n}"
      },
      {
        "partial": "cindex.comp <- function(cindex1, cindex2) {\n  # Add input validation\n\n  eps <- 1E-15\n  n <- cindex1$n\n  r <- cor(cindex1$data$x, cindex2$data$x, use=\"complete.obs\", method=\"spearman\")\n  if((1 - abs(r)) > eps) {\n    t.stat <- (cindex1$c.index - cindex2$c.index) / sqrt(cindex1$se^2 + cindex2$se^2 - 2 * r * cindex1$se * cindex2$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"cindex1\"=cindex1$c.index, \"cindex2\"=cindex2$c.index))\n}",
        "complete": "cindex.comp <- function(cindex1, cindex2) {\n  if(cindex1$n != cindex2$n) { stop(\"the concordance indices are computed from different number of samples!\") }\n  if(is.na(cindex1$se) || is.na(cindex2$se)) { stop(\"the concordance indices must be computed using method noether!\") }\n  eps <- 1E-15\n  n <- cindex1$n\n  r <- cor(cindex1$data$x, cindex2$data$x, use=\"complete.obs\", method=\"spearman\")\n  if((1 - abs(r)) > eps) {\n    t.stat <- (cindex1$c.index - cindex2$c.index) / sqrt(cindex1$se^2 + cindex2$se^2 - 2 * r * cindex1$se * cindex2$se)\n    diff.ci.p <- pt(q=t.stat, df=n - 1, lower.tail=FALSE)\n  } else { diff.ci.p <- 1 }\n  return(list(\"p.value\"=diff.ci.p, \"cindex1\"=cindex1$c.index, \"cindex2\"=cindex2$c.index))\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  },
  {
    "repo": "https://github.com/bhklab/ToxicoGx.git",
    "file": "../../../../repos/ToxicoGx/R/paramMissingHandler.R",
    "language": "R",
    "content": "# A Handler to Assign Default Values for Missing Parameters\n#\n# This function will take in the params of a function as well as its name.\n#   Missing values will then be assigned to a list, which will be used to\n#   populate the parent functions scope with the correct default argument for\n#   each missing parameter\n#\n# @param funName \\code{character} A string of the function name. This argument is\n#   used to match the correct parameter checking conditions with each functionss\n# @param ... \\code{pairlist} A list of all parameters passed as arguements to the\n#   function \"funName\".\n#\n# @return \\code{list} A list of all missing parameter argument values, named\n#    with the respective missing parameters,\n#\n#' @importFrom CoreGx .message .warning .error\n#' @keywords internal\nparamMissingHandler <- function(funName, tSet, mDataType, ...) {\n\n  ## Errors if tSet parameter not passed an argument\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  }\n\n  ## Errors if mDataType parameter not passed an argument\n  if (missing(mDataType)) {\n    if (funName == \"summarizeSensitivityProfiles\" | funName == \"subsetTo\") {\n      mDataType <- names(molecularProfilesSlot(tSet))\n    } else {\n      stop(paste0(funName, \" requires an mDataType argument!\"))\n    }\n  }\n\n  ## Interection of missing values for similar functions\n  intersectMissingChecks <- c(\n    \"cell_lines\", \"drugs\"\n  )\n\n  missingChecks <-\n    switch(funName,\n           \"summarizeMolecularProfiles\" =\n             c(intersectMissingChecks,\n               \"features\", \"durations\"\n             ),\n           \"summarizeSensitivityProfiles\" =\n             c(intersectMissingChecks,\n              \"duration\"\n              ),\n           \"drugPerturbationSig\" =\n             c(intersectMissingChecks,\n               \"features\", \"durations\", \"dose\"\n               ),\n           \"subsetTo\" =\n             c(intersectMissingChecks,\n              \"features\", \"durations\", \"dose\"\n             ),\n    )\n\n  # Assigns values for missing parameters and throws warnings\n  return(\n    .checkParamsForMissing(funName = funName, tSet = tSet, mDataType = mDataType,\n        missingChecks = missingChecks, ...)\n  )\n}\n\n#' @importFrom CoreGx .message\n#' @keywords internal\n.checkParamsForMissing <- function(\n  funName = funName, tSet = tSet, missingChecks, mDataType, ...) {\n  # Initialize variable names in the local environment\n  cell_lines <- duration <- drugs <- features <- dose <- NULL\n  # Extract named arguments into local environment\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) { ## TODO:: Make this work with seq_along()\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n  # Prealocate memory for returned list, this speeds up execution as R is bad\n  # at dynamic memory allocation\n  missingParamValues <- list()\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {if (is.null(cell_lines)) { missingParamValues[[missing]] <- unique(sampleNames(tSet));\n        .message(paste0(missing, \" parameter not specified, defaults to all cell lines in the given tSet!\"))}\n        },\n      \"drugs\" = {if (is.null(drugs)) { missingParamValues[[missing]] <- unique(treatmentNames(tSet));\n        .message(paste0(missing, \" parameter not specified, defaults to all drugs in the given tSet!\"))}\n        },\n      \"features\" = {if (is.null(features)) {missingParamValues[[missing]] <- unique(fNames(tSet, mDataType[1]));\n        .message(paste0(missing, \" parameter not specified, defaults to all features in the given tSet for the specified mDataType!\"))}\n        },\n      \"durations\" = {if (is.null(duration)) {missingParamValues[[missing]] <- unique(as.character(ToxicoGx::sensitivityInfo(tSet)$duration_h));\n      .message(paste0(missing, \" parameter not specified, defaults to all experimental durations in given tSet!\"))}\n        },\n      \"duration\" = {if (is.null(duration)) {missingParamValues[[missing]] <- unique(as.character(ToxicoGx::sensitivityInfo(tSet)$duration_h))[1];\n      .message(paste0(missing, \" parameter not specified, defaults to \", missingParamValues[[missing]]))}\n      },\n      \"dose\" = {if (is.null(dose)) {missingParamValues[[missing]] <- unique(phenoInfo(tSet, mDataType)$dose_level);\n      .message(paste0(missing, \" parameter not specified, defaults to all dose levels in the given tSet for the specified mDataType!\"))}}\n    )\n  }\n  return(missingParamValues)\n}\n",
    "qa_pairs": [
      {
        "question": "What is the purpose of the `paramMissingHandler` function and how does it handle missing parameters?",
        "answer": "The `paramMissingHandler` function is designed to assign default values for missing parameters in other functions. It takes the function name, a `tSet` object, an `mDataType`, and additional parameters. It checks for missing required parameters (`tSet` and `mDataType`), determines which parameters to check based on the function name, and then calls `.checkParamsForMissing` to assign default values for any missing optional parameters. It returns a list of default values for missing parameters, which can be used to populate the parent function's scope."
      },
      {
        "question": "How does the `switch` statement in the `paramMissingHandler` function work, and what is its purpose?",
        "answer": "The `switch` statement in `paramMissingHandler` is used to determine which parameters should be checked for missing values based on the input `funName`. It defines a list of `missingChecks` for each supported function (e.g., 'summarizeMolecularProfiles', 'summarizeSensitivityProfiles', etc.). The `intersectMissingChecks` variable contains common parameters checked across multiple functions. This approach allows the function to flexibly handle different parameter sets for various functions, ensuring that only relevant parameters are checked and assigned default values if missing."
      },
      {
        "question": "Explain the purpose and functionality of the `.checkParamsForMissing` function.",
        "answer": "The `.checkParamsForMissing` function is an internal helper function that performs the actual checking and assignment of default values for missing parameters. It takes the function name, `tSet` object, `mDataType`, a list of parameters to check (`missingChecks`), and additional arguments. The function iterates through the `missingChecks` list, using a `switch` statement to handle each potential missing parameter. For each missing parameter, it assigns an appropriate default value (usually based on the `tSet` object) and adds a message to inform the user about the default assignment. The function returns a list of default values for all missing parameters, which can then be used in the calling function."
      }
    ],
    "completion_tasks": [
      {
        "partial": "paramMissingHandler <- function(funName, tSet, mDataType, ...) {\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  }\n\n  if (missing(mDataType)) {\n    if (funName == \"summarizeSensitivityProfiles\" | funName == \"subsetTo\") {\n      mDataType <- names(molecularProfilesSlot(tSet))\n    } else {\n      stop(paste0(funName, \" requires an mDataType argument!\"))\n    }\n  }\n\n  intersectMissingChecks <- c(\"cell_lines\", \"drugs\")\n\n  missingChecks <- switch(funName,\n    \"summarizeMolecularProfiles\" = c(intersectMissingChecks, \"features\", \"durations\"),\n    \"summarizeSensitivityProfiles\" = c(intersectMissingChecks, \"duration\"),\n    \"drugPerturbationSig\" = c(intersectMissingChecks, \"features\", \"durations\", \"dose\"),\n    \"subsetTo\" = c(intersectMissingChecks, \"features\", \"durations\", \"dose\")\n  )\n\n  return(\n    # Complete the function call\n  )\n}",
        "complete": "paramMissingHandler <- function(funName, tSet, mDataType, ...) {\n  if (missing(tSet)) {\n    stop(paste0(funName, \" requires a tSet argument!\"))\n  }\n\n  if (missing(mDataType)) {\n    if (funName == \"summarizeSensitivityProfiles\" | funName == \"subsetTo\") {\n      mDataType <- names(molecularProfilesSlot(tSet))\n    } else {\n      stop(paste0(funName, \" requires an mDataType argument!\"))\n    }\n  }\n\n  intersectMissingChecks <- c(\"cell_lines\", \"drugs\")\n\n  missingChecks <- switch(funName,\n    \"summarizeMolecularProfiles\" = c(intersectMissingChecks, \"features\", \"durations\"),\n    \"summarizeSensitivityProfiles\" = c(intersectMissingChecks, \"duration\"),\n    \"drugPerturbationSig\" = c(intersectMissingChecks, \"features\", \"durations\", \"dose\"),\n    \"subsetTo\" = c(intersectMissingChecks, \"features\", \"durations\", \"dose\")\n  )\n\n  return(\n    .checkParamsForMissing(funName = funName, tSet = tSet, mDataType = mDataType,\n        missingChecks = missingChecks, ...)\n  )\n}"
      },
      {
        "partial": ".checkParamsForMissing <- function(funName, tSet, missingChecks, mDataType, ...) {\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) {\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n  missingParamValues <- list()\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {\n        # Complete the cell_lines case\n      },\n      \"drugs\" = {\n        # Complete the drugs case\n      },\n      \"features\" = {\n        # Complete the features case\n      },\n      \"durations\" = {\n        # Complete the durations case\n      },\n      \"duration\" = {\n        # Complete the duration case\n      },\n      \"dose\" = {\n        # Complete the dose case\n      }\n    )\n  }\n  return(missingParamValues)\n}",
        "complete": ".checkParamsForMissing <- function(funName, tSet, missingChecks, mDataType, ...) {\n  argList <- list(...)\n  for (idx in seq_len(length(argList))) {\n    assign(names(argList)[idx], argList[[idx]])\n  }\n\n  missingParamValues <- list()\n\n  for (missing in missingChecks) {\n    switch(\n      missing,\n      \"cell_lines\" = {\n        if (is.null(cell_lines)) {\n          missingParamValues[[missing]] <- unique(sampleNames(tSet))\n          .message(paste0(missing, \" parameter not specified, defaults to all cell lines in the given tSet!\"))\n        }\n      },\n      \"drugs\" = {\n        if (is.null(drugs)) {\n          missingParamValues[[missing]] <- unique(treatmentNames(tSet))\n          .message(paste0(missing, \" parameter not specified, defaults to all drugs in the given tSet!\"))\n        }\n      },\n      \"features\" = {\n        if (is.null(features)) {\n          missingParamValues[[missing]] <- unique(fNames(tSet, mDataType[1]))\n          .message(paste0(missing, \" parameter not specified, defaults to all features in the given tSet for the specified mDataType!\"))\n        }\n      },\n      \"durations\" = {\n        if (is.null(duration)) {\n          missingParamValues[[missing]] <- unique(as.character(ToxicoGx::sensitivityInfo(tSet)$duration_h))\n          .message(paste0(missing, \" parameter not specified, defaults to all experimental durations in given tSet!\"))\n        }\n      },\n      \"duration\" = {\n        if (is.null(duration)) {\n          missingParamValues[[missing]] <- unique(as.character(ToxicoGx::sensitivityInfo(tSet)$duration_h))[1]\n          .message(paste0(missing, \" parameter not specified, defaults to \", missingParamValues[[missing]]))\n        }\n      },\n      \"dose\" = {\n        if (is.null(dose)) {\n          missingParamValues[[missing]] <- unique(phenoInfo(tSet, mDataType)$dose_level)\n          .message(paste0(missing, \" parameter not specified, defaults to all dose levels in the given tSet for the specified mDataType!\"))\n        }\n      }\n    )\n  }\n  return(missingParamValues)\n}"
      }
    ],
    "dependencies": {
      "imports": [],
      "from_imports": []
    },
    "project_dependencies": []
  }
]